<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>sylvia</title>
  
  <subtitle>Viva La Vida</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://janvia.github.io/"/>
  <updated>2019-01-25T09:15:12.959Z</updated>
  <id>https://janvia.github.io/</id>
  
  <author>
    <name>sylvia</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>语义分割</title>
    <link href="https://janvia.github.io/2019/01/25/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>https://janvia.github.io/2019/01/25/语义分割/</id>
    <published>2019-01-25T08:59:31.000Z</published>
    <updated>2019-01-25T09:15:12.959Z</updated>
    
    <content type="html"><![CDATA[<h3 id="语义分割-semantic-segmentation"><a href="#语义分割-semantic-segmentation" class="headerlink" title="语义分割 semantic segmentation"></a>语义分割 semantic segmentation</h3><h4 id="Pascal-VOC"><a href="#Pascal-VOC" class="headerlink" title="Pascal VOC"></a>Pascal VOC</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_001.png" alt=""></p><h4 id="CityScapes"><a href="#CityScapes" class="headerlink" title="CityScapes"></a>CityScapes</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_002.png" alt=""></p><h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><p>Pascal VOC 2012：<br>        <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/" target="_blank" rel="noopener">http://host.robots.ox.ac.uk/pascal/VOC/voc2012/</a><br>        <a href="https://www.dropbox.com/s/oeu149j8qtbs1x0/SegmentationClassAug.zip?dl=0" target="_blank" rel="noopener">https://www.dropbox.com/s/oeu149j8qtbs1x0/SegmentationClassAug.zip?dl=0</a></p><p>Paper：<br>        <a href="https://arxiv.org/pdf/1706.05587.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1706.05587.pdf</a><br>Source Code：<br>        <a href="https://github.com/NanqingD/DeepLabV3-Tensorflow" target="_blank" rel="noopener">https://github.com/NanqingD/DeepLabV3-Tensorflow</a></p><h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><h4 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_008.png" alt=""></p><h4 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_003.png" alt=""></p><p>Image Source: <a href="https://skymind.ai/wiki/convolutional-network" target="_blank" rel="noopener">https://skymind.ai/wiki/convolutional-network</a></p><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h4 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p>Graph and Session：<br>        Tensorflow separates definition of computations from their execution</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_004.png" alt=""></p><h3 id="DeepLab"><a href="#DeepLab" class="headerlink" title="DeepLab"></a>DeepLab</h3><h4 id="Atrous-Convolution"><a href="#Atrous-Convolution" class="headerlink" title="Atrous Convolution"></a>Atrous Convolution</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_005.png" alt=""></p><h4 id="Residual-Unit"><a href="#Residual-Unit" class="headerlink" title="Residual Unit"></a>Residual Unit</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_006.png" alt=""></p><h4 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/语义分割_007.png" alt=""></p><p>​        Softmax Loss Function</p><script type="math/tex; mode=display">H(y,p)=-\sum_iy_ilog(p_i)</script><p>​        Data Preprocessing<br>​        Train/Evaluation<br>​        Finetuning</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;语义分割-semantic-segmentation&quot;&gt;&lt;a href=&quot;#语义分割-semantic-segmentation&quot; class=&quot;headerlink&quot; title=&quot;语义分割 semantic segmentation&quot;&gt;&lt;/a&gt;语义分割 sem
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="语义分割" scheme="https://janvia.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>pandas</title>
    <link href="https://janvia.github.io/2019/01/25/pandas/"/>
    <id>https://janvia.github.io/2019/01/25/pandas/</id>
    <published>2019-01-25T00:43:41.000Z</published>
    <updated>2019-01-25T05:56:08.474Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Series对象"><a href="#Series对象" class="headerlink" title="Series对象"></a>Series对象</h2><p>pandas库的Series对象用来表示一维数据结构，跟数组类似，但多了一些额外的功能，它的内部结构很简单(如下表)，由两个相互关联的数组组成，其中主数组用于存放数据（Numpy任意类型数据）。主数组的每个元素都有一个与之相关联的标签，这些标签存储的另一个叫做Index的数组中。</p><p>|Series| -|- index|value 0|12 1|-4 2|7 3|9</p><p>In:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = pd.Series([<span class="number">12</span>,<span class="number">-4</span>,<span class="number">7</span>,<span class="number">9</span>])</span><br><span class="line">s</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    12</span><br><span class="line">1    -4</span><br><span class="line">2     7</span><br><span class="line">3     9</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>可以看出左侧Index是一列标签，右侧是标签对应的元素</p><p>声明Series时，若不指定标签，pandas默认使用从0开始一次递增的数值作为标签。这种情况下，标签与Series对象中的元素索引一致。但是最好使用有意义的标签，用以区分和识别每个元素</p><p>in:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = pd.Series([<span class="number">12</span>,<span class="number">-4</span>,<span class="number">7</span>,<span class="number">9</span>],index=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>])</span><br><span class="line">s</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    12</span><br><span class="line">b    -4</span><br><span class="line">c     7</span><br><span class="line">d     9</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h3 id="获取元素"><a href="#获取元素" class="headerlink" title="获取元素"></a>获取元素</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s.values</span><br></pre></td></tr></table></figure><p>array([12, -4,  7,  9], dtype=int64)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s.index</span><br></pre></td></tr></table></figure><p>Index([‘a’, ‘b’, ‘c’, ‘d’], dtype=’object’)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[2]</span><br></pre></td></tr></table></figure><ul><li>7</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[&apos;c&apos;]</span><br></pre></td></tr></table></figure><ul><li>7</li></ul><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[:2]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    12</span><br><span class="line">b    -4</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[[&apos;b&apos;,&apos;c&apos;]]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">b   -4</span><br><span class="line">c    7</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h3 id="为元素赋值"><a href="#为元素赋值" class="headerlink" title="为元素赋值"></a>为元素赋值</h3><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[1]=0</span><br><span class="line">s</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    12</span><br><span class="line">b     0</span><br><span class="line">c     7</span><br><span class="line">d     9</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[&apos;b&apos;] = 1</span><br><span class="line">s</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    12</span><br><span class="line">b     1</span><br><span class="line">c     7</span><br><span class="line">d     9</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h3 id="用Numpy数组或其他Series对象定义新Series对象"><a href="#用Numpy数组或其他Series对象定义新Series对象" class="headerlink" title="用Numpy数组或其他Series对象定义新Series对象"></a>用Numpy数组或其他Series对象定义新Series对象</h3><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.array([1,2,3,4])</span><br><span class="line">b= pd.Series(a)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1</span><br><span class="line">1    2</span><br><span class="line">2    3</span><br><span class="line">3    4</span><br><span class="line">dtype: int32</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c= pd.Series(b)</span><br><span class="line">c</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1</span><br><span class="line">1    2</span><br><span class="line">2    3</span><br><span class="line">3    4</span><br><span class="line">dtype: int32</span><br></pre></td></tr></table></figure><p>这样做时不要忘记新Series对象中的元素不是原Num数组或Series对象的副本，而是对他们的引用，也就是说，这些对象是动态插入到新Series对象中。如改变原有对象元素的值，新Series对象中这些元素也会发生改变。</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">b[2]=11</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0     1</span><br><span class="line">1     2</span><br><span class="line">2    11</span><br><span class="line">3     4</span><br><span class="line">dtype: int32</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0     1</span><br><span class="line">1     2</span><br><span class="line">2    11</span><br><span class="line">3     4</span><br><span class="line">dtype: int32</span><br></pre></td></tr></table></figure><h3 id="筛选元素"><a href="#筛选元素" class="headerlink" title="筛选元素"></a>筛选元素</h3><p>pandas库的开发是以NumPy库为基础的，因此就数据结构而言，NumPy数组的多种操作方法得以扩展到Series对象中，其中就是根据条件筛选数据结构中的元素之一方法。</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[s&gt;8]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    12</span><br><span class="line">d     9</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h3 id="运算和数学函数"><a href="#运算和数学函数" class="headerlink" title="运算和数学函数"></a>运算和数学函数</h3><p>适用于NumPy数组的运算符（+，-，* ，/ ）或其他数学函数，也适用于Series对象。</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s / 2</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    6.0</span><br><span class="line">b    0.5</span><br><span class="line">c    3.5</span><br><span class="line">d    4.5</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    12</span><br><span class="line">b     1</span><br><span class="line">c     7</span><br><span class="line">d     9</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>NumPy库的数学函数，必须制定他们出处np,并把Series实例作为参数传入。</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.log(s)</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a    2.484907</span><br><span class="line">b    0.000000</span><br><span class="line">c    1.945910</span><br><span class="line">d    2.197225</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h3 id="Series对象的组成元素"><a href="#Series对象的组成元素" class="headerlink" title="Series对象的组成元素"></a>Series对象的组成元素</h3><p>in:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">color = pd.Series([<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],index=[<span class="string">'white'</span>,<span class="string">'white'</span>,<span class="string">'blue'</span>,<span class="string">'green'</span>,<span class="string">'green'</span>,<span class="string">'yellow'</span>])</span><br><span class="line">color</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">white     1</span><br><span class="line">white     0</span><br><span class="line">blue      2</span><br><span class="line">green     1</span><br><span class="line">green     2</span><br><span class="line">yellow    3</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">color.unique()</span><br></pre></td></tr></table></figure><p>array([1, 0, 2, 3], dtype=int64)</p><p>返回一个数组，包含去重后的元素，但乱序</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">color.value_counts()</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2    2</span><br><span class="line">1    2</span><br><span class="line">3    1</span><br><span class="line">0    1</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>返回各个不同的元素，还计算每个元素在Series中出现次数</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">color.isin([0,3])</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">white     False</span><br><span class="line">white      True</span><br><span class="line">blue      False</span><br><span class="line">green     False</span><br><span class="line">green     False</span><br><span class="line">yellow     True</span><br><span class="line">dtype: bool</span><br></pre></td></tr></table></figure><p>判断给定的一列元素是否包含在数据结构中,返回布尔值</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">color[color.isin([0,3])]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">white     0</span><br><span class="line">yellow    3</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h3 id="NaN"><a href="#NaN" class="headerlink" title="NaN"></a>NaN</h3><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s = pd.Series([1,2,np.NaN,14])</span><br><span class="line">s</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0     1.0</span><br><span class="line">1     2.0</span><br><span class="line">2     NaN</span><br><span class="line">3    14.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s.isnull()</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    False</span><br><span class="line">1    False</span><br><span class="line">2     True</span><br><span class="line">3    False</span><br><span class="line">dtype: bool</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s.notnull()</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0     True</span><br><span class="line">1     True</span><br><span class="line">2    False</span><br><span class="line">3     True</span><br><span class="line">dtype: bool</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[s.notnull()]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0     1.0</span><br><span class="line">1     2.0</span><br><span class="line">3    14.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s[s.isnull()]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2   NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h3 id="Series用作字典"><a href="#Series用作字典" class="headerlink" title="Series用作字典"></a>Series用作字典</h3><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mydict = &#123;&apos;red&apos;:2000,&apos;blue&apos;:1000,&apos;yellow&apos;:500,&apos;orange&apos;:1000&#125;</span><br><span class="line">myseries = pd.Series(mydict)</span><br><span class="line">myseries</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blue      1000</span><br><span class="line">orange    1000</span><br><span class="line">red       2000</span><br><span class="line">yellow     500</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>索引数组用字典的键来填充，每个索引所对应的元素为用作索引的键在字典中对应的值。你还可以单独制定索引，pandas会控制字典的键和数组索引标签之间的相关性。如遇缺失值处，pandas就会为其添加NaN。</p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">colors = [&apos;red&apos;,&apos;yellow&apos;,&apos;orange&apos;,&apos;blue&apos;,&apos;green&apos;]</span><br><span class="line">myseries = pd.Series(mydict,index =colors)</span><br><span class="line">myseries</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       2000.0</span><br><span class="line">yellow     500.0</span><br><span class="line">orange    1000.0</span><br><span class="line">blue      1000.0</span><br><span class="line">green        NaN</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h3 id="Series-对象之间的运算"><a href="#Series-对象之间的运算" class="headerlink" title="Series 对象之间的运算"></a>Series 对象之间的运算</h3><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mydict = &#123;&apos;red&apos;:200,&apos;blue&apos;:100,&apos;yellow&apos;:50,&apos;orange&apos;:100,&apos;black&apos;:700&#125;</span><br><span class="line">myseries2 = pd.Series(mydict)</span><br><span class="line">myseries2</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">black     700</span><br><span class="line">blue      100</span><br><span class="line">orange    100</span><br><span class="line">red       200</span><br><span class="line">yellow     50</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myseries + myseries2</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">black        NaN</span><br><span class="line">blue      1100.0</span><br><span class="line">green        NaN</span><br><span class="line">orange    1100.0</span><br><span class="line">red       2200.0</span><br><span class="line">yellow     550.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h2 id="DataFrame对象"><a href="#DataFrame对象" class="headerlink" title="DataFrame对象"></a>DataFrame对象</h2><p>DataFrame这种列表式数据结构跟工作表（最常见的是Excel工作表）极为相似，其设计初衷是将Series的使用场景由一维扩展到多维。DataFrame由按一定顺序排列的多列数据组成，各列数据类型可以有不同。</p><h3 id="定义DataFrame对象"><a href="#定义DataFrame对象" class="headerlink" title="定义DataFrame对象"></a>定义DataFrame对象</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data = &#123;&apos;color&apos;:[&apos;blue&apos;,&apos;green&apos;,&apos;yellow&apos;,&apos;red&apos;,&apos;white&apos;],&apos;object&apos;:[&apos;ball&apos;,&apos;pen&apos;,&apos;pecil&apos;,&apos;paper&apos;,&apos;mug&apos;],&apos;price&apos;:[1.2,1.0,0.6,0.9,1.7]&#125;</span><br><span class="line">frame = pd.DataFrame(data)</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_001.png" alt=""></p><p>如果用来创建DataFrame对象的dict对象包含一些用不到的数据，你可以只选择自己感兴趣的。在DataFrame构造函数中，用columns选项制定需要的列即可。新建的DataFrame各列顺序与你制定的列顺序一致，而与他们在字典中的顺序无关。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2 = pd.DataFrame(data,columns=[&apos;object&apos;,&apos;price&apos;])</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_002.png" alt=""></p><p>DataFrame对象和Series一样，如果Index数组没有明确制定标签，pandas也会自动为其添加一列从0开始的数值作为索引。如果想用标签作为DataFrame的索引，则要把标签放在数组中，赋给index选项</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3 = pd.DataFrame(data,index=[&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;,&apos;five&apos;])</span><br><span class="line">frame3</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_003.png" alt=""></p><h3 id="选取元素"><a href="#选取元素" class="headerlink" title="选取元素"></a>选取元素</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.columns #列名</span><br></pre></td></tr></table></figure><p>Index([‘color’, ‘object’, ‘price’], dtype=’object’)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.index #索引</span><br></pre></td></tr></table></figure><p>RangeIndex(start=0, stop=5, step=1)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.values #所有元素</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[&apos;blue&apos;, &apos;ball&apos;, 1.2],</span><br><span class="line">       [&apos;green&apos;, &apos;pen&apos;, 1.0],</span><br><span class="line">       [&apos;yellow&apos;, &apos;pecil&apos;, 0.6],</span><br><span class="line">       [&apos;red&apos;, &apos;paper&apos;, 0.9],</span><br><span class="line">       [&apos;white&apos;, &apos;mug&apos;, 1.7]], dtype=object)</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&apos;price&apos;]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1.2</span><br><span class="line">1    1.0</span><br><span class="line">2    0.6</span><br><span class="line">3    0.9</span><br><span class="line">4    1.7</span><br><span class="line">Name: price, dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.price</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1.2</span><br><span class="line">1    1.0</span><br><span class="line">2    0.6</span><br><span class="line">3    0.9</span><br><span class="line">4    1.7</span><br><span class="line">Name: price, dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.ix[2]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">color     yellow</span><br><span class="line">object     pecil</span><br><span class="line">price        0.6</span><br><span class="line">Name: 2, dtype: object</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_004.png" alt=""></p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.loc[2]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">color     yellow</span><br><span class="line">object     pecil</span><br><span class="line">price        0.6</span><br><span class="line">Name: 2, dtype: object</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.iloc[2]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">color     yellow</span><br><span class="line">object     pecil</span><br><span class="line">price        0.6</span><br><span class="line">Name: 2, dtype: object</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.loc[[2,4]]</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_005.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.iloc[[2,4]] #i表示整数</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_005.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3.loc[&apos;one&apos;]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">color     blue</span><br><span class="line">object    ball</span><br><span class="line">price      1.2</span><br><span class="line">Name: one, dtype: object</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[1:3]</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_006.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&apos;object&apos;][3]</span><br></pre></td></tr></table></figure><p>‘paper’</p><h3 id="赋值"><a href="#赋值" class="headerlink" title="赋值"></a>赋值</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.index.name = &apos;id&apos;</span><br><span class="line">frame.columns.name = &apos;item&apos;</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_007.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&apos;new&apos;] = 12</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_008.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&apos;new&apos;] = [3.0,1.3,2.2,0.8,1.1]</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_009.png" alt=""></p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser = pd.Series(np.arange(5))</span><br><span class="line">ser</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    0</span><br><span class="line">1    1</span><br><span class="line">2    2</span><br><span class="line">3    3</span><br><span class="line">4    4</span><br><span class="line">dtype: int32</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&apos;new&apos;]  = ser</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_010.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&apos;price&apos;][2] = 3.3</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_011.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.set_value(2,&apos;price&apos;,2)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_012.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.at[2,&apos;price&apos;]=22</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_013.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.isin([1.0,&apos;pen&apos;])</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_014.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[frame.isin([1.0,&apos;pen&apos;])]</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_015.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> frame[<span class="string">'new'</span>]</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_016.png" alt=""></p><p>删除一列</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">d1 = &#123;&apos;red&apos;:&#123;2012:22,2013:33&#125;,&apos;white&apos;:&#123;2011:13,2012:22,2013:16&#125;,&apos;blue&apos;:&#123;2011:17,2012:27,2013:18&#125;&#125;</span><br><span class="line">frame2 = pd.DataFrame(d1)</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_017.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.T</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_018.png" alt=""></p><h3 id="Index对象"><a href="#Index对象" class="headerlink" title="Index对象"></a>Index对象</h3><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ins = pd.Series([5,0,3,8,4],index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;,&apos;green&apos;])</span><br><span class="line">ins</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       5</span><br><span class="line">blue      0</span><br><span class="line">yellow    3</span><br><span class="line">white     8</span><br><span class="line">green     4</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ins.index</span><br></pre></td></tr></table></figure><p>Index([‘red’, ‘blue’, ‘yellow’, ‘white’, ‘green’], dtype=’object’)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ins.idxmin() #返回索引值最小的元素</span><br></pre></td></tr></table></figure><p>‘blue’</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ins.idxmax() #返回索引值最大的元素</span><br></pre></td></tr></table></figure><p>‘white’</p><h3 id="重复标签的Index"><a href="#重复标签的Index" class="headerlink" title="重复标签的Index"></a>重复标签的Index</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">serd = pd.Series(range(6),index=[&apos;white&apos;,&apos;white&apos;,&apos;blue&apos;,&apos;green&apos;,&apos;green&apos;,&apos;yellow&apos;])</span><br><span class="line">serd</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">white     0</span><br><span class="line">white     1</span><br><span class="line">blue      2</span><br><span class="line">green     3</span><br><span class="line">green     4</span><br><span class="line">yellow    5</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">serd[&apos;white&apos;]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">white    0</span><br><span class="line">white    1</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">serd.index.is_unique</span><br></pre></td></tr></table></figure><p>False</p><p>判断是否存在重复项</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.index.is_unique</span><br></pre></td></tr></table></figure><p>True</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_019.png" alt=""></p><h3 id="索引对象的其他功能"><a href="#索引对象的其他功能" class="headerlink" title="索引对象的其他功能"></a>索引对象的其他功能</h3><h4 id="更换索引"><a href="#更换索引" class="headerlink" title="更换索引"></a>更换索引</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser = pd.Series([2,3,4,5],index=[&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;])</span><br><span class="line">ser</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">one      2</span><br><span class="line">two      3</span><br><span class="line">three    4</span><br><span class="line">four     5</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser.reindex([&apos;three&apos;,&apos;four&apos;,&apos;five&apos;,&apos;one&apos;])</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">three    4.0</span><br><span class="line">four     5.0</span><br><span class="line">five     NaN</span><br><span class="line">one      2.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h4 id="自动编制索引"><a href="#自动编制索引" class="headerlink" title="自动编制索引"></a>自动编制索引</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser2 = pd.Series([1,5,6,3],index =[0,3,5,6])</span><br><span class="line">ser2</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1</span><br><span class="line">3    5</span><br><span class="line">5    6</span><br><span class="line">6    3</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser2.reindex(range(6),method=&apos;ffill&apos;) #插值，以得到一个完整的序列（前插）</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1</span><br><span class="line">1    1</span><br><span class="line">2    1</span><br><span class="line">3    5</span><br><span class="line">4    5</span><br><span class="line">5    6</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser2.reindex(range(6),method=&apos;bfill&apos;) #插值，以得到一个完整的序列（后插）</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1</span><br><span class="line">1    5</span><br><span class="line">2    5</span><br><span class="line">3    5</span><br><span class="line">4    6</span><br><span class="line">5    6</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>pandas提供专门的删除操作函数：drop()</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser3 = pd.Series(np.arange(4.),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;])</span><br><span class="line">ser3</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       0.0</span><br><span class="line">blue      1.0</span><br><span class="line">yellow    2.0</span><br><span class="line">white     3.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ser3.drop(<span class="string">'yellow'</span>)</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red      0.0</span><br><span class="line">blue     1.0</span><br><span class="line">white    3.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser3.drop([&apos;blue&apos;,&apos;white&apos;])</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       0.0</span><br><span class="line">yellow    2.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(np.arange(16).reshape((4,4)),index=[&apos;blue&apos;,&apos;yellow&apos;,&apos;red&apos;,&apos;white&apos;],columns=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_020.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.drop([&apos;blue&apos;,&apos;yellow&apos;]) #默认删除行</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_021.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.drop([&apos;pen&apos;,&apos;pencil&apos;],axis=1) #删除列</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_022.png" alt=""></p><h3 id="add-sub-div-mul"><a href="#add-sub-div-mul" class="headerlink" title="add() sub() div() mul()"></a>add() sub() div() mul()</h3><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser4 = pd.Series(np.arange(4.),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;])</span><br><span class="line">ser4</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       0.0</span><br><span class="line">blue      1.0</span><br><span class="line">yellow    2.0</span><br><span class="line">white     3.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser5 = pd.Series(np.arange(5.),index=[&apos;red&apos;,&apos;blue&apos;,&apos;black&apos;,&apos;brown&apos;,&apos;yellow&apos;])</span><br><span class="line">ser5</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       0.0</span><br><span class="line">blue      1.0</span><br><span class="line">black     2.0</span><br><span class="line">brown     3.0</span><br><span class="line">yellow    4.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser4 + ser5</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">black     NaN</span><br><span class="line">blue      2.0</span><br><span class="line">brown     NaN</span><br><span class="line">red       0.0</span><br><span class="line">white     NaN</span><br><span class="line">yellow    6.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame1 = pd.DataFrame(np.arange(16).reshape((4,4)),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;],columns=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])</span><br><span class="line">frame1</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_023.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2 = pd.DataFrame(np.arange(12).reshape((4,3)),index=[&apos;blue&apos;,&apos;green&apos;,&apos;white&apos;,&apos;yellow&apos;],columns=[&apos;mug&apos;,&apos;pen&apos;,&apos;ball&apos;])</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_024.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame1 + frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_025.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame1.add(frame2)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_025.png" alt=""></p><h4 id="-1"><a href="#-1" class="headerlink" title=" "></a> </h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2 = pd.DataFrame(np.arange(16).reshape((4,4)),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;],columns=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_026.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser1 = pd.Series(np.arange(4),index=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])</span><br><span class="line">ser1</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball      0</span><br><span class="line">pen       1</span><br><span class="line">pencil    2</span><br><span class="line">paper     3</span><br><span class="line">dtype: int32</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2 - ser1</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_027.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser1[&apos;mug&apos;] = 9</span><br><span class="line">ser1</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball      0</span><br><span class="line">pen       1</span><br><span class="line">pencil    2</span><br><span class="line">paper     3</span><br><span class="line">mug       9</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2 - ser1</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_028.png" alt=""></p><h3 id="通用函数"><a href="#通用函数" class="headerlink" title="通用函数"></a>通用函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.sqrt(frame2) #平方根</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_029.png" alt=""></p><h3 id="按行或列执行操作的函数"><a href="#按行或列执行操作的函数" class="headerlink" title="按行或列执行操作的函数"></a>按行或列执行操作的函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f = lambda x:x.max() - x.min()</span><br><span class="line"></span><br><span class="line">frame2.apply(f)</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball      12</span><br><span class="line">pen       12</span><br><span class="line">pencil    12</span><br><span class="line">paper     12</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.apply(f,axis = 1) # 行</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       3</span><br><span class="line">blue      3</span><br><span class="line">yellow    3</span><br><span class="line">white     3</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> pd.Series([x.min(),x.max()],index=[<span class="string">'min'</span>,<span class="string">'max'</span>])</span><br><span class="line">    </span><br><span class="line">frame2.apply(f)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_030.png" alt=""></p><h3 id="统计函数"><a href="#统计函数" class="headerlink" title="统计函数"></a>统计函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.sum()</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball      24</span><br><span class="line">pen       28</span><br><span class="line">pencil    32</span><br><span class="line">paper     36</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.describe()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_031.png" alt=""></p><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><h4 id="根据索引排序"><a href="#根据索引排序" class="headerlink" title="根据索引排序"></a>根据索引排序</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser = pd.Series([5,0,3,8,4],index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;,&apos;green&apos;])</span><br><span class="line">ser</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       5</span><br><span class="line">blue      0</span><br><span class="line">yellow    3</span><br><span class="line">white     8</span><br><span class="line">green     4</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser.sort_index() #a-zp升序</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blue      0</span><br><span class="line">green     4</span><br><span class="line">red       5</span><br><span class="line">white     8</span><br><span class="line">yellow    3</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser.sort_index(ascending=False)  #降序</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yellow    3</span><br><span class="line">white     8</span><br><span class="line">red       5</span><br><span class="line">green     4</span><br><span class="line">blue      0</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_032.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.sort_index()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_033.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.sort_index(axis=1)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_034.png" alt=""></p><h4 id="根据对象排序"><a href="#根据对象排序" class="headerlink" title="根据对象排序"></a>根据对象排序</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.sort_values(by = &apos;pen&apos;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_035.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.at[&apos;red&apos;,&apos;pen&apos;]=18</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_036.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.sort_values(by = &apos;pen&apos;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_037.png" alt=""></p><h4 id="排位"><a href="#排位" class="headerlink" title="排位"></a>排位</h4><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser.rank() #排位</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       4.0</span><br><span class="line">blue      1.0</span><br><span class="line">yellow    2.0</span><br><span class="line">white     5.0</span><br><span class="line">green     3.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser.rank(method = &apos;first&apos;)</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       4.0</span><br><span class="line">blue      1.0</span><br><span class="line">yellow    2.0</span><br><span class="line">white     5.0</span><br><span class="line">green     3.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ser.rank(ascending=False) #降序</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">red       2.0</span><br><span class="line">blue      5.0</span><br><span class="line">yellow    4.0</span><br><span class="line">white     1.0</span><br><span class="line">green     3.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.rank()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_038.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3 = frame2.sort_values(by = &apos;pen&apos;)</span><br><span class="line">frame3.rank()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_039.png" alt=""></p><h3 id="相关性和协方差"><a href="#相关性和协方差" class="headerlink" title="相关性和协方差"></a>相关性和协方差</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">seq2 = pd.Series([3,4,3,4,5,4,3,2],[&apos;2006&apos;,&apos;2007&apos;,&apos;2008&apos;,&apos;2009&apos;,&apos;2010&apos;,&apos;2011&apos;,&apos;2012&apos;,&apos;2013&apos;])</span><br><span class="line">seq2</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2006    3</span><br><span class="line">2007    4</span><br><span class="line">2008    3</span><br><span class="line">2009    4</span><br><span class="line">2010    5</span><br><span class="line">2011    4</span><br><span class="line">2012    3</span><br><span class="line">2013    2</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">seq = pd.Series([1,2,3,4,4,3,2,1],[&apos;2006&apos;,&apos;2007&apos;,&apos;2008&apos;,&apos;2009&apos;,&apos;2010&apos;,&apos;2011&apos;,&apos;2012&apos;,&apos;2013&apos;])</span><br><span class="line">seq</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2006    1</span><br><span class="line">2007    2</span><br><span class="line">2008    3</span><br><span class="line">2009    4</span><br><span class="line">2010    4</span><br><span class="line">2011    3</span><br><span class="line">2012    2</span><br><span class="line">2013    1</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">seq.corr(seq2)</span><br></pre></td></tr></table></figure><p>0.7745966692414835</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">seq.cov(seq2)</span><br></pre></td></tr></table></figure><p>0.8571428571428571</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2 = pd.DataFrame([[1,4,3,6],[4,5,6,1],[3,3,1,5],[4,1,6,4]],index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;],columns = [&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_040.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.corr()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_041.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.cov()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_042.png" alt=""></p><p><strong>corrwith()方法可以计算DataFrame对象的列或行与Series对象或其他DataFrame对象元素两两之间的相关性</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame2.corrwith(ser)</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball     -0.140028</span><br><span class="line">pen      -0.869657</span><br><span class="line">pencil    0.080845</span><br><span class="line">paper     0.595854</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f1 = frame2.corrwith(frame)</span><br><span class="line">f1</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball     -0.182574</span><br><span class="line">pen      -0.831522</span><br><span class="line">pencil    0.105409</span><br><span class="line">paper     0.597614</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f1.dropna() #删除NaN</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball     -0.182574</span><br><span class="line">pen      -0.831522</span><br><span class="line">pencil    0.105409</span><br><span class="line">paper     0.597614</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f1[f1.notnull()]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ball     -0.182574</span><br><span class="line">pen      -0.831522</span><br><span class="line">pencil    0.105409</span><br><span class="line">paper     0.597614</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3 = pd.DataFrame([[6,np.nan,6],[np.nan,np.nan,np.nan],[2,np.nan,5]],index = [&apos;blue&apos;,&apos;green&apos;,&apos;red&apos;],columns = [&apos;ball&apos;,&apos;mug&apos;,&apos;pen&apos;])</span><br><span class="line">frame3</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_043.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3.dropna()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_044.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3.dropna(how =&apos;all&apos;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_045.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3.fillna(0) #指定缺失值填充</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_046.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3.fillna(&#123;&apos;ball&apos;:1,&apos;mug&apos;:0,&apos;pen&apos;:99&#125;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_047.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mser = pd.Series(np.random.rand(8),index=[[&apos;white&apos;,&apos;white&apos;,&apos;white&apos;,&apos;blue&apos;,&apos;blue&apos;,&apos;red&apos;,&apos;red&apos;,&apos;red&apos;],[&apos;up&apos;,&apos;down&apos;,&apos;right&apos;,&apos;up&apos;,&apos;down&apos;,&apos;up&apos;,&apos;down&apos;,&apos;left&apos;]])</span><br><span class="line">mser #等级索引</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">white  up       0.096961</span><br><span class="line">       down     0.633575</span><br><span class="line">       right    0.652724</span><br><span class="line">blue   up       0.269485</span><br><span class="line">       down     0.518140</span><br><span class="line">red    up       0.143647</span><br><span class="line">       down     0.335544</span><br><span class="line">       left     0.574777</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mser.index</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MultiIndex(levels=[[&apos;blue&apos;, &apos;red&apos;, &apos;white&apos;], [&apos;down&apos;, &apos;left&apos;, &apos;right&apos;, &apos;up&apos;]],</span><br><span class="line">           labels=[[2, 2, 2, 0, 0, 1, 1, 1], [3, 0, 2, 3, 0, 3, 0, 1]])</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mser[&apos;white&apos;]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">up       0.096961</span><br><span class="line">down     0.633575</span><br><span class="line">right    0.652724</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mser[:,&apos;up&apos;]</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">white    0.096961</span><br><span class="line">blue     0.269485</span><br><span class="line">red      0.143647</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mser[&apos;white&apos;,&apos;up&apos;]</span><br></pre></td></tr></table></figure><p>0.09696136257353527</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame = mser.unstack() #把等级索引Series转换成简单的DataFrame对象</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_048.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame.stack()</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blue   down     0.518140</span><br><span class="line">       up       0.269485</span><br><span class="line">red    down     0.335544</span><br><span class="line">       left     0.574777</span><br><span class="line">       up       0.143647</span><br><span class="line">white  down     0.633575</span><br><span class="line">       right    0.652724</span><br><span class="line">       up       0.096961</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mframe = pd.DataFrame(np.random.randn(16).reshape(4,4),</span><br><span class="line">                     index =[[&apos;white&apos;,&apos;white&apos;,&apos;red&apos;,&apos;red&apos;],[&apos;up&apos;,&apos;down&apos;,&apos;up&apos;,&apos;down&apos;]],</span><br><span class="line">                     columns=[[&apos;pen&apos;,&apos;pen&apos;,&apos;paper&apos;,&apos;paper&apos;],[1,2,1,2]])</span><br><span class="line">mframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_049.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mframe.columns.names =[&apos;objects&apos;,&apos;id&apos;]</span><br><span class="line">mframe.index.names = [&apos;colors&apos;,&apos;status&apos;]</span><br><span class="line">mframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_050.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mframe.swaplevel(&apos;colors&apos;,&apos;status&apos;) #互换位置</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_051.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mframe.sort_index(level=&apos;colors&apos;) #根据层级排序</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_052.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mframe.sum(level=&apos;colors&apos;)  #按照层级统计</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_053.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mframe.sum(level=&apos;id&apos;,axis=1)  #按照层级统计</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_054.png" alt=""></p><h3 id="pandas：数据读写"><a href="#pandas：数据读写" class="headerlink" title="pandas：数据读写"></a>pandas：数据读写</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_055.png" alt=""></p><h4 id="csv和文本文件"><a href="#csv和文本文件" class="headerlink" title="csv和文本文件"></a>csv和文本文件</h4><p>多年以来，人们已习惯于文本文件的读写，特别是列表形式的数据。如果文件每一行的多 个元素是用逗号隔开的，则这种格式叫作CSV，这可能是最广为人知和最受欢迎的格式。</p><p>其他由空格或制表符分隔的列表数据通常存储在各种类型的文本文件中（扩展名一般 为.txt )。</p><p>因此这种文件类型是最常见的数据源，它易于转录和解释。pandas的下列函数专门用来处理 这种文件类型：</p><ul><li>read_csv</li><li>read_table</li><li>to_csv</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">csvframe = pd.read_csv(&apos;myCSV_01.csv&apos;)</span><br><span class="line">csvframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_056.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">csvframe = pd.read_table(&apos;myCSV_01.csv&apos;,sep=&apos;,&apos;)</span><br><span class="line">csvframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_057.png" alt=""></p><p>第一行作为列名称，但是往往很多数据第一行不是列名</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">csvframe = pd.read_csv(&apos;myCSV_02.csv&apos;)</span><br><span class="line">csvframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_058.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">csvframe = pd.read_csv(&apos;myCSV_02.csv&apos;,header=None) #添加默认表头</span><br><span class="line">csvframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_059.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">csvframe = pd.read_csv(&apos;myCSV_02.csv&apos;,names=[&apos;white&apos;,&apos;red&apos;,&apos;blue&apos;,&apos;green&apos;,&apos;animal&apos;]) #指定表头</span><br><span class="line">csvframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_060.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">csvframe = pd.read_csv(&apos;myCSV_03.csv&apos;)</span><br><span class="line">csvframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_061.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">csvframe = pd.read_csv(&apos;myCSV_03.csv&apos;,index_col=[&apos;color&apos;,&apos;status&apos;]) #等级索引</span><br><span class="line">csvframe</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_062.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pd.read_table(&apos;ch05_04.txt&apos;,sep=&apos;\s+&apos;) #根据正则解析</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_063.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pd.read_table(&apos;ch05_05.txt&apos;,sep=r&apos;\D+&apos;,header=None,engine=&apos;python&apos;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_064.png" alt=""></p><p>另一种很常见的情况是，解析数据时把空行排除在外。文件中的表头或没有必要的注释，有时用不到。使用skiprows选项，可以排除多余的行。把要排除的行的行号放到数组中，赋给该选项即可。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pd.read_table(&apos;ch05_06.txt&apos;,sep=&apos;,&apos;,skiprows=[0,1,3,6])</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_065.png" alt=""></p><h4 id="从TXT文件读取部分数据"><a href="#从TXT文件读取部分数据" class="headerlink" title="从TXT文件读取部分数据"></a>从TXT文件读取部分数据</h4><p>处理大文件或是只对文件部分数据感兴趣时，往往需要按照部分（块）读取文件，因为只需 要部分数据s这两种情况都得使用迭代。 举例来说，假如只想读取文件的一部分，可明确指定要解析的行号，这时要用到nrows和skiprows选项。你可以指定起始行n (n = SkipRows)和从起始行往后读多少行（nrows = i).</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pd.read_csv(&apos;myCSV_02.csv&apos;,skiprows=[2],nrows=3,header=None)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_066.png" alt=""></p><p>另外一项既有趣又很常用的操作是切分想要解析的文本，然后遍历各个部分，逐一对其执行 某一特定操作。</p><p>例如，对于一列数字，每隔两行取一个累加起来，最后把和插人到Series对象中„这个小例 子理解起来很简单，也没有实际应用价值，但是一旦领会了其原理，你就能将其用到更加复杂的情况。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">out = pd.Series()</span><br><span class="line">pieces = pd.read_csv(&apos;myCSV_01.csv&apos;,chunksize=3)</span><br><span class="line">pieces</span><br></pre></td></tr></table></figure><pandas.io.parsers.textfilereader at="" 0x11dfa4a8=""><p>In:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> piece <span class="keyword">in</span> pieces:</span><br><span class="line">    print(piece[<span class="string">'white'</span>])</span><br><span class="line">    out.at[i] = piece[<span class="string">'white'</span>].sum()</span><br><span class="line">    i += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0    1</span><br><span class="line">1    2</span><br><span class="line">2    3</span><br><span class="line">Name: white, dtype: int64</span><br><span class="line">3    2</span><br><span class="line">4    4</span><br><span class="line">5    4</span><br><span class="line">Name: white, dtype: int64</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">out</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0     6</span><br><span class="line">1    10</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h3 id="往CSV文件写入数据"><a href="#往CSV文件写入数据" class="headerlink" title="往CSV文件写入数据"></a>往CSV文件写入数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame1</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_067.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame1.to_csv(&apos;ch05_07.csv&apos;)</span><br></pre></td></tr></table></figure><p>把DataFrame写人文件时，索引和列名称连同数据一起写入。使用index和 header选项，把它们的值设置为False,可取消这一默认行为</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame1.to_csv(&apos;ch05_07b.csv&apos;,index =False,header=False)</span><br><span class="line">frame3</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_068.png" alt=""></p><p>需要注意的是，数据结构中的NaN写入文件后，显示为空字段</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3.to_csv(&apos;ch05_08.csv&apos;)</span><br></pre></td></tr></table></figure><p>可以用to_csv()函数的na_rep选项把空字段替换为你需要的值。常用值有NULL、0和NaN</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame3.to_csv(&apos;ch05_09.csv&apos;,na_rep=&apos;NaN&apos;)</span><br></pre></td></tr></table></figure><h3 id="读写HTML文件"><a href="#读写HTML文件" class="headerlink" title="读写HTML文件"></a>读写HTML文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(np.arange(4).reshape(2,2))</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_069.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">print(frame.to_html())</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;</span><br><span class="line">  &lt;thead&gt;</span><br><span class="line">    &lt;tr style=&quot;text-align: right;&quot;&gt;</span><br><span class="line">      &lt;th&gt;&lt;/th&gt;</span><br><span class="line">      &lt;th&gt;0&lt;/th&gt;</span><br><span class="line">      &lt;th&gt;1&lt;/th&gt;</span><br><span class="line">    &lt;/tr&gt;</span><br><span class="line">  &lt;/thead&gt;</span><br><span class="line">  &lt;tbody&gt;</span><br><span class="line">    &lt;tr&gt;</span><br><span class="line">      &lt;th&gt;0&lt;/th&gt;</span><br><span class="line">      &lt;td&gt;0&lt;/td&gt;</span><br><span class="line">      &lt;td&gt;1&lt;/td&gt;</span><br><span class="line">    &lt;/tr&gt;</span><br><span class="line">    &lt;tr&gt;</span><br><span class="line">      &lt;th&gt;1&lt;/th&gt;</span><br><span class="line">      &lt;td&gt;2&lt;/td&gt;</span><br><span class="line">      &lt;td&gt;3&lt;/td&gt;</span><br><span class="line">    &lt;/tr&gt;</span><br><span class="line">  &lt;/tbody&gt;</span><br><span class="line">&lt;/table&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> frame = pd.DataFrame( np.random.random((4,4)),</span><br><span class="line">index = [&apos;white&apos;,&apos;black&apos;,&apos;red&apos;,&apos;blue1&apos;],</span><br><span class="line">columns = [&apos;up&apos;,&apos;down&apos;,&apos;right&apos;,&apos;left&apos;])</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_070.png" alt=""></p><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s = [&apos;&lt;HTML&gt;&apos;]</span><br><span class="line">s.append(&apos;&lt;HEAD&gt;&lt;TITLE&gt;My DataFrame&lt;/TITLE&gt;&lt;/HEAD&gt;&apos;)</span><br><span class="line">s.append(&apos; &lt;B0DY&gt;&apos;)</span><br><span class="line">s.append(frame.to_html())</span><br><span class="line">s.append(&apos;&lt;/BODY&gt;&lt;/HTML&gt;&apos;)</span><br><span class="line">html = &apos;&apos;.join(s)</span><br><span class="line">html_file = open(&apos;myFrame.html&apos;,&apos;w&apos;)</span><br><span class="line">html_file.write(html)</span><br><span class="line">html_file.close()</span><br></pre></td></tr></table></figure><h4 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web_frames = pd.read_html(&apos;myFrame.html&apos;)</span><br><span class="line">web_frames[0]</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_071.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ranking = pd.read_html(&apos;http://www.meccanismocomplesso.org/en/ meccanismo-complesso-sito-2/classifica-punteggio/&apos;)</span><br><span class="line">ranking[0]</span><br></pre></td></tr></table></figure><p>此处省略。。。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ranking[1]</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_072.png" alt=""></p><h3 id="从XML读取数据"><a href="#从XML读取数据" class="headerlink" title="从XML读取数据"></a>从XML读取数据</h3><p>pandas的所有I/O API函数中，没有专门用来处理XML(可扩展标记语言）格式的。虽然没有， 但这种格式其实很重要，因为很多结构化数据都是以XML格式存储的。pandas没有专门的处理函 数也没关系，因为Python有很多读写XML格式数据的库（除了pandas)。</p><p>其中一个库叫作lxml,它在大文件处理方面性能优异，因而从众多同类库之中脱颖而出。这 一节将介绍如何用它处理XML文件，以及如何把它和pandas整合起来，以最终从XML文件中获 取到所需数据并将其转换为DataFrame对象。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> objectify</span><br><span class="line"></span><br><span class="line">xml = objectify.parse(<span class="string">'books.xml'</span>)</span><br><span class="line">xml</span><br></pre></td></tr></table></figure><lxml.etree._elementtree at="" 0x124ee988=""><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root = xml.getroot()</span><br><span class="line">root</span><br></pre></td></tr></table></figure><element catalog="" at="" 0x124ee948=""><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root.Book.Author</span><br></pre></td></tr></table></figure><p>‘ 272103_l_EnRoss, Mark’</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root.Book.PublishDate</span><br></pre></td></tr></table></figure><p>‘2014-22-0l’</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mes = root.Book.getchildren()</span><br><span class="line">mes</span><br></pre></td></tr></table></figure><p>[‘ 272103_l_EnRoss, Mark’, ‘XML Cookbook’, ‘Computer’, 23.56, ‘2014-22-0l’]</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[child.tag for child in mes]</span><br></pre></td></tr></table></figure><p>[‘Author’, ‘Title’, ‘Genre’, ‘Price’, ‘PublishDate’]</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[child.text for child in mes]</span><br></pre></td></tr></table></figure><p>[‘ 272103_l_EnRoss, Mark’, ‘XML Cookbook’, ‘Computer’, ‘23.56’, ‘2014-22-0l’]</p><h3 id="读写-Microsoft-Excel文件"><a href="#读写-Microsoft-Excel文件" class="headerlink" title="读写 Microsoft Excel文件"></a>读写 Microsoft Excel文件</h3><ul><li>to_excel()</li><li>read_excel()</li></ul><p>能够读取.xls和.xlsx两种类型的文件</p><h3 id="读写JSON数据"><a href="#读写JSON数据" class="headerlink" title="读写JSON数据"></a>读写JSON数据</h3><ul><li>read_json()</li><li>to_json()</li></ul><h3 id="HDF5格式"><a href="#HDF5格式" class="headerlink" title="HDF5格式"></a>HDF5格式</h3><p>至此，已学习了文本格式的读写。若要分析大量数据，最好使用二进制格式。Python有多 种二进制数据处理工具。HDF5库在这个方面取得了一定的成功。</p><p>HDF代表等级数据格式（hierarchical data format )。HDF5库关注的是HDF5文件的读写，这种文件的数据结构由节点组成，能够存储大量数据集。</p><p>该库全部用c语言开发，提供了python/matlab和Java语言接口。它的迅速扩展得益于开发人 员的广泛使用，还得益于它的效率，尤其是使用这种格式存储大量数据，其效率很高。比起其他处理起二进制数据更为简单的格式，HDF5支持实时压缩，因而能够利用数据结构中的重复模式压缩文件。</p><p>目前，Python提供两种操纵HDF5格式数据的方法：PyTables和h5py。这两种方法有几点不同，选用哪一种很大程度上取决于具体需求。</p><p>h5py为HDF5的高级API提供接口。PyTables封装了很多HDF5细节，提供更加灵活的数据容器、索引表、搜索功能和其他计算相关的介质。</p><p>pandas还有一个叫作HDFStore、类似于diet的类，它用PyTables存储pandas对象。使用HDF5格式之前，必须导人HDFStore类。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.io.pytables <span class="keyword">import</span> HDFStore</span><br><span class="line"></span><br><span class="line">frame = pd.DataFrame(np.arange(<span class="number">16</span>).reshape(<span class="number">4</span>,<span class="number">4</span>),</span><br><span class="line"></span><br><span class="line">index=[<span class="string">'white'</span>,<span class="string">'black1'</span>,<span class="string">'red'</span>,<span class="string">'blue'</span>],</span><br><span class="line"></span><br><span class="line">columns=[<span class="string">'up'</span>,<span class="string">'down'</span>,<span class="string">'right'</span>,<span class="string">'left'</span>])</span><br><span class="line"></span><br><span class="line">frame1</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_073.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">store = HDFStore(&apos;mydata.h5&apos;)</span><br><span class="line">store[&apos;obj1&apos;] = frame</span><br><span class="line">frame2</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_074.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">store[&apos;obj2&apos;] = frame2</span><br><span class="line">store</span><br></pre></td></tr></table></figure><p><class 'pandas.io.pytables.hdfstore'=""><br>File path: mydata.h5</class></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">store[&apos;obj2&apos;]</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_075.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">store[&apos;obj1&apos;]</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_076.png" alt=""></p><h3 id="pickle-——python对象序列化"><a href="#pickle-——python对象序列化" class="headerlink" title="pickle ——python对象序列化"></a>pickle ——python对象序列化</h3><p>pickle模块实现了一个强大的算法，能够对用Python实现的数据结构进行序列化（pickling) 和反序列化操作。序列化是指把对象的层级结构转换为字节流的过程。序列化便于对象的传输、存储和重建，仅用接收器就能重建对象，还能保留它的所有原始特征。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">data = &#123; <span class="string">'color'</span>: [<span class="string">'white'</span>,<span class="string">'red'</span>], <span class="string">'value'</span>: [<span class="number">5</span>, <span class="number">7</span>]&#125;</span><br><span class="line"></span><br><span class="line">pickled_data = pickle.dumps(data)</span><br><span class="line"></span><br><span class="line">pickled_data</span><br></pre></td></tr></table></figure><p>b’\x80\x03}q\x00(X\x05\x00\x00\x00colorq\x01]q\x02(X\x05\x00\x00\x00whiteq\x03X\x03\x00\x00\x00redq\x04eX\x05\x00\x00\x00valueq\x05]q\x06(K\x05K\x07eu.’</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nframe = pickle.loads(pickled_data)</span><br><span class="line">nframe</span><br></pre></td></tr></table></figure><p>{‘color’: [‘white’, ‘red’], ‘value’: [5, 7]}</p><h4 id="用pandas实现对象序列化"><a href="#用pandas实现对象序列化" class="headerlink" title="用pandas实现对象序列化"></a>用pandas实现对象序列化</h4><p>用pandas库实现对象序列化（反序列化）很方便，所有工具都是现成的，无需在Python会话中导入cPickle模块，所有的操作都是隐式进行的。 pandas的序列化格式并不是完全使用ASCII编码</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(np.arange(16).reshape(4,4), index = [&apos;up&apos;,&apos;down&apos;,&apos;left&apos;,&apos;right&apos;])</span><br><span class="line"></span><br><span class="line">frame.to_pickle(&apos;frame.pkl&apos;)</span><br><span class="line"></span><br><span class="line">pd.read_pickle(&apos;frame.pkl&apos;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_077.png" alt=""></p><p>pandas的所有序列化和反序列化操作都在后台运行，用户根本看不到。这使得这两项操作对数据分析人员而言尽可能简单和易于理解。</p><p><strong>注意 :</strong>使用这种格式时，要确保打开的文件的安全性。pickle格式无法规避错误和恶意数据。</p><h3 id="对接数据库"><a href="#对接数据库" class="headerlink" title="对接数据库"></a>对接数据库</h3><p>在很多应用中，所使用的数据来自于文本文件的很少，因为文本文件不是存储数据最有效的方式</p><p>数据往往存储于SQL类关系型数据库，作为补充，NoSQL数据库近来也已流行开来。</p><p>从SQL数据库加载数据，将其转换为DataFrame对象很简单pandas提供的几个函数简化了该过程。</p><p>pandas.io.sql模块提供独立于数据库、叫作sqlalchemy的统一接口。该接口简化了连接模式， 不管对于什么类型的数据库，操作命令都只有一套。连接数据库使用create_engine()函数，你可以用它配置驱动器所需的用户名、密码、端口和数据库实例等所有属性。 数据库URL的典型形式是：</p><p>dialect+driver://username:password@host:port/database</p><p>名称的标识名称，例如sqlite，mysql，postgresql，oracle，或mssql。drivername是用于使用全小写字母连接到数据库的DBAPI的名称。如果未指定，则将导入“默认”DBAPI（如果可用） - 此默认值通常是该后端可用的最广泛的驱动程序。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sqlalchemy import create_engine</span><br></pre></td></tr></table></figure><h4 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h4><h5 id="default"><a href="#default" class="headerlink" title="default"></a>default</h5><p>engine = create_engine(‘postgresql://scott:tiger@localhost/mydatabase’)</p><h5 id="psycopg2"><a href="#psycopg2" class="headerlink" title="psycopg2"></a>psycopg2</h5><p>engine = create_engine(‘postgresql+psycopg2://scott:tiger@localhost/mydatabase’)</p><h5 id="pg8000"><a href="#pg8000" class="headerlink" title="pg8000"></a>pg8000</h5><p>engine = create_engine(‘postgresql+pg8000://scott:tiger@localhost/mydatabase’)</p><h4 id="MySql"><a href="#MySql" class="headerlink" title="MySql"></a>MySql</h4><h5 id="default-1"><a href="#default-1" class="headerlink" title="default"></a>default</h5><p>engine = create_engine(‘mysql://scott:tiger@localhost/foo’)</p><h5 id="mysql-python"><a href="#mysql-python" class="headerlink" title="mysql-python"></a>mysql-python</h5><p>engine = create_engine(‘mysql+mysqldb://scott:tiger@localhost/foo’)</p><h5 id="MySQL-connector-python"><a href="#MySQL-connector-python" class="headerlink" title="MySQL-connector-python"></a>MySQL-connector-python</h5><p>engine = create_engine(‘mysql+mysqlconnector://scott:tiger@localhost/foo’)</p><h5 id="OurSQL"><a href="#OurSQL" class="headerlink" title="OurSQL"></a>OurSQL</h5><p>engine = create_engine(‘mysql+oursql://scott:tiger@localhost/foo’)</p><h4 id="Oracle"><a href="#Oracle" class="headerlink" title="Oracle"></a>Oracle</h4><p>engine = create_engine(‘oracle://scott:<a href="mailto:tiger@127.0.0.1" target="_blank" rel="noopener">tiger@127.0.0.1</a>:1521/sidname’)</p><p>engine = create_engine(‘oracle+cx_oracle://scott:tiger@tnsname’)</p><h4 id="Microsoft-SQL"><a href="#Microsoft-SQL" class="headerlink" title="Microsoft SQL"></a>Microsoft SQL</h4><h5 id="pyodbc"><a href="#pyodbc" class="headerlink" title="pyodbc"></a>pyodbc</h5><p>engine = create_engine(‘mssql+pyodbc://scott:tiger@mydsn’)</p><h5 id="pymssql"><a href="#pymssql" class="headerlink" title="pymssql"></a>pymssql</h5><p>engine = create_engine(‘mssql+pymssql://scott:tiger@hostname:port/dbname’)</p><h4 id="SQLite"><a href="#SQLite" class="headerlink" title="SQLite"></a>SQLite</h4><p>由于SQLite连接到本地文件，因此URL格式略有不同。URL的“文件”部分是数据库的文件名。</p><p>对于相对文件路径，这需要三个斜杠：</p><p>sqlite:///</p><p>where is relative:</p><p>engine = create_engine(‘sqlite:///foo.db’)</p><p>对于绝对文件路径，三个斜杠后面是绝对路径：</p><p><strong>Unix/Mac - 4 initial slashes in total</strong></p><p>engine = create_engine(‘sqlite:////absolute/path/to/foo.db’)</p><p><strong>Windows</strong></p><p>engine = create_engine(‘sqlite:///C:\path\to\foo.db’)</p><p><strong>Windows alternative using raw string</strong></p><p>engine = create_engine(r’sqlite:///C:\path\to\foo.db’)</p><h4 id="SQLite3数据读写"><a href="#SQLite3数据读写" class="headerlink" title="SQLite3数据读写"></a>SQLite3数据读写</h4><p>学习使用Python内置的SQLite数据库sqlite3。SQLite3工具实现了简单、 轻量级的DBMS SQL,因此可以内置于用Python语言实现的任何应用。它很实用，你可以在单个文件中创建一个嵌入式数据库。</p><p>若想使用数据库的所有功能而又不想安装真正的数据库，这个工具就是最佳选择。若想在使用真正的数据库之前练习数据库操作，或在单一程序中使用数据库存储数据而无需考虑接口， SQLite3都是不错的选择。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame( np.arange(<span class="number">20</span>).reshape(<span class="number">4</span>,<span class="number">5</span>),</span><br><span class="line">                        columns=[<span class="string">'white'</span>,<span class="string">'red'</span>,<span class="string">'blue'</span>,<span class="string">'black'</span>,<span class="string">'green'</span>])</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_078.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#连接SQLite3数据库</span><br><span class="line">engine = create_engine(&apos;sqlite:///foo.db&apos;)</span><br><span class="line"></span><br><span class="line">#把DataFrame转换为数据库表。</span><br><span class="line">frame.to_sql(&apos;colors&apos;,engine)</span><br><span class="line"></span><br><span class="line">#读取。</span><br><span class="line">pd.read_sql(&apos;colors&apos;,engine)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/pandas_079.png" alt=""></p></element></lxml.etree._elementtree></pandas.io.parsers.textfilereader>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Series对象&quot;&gt;&lt;a href=&quot;#Series对象&quot; class=&quot;headerlink&quot; title=&quot;Series对象&quot;&gt;&lt;/a&gt;Series对象&lt;/h2&gt;&lt;p&gt;pandas库的Series对象用来表示一维数据结构，跟数组类似，但多了一些额外的功能，它的
      
    
    </summary>
    
      <category term="工具" scheme="https://janvia.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="pandas" scheme="https://janvia.github.io/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>matplotlib</title>
    <link href="https://janvia.github.io/2019/01/24/matplotlib/"/>
    <id>https://janvia.github.io/2019/01/24/matplotlib/</id>
    <published>2019-01-24T03:24:27.000Z</published>
    <updated>2019-01-24T08:27:10.154Z</updated>
    
    <content type="html"><![CDATA[<h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><p>测试用数据：</p><p>unrate.csv：<a href="https://pan.baidu.com/s/1uVCVvYKfcphjqcbMpLBdkg" target="_blank" rel="noopener">https://pan.baidu.com/s/1uVCVvYKfcphjqcbMpLBdkg</a></p><p>fandango_scores.csv：<a href="https://pan.baidu.com/s/1jareiLJC0YzNKgTOUxdbqQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1jareiLJC0YzNKgTOUxdbqQ</a></p><p>percent-bachelors-degrees-women-usa.csv：<a href="https://pan.baidu.com/s/1oPtYASsjEoZbD8PEwNWFrw" target="_blank" rel="noopener">https://pan.baidu.com/s/1oPtYASsjEoZbD8PEwNWFrw</a></p><p>train.csv：<a href="https://pan.baidu.com/s/1Y2NaPDYtRxFWJABd1YxxJg" target="_blank" rel="noopener">https://pan.baidu.com/s/1Y2NaPDYtRxFWJABd1YxxJg</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd                                     </span><br><span class="line"></span><br><span class="line">unrate = pd.read_csv(<span class="string">'unrate.csv'</span>)                       </span><br><span class="line"><span class="comment">#unrate['DATE'] = pd.to_datetime(unrate['DATE'])          </span></span><br><span class="line">print(unrate.head(<span class="number">12</span>))</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">          DATE  VALUE</span><br><span class="line">0   1948-01-01    3.4</span><br><span class="line">1   1948-02-01    3.8</span><br><span class="line">2   1948-03-01    4.0</span><br><span class="line">3   1948-04-01    3.9</span><br><span class="line">4   1948-05-01    3.5</span><br><span class="line">5   1948-06-01    3.6</span><br><span class="line">6   1948-07-01    3.6</span><br><span class="line">7   1948-08-01    3.9</span><br><span class="line">8   1948-09-01    3.8</span><br><span class="line">9   1948-10-01    3.7</span><br><span class="line">10  1948-11-01    3.8</span><br><span class="line">11  1948-12-01    4.0</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt1.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">first_twelve = unrate[0:12]</span><br><span class="line">plt.plot(first_twelve[&apos;DATE&apos;], first_twelve[&apos;VALUE&apos;])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt2.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plt.plot(first_twelve[&apos;DATE&apos;], first_twelve[&apos;VALUE&apos;])</span><br><span class="line">plt.xticks(rotation=45)</span><br><span class="line"># print help(plt.xticks)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt3.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(10, 10))</span><br><span class="line">plt.plot(first_twelve[&apos;DATE&apos;], first_twelve[&apos;VALUE&apos;])</span><br><span class="line">plt.xticks(rotation=90)</span><br><span class="line">plt.xlabel(&apos;Month&apos;)</span><br><span class="line">plt.ylabel(&apos;Unemployment Rate&apos;)</span><br><span class="line">plt.title(&apos;Monthly Unemployment Trends, 1948&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt4.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax1 = fig.add_subplot(3,2,1)</span><br><span class="line">ax2 = fig.add_subplot(3,2,2)</span><br><span class="line">ax6 = fig.add_subplot(3,2,6)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt5.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">fig = plt.figure()</span><br><span class="line">#fig = plt.figure(figsize=(3, 3))</span><br><span class="line">ax1 = fig.add_subplot(2,1,1)</span><br><span class="line">ax2 = fig.add_subplot(2,1,2)</span><br><span class="line"></span><br><span class="line">ax1.plot(np.random.randint(1,5,5), np.arange(5))</span><br><span class="line">ax2.plot(np.arange(10)*3, np.arange(10))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt6.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">print(unrate[&apos;DATE&apos;])</span><br><span class="line">unrate[&apos;DATE&apos;] = pd.to_datetime(unrate[&apos;DATE&apos;]) </span><br><span class="line">print(unrate[&apos;DATE&apos;])</span><br><span class="line">#unrate[&apos;MONTH&apos;] = unrate[&apos;DATE&apos;].dt.month</span><br><span class="line">unrate[&apos;MONTH&apos;] = unrate[&apos;DATE&apos;].dt.month</span><br><span class="line">fig = plt.figure(figsize=(6,3))</span><br><span class="line"></span><br><span class="line">plt.plot(unrate[0:12][&apos;MONTH&apos;], unrate[0:12][&apos;VALUE&apos;], c=&apos;red&apos;)</span><br><span class="line">plt.plot(unrate[12:24][&apos;MONTH&apos;], unrate[12:24][&apos;VALUE&apos;], c=&apos;blue&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt7.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(10,6))</span><br><span class="line">colors = [&apos;red&apos;, &apos;blue&apos;, &apos;green&apos;, &apos;orange&apos;, &apos;black&apos;]</span><br><span class="line">for i in range(5):</span><br><span class="line">    start_index = i*12</span><br><span class="line">    end_index = (i+1)*12</span><br><span class="line">    subset = unrate[start_index:end_index]</span><br><span class="line">    plt.plot(subset[&apos;MONTH&apos;], subset[&apos;VALUE&apos;], c=colors[i])</span><br><span class="line">    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt8.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(10,6))</span><br><span class="line">colors = [&apos;red&apos;, &apos;blue&apos;, &apos;green&apos;, &apos;orange&apos;, &apos;black&apos;]</span><br><span class="line">for i in range(5):</span><br><span class="line">    start_index = i*12</span><br><span class="line">    end_index = (i+1)*12</span><br><span class="line">    subset = unrate[start_index:end_index]</span><br><span class="line">    label = str(1948 + i)</span><br><span class="line">    plt.plot(subset[&apos;MONTH&apos;], subset[&apos;VALUE&apos;], c=colors[i], label=label)</span><br><span class="line">plt.legend(loc=&apos;best&apos;)</span><br><span class="line">#print (help(plt.legend))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt9.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(10,6))</span><br><span class="line">colors = [&apos;red&apos;, &apos;blue&apos;, &apos;green&apos;, &apos;orange&apos;, &apos;black&apos;]</span><br><span class="line">for i in range(5):</span><br><span class="line">    start_index = i*12</span><br><span class="line">    end_index = (i+1)*12</span><br><span class="line">    subset = unrate[start_index:end_index]</span><br><span class="line">    label = str(1948 + i)</span><br><span class="line">    plt.plot(subset[&apos;MONTH&apos;], subset[&apos;VALUE&apos;], c=colors[i], label=label)</span><br><span class="line">plt.legend(loc=&apos;upper left&apos;)</span><br><span class="line">plt.xlabel(&apos;Month, Integer&apos;)</span><br><span class="line">plt.ylabel(&apos;Unemployment Rate, Percent&apos;)</span><br><span class="line">plt.title(&apos;Monthly Unemployment Trends, 1948-1952&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt10.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">reviews = pd.read_csv(&apos;fandango_scores.csv&apos;)</span><br><span class="line">cols = [&apos;FILM&apos;, &apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]</span><br><span class="line">norm_reviews = reviews[cols]</span><br><span class="line">print(norm_reviews[:1])</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                             FILM  RT_user_norm  Metacritic_user_nom  \</span><br><span class="line">0  Avengers: Age of Ultron (2015)           4.3                 3.55   </span><br><span class="line"></span><br><span class="line">   IMDB_norm  Fandango_Ratingvalue  Fandango_Stars  </span><br><span class="line">0        3.9                   4.5             5.0</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from numpy import arange</span><br><span class="line">#The Axes.bar() method has 2 required parameters, left and height. </span><br><span class="line">#We use the left parameter to specify the x coordinates of the left sides of the bar. </span><br><span class="line">#We use the height parameter to specify the height of each bar</span><br><span class="line">num_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]</span><br><span class="line"></span><br><span class="line">bar_heights = norm_reviews.loc[0, num_cols].values</span><br><span class="line">#print (bar_heights)</span><br><span class="line">bar_positions = arange(5) + 0.75</span><br><span class="line">#print (bar_positions)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.bar(bar_positions, bar_heights, 0.5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt11.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">num_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]</span><br><span class="line">bar_heights = norm_reviews.loc[0, num_cols].values</span><br><span class="line">bar_positions = arange(5) + 0.75</span><br><span class="line">tick_positions = range(1,6)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"># print(fig)</span><br><span class="line"># print(ax)</span><br><span class="line"># print(help(plt.subplots))</span><br><span class="line">ax.bar(bar_positions, bar_heights, 0.5)</span><br><span class="line">ax.set_xticks(tick_positions)</span><br><span class="line">ax.set_xticklabels(num_cols, rotation=90)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(&apos;Rating Source&apos;)</span><br><span class="line">ax.set_ylabel(&apos;Average Rating&apos;)</span><br><span class="line">ax.set_title(&apos;Average User Rating For Avengers: Age of Ultron (2015)&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt12.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from numpy import arange</span><br><span class="line">num_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]</span><br><span class="line"></span><br><span class="line">bar_widths = norm_reviews.loc[0, num_cols].values</span><br><span class="line">bar_positions = arange(5) + 0.75</span><br><span class="line">tick_positions = range(1,6)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.barh(bar_positions, bar_widths, 0.5)</span><br><span class="line"></span><br><span class="line">ax.set_yticks(tick_positions)</span><br><span class="line">ax.set_yticklabels(num_cols)</span><br><span class="line">ax.set_ylabel(&apos;Rating Source&apos;)</span><br><span class="line">ax.set_xlabel(&apos;Average Rating&apos;)</span><br><span class="line">ax.set_title(&apos;Average User Rating For Avengers: Age of Ultron (2015)&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt13.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(norm_reviews[&apos;Fandango_Ratingvalue&apos;], norm_reviews[&apos;RT_user_norm&apos;])</span><br><span class="line">ax.set_xlabel(&apos;Fandango&apos;)</span><br><span class="line">ax.set_ylabel(&apos;Rotten Tomatoes&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt14.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Switching Axes</span><br><span class="line">fig = plt.figure(figsize=(5,10))</span><br><span class="line">ax1 = fig.add_subplot(2,1,1)</span><br><span class="line">ax2 = fig.add_subplot(2,1,2)</span><br><span class="line">ax1.scatter(norm_reviews[&apos;Fandango_Ratingvalue&apos;], norm_reviews[&apos;RT_user_norm&apos;])</span><br><span class="line">ax1.set_xlabel(&apos;Fandango&apos;)</span><br><span class="line">ax1.set_ylabel(&apos;Rotten Tomatoes&apos;)</span><br><span class="line">ax2.scatter(norm_reviews[&apos;RT_user_norm&apos;], norm_reviews[&apos;Fandango_Ratingvalue&apos;])</span><br><span class="line">ax2.set_xlabel(&apos;Rotten Tomatoes&apos;)</span><br><span class="line">ax2.set_ylabel(&apos;Fandango&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt15.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">#ax.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;])</span><br><span class="line">#ax.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;],bins=20)</span><br><span class="line">ax.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;], range=(4, 5),bins=20) #4-5 其实结束</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt16.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(5,20))</span><br><span class="line">ax1 = fig.add_subplot(4,1,1)</span><br><span class="line">ax2 = fig.add_subplot(4,1,2)</span><br><span class="line">ax3 = fig.add_subplot(4,1,3)</span><br><span class="line">ax4 = fig.add_subplot(4,1,4)</span><br><span class="line">ax1.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;], bins=20, range=(0, 5))</span><br><span class="line">ax1.set_title(&apos;Distribution of Fandango Ratings&apos;)</span><br><span class="line">ax1.set_ylim(0, 50)</span><br><span class="line"></span><br><span class="line">ax2.hist(norm_reviews[&apos;RT_user_norm&apos;], 20, range=(0, 5))</span><br><span class="line">ax2.set_title(&apos;Distribution of Rotten Tomatoes Ratings&apos;)</span><br><span class="line">ax2.set_ylim(0, 50)</span><br><span class="line"></span><br><span class="line">ax3.hist(norm_reviews[&apos;Metacritic_user_nom&apos;], 20, range=(0, 5))</span><br><span class="line">ax3.set_title(&apos;Distribution of Metacritic Ratings&apos;)</span><br><span class="line">ax3.set_ylim(0, 50)</span><br><span class="line"></span><br><span class="line">ax4.hist(norm_reviews[&apos;IMDB_norm&apos;], 20, range=(0, 5))</span><br><span class="line">ax4.set_title(&apos;Distribution of IMDB Ratings&apos;)</span><br><span class="line">ax4.set_ylim(0, 50)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt17.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.boxplot(norm_reviews[&apos;RT_user_norm&apos;])</span><br><span class="line">ax.set_xticklabels([&apos;Rotten Tomatoes&apos;])</span><br><span class="line">ax.set_ylim(0, 5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt18.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">num_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;]</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.boxplot(norm_reviews[num_cols].values)   #箱线图</span><br><span class="line">ax.set_xticklabels(num_cols, rotation=90)</span><br><span class="line">ax.set_ylim(0,5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt19.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">women_degrees = pd.read_csv(&apos;percent-bachelors-degrees-women-usa.csv&apos;)</span><br><span class="line">plt.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt20.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plt.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;], c=&apos;blue&apos;, label=&apos;Women&apos;)</span><br><span class="line">plt.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[&apos;Biology&apos;], c=&apos;green&apos;, label=&apos;Men&apos;)</span><br><span class="line">plt.legend(loc=&apos;upper right&apos;)</span><br><span class="line">plt.title(&apos;Percentage of Biology Degrees Awarded By Gender&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt21.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">ax.tick_params(bottom=&quot;off&quot;, top=&apos;on&apos;, left=&quot;off&quot;, right=&quot;on&quot;)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">ax.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;], label=&apos;Women&apos;)</span><br><span class="line">ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[&apos;Biology&apos;], label=&apos;Men&apos;)</span><br><span class="line"></span><br><span class="line">ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)</span><br><span class="line">ax.set_title(&apos;Percentage of Biology Degrees Awarded By Gender&apos;)</span><br><span class="line">ax.legend(loc=&quot;upper right&quot;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt22.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt23.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;], c=&apos;blue&apos;, label=&apos;Women&apos;)</span><br><span class="line">ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[&apos;Biology&apos;], c=&apos;green&apos;, label=&apos;Men&apos;)</span><br><span class="line">ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)</span><br><span class="line">print(type(ax.spines))</span><br><span class="line">for key,spine in ax.spines.items():</span><br><span class="line">    spine.set_visible(False)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ax.legend(loc=&apos;upper right&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt24.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">major_cats = [&apos;Biology&apos;, &apos;Computer Science&apos;, &apos;Engineering&apos;, &apos;Math and Statistics&apos;]</span><br><span class="line">fig = plt.figure(figsize=(12, 12))</span><br><span class="line"></span><br><span class="line">for sp in range(0,4):</span><br><span class="line">    ax = fig.add_subplot(2,2,sp+1)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], women_degrees[major_cats[sp]], c=&apos;blue&apos;, label=&apos;Women&apos;)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[major_cats[sp]], c=&apos;green&apos;, label=&apos;Men&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.legend(loc=&apos;upper right&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt25.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Color</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">women_degrees = pd.read_csv(&apos;percent-bachelors-degrees-women-usa.csv&apos;)</span><br><span class="line">major_cats = [&apos;Biology&apos;, &apos;Computer Science&apos;, &apos;Engineering&apos;, &apos;Math and Statistics&apos;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cb_dark_blue = (0/255, 107/255, 164/255)</span><br><span class="line">cb_orange = (255/255, 128/255, 14/255)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(12, 12))</span><br><span class="line"></span><br><span class="line">for sp in range(0,4):</span><br><span class="line">    ax = fig.add_subplot(2,2,sp+1)</span><br><span class="line">    # The color for each line is assigned here.</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], women_degrees[major_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[major_cats[sp]], c=cb_orange, label=&apos;Men&apos;)</span><br><span class="line">    for key,spine in ax.spines.items():</span><br><span class="line">        spine.set_visible(False)</span><br><span class="line">    ax.set_xlim(1968, 2011)</span><br><span class="line">    ax.set_ylim(0,100)</span><br><span class="line">    ax.set_title(major_cats[sp])</span><br><span class="line">    ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=&apos;upper right&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt26.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Setting Line Width</span><br><span class="line">cb_dark_blue = (0/255, 107/255, 164/255)</span><br><span class="line">cb_orange = (255/255, 128/255, 14/255)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(12, 12))</span><br><span class="line"></span><br><span class="line">for sp in range(0,4):</span><br><span class="line">    ax = fig.add_subplot(2,2,sp+1)</span><br><span class="line">    # Set the line width when specifying how each line should look.</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], women_degrees[major_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=10)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[major_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=10)</span><br><span class="line">    for key,spine in ax.spines.items():</span><br><span class="line">        spine.set_visible(False)</span><br><span class="line">    ax.set_xlim(1968, 2011)</span><br><span class="line">    ax.set_ylim(0,100)</span><br><span class="line">    ax.set_title(major_cats[sp])</span><br><span class="line">    ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=&apos;upper right&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt27.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stem_cats = [&apos;Engineering&apos;, &apos;Computer Science&apos;, &apos;Psychology&apos;, &apos;Biology&apos;, &apos;Physical Sciences&apos;, &apos;Math and Statistics&apos;]</span><br><span class="line">fig = plt.figure(figsize=(18, 3))</span><br><span class="line"></span><br><span class="line">for sp in range(0,6):</span><br><span class="line">    ax = fig.add_subplot(1,6,sp+1)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], women_degrees[stem_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=3)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[stem_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=3)</span><br><span class="line">    for key,spine in ax.spines.items():</span><br><span class="line">        spine.set_visible(False)</span><br><span class="line">    ax.set_xlim(1968,2011)</span><br><span class="line">    ax.set_ylim(0,100)</span><br><span class="line">    ax.set_title(stem_cats[sp])</span><br><span class="line">    ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)</span><br><span class="line"></span><br><span class="line">plt.legend(loc=&apos;upper right&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt28.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(18, 3))</span><br><span class="line"></span><br><span class="line">for sp in range(0,6):</span><br><span class="line">    ax = fig.add_subplot(1,6,sp+1)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], women_degrees[stem_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=3)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[stem_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=3)</span><br><span class="line">    for key,spine in ax.spines.items():</span><br><span class="line">        spine.set_visible(False)</span><br><span class="line">    ax.set_xlim(1968, 2011)</span><br><span class="line">    ax.set_ylim(0,100)</span><br><span class="line">    ax.set_title(stem_cats[sp])</span><br><span class="line">    ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)</span><br><span class="line">plt.legend(loc=&apos;upper right&apos;)</span><br><span class="line">plt.show()</span><br><span class="line">fig = plt.figure(figsize=(18, 3))</span><br><span class="line"></span><br><span class="line">for sp in range(0,6):</span><br><span class="line">    ax = fig.add_subplot(1,6,sp+1)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], women_degrees[stem_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=3)</span><br><span class="line">    ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[stem_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=3)</span><br><span class="line">    for key,spine in ax.spines.items():</span><br><span class="line">        spine.set_visible(False)</span><br><span class="line">    ax.set_xlim(1968, 2011)</span><br><span class="line">    ax.set_ylim(0,100)</span><br><span class="line">    ax.set_title(stem_cats[sp])</span><br><span class="line">    ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)</span><br><span class="line">    </span><br><span class="line">    if sp == 0:</span><br><span class="line">        ax.text(2005, 87, &apos;Men&apos;)</span><br><span class="line">        ax.text(2002, 8, &apos;Women&apos;)</span><br><span class="line">    elif sp == 5:</span><br><span class="line">        ax.text(2005, 62, &apos;Men&apos;)</span><br><span class="line">        ax.text(2001, 35, &apos;Women&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt29.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/plt30.png" alt=""></p><h1 id="seaborn"><a href="#seaborn" class="headerlink" title="seaborn"></a>seaborn</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">titanic = pd.read_csv(&apos;train.csv&apos;)</span><br><span class="line">cols = [&apos;Survived&apos;, &apos;Pclass&apos;, &apos;Sex&apos;, &apos;Age&apos;, &apos;SibSp&apos;, &apos;Parch&apos;, &apos;Fare&apos;, &apos;Embarked&apos;]</span><br><span class="line">titanic = titanic[cols].dropna()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">sns.distplot(titanic[&apos;Age&apos;])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns1.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib as mpl</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def sinplot(flip=1):</span><br><span class="line">    x = np.linspace(0, 14, 100)</span><br><span class="line">    for i in range(1, 7):</span><br><span class="line">        plt.plot(x, np.sin(x + i * .5) * (7 - i) * flip)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns2.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set()</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns3.png" alt=""></p><h3 id="5种主题风格"><a href="#5种主题风格" class="headerlink" title="5种主题风格"></a><strong>5种主题风格</strong></h3><ul><li>darkgrid</li><li>whitegrid</li><li>dark</li><li>white</li><li>ticks</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_style(&quot;whitegrid&quot;)</span><br><span class="line">data = np.random.normal(size=(20, 6)) + np.arange(6) / 2</span><br><span class="line">sns.boxplot(data=data)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns4.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_style(&quot;dark&quot;)</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns5.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_style(&quot;white&quot;)</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns6.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_style(&quot;ticks&quot;)</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns7.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sinplot()</span><br><span class="line">sns.despine()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns8.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.violinplot(data)</span><br><span class="line">sns.despine(offset=10,trim=True)  #轴线的距离</span><br><span class="line"># sns.violinplot(data=data)</span><br><span class="line"># sns.despine(offset=10, trim=True);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns9.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_style(&quot;whitegrid&quot;)</span><br><span class="line">sns.boxplot(data=data,palette=&quot;deep&quot;)</span><br><span class="line">sns.despine(left=True)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns10.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">with sns.axes_style(&quot;darkgrid&quot;):</span><br><span class="line">    plt.subplot(211)</span><br><span class="line">    sinplot()</span><br><span class="line">plt.subplot(212)</span><br><span class="line">sinplot(-1)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns11.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set()</span><br><span class="line">sns.set_context(&quot;paper&quot;)</span><br><span class="line">plt.figure(figsize=(8, 6))</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns12.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_context(&quot;talk&quot;)</span><br><span class="line">plt.figure(figsize=(8, 6))</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns13.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_context(&quot;poster&quot;)</span><br><span class="line">plt.figure(figsize=(8, 6))</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns14.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.set_context(&quot;notebook&quot;, font_scale=1.5, rc=&#123;&quot;lines.linewidth&quot;: 2.5&#125;)</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns15.png" alt=""></p><h3 id="调色板"><a href="#调色板" class="headerlink" title="调色板"></a>调色板</h3><ul><li>颜色很重要</li><li>color_palette()能传入任何Matplotlib所支持的颜色</li><li>color_palette()不写参数则默认颜色</li><li>set_palette()设置所有图的颜色</li></ul><h3 id="分类色板"><a href="#分类色板" class="headerlink" title="分类色板"></a>分类色板</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">current_palette = sns.color_palette()</span><br><span class="line">sns.palplot(current_palette)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns16.png" alt=""></p><h3 id="圆形画板"><a href="#圆形画板" class="headerlink" title="圆形画板"></a>圆形画板</h3><p>当你有六个以上的分类要区分时，最简单的方法就是在一个圆形的颜色空间中画出均匀间隔的颜色(这样的色调会保持亮度和饱和度不变)。这是大多数的当他们需要使用比当前默认颜色循环中设置的颜色更多时的默认方案。</p><p>最常用的方法是使用hls的颜色空间，这是RGB值的一个简单转换。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.color_palette(&quot;hls&quot;, 8))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns17.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data = np.random.normal(size=(20, 8)) + np.arange(8) / 2</span><br><span class="line">sns.boxplot(data=data,palette=sns.color_palette(&quot;hls&quot;, 8))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns18.png" alt=""></p><p>hls_palette()函数来控制颜色的亮度和饱和</p><ul><li>l-亮度 lightness</li><li>s-饱和 saturation</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.hls_palette(8, l=.7, s=.9))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns19.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.color_palette(&quot;Paired&quot;,8))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns20.png" alt=""></p><h3 id="使用xkcd颜色来命名颜色"><a href="#使用xkcd颜色来命名颜色" class="headerlink" title="使用xkcd颜色来命名颜色"></a>使用xkcd颜色来命名颜色</h3><p>xkcd包含了一套众包努力的针对随机RGB色的命名。产生了954个可以随时通过xdcd_rgb字典中调用的命名颜色。</p><p><a href="https://xkcd.com/color/rgb/" target="_blank" rel="noopener">https://xkcd.com/color/rgb/</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plt.plot([0, 1], [0, 1], sns.xkcd_rgb[&quot;pale red&quot;], lw=3)           #https://xkcd.com/color/rgb/</span><br><span class="line">plt.plot([0, 1], [0, 2], sns.xkcd_rgb[&quot;medium green&quot;], lw=3)</span><br><span class="line">plt.plot([0, 1], [0, 3], sns.xkcd_rgb[&quot;denim blue&quot;], lw=3)</span><br><span class="line">plt.plot([0, 1], [0, 4], sns.xkcd_rgb[&quot;olive&quot;],lw = 5)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns21.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">colors = [&quot;windows blue&quot;, &quot;amber&quot;, &quot;greyish&quot;, &quot;faded green&quot;, &quot;dusty purple&quot;]</span><br><span class="line">sns.palplot(sns.xkcd_palette(colors))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns22.png" alt=""></p><h3 id="连续色板"><a href="#连续色板" class="headerlink" title="连续色板"></a>连续色板</h3><p>色彩随数据变换，比如数据越来越重要则颜色越来越深</p><hr><p>Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Vega10, Vega10_r, Vega20, Vega20_r, Vega20b, Vega20b_r, Vega20c, Vega20c_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spectral, spectral_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, vlag, vlag_r, winter, winter_r</p><hr><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.color_palette(&quot;Blues&quot;))</span><br><span class="line">sns.palplot(sns.color_palette(&quot;Accent&quot;))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns23.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns24.png" alt=""></p><p>如果想要翻转渐变，可以在面板名称中添加一个_r后缀</p><h3 id="cubehelix-palette-调色板"><a href="#cubehelix-palette-调色板" class="headerlink" title="cubehelix_palette()调色板"></a>cubehelix_palette()调色板</h3><p>色调线性变换</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.color_palette(&quot;cubehelix&quot;, 8))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns25.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.cubehelix_palette(8, start=.5, rot=-.75))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns26.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.cubehelix_palette(8, start=.75, rot=-.150))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns27.png" alt=""></p><h3 id="light-palette-和dark-palette-调用定制连续调色板"><a href="#light-palette-和dark-palette-调用定制连续调色板" class="headerlink" title="light_palette() 和dark_palette()调用定制连续调色板"></a>light_palette() 和dark_palette()调用定制连续调色板</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.light_palette(&quot;green&quot;))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns28.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.dark_palette(&quot;purple&quot;))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns29.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.light_palette(&quot;navy&quot;, reverse=True))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns30.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.palplot(sns.light_palette((210, 90, 60), input=&quot;husl&quot;))</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns31.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x = np.random.normal(size=100)</span><br><span class="line">sns.distplot(x,kde=False)       #kde 核密度估计</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns32.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.distplot(x, bins=20, kde=False)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns33.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from scipy import stats, integrate</span><br><span class="line">x = np.random.gamma(6, size=200)</span><br><span class="line">sns.distplot(x, kde=False, fit=stats.gamma)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns34.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mean, cov = [0, 1], [(1, .5), (.5, 1)]</span><br><span class="line">data = np.random.multivariate_normal(mean, cov, 200)</span><br><span class="line">df = pd.DataFrame(data, columns=[&quot;x&quot;, &quot;y&quot;])</span><br><span class="line">df</span><br></pre></td></tr></table></figure><h3 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a><strong>散点图</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=&quot;x&quot;, y=&quot;y&quot;, data=df)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns35.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=&quot;x&quot;, y=&quot;y&quot;, data=df,kind = &quot;reg&quot;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns36.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x, y = np.random.multivariate_normal(mean, cov, 1000).T</span><br><span class="line">with sns.axes_style(&quot;white&quot;):</span><br><span class="line">    sns.jointplot(x=x, y=y, kind=&quot;hex&quot;, color=&quot;k&quot;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns37.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iris = sns.load_dataset(&quot;iris&quot;)</span><br><span class="line">sns.pairplot(iris)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns38.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tips = sns.load_dataset(&quot;tips&quot;)</span><br><span class="line"></span><br><span class="line">tips.head()</span><br></pre></td></tr></table></figure><p>regplot()和lmplot()都可以绘制回归关系,推荐regplot()</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns39.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns40.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">anscombe = sns.load_dataset(&quot;anscombe&quot;)</span><br><span class="line">print(anscombe.head())</span><br><span class="line">print(type(anscombe))</span><br><span class="line">sns.regplot(x=&quot;x&quot;, y=&quot;y&quot;, data=anscombe.query(&quot;dataset == &apos;I&apos;&quot;),</span><br><span class="line">           ci=None, scatter_kws=&#123;&quot;s&quot;: 80&#125;)   # ci 置信区间    query 查询布尔表达式所在的数据</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns41.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=&quot;x&quot;, y=&quot;y&quot;, data=anscombe.query(&quot;dataset == &apos;II&apos;&quot;),</span><br><span class="line">           ci=None, scatter_kws=&#123;&quot;s&quot;: 80&#125;)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns42.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"x"</span>, y=<span class="string">"y"</span>, data=anscombe.query(<span class="string">"dataset == 'II'"</span>),</span><br><span class="line">           order=<span class="number">2</span>, ci=<span class="keyword">None</span>, scatter_kws=&#123;<span class="string">"s"</span>: <span class="number">80</span>&#125;)                       <span class="comment">#order : int, optional</span></span><br><span class="line"><span class="comment">#If order is greater than 1, use numpy.polyfit to estimate a polynomial regression.</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns43.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, hue=<span class="string">"smoker"</span>, data=tips);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns44.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, hue=<span class="string">"smoker"</span>, data=tips,                 </span><br><span class="line">           markers=[<span class="string">"o"</span>,<span class="string">"*"</span>], palette=<span class="string">"Set1"</span>);                               </span><br><span class="line"><span class="comment">#hue  列名分割</span></span><br><span class="line"><span class="comment">#matplotlib.markers</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns45.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, hue=<span class="string">"smoker"</span>, col=<span class="string">"time"</span>, data=tips);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns46.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, hue=<span class="string">"smoker"</span>,</span><br><span class="line">           col=<span class="string">"time"</span>, row=<span class="string">"sex"</span>, data=tips);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns47.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f, ax = plt.subplots(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">sns.regplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, data=tips, ax=ax);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns48.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, col=<span class="string">"day"</span>, data=tips,</span><br><span class="line">           col_wrap=<span class="number">2</span>, size=<span class="number">4</span>) <span class="comment">#size 图size</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns49.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, col=<span class="string">"day"</span>, data=tips,)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns50.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"tip"</span>, col=<span class="string">"day"</span>, data=tips,aspect=<span class="number">.5</span>)  <span class="comment"># aspect 长宽比</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns51.png" alt=""></p><h3 id="多变量"><a href="#多变量" class="headerlink" title="多变量"></a>多变量</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set(style=<span class="string">"whitegrid"</span>, color_codes=<span class="keyword">True</span>)</span><br><span class="line">sns.stripplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns52.png" alt=""></p><p>重叠是很常见的现象，但是重叠影响我观察数据的量了</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.stripplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, data=tips, jitter=<span class="keyword">True</span>) <span class="comment">#抖动量</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns53.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.swarmplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns54.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.swarmplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"sex"</span>,data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns55.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.swarmplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"day"</span>, hue=<span class="string">"time"</span>, data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns56.png" alt=""></p><h3 id="盒图"><a href="#盒图" class="headerlink" title="盒图"></a>盒图</h3><ul><li>IQR即统计学概念四分位距，第1/4分位与第3/4分位之间的距离</li><li>$N = 1.5IQR$ 如果一个值$&gt;Q3+N$或$&lt;Ｑ1-N$,则为离群点</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.boxplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"time"</span>, data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns57.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.violinplot(x=<span class="string">"total_bill"</span>, y=<span class="string">"day"</span>, hue=<span class="string">"time"</span>, data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns58.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.violinplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"sex"</span>, data=tips, split=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns59.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.violinplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"sex"</span>, data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns60.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.violinplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, data=tips, inner=<span class="keyword">None</span>)  <span class="comment">#inner 小提琴内部图形</span></span><br><span class="line">sns.swarmplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, data=tips, color=<span class="string">"w"</span>, alpha=<span class="number">.5</span>)  <span class="comment"># alpha 透明度</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns61.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sns.violinplot(x=&quot;day&quot;, y=&quot;total_bill&quot;, data=tips, inner=None)</span><br><span class="line">sns.swarmplot(x=&quot;day&quot;, y=&quot;total_bill&quot;, data=tips, color=&quot;w&quot;,)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns62.png" alt=""></p><h3 id="条形图"><a href="#条形图" class="headerlink" title="条形图"></a>条形图</h3><p>显示值的集中趋势可以用条形图</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">titanic = sns.load_dataset(<span class="string">"titanic"</span>)</span><br><span class="line">print(titanic.describe())</span><br><span class="line">print(titanic.info())</span><br><span class="line">sns.barplot(x=<span class="string">"sex"</span>, y=<span class="string">"survived"</span>, hue=<span class="string">"class"</span>, data=titanic)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns63.png" alt=""></p><h3 id="点图"><a href="#点图" class="headerlink" title="点图"></a>点图</h3><p>点图可以更好的描述变化差异</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.pointplot(x=<span class="string">"sex"</span>, y=<span class="string">"survived"</span>, hue=<span class="string">"class"</span>, data=titanic);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns64.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.pointplot(x=<span class="string">"class"</span>, y=<span class="string">"survived"</span>, hue=<span class="string">"sex"</span>, data=titanic,</span><br><span class="line">              palette=&#123;<span class="string">"male"</span>: <span class="string">"g"</span>, <span class="string">"female"</span>: <span class="string">"m"</span>&#125;,</span><br><span class="line">              markers=[<span class="string">"^"</span>, <span class="string">"o"</span>], linestyles=[<span class="string">"-"</span>, <span class="string">"--"</span>]);</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns65.png" alt=""></p><h3 id="宽形数据"><a href="#宽形数据" class="headerlink" title="宽形数据"></a>宽形数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.boxplot(data=iris,orient=<span class="string">"h"</span>) <span class="comment">#orient  垂直和水平</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns66.png" alt=""></p><h3 id="多层面板分类图"><a href="#多层面板分类图" class="headerlink" title="多层面板分类图"></a>多层面板分类图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.factorplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"smoker"</span>, data=tips)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns67.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.factorplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"smoker"</span>, data=tips, kind=<span class="string">"bar"</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns68.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.factorplot(x=<span class="string">"day"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"smoker"</span>,</span><br><span class="line">               col=<span class="string">"time"</span>, data=tips, kind=<span class="string">"swarm"</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns69.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.factorplot(x=<span class="string">"time"</span>, y=<span class="string">"total_bill"</span>, hue=<span class="string">"smoker"</span>,</span><br><span class="line">               col=<span class="string">"day"</span>, data=tips, kind=<span class="string">"box"</span>, size=<span class="number">4</span>, aspect=<span class="number">.5</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns70.png" alt=""></p><hr><p>seaborn.factorplot(x=None, y=None, hue=None, data=None, row=None, col=None, col_wrap=None, estimator=, ci=95, n_boot=1000, units=None, order=None, hue_order=None, row_order=None, col_order=None, kind=’point’, size=4, aspect=1, orient=None, color=None, palette=None, legend=True, legend_out=True, sharex=True, sharey=True, margin_titles=False, facet_kws=None, **kwargs)</p><p><strong>Parameters：</strong></p><ul><li>x,y,hue 数据集变量 变量名</li><li>date 数据集 数据集名</li><li>row,col 更多分类变量进行平铺显示 变量名</li><li>col_wrap 每行的最高平铺数 整数</li><li>estimator 在每个分类中进行矢量到标量的映射 矢量</li><li>ci 置信区间 浮点数或None</li><li>n_boot 计算置信区间时使用的引导迭代次数 整数</li><li>units 采样单元的标识符，用于执行多级引导和重复测量设计 数据变量或向量数据</li><li>order, hue_order 对应排序列表 字符串列表</li><li>row_order, col_order 对应排序列表 字符串列表</li><li>kind : 可选：point 默认, bar 柱形图, count 频次, box 箱体, violin 提琴, strip 散点，swarm 分散点 size 每个面的高度（英寸） 标量 aspect 纵横比 标量 orient 方向 “v”/“h” color 颜色 matplotlib颜色 palette 调色板 seaborn颜色色板或字典 legend hue的信息面板 True/False legend_out 是否扩展图形，并将信息框绘制在中心右边 True/False share{x,y} 共享轴线 True/False</li></ul><hr><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.FacetGrid(tips, col=<span class="string">"time"</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns71.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set(style=<span class="string">"ticks"</span>)</span><br><span class="line">g = sns.FacetGrid(tips, col=<span class="string">"time"</span>)  <span class="comment">#把数据中很多子集画出来</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns72.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.FacetGrid(tips, col=<span class="string">"time"</span>)                    <span class="comment">#占位</span></span><br><span class="line">print(help(g.map))</span><br><span class="line">g.map(plt.hist, <span class="string">"tip"</span>)                                <span class="comment">#画图</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns73.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.FacetGrid(tips, col=<span class="string">"sex"</span>, hue=<span class="string">"smoker"</span>)</span><br><span class="line">g.map(plt.scatter, <span class="string">"total_bill"</span>, <span class="string">"tip"</span>, alpha=<span class="number">.7</span>)</span><br><span class="line">g.add_legend()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns74.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.FacetGrid(tips, row=<span class="string">"smoker"</span>, col=<span class="string">"time"</span>, margin_titles=<span class="keyword">True</span>)  <span class="comment">#变量标题右侧，实验性并不总是有效</span></span><br><span class="line">g.map(sns.regplot, <span class="string">"size"</span>, <span class="string">"total_bill"</span>, color=<span class="string">".1"</span>, fit_reg=<span class="keyword">False</span>, x_jitter=<span class="number">.1</span>)  <span class="comment">#color 颜色深浅  fit_reg  回归的线  x_jitter 浮动</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns75.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.FacetGrid(tips, col=<span class="string">"day"</span>, size=<span class="number">4</span>, aspect=<span class="number">.5</span>)</span><br><span class="line">g.map(sns.barplot, <span class="string">"sex"</span>, <span class="string">"total_bill"</span>,order=[<span class="string">"Male"</span>,<span class="string">"Female"</span>])</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns76.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from pandas import Categorical</span><br><span class="line">ordered_days = tips.day.value_counts().index</span><br><span class="line">print (ordered_days)</span><br><span class="line">ordered_days = Categorical([&apos;Thur&apos;, &apos;Fri&apos;, &apos;Sat&apos;, &apos;Sun&apos;])</span><br><span class="line">g = sns.FacetGrid(tips, row=&quot;day&quot;, row_order=ordered_days,</span><br><span class="line">                  size=1.7, aspect=4)</span><br><span class="line">g.map(sns.boxplot, &quot;total_bill&quot;,order=[&quot;Male&quot;,&quot;Female&quot;])</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns77.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pal = dict(Lunch=<span class="string">"seagreen"</span>, Dinner=<span class="string">"gray"</span>)</span><br><span class="line">g = sns.FacetGrid(tips, hue=<span class="string">"time"</span>, palette=pal, size=<span class="number">5</span>)</span><br><span class="line">g.map(plt.scatter, <span class="string">"total_bill"</span>, <span class="string">"tip"</span>, s=<span class="number">50</span>, alpha=<span class="number">.7</span>, linewidth=<span class="number">.5</span>, edgecolors=<span class="string">"red"</span>) <span class="comment">#edgecolors 元素边界颜色  </span></span><br><span class="line">g.add_legend()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns78.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.FacetGrid(tips, hue=<span class="string">"sex"</span>, palette=<span class="string">"Set1"</span>, size=<span class="number">5</span>, hue_kws=&#123;<span class="string">"marker"</span>: [<span class="string">"^"</span>, <span class="string">"v"</span>]&#125;)</span><br><span class="line">g.map(plt.scatter, <span class="string">"total_bill"</span>, <span class="string">"tip"</span>, s=<span class="number">100</span>, linewidth=<span class="number">.5</span>, edgecolor=<span class="string">"white"</span>)</span><br><span class="line">g.add_legend()</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns79.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> sns.axes_style(<span class="string">"white"</span>):</span><br><span class="line">    g = sns.FacetGrid(tips, row=<span class="string">"sex"</span>, col=<span class="string">"smoker"</span>, margin_titles=<span class="keyword">True</span>, size=<span class="number">2.5</span>)</span><br><span class="line">g.map(plt.scatter, <span class="string">"total_bill"</span>, <span class="string">"tip"</span>, color=<span class="string">"#334488"</span>, edgecolor=<span class="string">"white"</span>, lw=<span class="number">.5</span>);</span><br><span class="line">g.set_axis_labels(<span class="string">"Total bill (US Dollars)"</span>, <span class="string">"Tip"</span>);</span><br><span class="line">g.set(xticks=[<span class="number">10</span>, <span class="number">30</span>, <span class="number">50</span>], yticks=[<span class="number">2</span>, <span class="number">6</span>, <span class="number">10</span>]);</span><br><span class="line">g.fig.subplots_adjust(wspace=<span class="number">.02</span>, hspace=<span class="number">.02</span>); <span class="comment">#子图与子图</span></span><br><span class="line"><span class="comment">#g.fig.subplots_adjust(left  = 0.125,right = 0.5,bottom = 0.1,top = 0.9, wspace=.02, hspace=.02)</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns80.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris = sns.load_dataset(<span class="string">"iris"</span>)</span><br><span class="line">g = sns.PairGrid(iris)</span><br><span class="line">g.map(plt.scatter)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns81.png" alt=""></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">g = sns.PairGrid(iris)</span><br><span class="line">g.map_diag(plt.hist)   #对角线</span><br><span class="line">g.map_offdiag(plt.scatter) #非对角线</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns82.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.PairGrid(iris, hue=<span class="string">"species"</span>)</span><br><span class="line">g.map_diag(plt.hist)</span><br><span class="line">g.map_offdiag(plt.scatter)</span><br><span class="line">g.add_legend();</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns83.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.PairGrid(iris, vars=[<span class="string">"sepal_length"</span>, <span class="string">"sepal_width"</span>], hue=<span class="string">"species"</span>)  <span class="comment">#vars 取一部分</span></span><br><span class="line"><span class="comment"># print(iris.species.value_counts().index)</span></span><br><span class="line"><span class="comment"># print(iris.describe())</span></span><br><span class="line"><span class="comment"># print(iris.info())</span></span><br><span class="line"><span class="comment"># print(iris.head(10))</span></span><br><span class="line">g.map(plt.scatter)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns84.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g = sns.PairGrid(tips, hue=<span class="string">"size"</span>, palette=<span class="string">"GnBu_d"</span>)</span><br><span class="line">g.map(plt.scatter, s=<span class="number">50</span>, edgecolor=<span class="string">"white"</span>)</span><br><span class="line">g.add_legend();</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns85.png" alt=""></p><h3 id="热力图"><a href="#热力图" class="headerlink" title="热力图"></a>热力图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">uniform_data = np.random.rand(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> (uniform_data)</span><br><span class="line">heatmap = sns.heatmap(uniform_data)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns86.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.heatmap(uniform_data, vmin=<span class="number">0.2</span>, vmax=<span class="number">0.5</span>)  <span class="comment">#最大最小取值</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns87.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">normal_data = np.random.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> (normal_data)</span><br><span class="line">ax = sns.heatmap(normal_data, center=<span class="number">0</span>)      <span class="comment">#中心值</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns88.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">flights = sns.load_dataset(<span class="string">"flights"</span>)</span><br><span class="line">flights.head()</span><br><span class="line"></span><br><span class="line">flights = flights.pivot(<span class="string">"month"</span>, <span class="string">"year"</span>, <span class="string">"passengers"</span>)  <span class="comment">#根据列值重塑数据</span></span><br><span class="line"><span class="keyword">print</span> (flights)</span><br><span class="line">ax = sns.heatmap(flights)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns89.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.heatmap(flights, annot=<span class="keyword">True</span>,fmt=<span class="string">"d"</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns90.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.heatmap(flights, linewidths=<span class="number">.5</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns91.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.heatmap(flights, cmap=<span class="string">"YlGnBu"</span>)</span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns92.png" alt=""></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = sns.heatmap(flights, cbar=<span class="keyword">False</span>) <span class="comment">#隐藏bar</span></span><br></pre></td></tr></table></figure><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/matplotlib/sns93.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;matplotlib&quot;&gt;&lt;a href=&quot;#matplotlib&quot; class=&quot;headerlink&quot; title=&quot;matplotlib&quot;&gt;&lt;/a&gt;matplotlib&lt;/h2&gt;&lt;p&gt;测试用数据：&lt;/p&gt;
&lt;p&gt;unrate.csv：&lt;a href=&quot;http
      
    
    </summary>
    
      <category term="工具" scheme="https://janvia.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="matplotlib" scheme="https://janvia.github.io/tags/matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>numpy</title>
    <link href="https://janvia.github.io/2019/01/23/numpy/"/>
    <id>https://janvia.github.io/2019/01/23/numpy/</id>
    <published>2019-01-23T08:14:30.000Z</published>
    <updated>2019-01-24T02:45:09.133Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Numpy是用Python进行科学计算，尤其是数据分析时，所用到的一个基础库。它是大量python数学和科学计算包的基础，比如后面要讲到的pandas库就用到了Numpy。pandas库专门用于数据分析，充分借鉴了Python标准库Numpy的相关概念。而Python标准库所提供的内置工具对数据分析方面的大多数计算来说都过于简单或不够用。</p><p>为了更好地理解和是用Python所有的科学计算包，尤其是pandas,需要先行掌握Numpy库的用法，这样才能把pandas的用法发挥到极致。</p></blockquote><h2 id="NumPy-数据类型"><a href="#NumPy-数据类型" class="headerlink" title="NumPy - 数据类型"></a>NumPy - 数据类型</h2><blockquote><p>NumPy 支持比 Python 更多种类的数值类型。 下表显示了 NumPy 中定义的不同标量数据类型。</p></blockquote><div class="table-container"><table><thead><tr><th>数据类型</th><th>类型代码</th><th>描述</th></tr></thead><tbody><tr><td>bool_</td><td></td><td>存储为一个字节的布尔值（真或假）</td></tr><tr><td>int_</td><td></td><td>默认整数，相当于 C 的long，通常为int32或int64</td></tr><tr><td>intc</td><td></td><td>相当于 C 的int，通常为int32或int64</td></tr><tr><td>intp</td><td></td><td>用于索引的整数，相当于 C 的size_t，通常为int32或int64</td></tr><tr><td>int8</td><td>i1</td><td>字节（-128 ~ 127）</td></tr><tr><td>int16</td><td>i2</td><td>16 位整数（-32768 ~ 32767）</td></tr><tr><td>int32</td><td>i4</td><td>32 位整数（-2147483648 ~ 2147483647）</td></tr><tr><td>int64</td><td>i8</td><td>64 位整数（-9223372036854775808 ~ 9223372036854775807）</td></tr><tr><td>uint8</td><td>u1</td><td>8 位无符号整数（0 ~ 255）</td></tr><tr><td>uint16</td><td>u2</td><td>16 位无符号整数（0 ~ 65535）</td></tr><tr><td>uint32</td><td>u4</td><td>32 位无符号整数（0 ~ 4294967295）</td></tr><tr><td>uint64</td><td>u8</td><td>64 位无符号整数（0 ~ 18446744073709551615）</td></tr><tr><td>float_</td><td></td><td>float64的简写</td></tr><tr><td>float16</td><td>f2</td><td>半精度浮点：符号位，5 位指数，10 位尾数</td></tr><tr><td>float32</td><td>f4或者f</td><td>单精度浮点：符号位，8 位指数，23 位尾数</td></tr><tr><td>float64</td><td>f8或者d</td><td>双精度浮点：符号位，11 位指数，52 位尾数</td></tr><tr><td>complex_</td><td>c16</td><td>complex128的简写</td></tr><tr><td>complex64</td><td>c8</td><td>复数，由两个 32 位浮点表示（实部和虚部）</td></tr><tr><td>omplex128</td><td>c16</td><td>复数，由两个 64 位浮点表示（实部和虚部）</td></tr><tr><td>bool</td><td>?</td><td>存储True和False值的布尔类型</td></tr><tr><td>object</td><td>O</td><td>python对象类型</td></tr><tr><td>String</td><td>S</td><td>固定场读字符串类型（每一个字符一个字节）。创建一个长度为8的字符串，应该使用S8</td></tr><tr><td>Unicode_</td><td>U</td><td>固定长度的unicode类型（字节数由平台决定），和字符串定义方式一样</td></tr></tbody></table></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.array([1,2],dtype=&apos;f8&apos;)</span><br></pre></td></tr></table></figure><p>结果：array([1., 2.])</p><h2 id="建立ndarray多维数组"><a href="#建立ndarray多维数组" class="headerlink" title="建立ndarray多维数组"></a>建立ndarray多维数组</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n3 = np.array(</span><br><span class="line">    [</span><br><span class="line">        [</span><br><span class="line">            [1,2,3,4],</span><br><span class="line">            [2,3,4,5]</span><br><span class="line">        ],</span><br><span class="line">        [</span><br><span class="line">            [3,4,5,6],</span><br><span class="line">            [4,5,6,7]</span><br><span class="line">        ]</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">n3</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[1, 2, 3, 4],</span><br><span class="line">      [2, 3, 4, 5]],</span><br><span class="line"></span><br><span class="line">      [[3, 4, 5, 6],</span><br><span class="line">      [4, 5, 6, 7]]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n3.ndim    #维度</span><br></pre></td></tr></table></figure><ul><li>3</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n3.shape   #形状</span><br></pre></td></tr></table></figure><ul><li>(2, 2, 4)</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n3.itemsize #每个元素的长度为几个字节</span><br></pre></td></tr></table></figure><ul><li>4</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n3.size     #数组长度</span><br></pre></td></tr></table></figure><ul><li>16</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n3.data    #指向数组数据开始的Python缓冲区对象</span><br></pre></td></tr></table></figure><ul><li><memory at="" 0x000000000588d7c8=""></memory></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n4 = np.array(</span><br><span class="line">    [</span><br><span class="line">        [</span><br><span class="line">            [1,2,3,4],</span><br><span class="line">            [2,3,4,5]</span><br><span class="line">        ],</span><br><span class="line">        [</span><br><span class="line">            [3,4,5,6],</span><br><span class="line">            [4,5,6,7]</span><br><span class="line">        ],</span><br><span class="line">        [</span><br><span class="line">            [3,4,5,6],</span><br><span class="line">            [4,5,6,7]</span><br><span class="line">        ]</span><br><span class="line">    </span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">n4</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[1, 2, 3, 4],</span><br><span class="line">    [2, 3, 4, 5]],</span><br><span class="line"></span><br><span class="line">    [[3, 4, 5, 6],</span><br><span class="line">    [4, 5, 6, 7]],</span><br><span class="line"></span><br><span class="line">    [[3, 4, 5, 6],</span><br><span class="line">    [4, 5, 6, 7]]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n4.shape</span><br></pre></td></tr></table></figure><ul><li>(3, 2, 4)</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n5 = np.array([[&apos;1&apos;,&apos;2&apos;]])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#&lt;表示字节顺序，小端（最小有效字节存储在最小地址中）| ：忽视字节顺序</span><br><span class="line">#&lt; ：低位字节在前，即小端模式(little endian)</span><br><span class="line"># &gt; ：高位字节在前，即大端模式(big endian)</span><br><span class="line"></span><br><span class="line">#U表示Unicode，数据类型</span><br><span class="line"></span><br><span class="line">#1表示元素位长，数据大小</span><br><span class="line">n5.dtype</span><br></pre></td></tr></table></figure><ul><li>dtype(‘&lt;U1’)</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n5.dtype.name</span><br></pre></td></tr></table></figure><ul><li>‘str32’</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n6 = np.array([[&apos;12&apos;,&apos;22&apos;]])</span><br><span class="line">n6.dtype</span><br></pre></td></tr></table></figure><ul><li>dtype(‘&lt;U2’)</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.array([&apos;Python&apos;,&apos;tanzhou &apos;,&apos;hello&apos;,&apos;sa&apos;],dtype=&apos;&lt;U4&apos;)</span><br></pre></td></tr></table></figure><ul><li>array([‘Pyth’, ‘tanz’, ‘hell’, ‘sa’], dtype=’&lt;U4’)</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.array([&apos;1&apos;,&apos;2 &apos;,&apos;2&apos;],dtype=&apos;int&apos;)</span><br></pre></td></tr></table></figure><ul><li>array([1, 2, 2])</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.array([&apos;1.1&apos;,&apos;2 &apos;,&apos;2&apos;],dtype=&apos;float&apos;)</span><br></pre></td></tr></table></figure><ul><li>array([1.1, 2. , 2. ])</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n6.size</span><br></pre></td></tr></table></figure><ul><li>2</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n6.dtype.type</span><br></pre></td></tr></table></figure><ul><li>numpy.str_</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n4[0][0][2]</span><br></pre></td></tr></table></figure><ul><li>3</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x = np.zeros((3,3))          #生成指定维度的全0矩阵</span><br><span class="line">x</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0., 0., 0.],</span><br><span class="line">    [0., 0., 0.],</span><br><span class="line">    [0., 0., 0.]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">y = np.zeros([3,3])  </span><br><span class="line">y</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0., 0., 0.],</span><br><span class="line">    [0., 0., 0.],</span><br><span class="line">    [0., 0., 0.]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.ones((3,4,5),dtype=np.int)  #生成指定维度的全1矩阵</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[1, 1, 1, 1, 1],</span><br><span class="line">        [1, 1, 1, 1, 1],</span><br><span class="line">        [1, 1, 1, 1, 1],</span><br><span class="line">        [1, 1, 1, 1, 1]],</span><br><span class="line"></span><br><span class="line">   [[1, 1, 1, 1, 1],</span><br><span class="line">    [1, 1, 1, 1, 1],</span><br><span class="line">    [1, 1, 1, 1, 1],</span><br><span class="line">    [1, 1, 1, 1, 1]],</span><br><span class="line"></span><br><span class="line">   [[1, 1, 1, 1, 1],</span><br><span class="line">    [1, 1, 1, 1, 1],</span><br><span class="line">    [1, 1, 1, 1, 1],</span><br><span class="line">    [1, 1, 1, 1, 1]]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.empty((3,4))   #生成指定维度的垃圾值矩阵，只分配，不对其进行初始化</span><br></pre></td></tr></table></figure><p>输出：<br>array([[4.6e-322, 0.0e+000, 0.0e+000, 0.0e+000],<br>       [0.0e+000, 0.0e+000, 0.0e+000, 0.0e+000],<br>       [0.0e+000, 0.0e+000, 0.0e+000, 0.0e+000]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.zeros((3,4,5))</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([[[0., 0., 0., 0., 0.],<br>        [0., 0., 0., 0., 0.],<br>        [0., 0., 0., 0., 0.],<br>        [0., 0., 0., 0., 0.]],</p><p>  [[0., 0., 0., 0., 0.],<br>        [0., 0., 0., 0., 0.],<br>        [0., 0., 0., 0., 0.],<br>        [0., 0., 0., 0., 0.]],</p><p>   [[0., 0., 0., 0., 0.],<br>    [0., 0., 0., 0., 0.],<br>    [0., 0., 0., 0., 0.],<br>    [0., 0., 0., 0., 0.]]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">b = np.zeros_like(a)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.]],</span><br><span class="line"></span><br><span class="line">       [[0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.]],</span><br><span class="line"></span><br><span class="line">       [[0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.]]])</span><br></pre></td></tr></table></figure><p>In:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c = np.ones_like(a)</span><br><span class="line">c</span><br></pre></td></tr></table></figure><p>out:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.]],</span><br><span class="line"></span><br><span class="line">       [[1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.]],</span><br><span class="line"></span><br><span class="line">       [[1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.],</span><br><span class="line">        [1., 1., 1., 1., 1.]]])</span><br></pre></td></tr></table></figure><p>in:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.arange(0,10)   #生成数值序列的数组 类似python range</span><br></pre></td></tr></table></figure><p>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.arange(0,10,0.6)</span><br></pre></td></tr></table></figure><p>array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. , 6.6, 7.2,7.8, 8.4, 9. , 9.6])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.arange(0,12).reshape(3,4)</span><br></pre></td></tr></table></figure><p>array([[ 0,  1,  2,  3],<br>       [ 4,  5,  6,  7],<br>       [ 8,  9, 10, 11]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.linspace(0,10,5)</span><br></pre></td></tr></table></figure><p>array([ 0. ,  2.5,  5. ,  7.5, 10. ])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.logspace(0,2,5) #0  表示 10^0  2 表示10^2 5个元素等比数列</span><br></pre></td></tr></table></figure><p>array([  1.   ,   3.16227766,  10.   ,  31.6227766 , 100.  ])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.logspace(0,2,5,endpoint=False) #10**(0.4)=2.51188643150958</span><br></pre></td></tr></table></figure><p>array([ 1.        ,  2.51188643,  6.30957344, 15.84893192, 39.81071706])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.logspace(0,1,12,base=2,endpoint=False)</span><br></pre></td></tr></table></figure><p>array([1.        , 1.05946309, 1.12246205, 1.18920712, 1.25992105,<br>       1.33483985, 1.41421356, 1.49830708, 1.58740105, 1.68179283,<br>       1.78179744, 1.88774863])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.logspace(0,1,12,base=np.e)</span><br></pre></td></tr></table></figure><p>array([1.        , 1.09516944, 1.1993961 , 1.31354196, 1.43855101,<br>       1.5754571 , 1.72539247, 1.88959711, 2.06942901, 2.26637541,<br>       2.48206508, 2.71828183])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.random.random(3)</span><br></pre></td></tr></table></figure><p>array([0.42129851, 0.82031203, 0.2013445 ])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.arange(0, 40, 10)</span><br><span class="line">b = np.tile(a, (3, 5)) </span><br><span class="line">print(a)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><ul><li><p>[ 0 10 20 30]</p></li><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 0, 10, 20, 30,  0, 10, 20, 30,  0, 10, 20, 30,  0, 10, 20, 30,</span><br><span class="line">         0, 10, 20, 30],</span><br><span class="line">       [ 0, 10, 20, 30,  0, 10, 20, 30,  0, 10, 20, 30,  0, 10, 20, 30,</span><br><span class="line">         0, 10, 20, 30],</span><br><span class="line">       [ 0, 10, 20, 30,  0, 10, 20, 30,  0, 10, 20, 30,  0, 10, 20, 30,</span><br><span class="line">         0, 10, 20, 30]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">s =  b&apos;Hello World&apos; </span><br><span class="line">a = np.frombuffer(s, dtype =  np.int8)  </span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([ 72, 101, 108, 108, 111,  32,  87, 111, 114, 108, 100], dtype=int8)</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.fromfile(&apos;save_date.npy&apos;)</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([1.87585069e-309, 1.17119999e+171, 5.22741680e-037, 8.44740097e+252,</span><br><span class="line">       2.65141232e+180, 9.92152605e+247, 2.16209968e+233, 1.05176541e-153,</span><br><span class="line">       6.01399921e-154, 6.01347002e-154, 6.01347002e-154, 6.01347002e-154,</span><br><span class="line">       6.01347002e-154, 6.01347002e-154, 6.01347002e-154, 6.55490914e-260,</span><br><span class="line">       6.54218855e-001, 3.99443697e-001, 4.50091561e-001, 6.60862373e-001,</span><br><span class="line">       8.77753297e-001, 3.89115607e-001, 9.45576953e-001, 4.07118309e-001,</span><br><span class="line">       3.05937465e-001, 7.01606366e-001, 9.23868345e-001, 3.49139962e-001,</span><br><span class="line">       2.71655829e-001, 6.88059971e-001, 1.25104393e-001, 5.42319627e-001])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def func(i,x):</span><br><span class="line">    #return i%4 + 1</span><br><span class="line">    return i</span><br><span class="line"></span><br><span class="line">np.fromfunction(func,(10,2))</span><br></pre></td></tr></table></figure><p>array([[0., 0.],<br>       [1., 1.],<br>       [2., 2.],<br>       [3., 3.],<br>       [4., 4.],<br>       [5., 5.],<br>       [6., 6.],<br>       [7., 7.],<br>       [8., 8.],<br>       [9., 9.]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def func2(i,j):</span><br><span class="line">    return (i+1)*(j+1)</span><br><span class="line"></span><br><span class="line">np.fromfunction(func2,(9,9))</span><br></pre></td></tr></table></figure><p>array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],<br>       [ 2.,  4.,  6.,  8., 10., 12., 14., 16., 18.],<br>       [ 3.,  6.,  9., 12., 15., 18., 21., 24., 27.],<br>       [ 4.,  8., 12., 16., 20., 24., 28., 32., 36.],<br>       [ 5., 10., 15., 20., 25., 30., 35., 40., 45.],<br>       [ 6., 12., 18., 24., 30., 36., 42., 48., 54.],<br>       [ 7., 14., 21., 28., 35., 42., 49., 56., 63.],<br>       [ 8., 16., 24., 32., 40., 48., 56., 64., 72.],<br>       [ 9., 18., 27., 36., 45., 54., 63., 72., 81.]])</p><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><h3 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h3><div class="table-container"><table><thead><tr><th>算术</th><th>函数</th></tr></thead><tbody><tr><td>y = x1 + x2</td><td>add(x1, x2 [, y])</td></tr><tr><td>y = x1 - x2</td><td>subtract(x1, x2 [, y])</td></tr><tr><td>y = x1 * x2</td><td>multiply (x1, x2 [, y])</td></tr><tr><td>y = x1 / x2</td><td>divide (x1, x2 [, y]), 如果两个数组的元素为整数，那么用整数除法</td></tr><tr><td>y = x1 / x2</td><td>true_divide (x1, x2 [, y]), 总是返回精确的商</td></tr><tr><td>y = x1 // x2</td><td>floor_divide (x1, x2 [, y]), 总是对返回值取整</td></tr><tr><td>y = - x</td><td>negative(x [,y])</td></tr><tr><td>y = x1 ** x 2</td><td>power(x1, x2 [, y])</td></tr><tr><td>y = x1 % x2</td><td>remainder(x1, x2 [, y]),或mod(x1, x2, [, y])</td></tr></tbody></table></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.arange(4)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([0, 1, 2, 3])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">b = a+4</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>array([4, 5, 6, 7])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a*2</span><br></pre></td></tr></table></figure><p>array([0, 2, 4, 6])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c = a + b  #元素级操作，对应位置元素运算组成新数组</span><br><span class="line">c</span><br></pre></td></tr></table></figure><p>array([ 4,  6,  8, 10])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c-a</span><br></pre></td></tr></table></figure><p>array([4, 5, 6, 7])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a * np.sin(b)             #正弦曲线</span><br></pre></td></tr></table></figure><p>array([-0.        , -0.95892427, -0.558831  ,  1.9709598 ])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a * np.sqrt(b)            #平方根</span><br></pre></td></tr></table></figure><p>array([0.        , 2.23606798, 4.89897949, 7.93725393])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = np.arange(0,9).reshape(3,3)</span><br><span class="line">A</span><br></pre></td></tr></table></figure><p>array([[0, 1, 2],<br>       [3, 4, 5],<br>       [6, 7, 8]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">B = np.ones((3,3))</span><br><span class="line">B</span><br></pre></td></tr></table></figure><p>array([[1., 1., 1.],<br>       [1., 1., 1.],<br>       [1., 1., 1.]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A*B</span><br></pre></td></tr></table></figure><p>array([[0., 1., 2.],<br>       [3., 4., 5.],<br>       [6., 7., 8.]])</p><h3 id="矩阵积"><a href="#矩阵积" class="headerlink" title="矩阵积"></a>矩阵积</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.dot(A,B)</span><br></pre></td></tr></table></figure><p>array([[ 3.,  3.,  3.],<br>       [12., 12., 12.],<br>       [21., 21., 21.]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A.dot(B)</span><br></pre></td></tr></table></figure><p>array([[ 3.,  3.,  3.],<br>       [12., 12., 12.],<br>       [21., 21., 21.]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">B.dot(A)</span><br></pre></td></tr></table></figure><p>array([[ 9., 12., 15.],<br>       [ 9., 12., 15.],<br>       [ 9., 12., 15.]])</p><h3 id="自增自减"><a href="#自增自减" class="headerlink" title="自增自减"></a>自增自减</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.arange(4)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([0, 1, 2, 3])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a += 1</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([1, 2, 3, 4])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a -= 1</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([0, 1, 2, 3])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a *= 2</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([0, 2, 4, 6])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a+=1</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([1, 3, 5, 7])</p><h3 id="通用函数"><a href="#通用函数" class="headerlink" title="通用函数"></a>通用函数</h3><p>通用函数（ufunc）是一种对ndarray中的数据执行元素级运算的函数。</p><h4 id="一元ufunc"><a href="#一元ufunc" class="headerlink" title="一元ufunc"></a>一元ufunc</h4><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>abs、fabs</td><td>计算整数、浮点数或复数的绝对值</td></tr><tr><td>sqrt</td><td>计算各元素平方根</td></tr><tr><td>square</td><td>计算各元素平方</td></tr><tr><td>exp</td><td>计算各元素的指数</td></tr><tr><td>log、log10、log2、log1p</td><td>分别为自然对数(底数为e)、底数为10的log、底数为2的log、log(1+x)</td></tr><tr><td>sign</td><td>计算各元素的正负号</td></tr><tr><td>ceil</td><td>计算各元素的ceiling值，即大于等于该值的最小整数</td></tr><tr><td>floor</td><td>计算各元素的floor值，即小于等于该值的最大整数</td></tr><tr><td>rint</td><td>将各元素值四舍五入到最接近的</td></tr><tr><td>modf</td><td>将数组的小数和整数部分以两个独立的数组形式返回</td></tr><tr><td>isnan</td><td>“哪些值是NaN” 返回布尔值</td></tr><tr><td>isfinite、isinf</td><td>“哪些元素是有穷的” “哪些元素是无穷的”</td></tr><tr><td>cos、cosh、sin、sinh、tan、tanh</td><td>普通型和双曲型三角函数</td></tr><tr><td>arccos、arccosh、arcsin、arcsinh、arctan、arctanh</td><td>反三角函数</td></tr><tr><td>logical_not</td><td>计算各元素not x的真值，相当于</td></tr></tbody></table></div><h4 id="二元ufunc"><a href="#二元ufunc" class="headerlink" title="二元ufunc"></a>二元ufunc</h4><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>add</td><td>元素相加</td></tr><tr><td>subtract</td><td>从第一个数组中减去第二个数组的元算</td></tr><tr><td>multiply</td><td>元素相乘</td></tr><tr><td>divide、floor_divide</td><td>除法或向下圆整除法（丢弃余数）</td></tr><tr><td>power</td><td>A的b次方</td></tr><tr><td>maximum、fmax</td><td>元素级的最大值计算。fmax将忽略nan</td></tr><tr><td>minimum、fmin</td><td>元素级的最小值计算。fmin将忽略nan</td></tr><tr><td>mod</td><td>元素级的求模计算（除法）</td></tr><tr><td>copysign</td><td>将第二个数组中的值的符号复制给第一个数组中的</td></tr><tr><td>greater、greater_equal、less、less_equal、equal、not_equal</td><td>执行元素级的比较运算，产生布尔型数组</td></tr><tr><td>logical_and、logical_or、logical_xor</td><td>执行元素级的真值逻辑运算。相当于&amp; \</td></tr></tbody></table></div><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.arange(1,5)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([1, 2, 3, 4])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">b = np.arange(1,5)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>array([1, 2, 3, 4])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.add(a,b)</span><br></pre></td></tr></table></figure><p>array([2, 4, 6, 8])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.sqrt(a)</span><br></pre></td></tr></table></figure><p>array([1.        , 1.41421356, 1.73205081, 2.        ])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.log(a)</span><br></pre></td></tr></table></figure><p>array([0.        , 0.69314718, 1.09861229, 1.38629436])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.sin(a)</span><br></pre></td></tr></table></figure><p>array([ 0.84147098,  0.90929743,  0.14112001, -0.7568025 ])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x = np.random.rand(12).reshape(3,4)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p>array([[0.07660223, 0.88255407, 0.24269254, 0.18597141],<br>       [0.25274604, 0.80124666, 0.9287589 , 0.91310848],<br>       [0.28050844, 0.17827769, 0.98518043, 0.05057346]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.sort(x)   #每行</span><br></pre></td></tr></table></figure><p>array([[0.07660223, 0.18597141, 0.24269254, 0.88255407],<br>       [0.25274604, 0.80124666, 0.91310848, 0.9287589 ],<br>       [0.05057346, 0.17827769, 0.28050844, 0.98518043]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.sort(x,axis = 0)</span><br></pre></td></tr></table></figure><p>array([[0.07660223, 0.17827769, 0.24269254, 0.05057346],<br>       [0.25274604, 0.80124666, 0.9287589 , 0.18597141],<br>       [0.28050844, 0.88255407, 0.98518043, 0.91310848]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">j = np.argsort(x)   #每行，索引</span><br><span class="line">j</span><br></pre></td></tr></table></figure><p>array([[0, 3, 2, 1],<br>       [0, 1, 3, 2],<br>       [3, 1, 0, 2]], dtype=int64)</p><h3 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.array([3.3,4.4,5.5,6.6,7.7],dtype=&apos;f8&apos;)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([3.3, 4.4, 5.5, 6.6, 7.7])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.sum()</span><br></pre></td></tr></table></figure><p>27.499999999999996</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.min()</span><br></pre></td></tr></table></figure><p>3.3</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.max()</span><br></pre></td></tr></table></figure><p>7.7</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.mean()</span><br></pre></td></tr></table></figure><p>5.499999999999999</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.std()</span><br></pre></td></tr></table></figure><p>1.5556349186104046</p><h3 id="索引机制、切片和迭代方法"><a href="#索引机制、切片和迭代方法" class="headerlink" title="索引机制、切片和迭代方法"></a>索引机制、切片和迭代方法</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.arange(10,16)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([10, 11, 12, 13, 14, 15])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a[4]</span><br></pre></td></tr></table></figure><p>14</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a[-1]</span><br></pre></td></tr></table></figure><p>15</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a[:]</span><br></pre></td></tr></table></figure><p>array([10, 11, 12, 13, 14, 15])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a[1:3]</span><br></pre></td></tr></table></figure><p>array([11, 12])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a[1:5:2]</span><br></pre></td></tr></table></figure><p>array([11, 13])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = np.arange(10,19).reshape(3,3)</span><br><span class="line">A</span><br></pre></td></tr></table></figure><p>array([[10, 11, 12],<br>       [13, 14, 15],<br>       [16, 17, 18]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A[1,2]</span><br></pre></td></tr></table></figure><p>15</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A[0:]</span><br></pre></td></tr></table></figure><p>array([[10, 11, 12],<br>       [13, 14, 15],<br>       [16, 17, 18]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A[:,0]</span><br></pre></td></tr></table></figure><p>array([10, 13, 16])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A[0:2,0:2]</span><br></pre></td></tr></table></figure><p>array([[10, 11],<br>       [13, 14]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A[[0,2],0:2]         #抽取行或列的索引不连续，可以吧这几个索引放在数组中</span><br></pre></td></tr></table></figure><p>array([[10, 11],<br>       [16, 17]])</p><h3 id="数组迭代"><a href="#数组迭代" class="headerlink" title="数组迭代"></a>数组迭代</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for row in A:</span><br><span class="line">    print(row)</span><br></pre></td></tr></table></figure><p>[10 11 12]<br>[13 14 15]<br>[16 17 18]</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for item in A.flat:            #遍历每一个元素，A.flat</span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure><p>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18</p><h4 id="除了for循环，Numpy提供了更为优雅的遍历方法"><a href="#除了for循环，Numpy提供了更为优雅的遍历方法" class="headerlink" title="除了for循环，Numpy提供了更为优雅的遍历方法"></a>除了for循环，Numpy提供了更为优雅的遍历方法</h4><p>通常用函数处理行、列或单个元素时，需要用到遍历。如果想用聚合函数处理每一列或行，返回一个数值作为结果，做好用纯NumPy方法处理循环：apply_along_axis()函数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.apply_along_axis(np.mean,axis = 0,arr = A )  #axis 为0 按列</span><br></pre></td></tr></table></figure><p>array([13., 14., 15.])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.apply_along_axis(np.mean,axis = 1,arr = A )  #axis 为1 按行</span><br></pre></td></tr></table></figure><p>array([11., 14., 17.])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def foo(x):</span><br><span class="line">    return x/2</span><br><span class="line">np.apply_along_axis(foo,axis = 0,arr = A )</span><br></pre></td></tr></table></figure><p>array([[5. , 5.5, 6. ],<br>       [6.5, 7. , 7.5],<br>       [8. , 8.5, 9. ]])</p><h3 id="条件和布尔数组"><a href="#条件和布尔数组" class="headerlink" title="条件和布尔数组"></a>条件和布尔数组</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = np.random.random((4,4))</span><br><span class="line">A</span><br></pre></td></tr></table></figure><p>array([[0.06191449, 0.69862293, 0.60835369, 0.46886347],<br>       [0.06462235, 0.76134531, 0.22378327, 0.13396092],<br>       [0.81113357, 0.84190968, 0.97530762, 0.55843035],<br>       [0.89516065, 0.42526586, 0.54832821, 0.63796767]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A&lt;0.5</span><br></pre></td></tr></table></figure><p>array([[ True, False, False,  True],<br>       [ True, False,  True,  True],<br>       [False, False, False, False],<br>       [False,  True, False, False]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A[A&lt;0.5]</span><br></pre></td></tr></table></figure><p>array([0.06191449, 0.46886347, 0.06462235, 0.22378327, 0.13396092,<br>       0.42526586])</p><h3 id="形状变换"><a href="#形状变换" class="headerlink" title="形状变换"></a>形状变换</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.random.random(12)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([0.20564606, 0.13384151, 0.14979041, 0.52310893, 0.29431663,0.21416307, 0.97855221, 0.96023057, 0.88113124, 0.70537608,0.2383707 , 0.80332851])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = a.reshape(3,4)    #返回新数组，创建新对象</span><br><span class="line">A</span><br></pre></td></tr></table></figure><p>array([[0.20564606, 0.13384151, 0.14979041, 0.52310893],<br>       [0.29431663, 0.21416307, 0.97855221, 0.96023057],<br>       [0.88113124, 0.70537608, 0.2383707 , 0.80332851]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.shape = 3,4    #a.shape = （3,4）</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([[0.20564606, 0.13384151, 0.14979041, 0.52310893],<br>       [0.29431663, 0.21416307, 0.97855221, 0.96023057],<br>       [0.88113124, 0.70537608, 0.2383707 , 0.80332851]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = a.ravel()</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([0.20564606, 0.13384151, 0.14979041, 0.52310893, 0.29431663,<br>       0.21416307, 0.97855221, 0.96023057, 0.88113124, 0.70537608,<br>       0.2383707 , 0.80332851])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.shape = (3,4)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([[0.20564606, 0.13384151, 0.14979041, 0.52310893],<br>       [0.29431663, 0.21416307, 0.97855221, 0.96023057],<br>       [0.88113124, 0.70537608, 0.2383707 , 0.80332851]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a.shape = 12</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>array([0.20564606, 0.13384151, 0.14979041, 0.52310893, 0.29431663,<br>       0.21416307, 0.97855221, 0.96023057, 0.88113124, 0.70537608,<br>       0.2383707 , 0.80332851])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A.transpose()</span><br></pre></td></tr></table></figure><p>array([[0.20564606, 0.29431663, 0.88113124],<br>       [0.13384151, 0.21416307, 0.70537608],<br>       [0.14979041, 0.97855221, 0.2383707 ],<br>       [0.52310893, 0.96023057, 0.80332851]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A.T</span><br></pre></td></tr></table></figure><p>array([[0.20564606, 0.29431663, 0.88113124],<br>       [0.13384151, 0.21416307, 0.70537608],<br>       [0.14979041, 0.97855221, 0.2383707 ],<br>       [0.52310893, 0.96023057, 0.80332851]])</p><h3 id="数组操作"><a href="#数组操作" class="headerlink" title="数组操作"></a>数组操作</h3><h4 id="连接数组"><a href="#连接数组" class="headerlink" title="连接数组"></a>连接数组</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = np.ones((3,3))</span><br><span class="line">B = np.zeros((3,3))</span><br><span class="line">A</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[1., 1., 1.],</span><br><span class="line">       [1., 1., 1.],</span><br><span class="line">       [1., 1., 1.]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">B</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0., 0., 0.],</span><br><span class="line">       [0., 0., 0.],</span><br><span class="line">       [0., 0., 0.]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.vstack((A,B))</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[1., 1., 1.],</span><br><span class="line">       [1., 1., 1.],</span><br><span class="line">       [1., 1., 1.],</span><br><span class="line">       [0., 0., 0.],</span><br><span class="line">       [0., 0., 0.],</span><br><span class="line">       [0., 0., 0.]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.hstack((A,B))</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[1., 1., 1., 0., 0., 0.],</span><br><span class="line">       [1., 1., 1., 0., 0., 0.],</span><br><span class="line">       [1., 1., 1., 0., 0., 0.]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c = np.arange(16).reshape(4,4)</span><br><span class="line">c</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 0,  1,  2,  3],</span><br><span class="line">       [ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.array([0,1,2])</span><br><span class="line">b = np.array([3,4,5])</span><br><span class="line">c = np.array([6,7,8])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.column_stack((a,b,c))</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0, 3, 6],</span><br><span class="line">       [1, 4, 7],</span><br><span class="line">       [2, 5, 8]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.row_stack((a,b,c))</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0, 1, 2],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [6, 7, 8]])</span><br></pre></td></tr></table></figure></li></ul><h3 id="数组切分"><a href="#数组切分" class="headerlink" title="数组切分"></a>数组切分</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = np.arange(16).reshape((4,4))</span><br><span class="line">A</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 0,  1,  2,  3],</span><br><span class="line">       [ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[B,C] = np.hsplit(A,2)</span><br><span class="line">B</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 0,  1],</span><br><span class="line">       [ 4,  5],</span><br><span class="line">       [ 8,  9],</span><br><span class="line">       [12, 13]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 2,  3],</span><br><span class="line">       [ 6,  7],</span><br><span class="line">       [10, 11],</span><br><span class="line">       [14, 15]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[B,C] = np.vsplit(A,2)</span><br><span class="line">B</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0, 1, 2, 3],</span><br><span class="line">       [4, 5, 6, 7]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[A1,A2,A3] = np.split(A,[1,3],axis=1)   #axis = 0 按行切分，axis = 1 按列切分</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A1</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 0],</span><br><span class="line">       [ 4],</span><br><span class="line">       [ 8],</span><br><span class="line">       [12]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A2</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 1,  2],</span><br><span class="line">       [ 5,  6],</span><br><span class="line">       [ 9, 10],</span><br><span class="line">       [13, 14]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A3</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 3],</span><br><span class="line">       [ 7],</span><br><span class="line">       [11],</span><br><span class="line">       [15]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[A1,A2,A3] = np.split(A,[1,3],axis=0)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A1</span><br></pre></td></tr></table></figure><p>array([[0, 1, 2, 3]])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A2</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A3</span><br></pre></td></tr></table></figure><p>array([[12, 13, 14, 15]])</p><h3 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h3><blockquote><p>广播机制这一操作实现了对两个或以上数组进行运算或用函数处理，即使这些数组形状并不完全相同。并不是所有的维度都要彼此兼容才符合广播机制的要求，但它们必须满足一定的条件。</p><p>若两个数组的各维度兼容，也就是两个数组的每一维等长，或其中一个数组为一维，那么广播机制就适用。如果这两个条件都不能满足，Numpy就会抛出异常，说两个数组不兼容。</p><p>广播机制两条规则。第一条是为缺失的维度补上个1.如果这时满足兼容性条件，就可以应用光比机制。再来看第二条规则。 第二条规则鉴定缺失元素（一维）都用已有值进行了补充。</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A = np.arange(16).reshape(4,4)</span><br><span class="line">b = np.arange(4)</span><br><span class="line">A</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 0,  1,  2,  3],</span><br><span class="line">       [ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">b</span><br></pre></td></tr></table></figure><p>array([0, 1, 2, 3])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A + b</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 0,  2,  4,  6],</span><br><span class="line">       [ 4,  6,  8, 10],</span><br><span class="line">       [ 8, 10, 12, 14],</span><br><span class="line">       [12, 14, 16, 18]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">m = np.arange(6).reshape(3,1,2)</span><br><span class="line">n = np.arange(6).reshape(3,2,1)</span><br><span class="line">m</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[0, 1]],</span><br><span class="line"></span><br><span class="line">       [[2, 3]],</span><br><span class="line"></span><br><span class="line">       [[4, 5]]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[0],</span><br><span class="line">        [1]],</span><br><span class="line"></span><br><span class="line">       [[2],</span><br><span class="line">        [3]],</span><br><span class="line"></span><br><span class="line">       [[4],</span><br><span class="line">        [5]]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">m + n</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[[ 0,  1],</span><br><span class="line">        [ 1,  2]],</span><br><span class="line"></span><br><span class="line">       [[ 4,  5],</span><br><span class="line">        [ 5,  6]],</span><br><span class="line"></span><br><span class="line">       [[ 8,  9],</span><br><span class="line">        [ 9, 10]]])</span><br></pre></td></tr></table></figure></li></ul><h3 id="结构化数组"><a href="#结构化数组" class="headerlink" title="结构化数组"></a>结构化数组</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">structarray = np.array([(1,&apos;First&apos;,0.5,1+2j),(2,&apos;Second&apos;,1.3,2-2j),(3,&apos;Third&apos;,0.8,1+3j)],dtype=(&apos;i2,a6,f4,c8&apos;))</span><br><span class="line">structarray</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([(1, b&apos;First&apos;, 0.5, 1.+2.j), (2, b&apos;Second&apos;, 1.3, 2.-2.j),</span><br><span class="line">       (3, b&apos;Third&apos;, 0.8, 1.+3.j)],</span><br><span class="line">      dtype=[(&apos;f0&apos;, &apos;&lt;i2&apos;), (&apos;f1&apos;, &apos;S6&apos;), (&apos;f2&apos;, &apos;&lt;f4&apos;), (&apos;f3&apos;, &apos;&lt;c8&apos;)])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">structarray = np.array([(1,&apos;First&apos;,0.5,1+2j),(2,&apos;Second&apos;,1.3,2-2j),(3,&apos;Third&apos;,0.8,1+3j)])</span><br><span class="line">structarray</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[&apos;1&apos;, &apos;First&apos;, &apos;0.5&apos;, &apos;(1+2j)&apos;],</span><br><span class="line">       [&apos;2&apos;, &apos;Second&apos;, &apos;1.3&apos;, &apos;(2-2j)&apos;],</span><br><span class="line">       [&apos;3&apos;, &apos;Third&apos;, &apos;0.8&apos;, &apos;(1+3j)&apos;]], dtype=&apos;&lt;U11&apos;)</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">structarray = np.array([(1,&apos;First&apos;,0.5,1+2j),(2,&apos;Second&apos;,1.3,2-2j),(3,&apos;Third&apos;,0.8,1+3j)],dtype=[(&apos;id&apos;,&apos;&lt;i2&apos;),(&apos;position&apos;,&apos;S6&apos;),(&apos;value&apos;,&apos;f4&apos;),(&apos;complex&apos;,&apos;c8&apos;)])</span><br><span class="line">structarray</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([(1, b&apos;First&apos;, 0.5, 1.+2.j), (2, b&apos;Second&apos;, 1.3, 2.-2.j),</span><br><span class="line">       (3, b&apos;Third&apos;, 0.8, 1.+3.j)],</span><br><span class="line">      dtype=[(&apos;id&apos;, &apos;&lt;i2&apos;), (&apos;position&apos;, &apos;S6&apos;), (&apos;value&apos;, &apos;&lt;f4&apos;), (&apos;complex&apos;, &apos;&lt;c8&apos;)])</span><br></pre></td></tr></table></figure></li></ul><h3 id="数组数据文件的读写"><a href="#数组数据文件的读写" class="headerlink" title="数组数据文件的读写"></a>数组数据文件的读写</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data = np.random.random(16).reshape(4,4)</span><br><span class="line">data</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0.51264409, 0.4027414 , 0.49030108, 0.60320778],</span><br><span class="line">       [0.09145262, 0.15780606, 0.43957007, 0.46891392],</span><br><span class="line">       [0.60041983, 0.93856545, 0.22183402, 0.51324425],</span><br><span class="line">       [0.76605488, 0.74672403, 0.02454652, 0.85436632]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.save(&apos;save_date&apos;,data)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">loaded_data = np.load(&apos;save_date.npy&apos;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">loaded_data</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[0.51264409, 0.4027414 , 0.49030108, 0.60320778],</span><br><span class="line">       [0.09145262, 0.15780606, 0.43957007, 0.46891392],</span><br><span class="line">       [0.60041983, 0.93856545, 0.22183402, 0.51324425],</span><br><span class="line">       [0.76605488, 0.74672403, 0.02454652, 0.85436632]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data = np.array([(1., 123., 1.4, 23.), (2., 110., 0.5, 18.), (3., 164., 2.1, 19.)],</span><br><span class="line">      dtype=[(&apos;id&apos;, &apos;&lt;f8&apos;), (&apos;value1&apos;, &apos;&lt;f8&apos;), (&apos;value2&apos;, &apos;&lt;f8&apos;), (&apos;value3&apos;, &apos;&lt;f8&apos;)])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.savetxt(&apos;datas.csv&apos;,data,delimiter=&apos;,&apos;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.loadtxt(&apos;datas.csv&apos;,delimiter=&apos;,&apos;)</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[  1. , 123. ,   1.4,  23. ],</span><br><span class="line">       [  2. , 110. ,   0.5,  18. ],</span><br><span class="line">       [  3. , 164. ,   2.1,  19. ]])</span><br></pre></td></tr></table></figure></li></ul><p>读写文本格式的数据（如TXT或CSV）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data = np.genfromtxt(&apos;data.csv&apos;,delimiter=&apos;,&apos;,names = True) #文件名，分割值的字符，是否含有标题</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([(1., 123., 1.4, 23.), (2., 110., 0.5, 18.), (3., 164., 2.1, 19.)],</span><br><span class="line">      dtype=[(&apos;id&apos;, &apos;&lt;f8&apos;), (&apos;value1&apos;, &apos;&lt;f8&apos;), (&apos;value2&apos;, &apos;&lt;f8&apos;), (&apos;value3&apos;, &apos;&lt;f8&apos;)])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data[&apos;id&apos;]</span><br></pre></td></tr></table></figure><p>array([1., 2., 3.])</p><h3 id="np-where函数"><a href="#np-where函数" class="headerlink" title="np.where函数"></a>np.where函数</h3><p>np.where函数是三元表达式 x if condition else y 的矢量化版本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x = np.array([2,3,4,5,6,])</span><br><span class="line">y = np.array([10,11,12,13,14])</span><br><span class="line"></span><br><span class="line">condition =np.array([True,False,True,True,False])</span><br><span class="line"></span><br><span class="line">z = np.where(condition,x,y)</span><br><span class="line">z</span><br></pre></td></tr></table></figure><p>array([ 2, 11,  4,  5, 14])</p><h4 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data =np.array([[1,2,np.NaN,4],[np.NaN,2,3,4]])</span><br><span class="line">data</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[ 1.,  2., nan,  4.],</span><br><span class="line">       [nan,  2.,  3.,  4.]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.isnan(data)</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[False, False,  True, False],</span><br><span class="line">       [ True, False, False, False]])</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.where(np.isnan(data),0,data)</span><br></pre></td></tr></table></figure><ul><li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array([[1., 2., 0., 4.],</span><br><span class="line">       [0., 2., 3., 4.]])</span><br></pre></td></tr></table></figure></li></ul><h4 id="数组去重"><a href="#数组去重" class="headerlink" title="数组去重"></a>数组去重</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">np.unique([1, 1, 2, 2, 3, 3])</span><br></pre></td></tr></table></figure><p>array([1, 2, 3])</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = np.array([[1, 1], [2, 3]])</span><br><span class="line">np.unique(a)</span><br></pre></td></tr></table></figure><p>array([1, 2, 3])</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Numpy是用Python进行科学计算，尤其是数据分析时，所用到的一个基础库。它是大量python数学和科学计算包的基础，比如后面要讲到的pandas库就用到了Numpy。pandas库专门用于数据分析，充分借鉴了Python标准库Numpy的相关
      
    
    </summary>
    
      <category term="工具" scheme="https://janvia.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="numpy" scheme="https://janvia.github.io/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>聚类</title>
    <link href="https://janvia.github.io/2019/01/23/%E8%81%9A%E7%B1%BB/"/>
    <id>https://janvia.github.io/2019/01/23/聚类/</id>
    <published>2019-01-23T02:23:37.000Z</published>
    <updated>2019-01-23T06:59:11.470Z</updated>
    
    <content type="html"><![CDATA[<h3 id="聚类的概念"><a href="#聚类的概念" class="headerlink" title="聚类的概念"></a>聚类的概念</h3><p>聚类是一种无监督机器学习方法，它基于数据的内部结构寻找观察样本的自然族群（即集群），常用于新闻分类、推荐系统等。聚类的特点是训练数据没有标注，通常使用数据可视化评价结果。</p><p>聚类分析仅根据在数据中发现的描述对象及其关系的信息，将数据对象分组。其目标是，组内的对象相互之间是相似的（相关的），而不同组中的对象是不同的（不相关的）。组内的相似性（同质性）越大，组间差别越大，聚类就越好。</p><h3 id="聚类的方法"><a href="#聚类的方法" class="headerlink" title="聚类的方法"></a>聚类的方法</h3><p>聚类的常用方法包括：</p><ul><li><strong>划分聚类法</strong>，<strong>K均值</strong>:是基于原型的、划分的聚类技术。它试图发现用户指定个数K的簇（由质心代表）。</li><li><strong>层次聚类。凝聚的层次聚类：</strong>开始，每个点作为一个单点簇；然后，重复地合并两个最靠近的簇，直到产生单个的、包含所有点的簇。</li><li><strong>基于密度的聚类，</strong> <strong>DBSCAN</strong>是一种产生划分聚类的基于密度的聚类算法，簇的个数由算法自动地确定。低密度区域中的点被视为噪声而忽略，因此DBSCAN不产生完全聚类。</li></ul><h3 id="常用的聚类数据集"><a href="#常用的聚类数据集" class="headerlink" title="常用的聚类数据集"></a>常用的聚类数据集</h3><p>常用的聚类数据集包括</p><ul><li>scikit-learn blob: 简单聚类</li><li>scikit-learn circle: 非线性可分数据集</li><li>scikit-learn moon: 更复杂的数据集</li></ul><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类.png" alt=""></p><h3 id="聚类的性能度量"><a href="#聚类的性能度量" class="headerlink" title="聚类的性能度量"></a>聚类的性能度量</h3><p>我们希望聚类结果的<strong>“簇内相似度”高</strong>且<strong>“簇间相似度”低</strong>。</p><p>其性能度量大致有两类：</p><ul><li><p>将聚类结果与某个“参考模型”进行比较。称为“外部指标”。</p></li><li><p>直接考查聚类结果而不利于任何参考模型。称为“内部指标”。</p></li></ul><h3 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h3><p>对数据集<script type="math/tex">D={x_1,x_2,…,x_m}</script>,假定通过聚类给出的簇划分为<script type="math/tex">C=C_1,C_2,…,C_k</script>,参考模型给出的簇划分为<script type="math/tex">C’=C_1^T,C_2^T,…,C_s^T</script>。相应的，令λ与<script type="math/tex">λ^T</script>分别表示与<script type="math/tex">C</script>和<script type="math/tex">C^T</script>对应的簇标记向量。注意的是，参考模型给出的划分类别数量不一定等于通过聚类得到的数量。</p><p>样本两两配对：</p><p>1.<script type="math/tex">a=\mid SS \mid ,SS={(x_i,x_j)\mid \lambda_i = \lambda_j,\lambda_i^T=\lambda_j^T,i<j}</script></p><p>2.<script type="math/tex">b=\mid SD \mid ,SD={(x_i,x_j)\mid \lambda_i = \lambda_j,\lambda_i^T\neq \lambda_j^T,i<j}</script></p><p>3.<script type="math/tex">c=\mid DS \mid ,DS={(x_i,x_j)\mid \lambda_i \neq \lambda_j,\lambda_i^T=\lambda_j^T,i<j}</script></p><p>4.<script type="math/tex">d=\mid DD \mid ,DD={(x_i,x_j)\mid \lambda_i \neq \lambda_j,\lambda_i^T \neq \lambda_j^T,i<j}</script></p><p>集合SS包含了C中隶属于相同簇且在C′中也隶属于相同簇的样本对，集合SD包含了在C中隶属于相同簇但在$C_T$中隶属于不同簇的样本对 .</p><p>Jaccard系数：<script type="math/tex">JC=\frac{a}{a+b+c}</script></p><p>FM指数：<script type="math/tex">FMI=\sqrt{\frac{a}{a+b}\frac{a}{a+c}}</script></p><p>Rand指数：<script type="math/tex">RI=\frac{2(a+d)}{m(m-1)}</script></p><p>上述性能度量的结果值均在[0,1]区间，值越大越好。</p><h3 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h3><p>考虑聚类结果的簇划分<script type="math/tex">C=C_1,C_2,…,C_k</script>，定义:</p><ol><li><script type="math/tex; mode=display">avg(C)=\frac{2}{\mid C \mid(\mid C \mid -1)}\sum_{1 \leq i < j \leq \mid C \mid}dist(x_i,x_j)</script></li><li><script type="math/tex; mode=display">diam(C)=\max_{1 \leq i <j \leq \mid C \mid}dist(x_i,x_j)</script></li><li><script type="math/tex; mode=display">d_\min(C_i,C_j)=\min_{x_i \in C_i , x_j \in C_j} dist(x_i,x_j)</script></li><li><script type="math/tex; mode=display">d_{cen}(C_i,C_j)=dist(\mu_i,\mu_j)</script></li></ol><p>我们在上面的式子中，dist是计算两个样本之间的距离，$\mu$代表簇的中心点<script type="math/tex">\mu=\frac{\sum_{1 \leq i \leq \mid C \mid x_i}}{\mid C \mid}</script> ，avg(C)代表簇内样本间的平均距离，diam(C)对应与簇C内样本间的最远距离，<script type="math/tex">d_{min}(C_i,C_j)</script>对应与簇 i 和簇 j 最近样本间的距离；<script type="math/tex">d_{cen}(C_i,C_j)</script>对应与簇 i 和 j 中心点间的距离。</p><p>基于上面的指标，推出下面几个内部指标</p><ol><li><script type="math/tex; mode=display">DBI=\frac{1}{k}\sum\limits_{i=1}^k\max\limits_{j \neq i}(\frac{avg(C_i)+avg(C_j)}{d_{cen}(\mu_i,\mu_j)})</script></li><li><script type="math/tex; mode=display">DI=\min\limits_{1 \leq i \leq k} \{ \min\limits_{j \neq i}(\frac{d_{min}(C_i,C_j)}{\max_{1\leq l \leq k} diam(C_l)}) \}</script></li></ol><p>显然，DBI的值越小越好，DI值越大越好</p><h3 id="相似度-距离度量"><a href="#相似度-距离度量" class="headerlink" title="相似度/距离度量"></a>相似度/距离度量</h3><p>“距离度量”需满足一些基本性质，如<strong>非负性、同一性、对称性和直递性</strong>。最常用的是闵可夫斯基距离、欧氏距离(p=2)和曼哈顿距离(p=1)（后两者其实都是闵可夫斯基距离的特例）。</p><p>闵可夫斯基距离只可用于有序属性，对无序属性可采用VDM（Value Difference Metric）。</p><p>计算方法总结：</p><ul><li><p>闵可夫斯基距离Minkowski/欧式距离：<script type="math/tex">dist(X,Y)=(\sum_{i=1}^n|x_i-y_i|^p)^\frac1p</script></p></li><li><p>杰卡德相似系数(Jaccard): <script type="math/tex">J(A,B)=\frac{|A\cap B|}{|A\cup B|}</script></p></li><li><p>余弦相似度(cosine similarity):<script type="math/tex">cos(\theta)=\frac{a^Tb}{|a|\cdot |b|}</script></p></li><li><p>Pearson相似系数: <script type="math/tex">\rho_{xy}=\frac{cov(x,y)}{\sigma_x\sigma_y}=\frac{E[(x-u_x)(y-u_y)]}{\sigma_x\sigma_y}=\frac{\sum_{i=1}^n (x_i-u_x)(y_i-u_y) }{\sqrt{\sum_{i=1}^n(x_i-u_x)^2} \sqrt{\sum_{i=1}^n(y_i-u_y)^2}}</script></p></li><li><p>相对熵（K-L距离）：<script type="math/tex">D(P||q)=\sum_xp(x)log\frac{p(x)}{q(x)}=E_{p(x)}log\frac{p(x)}{q(x)}</script></p></li><li><p>Hellinger距离：<script type="math/tex">D_a(p||q)=\frac{2}{1-a^2}(1-\int p(x)^\frac{1+a}{2}\cdot q(x)^\frac{1-a}{2}dx)</script></p></li></ul><h3 id="聚类的基本思想"><a href="#聚类的基本思想" class="headerlink" title="聚类的基本思想"></a>聚类的基本思想</h3><p>给定一个有N个对象的数据集，构造数据的K个簇，$k≤n$,满足下列条件：</p><ul><li>每一个簇至少包含一个对象</li><li>每一个对象属于且仅属于一个簇</li><li>将满足上述条件的K个簇称作一个合理的划分</li></ul><p><strong>基本思想</strong>：对于给定的类别数目K，首先给出初始划分，通过迭代改变样本和簇的隶属关系，使得每一次改进之后的划分方案都比前一次好。</p><h3 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h3><p>原型聚类亦称“基于原型的聚类”，假设聚类结构能通过一组原型（原型是指样本空间中具有代表性的点）刻画。</p><p>常用的方法包括</p><ul><li>k均值算法</li><li>学习向量化</li><li>高斯混合聚类（基于概率模型）</li></ul><h3 id="K-Means-聚类"><a href="#K-Means-聚类" class="headerlink" title="K-Means 聚类"></a>K-Means 聚类</h3><p><strong>K-Means</strong>算法的基本思想是初始随机给定K个簇中心，按照最邻近原则把待分类样本点分到各个簇。然后按平均法重新计算各个簇的质心(这个点可以不是样本点)，从而确定新的簇心。一直迭代，直到簇心的移动距离小于某个给定的值。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类1.png" alt=""></p><p>K-Means聚类算法步骤:</p><p>1、给定数据</p><p>2、确定类别数K（如K=5），并初始化K个类的中心（如随机选择K个点）</p><p>3、对每个数据点，计算离其最近的类（使得每个类拥有自己的一些数据）</p><script type="math/tex; mode=display">C_i^{(t)}=\arg \limits_{k} \min(\mu_k-x_i)^2</script><p>4、对每个类，计算其所有数据的中心，并跳到新的中心</p><script type="math/tex; mode=display">\mu_k^{(t+1)}=\arg \limits_{\mu} \min \sum_{i \in C(k)}(\mu-x_i)^2</script><p>– 等价于$µ_i$ 为类中数据的均值</p><p>5、重复3~4步，知道数据点所属类别类不再改变</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类3.png" alt=""></p><h4 id="K-means的优化目标"><a href="#K-means的优化目标" class="headerlink" title="K-means的优化目标"></a>K-means的优化目标</h4><p>均值$\mu$和数据点所属集合Ｃ的势能函数为：</p><script type="math/tex; mode=display">F(\mu,C)=\sum_{i=1}^N (\mu_{C(i)}-x_i)^2</script><p>-$C_{(i)}$:样本 i 所属的簇</p><p>K-means的优化目标：</p><script type="math/tex; mode=display">min_\mu min_C F(\mu,C)</script><h4 id="K-means的收敛性"><a href="#K-means的收敛性" class="headerlink" title="K-means的收敛性"></a>K-means的收敛性</h4><p>优化势能函数：</p><script type="math/tex; mode=display">min_\mu min_C F(\mu,C)＝min_\mu min_C \sum_{k=1}^K \sum_{i\in C_{(i)}}(\mu_k-x_i)^2</script><p><strong>坐标下降：</strong></p><ul><li><p>固定$\mu$，优化Ｃ</p></li><li><p>固定Ｃ，优化$\mu$</p></li></ul><p><strong>收敛性</strong>:</p><ul><li><p>若Ｆ有界，会收敛到一个局部极小</p></li><li><p>K-means不保证达到全局最优（收敛，但没有达到全局最优的情况）</p></li></ul><p><strong>解决方案：</strong></p><p>•  仔细寻找初始值<br>– 随机确定第一个类的中心，其他类中心的位置尽量远离已有类的中心<br>– Scikit learn中K-means实现中参数（ init=’k-means++’ ）将初始化 centroids （质心）彼此远离，得到比随机初始化更好的结果。<br>•  重复多次（如10次），每次初始值不同，最后选择使目标函数最小的结果</p><p><strong>如何决定k</strong></p><ul><li><p>尝试不同的 k</p></li><li><p>当 K = 2, SSE = 173.1</p></li><li><p>当 K = 3, SSE = 133.6</p></li><li><p>画出不同K=1 到 6 的误差曲线图<br>-转折点 K=2 较好<br>-有些情况并没有明显的转折点</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类9.png" alt=""></p></li></ul><h3 id="Scikit-learn中的K-means实现"><a href="#Scikit-learn中的K-means实现" class="headerlink" title="Scikit learn中的K-means实现"></a>Scikit learn中的K-means实现</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类10.png" alt=""></p><h3 id="K-centers聚类"><a href="#K-centers聚类" class="headerlink" title="K-centers聚类"></a>K-centers聚类</h3><p>• 亦被称为K-median聚类、 K-mediods聚类</p><p>• 与K-means类似，只是将K-means聚类中的均值换成中值<br>    – 均值极有可能是一个不存在的样本点，不足以代表该簇中    的样本，而中值是一个样本集合中真实存在的一个样本点<br>    – 同时中值相对均值而言，对噪声（孤立点、离群点）不那    么敏感</p><h3 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means++"></a>K-Means++</h3><p>k个初始化的质心的位置选择对最后的聚类结果和运行时间都有很大的影响，因此需要选择合适的k个质</p><p>心。如果仅仅是完全随机的选择，有可能导致算法收敛很慢。K-Means++算法就是对<strong>K-Means随机初始</strong></p><p><strong>化质心的方法的优化</strong>。</p><p>K-Means++的对于初始化质心的优化策略也很简单，如下：</p><p>a)  从输入的数据点集合中随机选择一个点作为第一个聚类中心μ1</p><p>b) 对于数据集中的每一个点xi，计算它与已选择的聚类中心中最近聚类中心的距离 </p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类11.png" alt=""></p><p>c) 选择一个新的数据点作为新的聚类中心，选择的原则是：D(x) 较大的点，被选取作为聚类中心的概率较大</p><p>d) 重复b和c直到选择出k个聚类质心</p><p>e) 利用这k个质心来作为初始化质心去运行标准的K-Means算法 </p><h3 id="Mini-Batch-K-Means"><a href="#Mini-Batch-K-Means" class="headerlink" title="Mini Batch K-Means"></a>Mini Batch K-Means</h3><p>• MiniBatchKMeans 是 K-Means 算法的一个变体：<br>– 使用 mini-batches （小批量）减少计算时间<br>– 目标函数相同<br>– 收敛速度比 K-Means 快，但是结果的质量会降低（在实践中，质量差异可能相当小）</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类12.png" alt=""></p><h3 id="K均值算法"><a href="#K均值算法" class="headerlink" title="K均值算法"></a>K均值算法</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类4.png" alt=""></p><p><strong>k均值常用的邻近度，质心和目标函数</strong>的选择：</p><p>邻近度函数：曼哈顿距离。质心：中位数。目标函数：最小化对象到其簇质心的距离和。</p><p>邻近度函数：平方欧几里德距离。质心：均值。目标函数：最小化对象到其簇质心的距离的平方和。</p><p>邻近度函数：余弦。质心：均值。最大化对象与其质心的余弦相似度和。</p><p>邻近度函数：Bregman散度。质心：均值。目标函数：最小化对象到其簇质心的Bregman散度和。</p><p>由于基本K均值算法采取随机地选取初始质心的办法，导致最后形成的簇的质量常常很糟糕。在此基础上引出了基本K均值算法的扩充：<strong>二分K均值算法</strong>。二分K均值算法不太受初始化问题的影响。</p><h3 id="二分K均值算法"><a href="#二分K均值算法" class="headerlink" title="二分K均值算法"></a>二分K均值算法</h3><ol><li>把所有数据作为一个cluster加入cluster list</li><li>repeat</li><li>从cluster list中挑选出一个SSE最大的cluster来进行划分</li><li>for i=1 to预设的循环次数</li><li>用基本K均值算法把挑选出来的cluster划分成两个子cluster</li><li>计算两个子cluster的SSE和。</li><li>end for</li><li>把for循环中SSE和最小的那两个子cluster加入cluster list</li><li><strong>until</strong> cluster list拥有K个cluster</li></ol><p>除此以外，每次划分不止执行一次基本K均值算法，而是预先设置一个ITER值，然后对这个cluster进行ITER次执行基本K均值运算。因为基本K均值每次一开始都是随机选K个质心来执行，所以i一般来说ITER次执行基本K均值，每次都会得到不同的两个cluster。那么应该选哪对cluster来作为划分以后的cluster呢？答案就是在每次循环中，每次都计算当次基本K均值划分出来的两个cluster的SSE和，最后就选SSE和最小的那对cluster作为划分以后的cluster。</p><h3 id="学习向量化"><a href="#学习向量化" class="headerlink" title="学习向量化"></a>学习向量化</h3><p>与k均值算法类似，“学习向量量化”（Learning Vector Quantization，简称LVQ）也是试图找到一组原型向量来刻画聚类结构，但与一般的聚类算法不同的是，LVQ假设数据样本带有类别标记，学习过程用样本的这些监督信息来辅助聚类。</p><h3 id="学习向量化算法"><a href="#学习向量化算法" class="headerlink" title="学习向量化算法"></a>学习向量化算法</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类5.png" alt=""></p><h3 id="高斯混合模型"><a href="#高斯混合模型" class="headerlink" title="高斯混合模型"></a>高斯混合模型</h3><p>高斯混合聚类使用了一个很流行的算法：GMM(Gaussian Mixture Model)。高斯混合聚类与k均值聚类类似，但是采用了<strong>概率模型</strong>来表达聚类原型。每个高斯模型（Gaussian Model）就代表了一个簇（类）。GMM是单一高斯概率密度函数的延伸，能够平滑地近似任意形状的密度分布。在高斯混合聚类中，每个GMM会由k个高斯模型分布组成，每个高斯模型被称为一个component，这些component线性加乘在一起就组成了GMM的。</p><p>简单地来说，k-Means的结果是每个数据点没分配到其中某一个cluster,而GMM则给出的是这个数据点被分配到每个cluster的概率，又称为soft assignment。</p><h3 id="高斯混合模型聚类算法"><a href="#高斯混合模型聚类算法" class="headerlink" title="高斯混合模型聚类算法"></a>高斯混合模型聚类算法</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类6.png" alt=""></p><h3 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h3><p>层次聚类（hierarchical clustering）试图在不同层次对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用“自底向上”的聚合策略，也可采用“自顶向下”的分拆策略。 典型的<strong>AGNES</strong>是一种采用自底向上聚合策略的层次聚类算法。它先将数据集中的每个样本看作一个初始聚类簇，然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并，该过程不断重复，直至达到预设的聚类簇个数。</p><h4 id="有两种产生层次聚类的基本方法："><a href="#有两种产生层次聚类的基本方法：" class="headerlink" title="有两种产生层次聚类的基本方法："></a>有两种产生层次聚类的基本方法：</h4><ol><li>凝聚的。从点作为个体簇开始，每一步合并两个最接近的簇。这需要定义簇的临近性概念。凝聚层次聚类技术最常见。</li><li>分裂的。从包含所有点的某个簇开始，每一步分裂一个簇，直到仅剩下单点簇。在这种情况下，我们需要确定每一步分裂哪个簇，以及如何分裂。</li><li></li></ol><h3 id="层次聚类算法"><a href="#层次聚类算法" class="headerlink" title="层次聚类算法"></a>层次聚类算法</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类7.png" alt=""></p><p><strong>基本凝聚层次聚类算法：</strong></p><ol><li>如果需要，计算临近度矩阵</li><li>repeat</li><li>合并最接近的两个簇</li><li>更新临近度矩阵，以反映新的簇与原来的簇之间的临近性。</li><li>until 仅剩下一个簇</li></ol><p><strong>簇之间的临近性有3种定义方式：</strong></p><ol><li>MIN（单链）。不同簇中的两个最近的点之间的距离作为临近度。</li><li>MAX（全链）。不同簇中的两个最远的点之间的距离作为临近度。</li><li>GROUP（组平均）。取自不同簇的所有点对距离的平均值作为临近度。</li></ol><p><strong>注意：</strong></p><ol><li>簇与簇合并的原则永远是dist最小。</li><li>但在计算dist值的时候，可以采用MIN, MAX, GROUP AVG 3中方式得出dist的值。</li></ol><h3 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h3><p>密度聚类亦称“基于密度的聚类”，假设聚类结构能通过样本分布的紧密程度确定。典型的代表算法为<strong>DBSCAN算法</strong>，它基于一组“领域”（neighborhood）参数来刻画样本分布的紧密程度。</p><p>DBSCAN将“簇”定义为：由密度可达关系导出的最大的密度相连样本集合。</p><h3 id="DBSCAN算法"><a href="#DBSCAN算法" class="headerlink" title="DBSCAN算法"></a>DBSCAN算法</h3><p>基于密度的聚类寻找被低密度区域分离的高密度区域。DBSCAN是一种简单、有效的基于密度的聚类算法。</p><h4 id="DBSCAN基础概念"><a href="#DBSCAN基础概念" class="headerlink" title="DBSCAN基础概念"></a>DBSCAN基础概念</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类13.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类14.png" alt=""></p><p>(6) 边界点：非核心点，从某一核心点直接密度可达。</p><p>(7) 噪声：聚类结束时，不属于任何簇的点。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类15.png" alt=""></p><h4 id="DBSCAN算法描述"><a href="#DBSCAN算法描述" class="headerlink" title="DBSCAN算法描述"></a>DBSCAN算法描述</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类16.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类17.png" alt=""></p><p><strong>DBSCAN算法：</strong></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类8.png" alt=""></p><ol><li>将所有点标记为核心点、边界点或噪声点。</li><li>删除噪声点。</li><li>为距离在Eps之内的所有核心点之间连线。</li><li>每组连通的核心点形成一个簇。</li><li>将每个边界点指派到一个与之关联的核心点的簇中。</li></ol><p><strong>DBSCAN算法阐释：</strong></p><ol><li><p>算法需要用户输入2个参数： 半径Eps; 最小（少）点值MinPts。</p></li><li><p>确定Eps和MinPts需要用到K-距离的概念。K-距离就是“到第K近的点的距离”，按经验一般取值为4。并且，一般取K的值为MinPts参数的值。</p></li><li><p>首先计算每个点到所有其余点的欧式距离，升序排序后，选出每个点的“K距离”。</p></li><li><p>所有点的K距离形成一个集合D。对D进行升序排序，依此可以形成一个样本数据的K距离图。</p></li><li><p>图中急剧变化处的值，即为Eps。</p></li><li><p>根据Eps和MinPts，计算出所有的核心点。</p></li><li><p>给核心点到小于Eps的另一个核心点赋予一个连线，到核心点的距离等于Eps的点被识别为边界点。最后，核心点、边界点之外的点都是噪声点。</p></li><li><p>将能够连线的点和与之关联的边界点都放到一起，形成了一个簇。</p></li></ol><h4 id="DBSCAN算法举例"><a href="#DBSCAN算法举例" class="headerlink" title="DBSCAN算法举例"></a>DBSCAN算法举例</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类18.png" alt=""></p><p>第1步，在数据库中选择一点1，由于在以它为圆心的，以1为半径的圆内包含2个点（小于4），因此它不是核心点，选择下一个点。<br>第2步，在数据库中选择一点2，由于在以它为圆心的，以1为半径的圆内包含2个点，因此它不是核心点，选择下一个点。<br>第3步，在数据库中选择一点3，由于在以它为圆心的，以1为半径的圆内包含3个点，因此它不是核心点，选择下一个点。<br>第4步，在数据库中选择一点4，由于在以它为圆心的，以1为半径的圆内包含5个点，因此它是核心点，寻找从它出发可达的点（直接可达4个，间接可达3个），聚出的新类{1，3，4，5，9，10，12}，选择下一个点。<br>第5步，在数据库中选择一点5，已经在簇1中，选择下一个点。<br>第6步，在数据库中选择一点6，由于在以它为圆心的，以1为半径的圆内包含3个点，因此它不是核心点，选择下一个点。<br>第7步，在数据库中选择一点7，由于在以它为圆心的，以1为半径的圆内包含5个点，因此它是核心点，寻找从它出发可达的点，聚出的新类{2，6，7，8，11}，选择下一个点。<br>第8步，在数据库中选择一点8，已经在簇2中，选择下一个点。<br>第9步，在数据库中选择一点9，已经在簇1中，选择下一个点。<br>第10步，在数据库中选择一点10，已经在簇1中，选择下一个点。<br>第11步，在数据库中选择一点11，已经在簇2中，选择下一个点。<br>第12步，选择12点，已经在簇1中，由于这已经是最后一点所有点都以处理，</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类19.png" alt=""></p><h4 id="Scikit-learn中DBSCAN算法的实现"><a href="#Scikit-learn中DBSCAN算法的实现" class="headerlink" title="Scikit learn中DBSCAN算法的实现"></a>Scikit learn中DBSCAN算法的实现</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/聚类/聚类20.png" alt=""></p><h3 id="几种聚类的优缺点"><a href="#几种聚类的优缺点" class="headerlink" title="几种聚类的优缺点"></a>几种聚类的优缺点</h3><h4 id="层次聚类的优缺点"><a href="#层次聚类的优缺点" class="headerlink" title="层次聚类的优缺点"></a><strong>层次聚类的优缺点</strong></h4><p>优点：</p><ol><li>距离和规则的相似度容易定义，限制少；</li><li>不需要预先指定聚类数；</li><li>可以发现类的层次关系；</li><li>可以聚类成其他形状。</li></ol><p>缺点：</p><ol><li>计算复杂度太高；</li><li>奇异值也能产生很大影响；</li><li>算法很可能聚类成链状。</li></ol><h4 id="DBSCAN的优缺点"><a href="#DBSCAN的优缺点" class="headerlink" title="DBSCAN的优缺点"></a><strong>DBSCAN的优缺点</strong></h4><p>优点：</p><ol><li>不需要事先知道要形成的簇的数量。</li><li>可以发现任意形状的簇类。</li><li>对噪声点不敏感。</li><li>对样本点的顺序不敏感。</li></ol><p>缺点：</p><ol><li>簇的密度变化太大时，DBSCAN会有麻烦。</li><li>对于高维数据，密度定义困难，DBSCAN也有问题。</li></ol><p>注意：</p><ol><li>K均值对于圆形区域聚类的效果很好，DBSCAN基于密度，对于集中区域效果很好。</li><li>对于不规则形状，K均值完全无法使用。DBSCAN可以起到很好的效果。</li></ol><h4 id="K均值的优缺点"><a href="#K均值的优缺点" class="headerlink" title="K均值的优缺点"></a><strong>K均值的优缺点</strong></h4><p>优点：</p><ol><li>简单，易于理解和实现。</li><li>时间复杂度低。</li></ol><p>缺点：</p><ol><li>要手工输入K值，对初始值的设置很敏感。</li><li>对噪声和离群点很敏感。</li><li>只用于数值型数据，不适用于categorical类型的数据。</li><li>不能解决非凸数据。</li><li>主要发现圆形或者球形簇，不能识别非球形的簇。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;聚类的概念&quot;&gt;&lt;a href=&quot;#聚类的概念&quot; class=&quot;headerlink&quot; title=&quot;聚类的概念&quot;&gt;&lt;/a&gt;聚类的概念&lt;/h3&gt;&lt;p&gt;聚类是一种无监督机器学习方法，它基于数据的内部结构寻找观察样本的自然族群（即集群），常用于新闻分类、推荐系统等。聚类
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="聚类" scheme="https://janvia.github.io/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>决策树与随机森林</title>
    <link href="https://janvia.github.io/2019/01/23/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
    <id>https://janvia.github.io/2019/01/23/决策树与随机森林/</id>
    <published>2019-01-23T00:12:26.000Z</published>
    <updated>2019-01-23T02:21:33.048Z</updated>
    
    <content type="html"><![CDATA[<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p><strong>决策树（decision tree）</strong>是一种<strong>分类</strong>与<strong>回归</strong>方法，本文主要讨论用于<strong>分类</strong>的决策树，决策树的结构呈<strong>树形</strong>结构，在分类问题中，其代表基于特征对数据进行分类的过程，通常可以认为是if-then规则的集合，也可以认为是定义在<strong>特征空间与类空间上的条件概率分布</strong>。其主要优点是模型可读性好并且分类速度快。训练的时候，利用训练数据根据损失函数最小化的原则建立决策树模型。</p><p>决策树的学习通常包括三个步骤：<strong>特征选择，生成决策树，对决策树进行剪枝</strong>。这些决策树的思想主要来自Quinlan在1986年提出的ID3算法和1993年提出的C4.5算法，以及Breiman等人在1984年提出的CART算法。</p><p>用于分类的决策树是一种对数据进行分类的树形结构。决策树主要由节点（node）和有向边（directed edge）组成。节点有两种类型：内部节点（internal node）以及叶节点（leaf node）。内部节点表示一个特征或者属性，叶节点表示一个类。其结构如图所示：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/随机森林/决策树１.png" alt=""></p><p>决策树学习采用的是<strong>自顶向下</strong>的递归方法, 其基本思想是以<strong>信息熵</strong>为度量构造一棵<strong>熵值 下降最快</strong>的树,到叶子节点处的熵值为零, 此时每个叶节点中的实例都属于同一类。</p><ul><li>最大优点: 可以自学习。在学习的过程中,不需要使用者了解过多背景知识,只需要对训练实例进行较好的标注,就能够进行学习。</li><li>显然,属于<strong>有监督学习</strong>。</li></ul><h3 id="决策树三种生成算法"><a href="#决策树三种生成算法" class="headerlink" title="决策树三种生成算法"></a>决策树三种生成算法</h3><p>１、 ID3 — <strong>信息增益</strong> <strong>最大</strong>的准则</p><p>​    ID3算法的核心是在决策树各个节点上使用<strong>信息增益</strong>作为特征选择的依据，递归的构建决策树。  从根节点开始，对节点计算所有可能的特征的信息增益，选择信息增益最大的特征作为节点的特征，由该特征的不同取值建立子节点；再对子节点递归的调用以上方法，构建决策树；知道所有特征的信息增益均很小或没有特征可以选择为止，得到最后一个决策树。ID3相当于用最大似然法进行概率模型的选择。</p><p>２、C4.5 — <strong>信息增益比</strong> 最大的准则</p><p>​    C4.5算法使用<strong>信息增益率</strong>作为特征选择的依据，算法的流程与ID3相似。</p><p>３、CART</p><ul><li>回归树: <strong>平方误差</strong> <strong>最小</strong> 的准则</li><li>分类树: <strong>基尼系数</strong> <strong>最小</strong>的准则</li></ul><p>CART树的名字其实非常有意思，Classification And Regression Tree（分类回归树），它使用基尼系数(Gini Index)作为特征的划分依据。顾名思义，CART既可以用来做分类也可以用来做回归。它是在给定输入随机变量X条件下输出随机变量Y的条件概率分布的学习方法。  CART树假设我们的决策树是二叉树，内部节点特征的取值为是或否。</p><p><strong>CART算法</strong>为：  </p><p>１．决策树的生成：基于训练数据集生成决策树，生成的决策树要尽量大；</p><p>２．决策树剪枝：用验证数据集对已经生成的巨额子树进行剪枝并选择最优子树。</p><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p><strong>信息熵（information entropy）</strong> 是度量样本集合纯度的最常用的一种指标。</p><ul><li><p>熵：$H(X)=-\sum_{x \in X} p(x,y)logp(x)$</p></li><li><p>联合熵：$H(X，Y)=-\sum_{x \in X,y \in Y} p(x,y)logp(x,y)$</p></li><li><p>条件熵：$H(X|Y)=-\sum_{x \in X,y \in Y} p(x,y)logp(x|y)$</p></li><li><p>相对熵：$D(p||q)=\sum_x p(x)log\frac{p(x)}{q(x)}$</p></li><li><p>互信息：$I(x,y)=\sum_{x\in X, y \in Y} p(x,y )log\frac{p(x,y)}{p(x)p(y)}$</p></li></ul><h3 id="决策树学习基本算法"><a href="#决策树学习基本算法" class="headerlink" title="决策树学习基本算法"></a>决策树学习基本算法</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/随机森林/决策树2.png" alt=""></p><h3 id="信息增益-g-D-A"><a href="#信息增益-g-D-A" class="headerlink" title="信息增益-$g(D,A)$"></a>信息增益-$g(D,A)$</h3><p><strong>信息增益(Information Gain)</strong>：表示得知特征A的信息而使得类X的信息的不确定性减少的程度。 定义：特征A对训练数据集D的<strong>信息增益</strong>g(D, A)，定义为集合D的<strong>经验熵</strong>H(D)与<strong>经验条件熵</strong>H(D|A)的差值。</p><script type="math/tex; mode=display">g(D,A)=H(D)−H(D|A)</script><p>而这又是互信息的定义。所以<strong>决策树中的信息增益等价于训练集中类与特征的互信息。</strong></p><p>总结：一般而言，<strong>信息增益</strong>g(D, A)越大，就意味着使用特征A来进行划分所获得的“纯度提升”就越大。著名的ID3决策树学习算法就是以信息增益为准则来学习划分属性的。</p><h3 id="增益率"><a href="#增益率" class="headerlink" title="增益率"></a>增益率</h3><p><strong>信息率(Information Gain Ratio)</strong>：  用信息增益作为划分特征的依据时，会存在一些问题。例如，如果使用数据的ID作为特征，这样，每个数据点相当于均匀分布，所以得到的信息增益一定是最大的，但是我们都知道ID是不能作为特征的。这样如果单纯的使用信息增益作为划分特征的依据的话，会导致我们生成的树比较矮胖，容易<strong>过拟合</strong>。</p><p>定义：特征A对训练数据集D的<strong>信息增益率</strong>$gR(D,A)$定义为其<strong>信息增益</strong>$g(D,A)$与训练数据集D关于特征A的值的<strong>信息熵</strong>$IV(D)$之比：</p><script type="math/tex; mode=display">gR(D,A)=\frac {g(D,A)}{IV(D)}</script><p>总结：信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，著名的C4.5决策树算法就不直接使用信息增益而是使用“增益率” 。</p><h3 id="Gini系数"><a href="#Gini系数" class="headerlink" title="Gini系数"></a>Gini系数</h3><p>数据集P的纯度可以用Gini值来度量。</p><script type="math/tex; mode=display">Gini(P)=\sum_{k=1}^K p_k(1-p_k)=1-\sum_{k=1}^Kp_k^2</script><p>总结：CART决策树使用Gini指数来选择划分属性。$Gini(P)$反映了从数据集D中随机抽取了两个样本，其类别标记不一致的概率，因此，$Gini（D）$越小，则数据集P的纯度就越高。</p><h3 id="决策树的评价-——-loss-function"><a href="#决策树的评价-——-loss-function" class="headerlink" title="决策树的评价 —— loss function"></a>决策树的评价 —— loss function</h3><p>  假定样本的总类别数为K个；树T的叶节点个数为$∣T∣$，t是树T的叶节点，叶节点有<script type="math/tex">N_t</script>个样本点，其中k类的样本点有<script type="math/tex">N_{ik}</script>个，<script type="math/tex">H_t(T)</script>为叶节点t上的<strong>经验熵</strong>，则决策树的loss function可以定义为：</p><script type="math/tex; mode=display">C_a(T)=\sum_{t\in Leaf}N_tH_t(T)+a|T|</script><h3 id="决策树种避免过拟合的方法——剪枝"><a href="#决策树种避免过拟合的方法——剪枝" class="headerlink" title="决策树种避免过拟合的方法——剪枝"></a>决策树种避免过拟合的方法——剪枝</h3><ul><li><strong>预剪枝</strong>：在决策树生成过程中，对每个结点在划分前先进行估计，如果当前的结点划分不能带来决策树泛化性能提升，则停止划分并将当前的结点标记为叶节点。</li><li><strong>后剪枝</strong>：先从训练集生成一个完整的决策树，然后自底向上的对非叶节点进行考察，若将该结点对应的子树替换为叶节点能带来决策树泛化能力性能提升，则就把该子树替换为叶结点。</li></ul><p>在上面决策树的评价指标loss function ：<script type="math/tex">C_a(T)=\sum_{t\in Leaf}N_tH_t(T)+a|T|</script>中：</p><ul><li>C(T)表示模型对训练数据集的预测误差，即模型与训练数据的拟合程度，</li><li>$∣T∣$表示模型复杂度，由参数α控制两者之间的影响。</li></ul><p>当α确定时：</p><ul><li>子树越大，与训练集的拟合越好，但模型的复杂度就越高；</li><li>子树越小，模型简单，但与训练集的拟合度不好。</li></ul><p>决策树生成学习局部的模型，而剪枝学习整体的模型!</p><p>剪枝的过程为：</p><ul><li><p>计算每个节点的经验熵；</p></li><li><p>递归的从树的叶节点向上回缩，设一组叶节点回缩到其父节点之前和之后的整体树分别为<script type="math/tex">T_B</script>和<script type="math/tex">T_A</script>，对应的损失函数值分别为<script type="math/tex">C_α(T_B)</script>和<script type="math/tex">C_α(T_A)</script>,如果<script type="math/tex">C_α(T_A)<=C_α(T_B)</script>，则进行剪枝。</p></li></ul><h3 id="决策树的优缺点"><a href="#决策树的优缺点" class="headerlink" title="决策树的优缺点"></a>决策树的优缺点</h3><ul><li>优点: 决策树对训练属于有很好的分类能力</li><li>缺点: 但对未知的测试数据未必有好的分类能力,泛化 能力弱,即可能发生过拟合现象。</li></ul><h3 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a>Bootstrap</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/随机森林/决策树3.png" alt=""></p><h3 id="Bagging（套袋法）"><a href="#Bagging（套袋法）" class="headerlink" title="Bagging（套袋法）"></a>Bagging（套袋法）</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/随机森林/决策树4.png" alt=""><br>bagging的算法过程如下：</p><ol><li>从原始样本集中使用Bootstraping方法随机抽取n个训练样本，共进行k轮抽取，得到k个训练集。（k个训练集之间相互独立，元素可以有重复）</li><li>对于k个训练集，我们训练k个模型（这k个模型可以根据具体问题而定，比如决策树，knn等）</li><li>对于分类问题：由投票表决产生分类结果；对于回归问题：由k个模型预测结果的均值作为最后预测结果。（所有模型的重要性相同）</li></ol><h3 id="Boosting（提升法）"><a href="#Boosting（提升法）" class="headerlink" title="Boosting（提升法）"></a>Boosting（提升法）</h3><p>boosting的算法过程如下：</p><ol><li>对于训练集中的每个样本建立权值wi，表示对每个样本的关注度。当某个样本被误分类的概率很高时，需要加大对该样本的权值。</li><li>进行迭代的过程中，每一步迭代都是一个弱分类器。我们需要用某种策略将其组合，作为最终模型。（例如AdaBoost给每个弱分类器一个权值，将其线性组合最为最终分类器。误差越小的弱分类器，权值越大）</li></ol><h3 id="Bagging，Boosting的主要区别"><a href="#Bagging，Boosting的主要区别" class="headerlink" title="Bagging，Boosting的主要区别"></a>Bagging，Boosting的主要区别</h3><ol><li><p>样本选择上：</p><p>Bagging采用的是Bootstrap随机有放回抽样；</p><p>Boosting每一轮的训练集是不变的，改变的只是每一个样本的权重。</p></li><li><p>样本权重：</p><p>Bagging使用的是均匀取样，每个样本权重相等；</p><p>Boosting根据错误率调整样本权重，错误率越大的样本权重越大。</p></li><li><p>预测函数：</p><p>Bagging所有的预测函数的权重相等；</p><p>Boosting中误差越小的预测函数其权重越大。</p></li><li><p>并行计算：</p><p>Bagging各个预测函数可以并行生成；</p><p>Boosting各个预测函数必须按顺序迭代生成。</p></li></ol><h3 id="决策树与这些算法框架进行结合所得到的新的算法"><a href="#决策树与这些算法框架进行结合所得到的新的算法" class="headerlink" title="决策树与这些算法框架进行结合所得到的新的算法"></a>决策树与这些算法框架进行结合所得到的新的算法</h3><p>1）Bagging + 决策树 = 随机森林</p><p>2）AdaBoost + 决策树 = 提升树</p><p>3）Gradient Boosting + 决策树 = GBDT</p><h3 id="随机森林（Random-Forests）"><a href="#随机森林（Random-Forests）" class="headerlink" title="随机森林（Random Forests）"></a>随机森林（Random Forests）</h3><p>随机森林是一种重要的基于Bagging的集成学习方法，可以用来做分类、回归等问题。</p><h4 id="随机森林的优点"><a href="#随机森林的优点" class="headerlink" title="随机森林的优点"></a>随机森林的优点</h4><ul><li>具有极高的准确率</li><li>随机性的引入，使得随机森林不容易过拟合</li><li>随机性的引入，使得随机森林有很好的抗噪声能力</li><li>能处理很高维度的数据，并且不用做特征选择</li><li>既能处理离散型数据，也能处理连续型数据，数据集无需规范化</li><li>训练速度快，可以得到变量重要性排序</li><li>容易实现并行化</li></ul><h4 id="随机森林的缺点"><a href="#随机森林的缺点" class="headerlink" title="随机森林的缺点"></a>随机森林的缺点</h4><ul><li>当随机森林中的决策树个数很多时，训练时需要的空间和时间会较大</li><li>随机森林模型还有许多不好解释的地方，有点算个黑盒模型</li></ul><h4 id="随机森林构建过程"><a href="#随机森林构建过程" class="headerlink" title="随机森林构建过程"></a>随机森林构建过程</h4><p>与上面介绍的Bagging过程相似，随机森林的构建过程大致如下：</p><ol><li>从原始训练集中使用Bootstraping方法随机有放回采样选出m个样本，共进行n_tree次采样，生成n_tree个训练集</li><li>对于n_tree个训练集，我们分别训练n_tree个决策树模型</li><li>对于单个决策树模型，假设训练样本特征的个数为n，那么每次分裂时根据信息增益/信息增益比/基尼指数选择最好的特征进行分裂</li><li>每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类。在决策树的分裂过程中不需要剪枝</li><li>将生成的多棵决策树组成随机森林。对于分类问题，按多棵树分类器投票决定最终分类结果；对于回归问题，由多棵树预测值的均值决定最终预测结果</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;决策树（decision tree）&lt;/strong&gt;是一种&lt;strong&gt;分类&lt;/strong&gt;与&lt;strong&gt;
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="决策树" scheme="https://janvia.github.io/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
      <category term="随机森林" scheme="https://janvia.github.io/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="https://janvia.github.io/2019/01/22/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>https://janvia.github.io/2019/01/22/逻辑回归/</id>
    <published>2019-01-22T07:49:22.000Z</published>
    <updated>2019-01-22T09:22:02.562Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p><strong>Logistic Regression</strong> 在《机器学习》-周志华一书中又叫<strong>对数几率回归</strong>。逻辑回归和多重线性回归实际上有很多的相同之处，除了它们的因变量（函数）不同外，其他的基本差不多，所以逻辑回归和线性回归又统属于<strong>广义线性模型</strong>（generalizedlinear  model）。</p><p>广义线性模型的形式其实都差不多，不同的就是因变量（函数）的不同。</p><ul><li>如果是<strong>连续</strong>的，就是<strong>多重线性回归</strong></li><li>如果是<strong>二项分布</strong>，就是<strong>Logistic回归</strong></li><li>如果是<strong>Poisson分布</strong>，就是<strong>Poisson分布</strong></li><li>如果是<strong>负二项分布</strong>，就是<strong>负二项回归</strong></li></ul><p>Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。</p><h3 id="主要用途"><a href="#主要用途" class="headerlink" title="主要用途"></a>主要用途</h3><ul><li>寻找危险因素：寻找某一疾病的危险因素等；</li><li>预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；</li><li>判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。</li></ul><h3 id="一般步骤"><a href="#一般步骤" class="headerlink" title="一般步骤"></a>一般步骤</h3><ol><li>寻找<strong>h</strong>函数（即hypothesis）；</li><li>构造<strong>J</strong>函数（损失函数）；</li><li>想办法使得J<strong>函数最小</strong>并求得回归参数（θ）</li></ol><h3 id="构造预测函数（hypothesis）"><a href="#构造预测函数（hypothesis）" class="headerlink" title="构造预测函数（hypothesis）"></a>构造预测函数（hypothesis）</h3><p>Logistic回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别），所以利用了Logistic函数（或称为<strong>Sigmoid函数</strong>），函数形式为：</p><p>$g(z)=\frac{1}{1+e^{-z}}$</p><p>为了方便后面使用我们求出g(z)g(z)的导数：</p><p>$g’(z)=\frac1{1+e^{-z} } \cdot (1- \frac1{1+e^{-z} })=g(z)(1-g(z))$</p><p>Sigmoid 函数在有个很漂亮的“S”形，如下图所示:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/逻辑回归/逻辑回归１.png" alt=""></p><h3 id="构建预测函数"><a href="#构建预测函数" class="headerlink" title="构建预测函数"></a>构建预测函数</h3><p>对于线性边界的情况，边界形式如下：</p><script type="math/tex; mode=display">\theta_0+\theta_1x_1+\cdot \cdot \cdot + \theta_nx_n=\sum_{i=1}^n \theta_ix_i = \theta^Tx</script><p>构建的预测函数为：</p><script type="math/tex; mode=display">h_\theta(x)=g(\theta^Tx)=\frac1{1+e^{-\theta^Tx}}</script><h3 id="构建损失函数"><a href="#构建损失函数" class="headerlink" title="构建损失函数"></a>构建损失函数</h3><p>由于是二项分布，函数$h_ \theta(x)$的值就有特殊的含义，它所表示的是结果取1的概率，因此对于输入x的分类结果就判别为类别1和类别0的概率分别为：</p><p>$P(y=1|x;\theta)=h_\theta(x) $</p><p>$P(y=0|x;\theta)=1-h_\theta(x)$</p><p>所以：</p><script type="math/tex; mode=display">P(y|x;\theta) = {h_\theta(x) }^y{(1-h_\theta(x)) }^{1-y}</script><h3 id="构建似然函数"><a href="#构建似然函数" class="headerlink" title="构建似然函数"></a>构建似然函数</h3><script type="math/tex; mode=display">L(\theta)=\prod_{i=1}^n P(y_i|x_i;\theta) =\prod_{i=1}^n {h_\theta(x_i) }^{y_i}{(1-h_\theta(x_i)) }^{1-y_i}</script><h3 id="对数似然函数"><a href="#对数似然函数" class="headerlink" title="对数似然函数"></a>对数似然函数</h3><script type="math/tex; mode=display">l(\theta)=logL(\theta)=\sum_{i=1}^n(y_ilogh_\theta(x_i)+(1-y_i)log(1-h_\theta(x_i)))</script><p>最大似然估计就是求使$l(\theta)$取最大值时的θ，其实这里可以使用梯度上升法求解，求得的θ就是要求的最佳参数。</p><h3 id="梯度下降法求的最小值"><a href="#梯度下降法求的最小值" class="headerlink" title="梯度下降法求的最小值"></a>梯度下降法求的最小值</h3><p>θ更新过程：</p><p>$\theta_j :=\theta_j-a(\frac{\partial l(\theta)}{\partial \theta_j})$</p><p>对θ求偏导:</p><p>$\frac{\partial l(\theta)}{\partial \theta_j}=\frac{\partial g(\theta^Tx)}{\partial \theta_j}(\frac{y}{g(\theta^Tx)}-\frac{1-y}{g(\theta^Tx)})$</p><p>$=g(\theta^Tx)(1-g(\theta^Tx)) \frac{\partial\theta^Tx}{\partial \theta_j}(\frac{y}{g(\theta^Tx)}-\frac{1-y}{g(\theta^Tx)})$</p><p>$=(y(1-g(\theta^Tx))-(1-y)g(\theta^Tx))x_j$</p><p>$=(y-h_\theta(x))x_j$</p><p>θ更新过程就可以写为：</p><script type="math/tex; mode=display">\theta_j :=\theta_j-a \sum_{i=1}^n (y_i-h_{\theta} (x_i))x_i^j</script><p>但是在在Andrew Ng的课程中将$J(\theta)$取为下式，即：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}l(\theta)</script><p>因为乘了一个负的系数-1/m，所以取$J(\theta)$最小值时的θ为要求的最佳参数。</p><script type="math/tex; mode=display">\frac{\partial l(\theta)}{\partial \theta_j}=\frac 1 m \sum_{i=1}^n(h_\theta(x_i)-y_i)x_i^j</script><p>相应的θ:</p><script type="math/tex; mode=display">\theta_j :=\theta_j-a \frac 1 m \sum_{i=1}^n (h_\theta(x_i)-y_i)x_i^j</script><h3 id="向量化（Vectorization-）"><a href="#向量化（Vectorization-）" class="headerlink" title="向量化（Vectorization ）"></a>向量化（<strong>Vectorization</strong> ）</h3><p>Vectorization是使用矩阵计算来代替for循环，以简化计算过程，提高效率。</p><p>如上式，Σ(…)是一个求和的过程，显然需要一个for语句循环m次，所以根本没有完全的实现vectorization。</p><p>下面介绍向量化的过程：</p><p>约定训练数据的矩阵形式如下，x的每一行为一条训练样本，而每一列为不同的特称取值：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/逻辑回归/逻辑回归2.png" alt=""></p><p>g(A)的参数A为一列向量，所以实现g函数时要支持列向量作为参数，并返回列向量。由上式可知$h_\theta(x)-y$可以由$g(A)-y$一次求得</p><p>θ更新过程可以改为:</p><script type="math/tex; mode=display">\theta_j :=\theta_j-a \frac 1 m \sum_{i=1}^n (h_\theta(x_i)-y_i)x_i^j=\theta_j-a \frac 1 m \sum_{i=1}^n e_ix_i^j=\theta_j-a \frac1 m x^TE</script><p><strong>综上所述，Vectorization后θ更新的步骤如下：</strong></p><ol><li>$A=x \cdot \theta$</li><li>$E=g(A)-y$</li><li>$\theta:=\theta-ax^TE$</li></ol><h3 id="正则化Regularization"><a href="#正则化Regularization" class="headerlink" title="正则化Regularization"></a>正则化Regularization</h3><p>同样逻辑回归也有<strong>欠拟合、适合拟合、过拟合问题</strong></p><p>对于线性回归或逻辑回归的损失函数构成的模型，可能会有些权重很大，有些权重很小，导致过拟合（就是过分拟合了训练数据），使得模型的复杂度提高，泛化能力较差（对未知数据的预测能力）。</p><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a><strong>解决方法</strong></h4><p>1）减少特征数量（减少特征会失去一些信息，即使特征选的很好）</p><ul><li>可用人工选择要保留的特征；</li><li>模型选择算法；</li></ul><p>2）正则化（特征较多时比较有效）</p><ul><li>保留所有特征，但减少θ的大小</li></ul><h4 id="正则化方法"><a href="#正则化方法" class="headerlink" title="正则化方法"></a><strong>正则化方法</strong></h4><p>正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或惩罚项。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化项就越大。</p><p>正则项可以取不同的形式，在回归问题中取平方损失，就是参数的L2范数，也可以取L1范数。取平方损失时，模型的损失函数变为：</p><script type="math/tex; mode=display">J(\theta)=\frac1{2m}\sum_{i=1}^{n}(h_\theta(x_i)-y_i)^2+\lambda\sum_{j=1}^n \theta_j^2</script><p>lambda是正则项系数：</p><ul><li>如果它的值很大，说明对模型的复杂度惩罚大，对拟合数据的损失惩罚小，这样它就不会过分拟合数据，在训练数据上的偏差较大，在未知数据上的方差较小，但是可能出现欠拟合的现象；</li><li>如果它的值很小，说明比较注重对训练数据的拟合，在训练数据上的偏差会小，但是可能会导致过拟合。</li></ul><p>正则化后的梯度下降算法θ的更新变为：</p><script type="math/tex; mode=display">\theta_j :=\theta_j-a \frac 1 m \sum_{i=1}^n (h_\theta(x_i)-y_i)x_i^j - \frac \lambda m \theta_j</script><h3 id="其他优化算法"><a href="#其他优化算法" class="headerlink" title="其他优化算法"></a><strong>其他优化算法</strong></h3><ul><li>Conjugate gradient method(共轭梯度法)</li><li>Quasi-Newton method(拟牛顿法)</li><li>BFGS method(局部优化法)</li><li>L-BFGS(Limited-memory BFGS)（有限内存局部优化法）</li></ul><p>后二者由拟牛顿法引申出来，与梯度下降算法相比，这些算法的优点是：</p><ul><li>第一，不需要手动的选择步长；</li><li>第二，通常比梯度下降算法快；</li></ul><p>但是缺点是更复杂。</p><h3 id="多类分类问题"><a href="#多类分类问题" class="headerlink" title="多类分类问题"></a>多类分类问题</h3><p>多类分类问题中,我们的训练集中有多个类(&gt;2),我们无法仅仅用一个二元变量(0或1)来做判断依据。例如我们要预测天气情况分四种类型:晴天、多云、下雨或下雪。</p><p>一种解决这类问题的途径是采用一对多(One-vs-All)方法（可以将其看做成二类分类问题：保留其中的一类，剩下的作为另一类 ）。在一对多方法中,我们将多类分类问题转化成二元分类问题。为了能实现这样的转变,我们将多个类中的一个类标记为正向类(y=1),然后将其他所有类都标记为负向类,这个模型记作：</p><p>$h_\theta^{(1)}(x)$</p><p>接着,类似地第我们选择另一个类标记为正向类(y=2),再将其它类都标记为负向类,将这个模型记作:</p><p>$h_\theta^{(2)}(x)$</p><p>依此类推。最后我们得到一系列的模型简记为:</p><p>$h_\theta^{(i)}(x)=p(y=i|x;\theta)$</p><p>最后,在我们需要做预测时,我们将所有的分类机都运行一遍,然后对每一个输入变量,都选择最高可能性的输出变量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Logistic Regression&lt;/strong&gt; 在《机器学习》-周志华一书中又叫&lt;strong&gt;对数几率回归&lt;/s
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="逻辑回归" scheme="https://janvia.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>机器学习简介</title>
    <link href="https://janvia.github.io/2019/01/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>https://janvia.github.io/2019/01/22/机器学习简介/</id>
    <published>2019-01-22T07:21:40.000Z</published>
    <updated>2019-01-22T07:45:00.848Z</updated>
    
    <content type="html"><![CDATA[<h3 id="机器学习任务的一般步骤"><a href="#机器学习任务的一般步骤" class="headerlink" title="机器学习任务的一般步骤"></a>机器学习任务的一般步骤</h3><p>１．确定特征<br>    – 可能是最重要的步骤! （收集训练数据）<br>２．确定模型<br>    – 目标函数/决策边界形状<br>３．模型训练：根据训练数据估计模型参数<br>    – 优化计算<br>４．模型评估：在校验集上评估模型预测性能<br>５．模型应用/预测</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/线性回归/线性回归7.png" alt=""></p><h3 id="非线性模型"><a href="#非线性模型" class="headerlink" title="非线性模型"></a>非线性模型</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/线性回归/线性回归8.png" alt=""></p><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/线性回归/线性回归2.png" alt=""></p><h3 id="损失函数—回归"><a href="#损失函数—回归" class="headerlink" title="损失函数—回归"></a>损失函数—回归</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/线性回归/线性回归3.png" alt=""></p><h3 id="损失函数—分类"><a href="#损失函数—分类" class="headerlink" title="损失函数—分类"></a>损失函数—分类</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/线性回归/线性回归4.png" alt=""></p><h3 id="正则项"><a href="#正则项" class="headerlink" title="正则项"></a>正则项</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/线性回归/线性回归5.png" alt=""></p><h3 id="常用正则函数"><a href="#常用正则函数" class="headerlink" title="常用正则函数"></a>常用正则函数</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/线性回归/线性回归6.png" alt=""></p><h3 id="常见线性模型的损失和正则项组合"><a href="#常见线性模型的损失和正则项组合" class="headerlink" title="常见线性模型的损失和正则项组合"></a>常见线性模型的损失和正则项组合</h3><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th>L2损失</th><th>L1损失</th><th>Huber</th><th>Logistic损失</th><th>合叶损失</th><th>ε-insentive损失</th></tr></thead><tbody><tr><td style="text-align:center">L2正则</td><td>岭回归</td><td></td><td></td><td>L2正则 Logistic回归</td><td>SVM</td><td>SVR</td></tr><tr><td style="text-align:center">L1正则</td><td>LASSO</td><td></td><td></td><td>L1正则 Logistic回归</td><td></td><td></td></tr><tr><td style="text-align:center">L2+L1正则</td><td>Elastic net</td><td></td><td></td><td></td><td></td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;机器学习任务的一般步骤&quot;&gt;&lt;a href=&quot;#机器学习任务的一般步骤&quot; class=&quot;headerlink&quot; title=&quot;机器学习任务的一般步骤&quot;&gt;&lt;/a&gt;机器学习任务的一般步骤&lt;/h3&gt;&lt;p&gt;１．确定特征&lt;br&gt;    – 可能是最重要的步骤! （收集训练数据
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://janvia.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="https://janvia.github.io/2019/01/22/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>https://janvia.github.io/2019/01/22/线性回归/</id>
    <published>2019-01-22T05:41:42.000Z</published>
    <updated>2019-01-22T07:12:12.008Z</updated>
    
    <content type="html"><![CDATA[<h3 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h3><p>数理统计中回归分析，用来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，其表达形式为$y=wx+e$，e为误差服从均值为0的正态分布，其中只有一个自变量的情况称为简单回归，多个自变量的情况叫多元回归。</p><p>注意，统计学中的回归并非如线性回归非与严格直线函数完全能拟合，所以我们统计中称之为回归用以与其直线函数区别。</p><p>下面看个例子：</p><p>数据：工资和年龄（2个特征）<br>目标：预测银行会贷款给我多少钱（标签）<br>考虑：工资和年龄都会影响最终银行贷款的结果那么它们各自有多大的影响呢？（参数）</p><div class="table-container"><table><thead><tr><th>工资</th><th>年龄</th><th>额度</th></tr></thead><tbody><tr><td>4000</td><td>25</td><td>20000</td></tr><tr><td>8000</td><td>30</td><td>70000</td></tr><tr><td>5000</td><td>28</td><td>35000</td></tr><tr><td>7500</td><td>33</td><td>50000</td></tr></tbody></table></div><p>这个表格表示的是<strong>可贷款的金额 </strong>与 <strong>工资 </strong>和 <strong>年龄</strong>之间的关系，其中 <strong>工资</strong> 和 <strong>年龄</strong> 为 特征，<strong>可贷款金额</strong>为目标函数值。  那么根据线性函数可得到以下公式：</p><script type="math/tex; mode=display">h_\theta(x)=\theta_{1}x_{1}+\theta_{2}x_{2}</script><p>上面的这个式子是当一个模型只有两个特征(x1,x2)的时候的线性回归式子。  正常情况下，现金贷中可贷款的额度和用户的很多特征相关联，并不只是简单的这两个特征。所以我们需要把这个式子进行通用化。  假如有n个特征的话，那么式子就会变成下面的样子：</p><script type="math/tex; mode=display">h_\theta(x)=\theta_{1}x_{1}+\theta_{2}x_{2} + \cdot \cdot \cdot \cdot \cdot+\theta_{n}x_{n} = \sum_{i=1}^{n}\theta_{i}x_{i}</script><h3 id="利用矩阵的知识对线性公式进行整合"><a href="#利用矩阵的知识对线性公式进行整合" class="headerlink" title="利用矩阵的知识对线性公式进行整合"></a>利用矩阵的知识对线性公式进行整合</h3><p>因为机器学习中基本上都是用矩阵的方式来表示参数的，也就是说我们需要把这个多项求和的式子用矩阵的方式表达出来，这样才方便后续的计算。</p><script type="math/tex; mode=display">\theta_{i \times 1} = [\theta_1,\theta_2,\cdot\cdot\cdot\theta_i,]</script><script type="math/tex; mode=display">X_{i\times1}=[x_1,x_2,\cdot \cdot \cdot x_i]</script><script type="math/tex; mode=display">\theta^TX=\begin{bmatrix}  \theta_1 \\  \theta_2 \\ \cdot \\ \cdot \\ \cdot \\ \theta_i \end{bmatrix} \cdot [x_1,x_2,\cdot \cdot \cdot x_i] = \sum_{i=1}^{n}\theta_{i}x_{i}</script><p>我们把权重参数和特征参数，都看成是1行n列的矩阵(或者是行向量)。那么就可以根据矩阵乘法的相关知识，把上述多项求和的式子，转换成矩阵的乘法的表达式。  由此我们就把多项求和化简称了 。</p><script type="math/tex; mode=display">h_\theta(x)=\theta^TX</script><h3 id="误差"><a href="#误差" class="headerlink" title="误差"></a>误差</h3><p>真实值和预测值之间肯定是存在误差的，我们用<script type="math/tex">\varepsilon</script>来表示该误差</p><p>所以回归函数变为：</p><script type="math/tex; mode=display">h_\theta(x)=\theta^Tx+\varepsilon</script><p>我们根据实际情况，假设认为这个误差项是满足以下几个条件的:</p><ol><li>误差<script type="math/tex">\varepsilon_{(i)}</script>是独立的。</li><li>具有相同的分布。</li><li>服从均值为0方差为<script type="math/tex">θ_2</script>的高斯分布。</li></ol><p>然后我们回到刚开始的现金贷产品的贷款额度问题上面:</p><ol><li>独立：张三和李四一起使用这款产品，可贷款额互不影响</li><li>同分布：张三和李四是使用的是同一款产品</li><li>高斯分布：绝大多数的情况下，在一个的空间内浮动不大</li></ol><h3 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h3><p>由前面两步，我们已经把线性回归模型，推导成下面的这个式子:</p><p>$y_{(i)}=\theta^Tx_i+\varepsilon_i$    (1)</p><p>因为误差项是符合高斯分布的，所以误差项的概率值：</p><p>$P(\varepsilon_i)=\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(\varepsilon_i)^2}{2\sigma^2})}$    (2)</p><p>将 (1) 式代入 (2) 式：</p><p>$P(y_i|x_i,\theta)=\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}$</p><p>由于是误差值，所以是越小越好，所以我们接下来就是讨论什么样的特征值和特征组合能够让误差值最小，似然函数的作用就是要根据样本求什么样的参数和特征的组成能够接近真实值，越接近真实值则误差就越小。</p><p>引入似然函数(似然函数就是求能让真实值和预测值相等的那个参数 )：</p><script type="math/tex; mode=display">L(\theta) = \prod_{i=1}^{N} P(y_i|x_i,\theta)=\prod_{i=1}^{N}\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}</script><p>$\prod$表示各元素相乘</p><p>上面的式子是多个参数的乘积的形式，很难进行计算，所以我们又采用了对数的一个小技巧，把多个数相乘，转化成多个数相加的形式。</p><p>因为对数的性质:</p><p>$logA\cdot B = logA+logB$</p><p>根据上面的这种换算关系，我们就把似然函数的式子换算成下面的这个。  (因为似然函数是越大越好，似然函数的值和对数似然函数的值是成正比的，对值求对数，并不会影响到最后求极限的值。所以才敢进行对数处理。)</p><p>$l(\theta) = logL(\theta) = log\prod_{i=1}^{N}\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}$</p><p>对上式进行整理：</p><p>$l(\theta) = logL(\theta) = \sum_{i=1}^{N}log\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}$</p><p>$= \sum_{i=1}^{N}(log\frac{1}{\sqrt{2\pi}\sigma}+loge^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})})$</p><p>$= Nlog\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$</p><p>因为：</p><p>$Nlog\frac{1}{\sqrt{2\pi}\sigma}$和$-\frac{1}{2\sigma^2}$是一个定值</p><p>似然函数是要越大越好</p><p>所以：</p><p>$l(\theta) = \sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$</p><p>$\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$越小越好——最小二乘法（损失函数）</p><h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p>上述代价函数中使用的均方误差，其实对应了我们常用的欧几里得的距离（欧式距离，<strong>Euclidean Distance</strong>）, 基于均方误差最小化进行模型求解的方法称为“最小二乘法”（<strong>least square method</strong>），即通过最小化误差的平方和寻找数据的最佳函数匹配；</p><p>当函数子变量为一维时，最小二乘法就蜕变成寻找一条直线；</p><p>然后我们把得到的损失函数推广到n维，转换成矩阵形式（参考前面利用矩阵的知识对线性公式进行整合）：</p><p>$J(\theta)=\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$(损失函数)</p><p>其对应的均方误差表示为如下矩阵：</p><p>$J(\theta) = {(y-X\theta)^T(y-X\theta)}$</p><p>其中Ｘ:</p><script type="math/tex; mode=display">X=\begin{bmatrix} 1 && x_1^T  \\ 1 && x_2^T  \\ \cdot \\ \cdot \\ \cdot  \\ 1 && x_N^T \end{bmatrix} =\begin{bmatrix} 1 &&    x_{11} && x_{12}  && \cdot \cdot \cdot  x_{1n}  \\ 1 && x_{21} && x_{22} && \cdot \cdot \cdot x_{2n}   \\ \cdot  \\  \cdot \\ \cdot \\ 1&& x_{m1} && x_{m2}  && \cdot \cdot \cdot x_{mn}  \end{bmatrix}</script><p>对$θ$求导:</p><p> $J(\theta) = {(y-X\theta)^T(y-X\theta)}=y^Ty-y^Tx\theta-\theta^Tx^Ty+\theta^Tx^Tx\theta$</p><p>$\frac{\partial J(\theta)}{\partial(\theta)} = \frac{\partial y^Ty}{\partial(\theta)} - \frac{\partial y^Tx\theta}{\partial(\theta)} - \frac{\partial \theta^Tx^Ty}{\partial(\theta)} + \frac{\partial \theta^Tx^Tx\theta}{\partial(\theta)}$</p><p>$\frac{\partial J(\theta)}{\partial(\theta)} = 0-x^Ty-x^Ty+2x^Tx\theta$</p><p>$\frac{\partial J(\theta)}{\partial(\theta)} =2x^T(x\theta-y)$</p><p>根据导数的性质，该值在导数为0时为最小</p><p>所以：</p><p>根据微积分定理，令上式等于零，可以得到 θ 最优的闭式解。当$2(x^Ty-x^Tx\theta)=0$时取得最小</p><p>最终：</p><p>$\theta = (x^Tx)^{-1}x^Ty$</p><p>X和Y都是已知的，那么得到了最终的参数值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;线性回归（Linear-Regression）&quot;&gt;&lt;a href=&quot;#线性回归（Linear-Regression）&quot; class=&quot;headerlink&quot; title=&quot;线性回归（Linear Regression）&quot;&gt;&lt;/a&gt;线性回归（Linear Regre
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="线性回归" scheme="https://janvia.github.io/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>SVM</title>
    <link href="https://janvia.github.io/2019/01/22/SVM/"/>
    <id>https://janvia.github.io/2019/01/22/SVM/</id>
    <published>2019-01-22T03:07:21.000Z</published>
    <updated>2019-01-22T03:51:25.789Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM1.png" alt=""></p><h3 id="最大间隔分类器"><a href="#最大间隔分类器" class="headerlink" title="最大间隔分类器"></a>最大间隔分类器</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM2.png" alt=""></p><h3 id="距离的计算"><a href="#距离的计算" class="headerlink" title="距离的计算"></a>距离的计算</h3><p>在样本空间中，划分超平面可通过如下线性方程描述：</p><script type="math/tex; mode=display">w^Tx+b=0</script><p>样本空间中任意点x到超平面的距离可写为:</p><script type="math/tex; mode=display">r=\frac{\lvert w^Tx+b\rvert}{\lVert w\rVert}</script><h3 id="数据标签定义"><a href="#数据标签定义" class="headerlink" title="数据标签定义"></a>数据标签定义</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM3.png" alt=""></p><h3 id="优化的目标"><a href="#优化的目标" class="headerlink" title="优化的目标"></a>优化的目标</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM4.png" alt=""></p><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM5.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM6.png" alt=""></p><h3 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM7.png" alt=""></p><h3 id="SVM求解"><a href="#SVM求解" class="headerlink" title="SVM求解"></a>SVM求解</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM8.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM9.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM10.png" alt=""></p><h3 id="SVM求解实例"><a href="#SVM求解实例" class="headerlink" title="SVM求解实例"></a>SVM求解实例</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM11.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM12.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM13.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM14.png" alt=""></p><p>支持向量：真正发挥作用的数据点，ɑ值不为0的点</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM15.png" alt=""></p><h3 id="带松弛因子的SVM：C-SVM"><a href="#带松弛因子的SVM：C-SVM" class="headerlink" title="带松弛因子的SVM：C-SVM"></a>带松弛因子的SVM：C-SVM</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM16.png" alt=""></p><h3 id="soft-margin"><a href="#soft-margin" class="headerlink" title="soft-margin"></a>soft-margin</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM17.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM18.png" alt=""></p><h3 id="核方法"><a href="#核方法" class="headerlink" title="核方法"></a>核方法</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM19.png" alt=""></p><h3 id="低维不可分问题"><a href="#低维不可分问题" class="headerlink" title="低维不可分问题"></a>低维不可分问题</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM20.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM21.png" alt=""></p><h3 id="常用核函数"><a href="#常用核函数" class="headerlink" title="常用核函数"></a>常用核函数</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM22.png" alt=""></p><h3 id="支持向量回归（SVR）"><a href="#支持向量回归（SVR）" class="headerlink" title="支持向量回归（SVR）"></a>支持向量回归（SVR）</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM23.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM24.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM25.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVR1.png" alt=""></p><h3 id="Scikit-learn-中的SVM实现"><a href="#Scikit-learn-中的SVM实现" class="headerlink" title="Scikit learn 中的SVM实现"></a>Scikit learn 中的SVM实现</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM26.png" alt=""></p><h3 id="Scikit-learn-中的SVC实现"><a href="#Scikit-learn-中的SVC实现" class="headerlink" title="Scikit learn 中的SVC实现"></a>Scikit learn 中的SVC实现</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM27.png" alt=""></p><h3 id="核函数kernel"><a href="#核函数kernel" class="headerlink" title="核函数kernel"></a>核函数kernel</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM28.png" alt=""></p><h3 id="RBF核的参数"><a href="#RBF核的参数" class="headerlink" title="RBF核的参数"></a>RBF核的参数</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM29.png" alt=""></p><h4 id="RBF核—核参数正好"><a href="#RBF核—核参数正好" class="headerlink" title="RBF核—核参数正好"></a>RBF核—核参数正好</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM30.png" alt=""></p><h4 id="RBF核—欠拟合"><a href="#RBF核—欠拟合" class="headerlink" title="RBF核—欠拟合"></a>RBF核—欠拟合</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM31.png" alt=""></p><h4 id="RBF核—过拟合"><a href="#RBF核—过拟合" class="headerlink" title="RBF核—过拟合"></a>RBF核—过拟合</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM32.png" alt=""></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>SVM的优点：<br>    – 在高维空间中行之有效<br>    – 当维数大于样本数时仍然可用（但性能不好）<br>    – 在决策函数中只使用训练点的一个子集（支持向量），大大节省了内存开    销<br>    – 用途广泛：决策函数中可使用不同的核函数<br>• 劣势： </p><p>​    – SVM不直接提供概率估计<br>​    – 可通过交叉验证计算，代价比较高<br>• Scikit-learn中的支持向量机同时支持密集样本向量（numpy.ndarray和可通过numpy.asarray转化的数据类型）和稀疏样本向量（任何scipy.sparse对象）。但如果想用SVM对稀疏数据进行预测，则必须先在这些数据上拟合。为了优化性能，应该使用C阶（C-Ordered）numpy.ndarray（密集的）或scipy.sparse.csr_matrix（稀疏的），并指定dtype=float64</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVM1.png&quot; 
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="SVM" scheme="https://janvia.github.io/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>SVD分解</title>
    <link href="https://janvia.github.io/2019/01/22/SVD%E5%88%86%E8%A7%A3/"/>
    <id>https://janvia.github.io/2019/01/22/SVD分解/</id>
    <published>2019-01-22T00:13:44.000Z</published>
    <updated>2019-01-22T01:08:38.450Z</updated>
    
    <content type="html"><![CDATA[<h2 id="奇异值分解-SVD-原理"><a href="#奇异值分解-SVD-原理" class="headerlink" title="奇异值分解(SVD)原理"></a>奇异值分解(SVD)原理</h2><p>奇异值分解(Singular Value Decomposition，以下简称SVD)是在机器学习领域广泛应用的算法，它不光可以用于降维算法中的特征分解，还可以用于推荐系统，以及自然语言处理等领域。是很多机器学习算法的基石。</p><h3 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD1.png" alt=""></p><p>注意到要进行特征分解，矩阵A必须为方阵。那么如果A不是方阵，即行和列不相同时，我们还可以对矩阵进行分解吗？</p><p>答案是可以，此时我们的SVD登场了。</p><h3 id="SVD的定义"><a href="#SVD的定义" class="headerlink" title="SVD的定义"></a>SVD的定义</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD2.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD3.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD4.png" alt=""></p><h2 id="SVD计算举例"><a href="#SVD计算举例" class="headerlink" title="SVD计算举例"></a>SVD计算举例</h2><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD5.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD6.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD7.png" alt=""></p><h2 id="SVD性质"><a href="#SVD性质" class="headerlink" title="SVD性质"></a>SVD性质</h2><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD8.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/SVD/SVD9.png" alt=""></p><p>由于这个重要的性质，SVD可以用于<strong>PCA降维</strong>，来做<strong>数据压缩</strong>和<strong>去噪</strong>。也可以用于推荐算法，将用户和喜好对应的矩阵做特征分解，进而得到隐含的用户需求来做推荐。同时也可以用于NLP中的算法，比如潜在语义索引（LSI）。下面我们就对SVD用于PCA降维做一个介绍。</p><h2 id="SVD用于PCA"><a href="#SVD用于PCA" class="headerlink" title="SVD用于PCA"></a>SVD用于PCA</h2><p>在主成分分析（PCA）中，我们讲到要用PCA降维，需要找到样本协方差矩阵 $XX^T$ 的最大的d个特征向量，然后用这最大的d个特征向量张成的矩阵来做低维投影降维。可以看出，在这个过程中需要先求出协方差矩阵 $XX^T$ ，当样本数多样本特征数也多的时候，这个计算量是很大的。</p><p>注意到我们的SVD也可以得到协方差矩阵 $XX^T$ 最大的d个特征向量张成的矩阵，但是SVD有个好处，有一些SVD的实现算法可以不先求出协方差矩阵 $XX^T$ ，也能求出我们的右奇异矩阵V。也就是说，我们的PCA算法可以不用做特征分解，而是做SVD来完成。这个方法在样本量很大的时候很有效。实际上，scikit-learn的PCA算法的背后真正的实现就是用的SVD，而不是我们我们认为的暴力特征分解。</p><p>另一方面，注意到PCA仅仅使用了我们SVD的右奇异矩阵，没有使用左奇异矩阵，那么左奇异矩阵有什么用呢？</p><p>假设我们的样本是m×n的矩阵X，如果我们通过SVD找到了矩阵 $XX^T$ 最大的d个特征向量张成的m×d维矩阵U，则我们如果进行如下处理：</p><script type="math/tex; mode=display">X'_{d\times n}=U_{d\times m}^TX_{m\times n}</script><p>可以得到一个d×n的矩阵X‘,这个矩阵和我们原来的m×n维样本矩阵X相比，行数从m减到了d，可见对行数进行了压缩。也就是说，左奇异矩阵可以用于行数的压缩。相对的，右奇异矩阵可以用于列数即特征维度的压缩，也就是我们的PCA降维。</p><h2 id="Numpy求解SVD"><a href="#Numpy求解SVD" class="headerlink" title="Numpy求解SVD"></a>Numpy求解SVD</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">data = np.array( </span><br><span class="line">[[1, 1, 1, 0, 0], </span><br><span class="line">[2, 2, 2, 0, 0], </span><br><span class="line">[3, 3, 3, 0, 0], </span><br><span class="line">[5, 5, 3, 2, 2], </span><br><span class="line">[0, 0, 0, 3, 3], </span><br><span class="line">[0, 0, 0, 6, 6]])</span><br><span class="line">u, sigma, vt = np.linalg.svd(data)   #SVD分解</span><br><span class="line">print(u.shape, sigma.shape, vt.shape)</span><br></pre></td></tr></table></figure><h2 id="SVD小结"><a href="#SVD小结" class="headerlink" title="SVD小结"></a>SVD小结</h2><p>SVD作为一个很基本的算法，在很多机器学习算法中都有它的身影，特别是在现在的大数据时代，由于SVD可以实现并行化，因此更是大展身手。SVD的原理不难，只要有基本的线性代数知识就可以理解，实现也很简单因此值得仔细的研究。当然，SVD的缺点是分解出的矩阵解释性往往不强，有点黑盒子的味道，不过这不影响它的使用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;奇异值分解-SVD-原理&quot;&gt;&lt;a href=&quot;#奇异值分解-SVD-原理&quot; class=&quot;headerlink&quot; title=&quot;奇异值分解(SVD)原理&quot;&gt;&lt;/a&gt;奇异值分解(SVD)原理&lt;/h2&gt;&lt;p&gt;奇异值分解(Singular Value Decomposi
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="SVD" scheme="https://janvia.github.io/tags/SVD/"/>
    
  </entry>
  
  <entry>
    <title>点击预估</title>
    <link href="https://janvia.github.io/2019/01/21/%E7%82%B9%E5%87%BB%E9%A2%84%E4%BC%B0/"/>
    <id>https://janvia.github.io/2019/01/21/点击预估/</id>
    <published>2019-01-21T07:26:02.000Z</published>
    <updated>2019-01-21T09:22:53.916Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>广告显示：只显示相关的广告</p><p>背景：</p><p>​    – 用户喜欢相关的广告<br>​    – 只有用户点击时，广告平台才能收到广告费</p><p> 所以预测一个广告是否会被点击很关键</p><p>方式：<br>    – 预估点击率 (predict Click Through Rate, pCTR)</p><h3 id="推荐系统-vs-点击率预估"><a href="#推荐系统-vs-点击率预估" class="headerlink" title="推荐系统 vs. 点击率预估"></a>推荐系统 vs. 点击率预估</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT1.png" alt=""></p><h3 id="CTR的挑战"><a href="#CTR的挑战" class="headerlink" title="CTR的挑战"></a>CTR的挑战</h3><p>• 用最少的资源在大量的数据上训练大量的模型</p><blockquote><p>上亿的特征数目（模型系数的数目）</p><p>每天有上亿的流量（提供上亿次预测服务）</p><p>上亿的训练样本数目</p></blockquote><p>• 其他</p><blockquote><p>正负样本数目不均衡</p><blockquote><p>面向稀有事件的 Logistic Regression 模型校准</p></blockquote><p>特征稀疏（OneHot编码）</p></blockquote><p><a href="https://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/15/model-calibration-for-logistic-regression-in-rare-events-data" target="_blank" rel="noopener">https://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/15/model-calibration-for-logistic-regression-in-rare-events-data</a></p><h3 id="CTR预估"><a href="#CTR预估" class="headerlink" title="CTR预估"></a>CTR预估</h3><p>• 预测模型：预估广告是否被点击，是一个两类分类问题</p><p>• 特征：用户、广告、场景、媒体</p><p>• 性能评估：准确率/召回率、AUC</p><h3 id="基础特征"><a href="#基础特征" class="headerlink" title="基础特征"></a>基础特征</h3><p>展示广告：在某场景下，通过某媒体向用户展示广告<br>– 场景：当时场景，如何时何地，使用何种设备，使用什么浏览器等<br>– 广告 - 广告主特征、广告自身的特征如campaign、创意、类型，是否重定向等<br>– 媒体 - 媒体（网页、app等）的特征、广告位的特征等<br>– 用户 - 用户画像、用户浏览历史、检索关键词等</p><h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><p>• 特征离散化<br>• 特征交叉<br>    FM/FFM： 类别型    特征<br>    OneHot编码后再组合<br>    GBDT：用树的叶子节点索引作为样本特征<br>    特征组合并特征离散化<br>• 特征选择：嵌入到模型</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT2.png" alt=""></p><h3 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h3><p>• Logistic回归（LR）：<br>    – 特征工程很重要<br>    – LR-FTRL： Google在2010年提出了一些理论基础，2013年给出了Paper，并且带有FTRL的实现伪代码。在此之后，FTRL才大规模应用在工业界。<br>• FM(Factorization Machines)<br>    – Steffen Rendle于2010年提出Factorization Machines（FM），并发布开源工具libFM。凭借这单个模型，他在KDD Cup 2012上，取得Track1的第2名和Track2的第3名。本质上可看作是：高效特征交叉 + LR。<br>• 深度学习DNN<br>    – 特征工程工作量少，但10^11 级别的原始广告特征、以及特征的稀疏性对DNN还是巨大挑战</p><h3 id="CTR模型评估"><a href="#CTR模型评估" class="headerlink" title="CTR模型评估"></a>CTR模型评估</h3><p>• 原则上分类性能评价指标均可用于CTR模型评估<br>    – Logloss、PR、…<br>• 最常用的评估指标：ROC曲线下的面积（Area Under Curve， AUC ）<br>    – 随机分类模型AUC为0.5<br>    – 越接近1模型的效果越好<br>当随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。</p><h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>• 当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变 ,AUC不变<br>• CTR场景下，测试数据中的正负样本的分布可能随着时间变化而变化</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT3.png" alt=""></p><h3 id="CTR预估-Logistic回归（LR）"><a href="#CTR预估-Logistic回归（LR）" class="headerlink" title="CTR预估-Logistic回归（LR）"></a>CTR预估-Logistic回归（LR）</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT4.png" alt=""></p><h3 id="Logistic回归-L1正则"><a href="#Logistic回归-L1正则" class="headerlink" title="Logistic回归 + L1正则"></a>Logistic回归 + L1正则</h3><p>由于CTR预估中特征维数非常高，我们希望得到稀疏解，利用L1正则，目标函数为</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT6.png" alt=""></p><h3 id="Google-Large-scale-LR-model"><a href="#Google-Large-scale-LR-model" class="headerlink" title="Google: Large scale LR model"></a>Google: Large scale LR model</h3><p>• Ad Click Prediction A view from the trenches<br>– Google FTRL模型在点击率预估任务上的应用<br>• FTRL是L1正则的LR，但对模型训练进行了优化：<br>– 在线学习（Online Learning）<br>– 模型稀疏<br>• 很重要，因为CTR问题中通常特征维数很高（上亿）<br>• 很稀疏（离散特征＋OneHot 编码）</p><h3 id="FTRL-Follow-The-Regulized-Leader"><a href="#FTRL-Follow-The-Regulized-Leader" class="headerlink" title="FTRL (Follow The Regulized Leader)"></a>FTRL (Follow The Regulized Leader)</h3><p>• 在批处理模式下，L1正则化通常产生稀疏模型<br>• 但Online中，每次权重向量的更新并不是沿着全局梯度进行下降，而是沿着某个样本的产生的梯度方向进行下降，整个寻优过程变得像是一个随机查找的过程，这样Online最优化求解即使采用L1正则化的方式，也很难产生稀疏解。<br>• 在线稀疏模：FTRL<br>    – FTRL 综合了RDA和FOBOS，在L1范数或者其他非光滑的正则项下，能高效地得到稀疏解</p><h3 id="FTRL"><a href="#FTRL" class="headerlink" title="FTRL"></a>FTRL</h3><p>• FTRL和SGD是等价的。</p><p>• FTRL工程实现技巧（如节省内存等）请见原始论文。</p><p>• Tensorflow支持FRTL：FtrlOptimizer</p><p>性能：</p><p> L1-FOBOS、L1-RDA和L1-FTRL在一个小规模数据集（10^6 ）上的性能</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT5.png" alt=""></p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] Convex function. <a href="http://en.wikipedia.org/wiki/Convex_function" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Convex_function</a><br>[2] Lagrange multiplier. <a href="http://en.wikipedia.org/wiki/Lagrange_multiplier" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Lagrange_multiplier</a><br>[3] Karush–Kuhn–Tucker conditions. <a href="http://en.wikipedia.org/wiki/Karush-Kuhn-Tucker_conditions" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Karush-Kuhn-Tucker_conditions</a><br>[4] 冯扬. 并行逻辑回归 . <a href="http://blog.sina.com.cn/s/blog_6cb8e53d0101oetv.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_6cb8e53d0101oetv.html</a><br>[5] Gradient. <a href="http://sv.wikipedia.org/wiki/Gradient" target="_blank" rel="noopener">http://sv.wikipedia.org/wiki/Gradient</a><br>[6] Subgradient. <a href="http://sv.wikipedia.org/wiki/Subgradient" target="_blank" rel="noopener">http://sv.wikipedia.org/wiki/Subgradient</a><br>[7] Andrew Ng. CS229 Lecture notes. <a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf" target="_blank" rel="noopener">http://cs229.stanford.edu/notes/cs229-notes1.pdf</a><br>[8] Stochastic Gradient Descent. <a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Stochastic_gradient_descent</a><br>[9] T. Hastie, R. Tibshirani &amp; J. Friedman. The Elements of Statistical Learning, Second Edition: Data Mining,Inference, and Prediction. Springer Series in Statistics. Springer, 2009</p><p>[10] John Langford, Lihong Li &amp; Tong Zhang. Sparse Online Learning via Truncated Gradient. Journal of Machine Learning Research, 2009<br>[11] John Duchi &amp; Yoram Singer. Efficient Online and Batch Learning using Forward Backward Splitting. Journal of<br>Machine Learning Research, 2009<br>[12] Lin Xiao. Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization. Journal of Machine Learning Research, 2010<br>[13] Convex Set. <a href="http://en.wikipedia.org/wiki/Convex_set" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Convex_set</a><br>[14] H. Brendan McMahan &amp; M Streter. Adaptive Bound Optimization for Online Convex Optimization. In COLT,2010<br>[15] H. Brendan McMahan. Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and L1 Regularization. In AISTATS, 2011</p><p>[16] H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Ad Click Prediction: a View from the Trenches. In ACM SIGKDD, 2013<br>[17] Martin A. Zinkevich, Markus Weimer, Alex Smola &amp; Lihong Li. Parallelized Stochastic Gradient Descent. In NIPS 2010</p><h3 id="Facebook-GBDT-LR"><a href="#Facebook-GBDT-LR" class="headerlink" title="Facebook : GBDT+LR"></a>Facebook : GBDT+LR</h3><p>• Practical Lessons from Predicting Clicks on Ads at Facebook [1]<br>• 用GBDT编码特征，然后再用LR做分类<br>– GBDT可替代FM做特征编码<br>– LR可用FTRL代替</p><p>[1] Xinran He et al. Practical Lessons from Predicting Clicks on Ads at Facebook, 2014.</p><p><a href="https://cloud.tencent.com/developer/article/1005052" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1005052</a></p><h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>• 用LR做CTR预估时，需做大量的特征工程 （非线性特征）<br>– 连续特征离散化（+ One-Hot编码）<br>– 特征进行二阶或者三阶的特征组合<br>• 问题：<br>– 连续变量切分点如何选取？<br>– 离散化为多少份合理？<br>– 选择哪些特征交叉？<br>– 多少阶交叉，二阶，三阶或更多？<br>• GBDT：一举解决了上面的问题<br>– 确定切分点和切分数目不在是凭主观经验，而是根据信息增益/Gini指标<br>– 每棵决策树从根节点到叶节点的路径，会经过不同的特征，此路径就是特征组合，而且包含了二阶，三阶甚至更多（所以GBDT提取特征时层数不用太深）</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT7.png" alt=""></p><p>如上图所示：</p><p>GBDT训练得到：<br>第一棵树有3个叶子结点<br>第二棵树有2个叶子节点</p><p>GBDT编码：对于一个输入样本点x，如果它在第一棵树最后落在其中的第3个叶子结点，在第二棵树里最后落在第1个叶子结点，则通过GBDT获得的新特征向量为[0, 0, 1, 1,0]，向量中的前三位对应第一棵树的3个叶子结点，后两位对应第二棵树的２个叶子结点</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>• xgboost：predict函数<br>– predict(data, output_margin=False, ntree_limit=0, pred_leaf=False, pred_contribs=False, approx_contribs=False)<br>• lightGBM: predict函数<br>– predict(data, output_margin=False, ntree_limit=0, pred_leaf=False, pred_contribs=False, approx_contribs=False)</p><p>xgb_feature = xgb.predict(dtv, pred_leaf = True)</p><h3 id="GBDT-FM"><a href="#GBDT-FM" class="headerlink" title="GBDT+FM"></a>GBDT+FM</h3><p>• Kaggle 2014年竞赛：Criteo Display Advertising Challenge<br>– <a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="noopener">https://www.kaggle.com/c/criteo-display-ad-challenge</a><br>• Rank1解决方案：3 idiot’s FM （FFM的发明者）</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT8.png" alt=""></p><p>• Kaggle 2015年竞赛： Click-Through Rate Prediction<br> – <a href="https://www.kaggle.com/c/avazu-ctr-prediction" target="_blank" rel="noopener">https://www.kaggle.com/c/avazu-ctr-prediction</a><br>• Rank2解决方案：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT9.png" alt=""></p><p>为什么不直接用GBDT？</p><p>• 因为GBDT在线预测比较困难，而且训练时间复杂度高于LR。</p><p>• 所以实际中，可以离线训练GBDT，然后将该模型作为在线ETL的一部分。</p><h3 id="Factorization-Machines（FM）"><a href="#Factorization-Machines（FM）" class="headerlink" title="Factorization Machines（FM）"></a>Factorization Machines（FM）</h3><p>• Steffen Rendle于2010年提出Factorization Machines[1]，并发布开源工具libFM</p><p>（<a href="http://www.libfm.org/" target="_blank" rel="noopener">http://www.libfm.org/</a> ）。<br>– 凭借这单个模型，他在KDD Cup 2012上，取得Track1的第2名和Track2的第3名。<br>• FM旨在解决稀疏数据的特征组合问题<br>– Recall：LR为线性模型，需要输入足够强的特征（特征组合）</p><p>[1] Steffen Rendle, Factorization Machines, Proceedings of the 10th IEEE International Conference on Data Mining (ICDM 2010), Sydney, Australia</p><h3 id="数据稀疏"><a href="#数据稀疏" class="headerlink" title="数据稀疏"></a>数据稀疏</h3><p>• CTR预估中很多类别型特征：例国家、节日<br>– 国家和节日为类别型特征 ，需要One Hot 编码</p><p>原始特征：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT10.png" alt=""></p><p>OneHot编码：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT11.png" alt=""></p><h3 id="特征组合"><a href="#特征组合" class="headerlink" title="特征组合"></a>特征组合</h3><p>某些特征经过关联之后，与label之间的相关性就会提高<br>例：将国家于假日组合：</p><ul><li><p>“ USA”与“Thanksgiving”</p></li><li><p>“China”与“Chinese New Year”</p></li></ul><p>这样的关联特征，对用户的点击有着正向的影响<br>来自“China”的用户很可能会在“Chinese New Year”有大量的浏览、购买行为，在“Thanksgiving”却不会有特别的消费行为。<br>更多示例：<br>• “化妆品”类商品与“女”性<br>• “球类运动配件”的商品与“男”性</p><h3 id="二阶多项式模型"><a href="#二阶多项式模型" class="headerlink" title="二阶多项式模型"></a>二阶多项式模型</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT12.png" alt=""></p><h3 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT13.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT14.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT15.png" alt=""></p><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT16.png" alt=""></p><h3 id="Field-aware-Factorization-Machines（FFM）"><a href="#Field-aware-Factorization-Machines（FFM）" class="headerlink" title="Field-aware Factorization Machines（ＦＦＭ）"></a>Field-aware Factorization Machines（ＦＦＭ）</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT17.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT18.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT19.png" alt=""></p><h3 id="FFM的二次交叉项"><a href="#FFM的二次交叉项" class="headerlink" title="FFM的二次交叉项"></a>FFM的二次交叉项</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT20.png" alt=""></p><h3 id="FFM实现"><a href="#FFM实现" class="headerlink" title="FFM实现"></a>FFM实现</h3><p>• 作者提供C++版本实现： libffm<br>– <a href="https://github.com/guestwalk/libffm" target="_blank" rel="noopener">https://github.com/guestwalk/libffm</a></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/CRT/CRT21.png" alt=""></p><h3 id="DNN-for-CTR"><a href="#DNN-for-CTR" class="headerlink" title="DNN for CTR"></a>DNN for CTR</h3><p>• Google: Deep wide DNN – Wide &amp; Deep Learning for Recommender Systems<br>• FNN:– Deep Learning over Multi - field Categorical Data – A Case Study on User Response<br>Prediction<br>• PNN:– Product - based Neural Networks for User Response Prediction<br>• NFM– Neural Factorization Machines for Sparse Predictive Analytics<br>• Alibaba display ads: Deep interest network<br>– Deep Interest Network for Click - Through Rate Prediction<br>– Use attention - like network structure to model local activation of user interest to candidate<br>ad.</p><h3 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h3><p>1、<a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">http://blog.csdn.net/lilyth_lilyth/article/details/48032119</a><br>2、<a href="http://www.cnblogs.com/Matrix_Yao/p/4773221.html" target="_blank" rel="noopener">http://www.cnblogs.com/Matrix_Yao/p/4773221.html</a><br>3、<a href="http://www.herbrich.me/papers/adclicksfacebook.pdf" target="_blank" rel="noopener">http://www.herbrich.me/papers/adclicksfacebook.pdf</a><br>4、<a href="https://www.kaggle.com/c/criteo-display-ad-challenge" target="_blank" rel="noopener">https://www.kaggle.com/c/criteo-display-ad-challenge</a><br>5、<a href="https://www.kaggle.com/c/avazu-ctr-prediction" target="_blank" rel="noopener">https://www.kaggle.com/c/avazu-ctr-prediction</a><br>6、<a href="https://en.wikipedia.org/wiki/Demand-side_platform" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Demand-side_platform</a><br>7、<a href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf" target="_blank" rel="noopener">http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf</a><br>8、<a href="http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf" target="_blank" rel="noopener">http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf</a><br>9、<a href="http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf" target="_blank" rel="noopener">http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf</a><br>10、<a href="https://github.com/guestwalk/libffm" target="_blank" rel="noopener">https://github.com/guestwalk/libffm</a><br>11、<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad</a><br>12、<a href="http://openmp.org/wp/openmp-specifications/" target="_blank" rel="noopener">http://openmp.org/wp/openmp-specifications/</a><br>13、<a href="http://blog.csdn.net/gengshenghong/article/details/7008704" target="_blank" rel="noopener">http://blog.csdn.net/gengshenghong/article/details/7008704</a><br>14、<a href="https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf" target="_blank" rel="noopener">https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h3&gt;&lt;p&gt;广告显示：只显示相关的广告&lt;/p&gt;
&lt;p&gt;背景：&lt;/p&gt;
&lt;p&gt;​    – 用户喜欢相关的广告&lt;br&gt;​    – 只有用户点击时，广告平
      
    
    </summary>
    
      <category term="机器学习" scheme="https://janvia.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="点击预估" scheme="https://janvia.github.io/tags/%E7%82%B9%E5%87%BB%E9%A2%84%E4%BC%B0/"/>
    
  </entry>
  
  <entry>
    <title>LSTM</title>
    <link href="https://janvia.github.io/2019/01/21/LSTM/"/>
    <id>https://janvia.github.io/2019/01/21/LSTM/</id>
    <published>2019-01-21T01:57:08.000Z</published>
    <updated>2019-01-21T07:11:58.977Z</updated>
    
    <content type="html"><![CDATA[<h3 id="LSTM模型"><a href="#LSTM模型" class="headerlink" title="ＬＳＴＭ模型"></a>ＬＳＴＭ模型</h3><p>LSTM（Long Short-Term Memory）是长短期记忆网络，是一种时间递归神经网络，适合于处理和预测时间序列中间隔和延迟相对较长的重要事件。<br>就是所谓的该记得会一直传递，不该记得就被“忘记”。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM1.png" alt=""></p><p>“记忆细胞”变得稍微复杂了一点</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM2.png" alt=""></p><h3 id="细胞状态"><a href="#细胞状态" class="headerlink" title="细胞状态"></a>细胞状态</h3><p>细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传会很容易保持不变。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM3.png" alt=""></p><p><strong>LSTM</strong>控制“细胞状态”的方式：</p><ul><li>通过“门”让信息选择性通过，来去除或者增加信息到细胞状态。</li><li>包含一个<code>SIGMOD</code>神经元层和一个<code>pointwise</code>乘法操作。</li><li><code>SIGMOD</code>层输出0到1之间的概率值，描述每个部分有多少量可以通过。0代表“不许任何量通过”，1就表示“允许任意量通过”。</li></ul><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM4.png" alt=""></p><h3 id="遗忘门"><a href="#遗忘门" class="headerlink" title="遗忘门"></a>遗忘门</h3><p>遗忘门（forget gate）顾名思义，是控制是否遗忘的，在LSTM中即以一定的概率控制是否遗忘上一层的隐藏细胞状态。遗忘门子结构如下图所示：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM5.png" alt=""></p><p>图中输入的有上一序列的隐藏状态<script type="math/tex">h_{t−1}</script>和本序列数据<script type="math/tex">x_t</script>，通过一个激活函数，一般情况下是<code>SIGMOD</code>，得到遗忘门的输出$f_t$。由于SIGMOD的输出$f_t$在[0,1]之间，因此这里的输出$f_t$代表了遗忘上一层隐藏细胞的概率。</p><p><strong>数学表达式</strong>：</p><p>$f(t)=\sigma(W<em>f h</em>{t-1}+U_f x_t+b_f)$</p><p>其中：$W_f、U_f、b_f$为线性关系的权重项和偏置项，σ为SIGMOD激活函数。</p><h3 id="输入门"><a href="#输入门" class="headerlink" title="输入门"></a>输入门</h3><p>输入门（input gate）负责处理当前序列位置的输入，它的子结构如下图：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM6.png" alt=""></p><p>从图中可以看到输入门由两部分组成，第一部分使用了sigmoid激活函数，输出为<script type="math/tex">i_{(t)}</script>,第二部分使用了tanh激活函数，输出为<script type="math/tex">c_{(t)}</script>, 两者的结果后面会相乘再去更新细胞状态。</p><ul><li>SIGMOD层决定什么值需要更新。</li><li>Tanh层创建一个新的候选值向量$c_{(t)}$</li><li>第二步还是为状态更新做准备。</li></ul><p><strong>数学表达式</strong>：</p><script type="math/tex; mode=display">i{(t)} = \sigma(W_ih_{t-1} + U_ix_t + b_i)</script><script type="math/tex; mode=display">\tilde c{(t)} =tanh(W_ah_{t-1} + U_ax_t + b_a)</script><p>其中$W_i,U_i,b_i,W_a,U_a,b_a$，为线性关系的权重项和偏置项，σ为SIGMOD激活函数。</p><h3 id="更新细胞"><a href="#更新细胞" class="headerlink" title="更新细胞"></a>更新细胞</h3><p>在研究LSTM输出门之前，我们要先看看LSTM之细胞状态。前面的遗忘门和输入门的结果都会作用于细胞状态 C(t)，我们来看看细胞如何从C(t−1)到C(t):</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM7.png" alt=""></p><p>由图可知：细胞状态<script type="math/tex">C_t</script>由两部分组成；第一部分是<script type="math/tex">C_{t−1}</script>和遗忘门输出<script type="math/tex">f_t</script>的乘积，第二部分是输入门的<script type="math/tex">i_t和\tilde c_{(t)}</script>的乘积，总结为如下三点：</p><ul><li>更新<script type="math/tex">C_{(t−1)}为C_{(t)}</script>。</li><li>把<script type="math/tex">C_{(t−1)}</script>和$f_{(t)}$相乘，丢弃掉我们确定需要丢弃的信息。</li><li>加上$i(t) * \tilde c_{(t)}$。最后得到新的候选值，根据我们决定更新每个状态的程度进行变化。</li></ul><p><strong>数学表达式</strong>：</p><script type="math/tex; mode=display">C_{(t)} = C_{(t-1)} \odot f{(t)} + i_{(t)} \odot \tilde c_{(t)}</script><p>其中，⨀为Hadamard积.</p><h3 id="输出门"><a href="#输出门" class="headerlink" title="输出门"></a>输出门</h3><p>有了新的隐藏细胞状态C(t)，我们就可以来看输出门了，子结构如下：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM8.png" alt=""></p><p>从图中可以看出：隐藏状态<script type="math/tex">h_t</script>的更新由两个部分组成：第一部分是<script type="math/tex">o_t</script>，它是由上一序列的隐藏状态<script type="math/tex">h_{t−1}</script>和本序列的<script type="math/tex">x_t</script>，以及激活函数SIGMOD得到的，第二部分是由隐藏状态<script type="math/tex">C_t和Tanh</script>激活函数组成，即：</p><ul><li>最开始先运行一个SIGMOD层来确定细胞状态的哪个部分将输出。</li><li>接着用tanh处理细胞状态（得到一个-1到1之间的值），再将它和SIGMOD门的输出相乘。输出我们确定输出的那部分值。</li></ul><p><strong>数学表达式</strong>：</p><script type="math/tex; mode=display">o_t=\sigma(W_o[h_{t-1},x_t]+b_o)</script><script type="math/tex; mode=display">h_t=o_t*tanh(C_t)</script><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM9.png" alt=""></p><h3 id="LSTM变体"><a href="#LSTM变体" class="headerlink" title="LSTM变体"></a>LSTM变体</h3><ul><li>增加<code>peephole connection</code></li><li>让门层也会接受细胞状态的输入。</li></ul><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM10.png" alt=""></p><p><strong>数学表达式</strong>：</p><script type="math/tex; mode=display">f_t=\sigma(W_f \cdot[C_{t-1}, h_{t-1},x_t]+b_f)</script><script type="math/tex; mode=display">i_t=\sigma(W_i \cdot[C_{t-1}, h_{t-1},x_t]+b_i)</script><script type="math/tex; mode=display">o_t=\sigma(W_o \cdot[C_{t-1}, h_{t-1},x_t]+b_o)</script><ul><li>通过使用<code>coupled</code>忘记和输入门</li><li>之前是分开确定需要忘记和添加的信息，然后一同做出决定。</li></ul><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM11.png" alt=""></p><p><strong>数学表达式</strong>：</p><script type="math/tex; mode=display">C_t=f_t * C_{t-1}+(1-f_t)  *  \tilde C_t</script><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p><strong>Gatad Reacurrent Unit (GRU)</strong>，2014年提出。</p><ul><li>将忘记门和输入门合成了一个单一的<strong>更新门</strong></li><li>混合了细胞状态和隐藏状态</li><li>比标准的LSTM简单</li></ul><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM13.png" alt=""></p><p><strong>数学表达式</strong>：</p><script type="math/tex; mode=display">z_t=\sigma(W_z \cdot [h_{t-1},x_t])</script><script type="math/tex; mode=display">r_t=\sigma(W_r \cdot [h_{t-1},x_t])</script><script type="math/tex; mode=display">\tilde h_t= tanh(W \cdot [r_t*h_{t-1},x_t])</script><script type="math/tex; mode=display">h_t=(1-z_t)  * h_{t-1} + z_t  *  \tilde h_t</script><h3 id="LSTM总结"><a href="#LSTM总结" class="headerlink" title="LSTM总结"></a>LSTM总结</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/LSTM14.png" alt=""></p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><h4 id="LSTM"><a href="#LSTM" class="headerlink" title="ＬＳＴＭ"></a>ＬＳＴＭ</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line"># 导入数据</span><br><span class="line">mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</span><br><span class="line"></span><br><span class="line"># 超参数设置</span><br><span class="line">lr = 0.001  # 学习率</span><br><span class="line">epochs = 100000  # 最大训练次数</span><br><span class="line">batch_size = 128  # 小批量样本数</span><br><span class="line">n_inputs = 28  # Mnist数据输入维度 (img shape: 28*28)</span><br><span class="line">n_steps = 28  # time steps</span><br><span class="line">n_hidden_units = 128  # 隐层神经元</span><br><span class="line">n_classes = 10  # MNIST 分类 (0-9 digits)</span><br><span class="line"></span><br><span class="line"># x y placeholder</span><br><span class="line">x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])  # [None, 28, 28]</span><br><span class="line">y = tf.placeholder(tf.float32, [None, n_classes])  # [None,10]</span><br><span class="line"></span><br><span class="line"># 对 weights biases 初始值的定义</span><br><span class="line">weights = &#123;</span><br><span class="line">    # shape (28, 128)</span><br><span class="line">    &apos;in&apos;: tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),</span><br><span class="line">    # shape (128, 10)</span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden_units, n_classes]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    # shape (128, )</span><br><span class="line">    &apos;in&apos;: tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),</span><br><span class="line">    # shape (10, )</span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.constant(0.1, shape=[n_classes, ]))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def RNN(X, weights, biases):</span><br><span class="line">    # input layer</span><br><span class="line">    # 原始的 X 是 3 维数据, 我们需要把它变成 2 维数据才能使用 weights 的矩阵乘法</span><br><span class="line">    # X ==&gt; (128 batches * 28 steps, 28 inputs)</span><br><span class="line">    X = tf.reshape(X, [-1, n_inputs])</span><br><span class="line"></span><br><span class="line">    # X_in = W*X + b</span><br><span class="line">    X_in = tf.matmul(X, weights[&apos;in&apos;]) + biases[&apos;in&apos;]</span><br><span class="line">    # X_in ==&gt; (128 batches, 28 steps, 128 hidden) 换回3维</span><br><span class="line">    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])</span><br><span class="line"></span><br><span class="line">    # cell计算</span><br><span class="line">    # 使用 basic LSTM Cell.</span><br><span class="line">    cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)</span><br><span class="line">    init_state = cell.zero_state(batch_size, dtype=tf.float32)  # 初始化全零 state</span><br><span class="line"></span><br><span class="line">    # 使用tf.nn.dynamic_rnn(cell, inputs)，我们要确定inputs的格式。</span><br><span class="line">    # tf.nn.dynamic_rnn中的time_major参数会针对不同inputs格式有不同的值。</span><br><span class="line">    # 如果inputs为（批次，步骤，输入）==&gt; time_major=False;</span><br><span class="line">    # 如果inputs为（步骤，批次，输入）==&gt; time_major=True;</span><br><span class="line">    outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False)</span><br><span class="line"></span><br><span class="line">    # 输出层</span><br><span class="line"></span><br><span class="line">    results = tf.matmul(final_state[1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]</span><br><span class="line">    return results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pred = RNN(x, weights, biases)</span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))</span><br><span class="line">train_optimizer = tf.train.AdamOptimizer(lr).minimize(cost)</span><br><span class="line"></span><br><span class="line">correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    step = 0</span><br><span class="line">    while step * batch_size &lt; epochs:</span><br><span class="line">        batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])</span><br><span class="line">        _ = sess.run([train_optimizer], feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line">        if step % 20 == 0:</span><br><span class="line">            # 计算批次数据的准确率</span><br><span class="line">            acc = sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line">            # Calculate batch loss</span><br><span class="line">            loss = sess.run(cost, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)</span><br><span class="line">            print(&quot;Iter &quot; + str(step * batch_size) + &quot;, Minibatch Loss= &quot; + \</span><br><span class="line">                  &quot;&#123;:.6f&#125;&quot;.format(loss) + &quot;, Training Accuracy= &quot; + \</span><br><span class="line">                  &quot;&#123;:.5f&#125;&quot;.format(acc))</span><br><span class="line">        step += 1</span><br><span class="line">    print(&quot; Finished!&quot;)</span><br><span class="line">    # 计算准确率 for 128 mnist test images</span><br><span class="line">    test_len = 128</span><br><span class="line">    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_inputs))</span><br><span class="line">    test_label = mnist.test.labels[:test_len]</span><br><span class="line">    print(&quot;Testing Accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label&#125;))</span><br></pre></td></tr></table></figure><h4 id="GRU-1"><a href="#GRU-1" class="headerlink" title="GRU"></a>GRU</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line"># 导入 MINST 数据集</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(&quot;MNIST_data&quot;, one_hot=True)</span><br><span class="line"></span><br><span class="line">n_input = 28  # MNIST data 输入 (img shape: 28*28)</span><br><span class="line">n_steps = 28  # timesteps</span><br><span class="line">n_hidden = 128  # hidden layer num of features</span><br><span class="line">n_classes = 10  # MNIST 列别 (0-9 ，一共10类)</span><br><span class="line"></span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"># tf Graph input</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</span><br><span class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</span><br><span class="line"></span><br><span class="line">x1 = tf.unstack(x, n_steps, 1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># gru</span><br><span class="line">gru = tf.contrib.rnn.GRUCell(n_hidden)</span><br><span class="line">outputs = tf.contrib.rnn.static_rnn(gru, x1, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">pred = tf.contrib.layers.fully_connected(outputs[-1], n_classes, activation_fn=None)</span><br><span class="line"></span><br><span class="line">learning_rate = 0.001</span><br><span class="line">training_iters = 100000</span><br><span class="line">batch_size = 128</span><br><span class="line">display_step = 10</span><br><span class="line"></span><br><span class="line"># Define loss and optimizer</span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"># Evaluate model</span><br><span class="line">correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line"># 启动session</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    step = 1</span><br><span class="line">    # Keep training until reach max iterations</span><br><span class="line">    while step * batch_size &lt; training_iters:</span><br><span class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line">        # Reshape data to get 28 seq of 28 elements</span><br><span class="line">        batch_x = batch_x.reshape((batch_size, n_steps, n_input))</span><br><span class="line">        # Run optimization op (backprop)</span><br><span class="line">        sess.run(optimizer, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">        if step % display_step == 0:</span><br><span class="line">            # 计算批次数据的准确率</span><br><span class="line">            acc = sess.run(accuracy, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">            # Calculate batch loss</span><br><span class="line">            loss = sess.run(cost, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">            print(&quot;Iter &quot; + str(step * batch_size) + &quot;, Minibatch Loss= &quot; + \</span><br><span class="line">                  &quot;&#123;:.6f&#125;&quot;.format(loss) + &quot;, Training Accuracy= &quot; + \</span><br><span class="line">                  &quot;&#123;:.5f&#125;&quot;.format(acc))</span><br><span class="line">        step += 1</span><br><span class="line">    print(&quot; Finished!&quot;)</span><br><span class="line"></span><br><span class="line">    # 计算准确率 for 128 mnist test images</span><br><span class="line">    test_len = 128</span><br><span class="line">    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))</span><br><span class="line">    test_label = mnist.test.labels[:test_len]</span><br><span class="line">    print(&quot;Testing Accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label&#125;))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;LSTM模型&quot;&gt;&lt;a href=&quot;#LSTM模型&quot; class=&quot;headerlink&quot; title=&quot;ＬＳＴＭ模型&quot;&gt;&lt;/a&gt;ＬＳＴＭ模型&lt;/h3&gt;&lt;p&gt;LSTM（Long Short-Term Memory）是长短期记忆网络，是一种时间递归神经网络，适合于处理
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="LSTM" scheme="https://janvia.github.io/tags/LSTM/"/>
    
      <category term="RNN" scheme="https://janvia.github.io/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>DCGAN</title>
    <link href="https://janvia.github.io/2019/01/21/DCGAN/"/>
    <id>https://janvia.github.io/2019/01/21/DCGAN/</id>
    <published>2019-01-21T00:13:02.000Z</published>
    <updated>2019-01-21T07:19:44.270Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>DCGAN即使用卷积网络的对抗网络，其原理和GAN一样，只是把CNN的卷积技术用于GAN模式的网络里，G（生成器）网在生成数据时，使用反卷积的重构技术来重构原始图片。D（判别器）网用卷积技术来识别图片特征，进而作出判别。</p><p><a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="noopener">https://arxiv.org/abs/1511.06434</a></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/DCGAN1.png" alt=""></p><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/DCGAN2.png" alt=""></p><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>在DCGAN中，生成式模型G(z)使用一个比较特殊的深度卷积网络来实现，如下图所示：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/DCGAN3.png" alt=""></p><h3 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h3><p>从前面两幅图中可以看出，DCGAN的生成式模型G(z)中出现了上采样（upsampling）。</p><p>卷积神经网络的下采样很好理解，加入pooling层即可，然而这里的上采样要如何实现呢？</p><p>这里，DCGAN通过“微步幅卷积”（fractionally-strided convolution）进行上采样。</p><p>假设有一个3×3的输入，希望输出的尺寸比这要大，那么可以把这个3×3的输入通过在像素之间插入0的方式来进行扩展，如下图所示。当扩展到7×7的尺寸后，再进行卷积，就可以得到尺寸比原来大的输出。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/DCGAN4.png" alt=""></p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/DCGAN5.png" alt=""></p><h3 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/DCGAN6.png" alt=""></p><p><a href="https://github.com/hindupuravinash/the-gan-" target="_blank" rel="noopener">https://github.com/hindupuravinash/the-gan-</a></p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>深度卷积神经网络生成Mnist手写数据集—-DCGAN</p><p>导入环境</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br></pre></td></tr></table></figure><p>数据准备与超参数设置</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(&apos;data&apos;)</span><br><span class="line"># 定义参数</span><br><span class="line">batch_size = 64</span><br><span class="line">noise_size = 100</span><br><span class="line">epochs = 5</span><br><span class="line">n_samples = 25</span><br><span class="line">learning_rate = 0.001</span><br></pre></td></tr></table></figure><p>数据处理</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_inputs(noise_dim, image_height, image_width, image_depth):</span><br><span class="line">    # 真实数据</span><br><span class="line">    inputs_real = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth], name=&apos;inputs_real&apos;)</span><br><span class="line">    # 噪声数据</span><br><span class="line">    inputs_noise = tf.placeholder(tf.float32, [None, noise_dim], name=&apos;inputs_noise&apos;)</span><br><span class="line"></span><br><span class="line">    return inputs_real, inputs_noise</span><br></pre></td></tr></table></figure><p>构建DCGAN网络结构</p><p>生成器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_generator(noise_img, output_dim, is_train=True, alpha=0.01):</span><br><span class="line">    with tf.variable_scope(&quot;generator&quot;, reuse=(not is_train)):</span><br><span class="line">        # 100 x 1 to 4 x 4 x 512</span><br><span class="line">        # 全连接层</span><br><span class="line">        layer1 = tf.layers.dense(noise_img, 4 * 4 * 512)</span><br><span class="line">        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])</span><br><span class="line">        # batch normalization</span><br><span class="line">        layer1 = tf.layers.batch_normalization(layer1, training=is_train)</span><br><span class="line">        # Leaky ReLU</span><br><span class="line">        layer1 = tf.maximum(alpha * layer1, layer1)</span><br><span class="line">        # dropout</span><br><span class="line">        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 4 x 4 x 512 to 7 x 7 x 256</span><br><span class="line">        layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding=&apos;valid&apos;)</span><br><span class="line">        layer2 = tf.layers.batch_normalization(layer2, training=is_train)</span><br><span class="line">        layer2 = tf.maximum(alpha * layer2, layer2)</span><br><span class="line">        layer2 = tf.nn.dropout(layer2, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 7 x 7 256 to 14 x 14 x 128</span><br><span class="line">        layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer3 = tf.layers.batch_normalization(layer3, training=is_train)</span><br><span class="line">        layer3 = tf.maximum(alpha * layer3, layer3)</span><br><span class="line">        layer3 = tf.nn.dropout(layer3, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 14 x 14 x 128 to 28 x 28 x 1</span><br><span class="line">        logits = tf.layers.conv2d_transpose(layer3, output_dim, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        # MNIST原始数据集的像素范围在0-1，这里的生成图片范围为(-1,1)</span><br><span class="line">        # 因此在训练时，记住要把MNIST像素范围进行resize</span><br><span class="line">        outputs = tf.tanh(logits)</span><br><span class="line"></span><br><span class="line">        return outputs</span><br></pre></td></tr></table></figure><p>判别器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_discriminator(inputs_img, reuse=False, alpha=0.01):</span><br><span class="line">    with tf.variable_scope(&quot;discriminator&quot;, reuse=reuse):</span><br><span class="line">        # 28 x 28 x 1 to 14 x 14 x 128</span><br><span class="line">        # 第一层不加入BN</span><br><span class="line">        layer1 = tf.layers.conv2d(inputs_img, 128, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer1 = tf.maximum(alpha * layer1, layer1)</span><br><span class="line">        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 14 x 14 x 128 to 7 x 7 x 256</span><br><span class="line">        layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer2 = tf.layers.batch_normalization(layer2, training=True)</span><br><span class="line">        layer2 = tf.maximum(alpha * layer2, layer2)</span><br><span class="line">        layer2 = tf.nn.dropout(layer2, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 7 x 7 x 256 to 4 x 4 x 512</span><br><span class="line">        layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer3 = tf.layers.batch_normalization(layer3, training=True)</span><br><span class="line">        layer3 = tf.maximum(alpha * layer3, layer3)</span><br><span class="line">        layer3 = tf.nn.dropout(layer3, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 4 x 4 x 512 to 4*4*512 x 1</span><br><span class="line">        flatten = tf.reshape(layer3, (-1, 4 * 4 * 512))</span><br><span class="line">        logits = tf.layers.dense(flatten, 1)</span><br><span class="line">        outputs = tf.sigmoid(logits)</span><br><span class="line"></span><br><span class="line">        return logits, outputs</span><br></pre></td></tr></table></figure><p>计算损失值</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_loss(inputs_real, inputs_noise, image_depth, smooth=0.1):</span><br><span class="line">    g_outputs = get_generator(inputs_noise, image_depth, is_train=True)</span><br><span class="line">    d_logits_real, d_outputs_real = get_discriminator(inputs_real)</span><br><span class="line">    d_logits_fake, d_outputs_fake = get_discriminator(g_outputs, reuse=True)</span><br><span class="line"></span><br><span class="line">    # 计算Loss</span><br><span class="line">    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,</span><br><span class="line">                                                                    labels=tf.ones_like(d_outputs_fake) * (1 - smooth)))</span><br><span class="line"></span><br><span class="line">    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,</span><br><span class="line">                                                                         labels=tf.ones_like(d_outputs_real) * (</span><br><span class="line">                                                                                     1 - smooth)))</span><br><span class="line">    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,</span><br><span class="line">                                                                         labels=tf.zeros_like(d_outputs_fake)))</span><br><span class="line">    d_loss = tf.add(d_loss_real, d_loss_fake)</span><br><span class="line"></span><br><span class="line">    return g_loss, d_loss</span><br></pre></td></tr></table></figure><p>初始化优化器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_optimizer(g_loss, d_loss, learning_rate=0.001):</span><br><span class="line">    train_vars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">    g_vars = [var for var in train_vars if var.name.startswith(&quot;generator&quot;)]</span><br><span class="line">    d_vars = [var for var in train_vars if var.name.startswith(&quot;discriminator&quot;)]</span><br><span class="line"></span><br><span class="line">    # Optimizer</span><br><span class="line">    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):</span><br><span class="line">        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)</span><br><span class="line">        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)</span><br><span class="line"></span><br><span class="line">    return g_opt, d_opt</span><br></pre></td></tr></table></figure><p>显示图片</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def plot_images(samples):</span><br><span class="line">    fig, axes = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True, figsize=(7, 7))</span><br><span class="line">    for img, ax in zip(samples, axes.flatten()):</span><br><span class="line">        ax.imshow(img.reshape((28, 28)), cmap=&apos;Greys_r&apos;)</span><br><span class="line">        ax.get_xaxis().set_visible(False)</span><br><span class="line">        ax.get_yaxis().set_visible(False)</span><br><span class="line">    fig.tight_layout(pad=0)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">def show_generator_output(sess, n_images, inputs_noise, output_dim):</span><br><span class="line">    noise_shape = inputs_noise.get_shape().as_list()[-1]</span><br><span class="line">    # 生成噪声图片</span><br><span class="line">    examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape])</span><br><span class="line"></span><br><span class="line">    samples = sess.run(get_generator(inputs_noise, output_dim, False),</span><br><span class="line">                       feed_dict=&#123;inputs_noise: examples_noise&#125;)</span><br><span class="line"></span><br><span class="line">    result = np.squeeze(samples, -1)</span><br><span class="line">    return result</span><br></pre></td></tr></table></figure><p>开始训练</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def train(noise_size, data_shape, batch_size, n_samples):</span><br><span class="line">    # 存储loss</span><br><span class="line">    losses = []</span><br><span class="line">    steps = 0</span><br><span class="line"></span><br><span class="line">    inputs_real, inputs_noise = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3])</span><br><span class="line">    g_loss, d_loss = get_loss(inputs_real, inputs_noise, data_shape[-1])</span><br><span class="line">    print(&quot;FUNCTION READY!!&quot;)</span><br><span class="line">    g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, learning_rate)</span><br><span class="line">    print(&quot;TRAINING....&quot;)</span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        # 迭代epoch</span><br><span class="line">        for e in range(epochs):</span><br><span class="line">            for batch_i in range(mnist.train.num_examples // batch_size):</span><br><span class="line">                steps += 1</span><br><span class="line">                batch = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">                batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3]))</span><br><span class="line">                # scale to -1, 1</span><br><span class="line">                batch_images = batch_images * 2 - 1</span><br><span class="line"></span><br><span class="line">                # noise</span><br><span class="line">                batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))</span><br><span class="line"></span><br><span class="line">                # run optimizer</span><br><span class="line">                sess.run(g_train_opt, feed_dict=&#123;inputs_real: batch_images,</span><br><span class="line">                                                 inputs_noise: batch_noise&#125;)</span><br><span class="line">                sess.run(d_train_opt, feed_dict=&#123;inputs_real: batch_images,</span><br><span class="line">                                                 inputs_noise: batch_noise&#125;)</span><br><span class="line"></span><br><span class="line">                if steps % 101 == 0:</span><br><span class="line">                    train_loss_d = d_loss.eval(&#123;inputs_real: batch_images,</span><br><span class="line">                                                inputs_noise: batch_noise&#125;)</span><br><span class="line">                    train_loss_g = g_loss.eval(&#123;inputs_real: batch_images,</span><br><span class="line">                                                inputs_noise: batch_noise&#125;)</span><br><span class="line">                    losses.append((train_loss_d, train_loss_g))</span><br><span class="line">                    print(&quot;Epoch &#123;&#125;/&#123;&#125;....&quot;.format(e + 1, epochs),</span><br><span class="line">                          &quot;Discriminator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_d),</span><br><span class="line">                          &quot;Generator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_g))</span><br><span class="line"></span><br><span class="line">            if e % 1 == 0:</span><br><span class="line">                # 显示图片</span><br><span class="line">                samples = show_generator_output(sess, n_samples, inputs_noise, data_shape[-1])</span><br><span class="line">                plot_images(samples)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">with tf.Graph().as_default():</span><br><span class="line">    train(noise_size, [-1, 28, 28, 1], batch_size, n_samples)</span><br><span class="line">    print(&quot;OPTIMIZER END!!&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;DCGAN即使用卷积网络的对抗网络，其原理和GAN一样，只是把CNN的卷积技术用于GAN模式的网络里，G（生成器）网在生成数据时，使用反卷积
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="DCGAN" scheme="https://janvia.github.io/tags/DCGAN/"/>
    
      <category term="GAN" scheme="https://janvia.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>PG3 &amp; IRL</title>
    <link href="https://janvia.github.io/2019/01/20/PG3%E5%92%8CIRL/"/>
    <id>https://janvia.github.io/2019/01/20/PG3和IRL/</id>
    <published>2019-01-20T11:54:47.000Z</published>
    <updated>2019-01-20T12:40:12.704Z</updated>
    
    <content type="html"><![CDATA[<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>Reinforcement Learning: An Introduction<br><a href="http://incompleteideas.net/book/the-book-2nd.html" target="_blank" rel="noopener">http://incompleteideas.net/book/the-book-2nd.html</a><br>Dave Silver强化学习课程<br><a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" target="_blank" rel="noopener">http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html</a></p><h3 id="PG"><a href="#PG" class="headerlink" title="ＰＧ"></a>ＰＧ</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/ppt4.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/ppt4_2.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL1.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL2.png" alt=""></p><h3 id="AC"><a href="#AC" class="headerlink" title="AC"></a>AC</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL3.png" alt=""></p><h3 id="PPO"><a href="#PPO" class="headerlink" title="ＰＰＯ"></a>ＰＰＯ</h3><p>近端策略优化（Proximal Policy Optimization，PPO)</p><p><a href="https://spinningup.openai.com/en/latest/algorithms/ppo.html" target="_blank" rel="noopener">https://spinningup.openai.com/en/latest/algorithms/ppo.html</a></p><p>PPO的优点：</p><p>VGP:在线采样，在线更新，采样完成的数据用来更新一次，因为更新过一次之后，策略就发生了改变（策略评估只能使用当下的策略生成数据），样本利用率低，效率低。<br>PPO:在线采样，离线更新，采样完后的数据可以用来多次更新网络，样本利用率高，效率高。<br>如何用之前的策略生成的数据评估当下的策略，重要性采样！</p><h4 id="重要性采样"><a href="#重要性采样" class="headerlink" title="重要性采样"></a>重要性采样</h4><p>因为：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL4.png" alt=""></p><p>所以期望：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL5.png" alt=""></p><p>方差：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL6.png" alt=""></p><p>可见：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL7.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/ppt10.png" alt=""></p><p>重要性采样（提高数据利用率）+约束策略变化幅度（减少方差）：</p><p>PPO:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/ppt11.png" alt=""></p><p>TRPO:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/ppt11_2.png" alt=""></p><p>PPO-Clip</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL8.png" alt=""></p><p>当优势值为正：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL9.png" alt=""></p><p>当优势值为负：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL10.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL11.png" alt=""></p><h3 id="IT"><a href="#IT" class="headerlink" title="ＩＴ"></a>ＩＴ</h3><p>正向强化学习中，所有的agent都是从头学习，其劣势有：<br>1：需要由专家给出合理的奖励函数，很难对复杂的动作给出一个合适的奖励动作，例如飞机特技表演。<br>2：比较耗时，需要训练成百上千个回合，并且有很多情况下，真实环境不具备这样的训练条件（不安全，价格昂贵），例如手术机器人学习动手术。<br>怎么办？<br>由专家进行演示，让学习者进行模仿<br>模仿学习（Imitation Learning）：</p><p>1：直接法：直接学习策略<br>监督式学习：行为克隆 Behavior    Cloning<br>2：间接法：学习奖励机制<br>逆向强化学习（Inverse reinforcement learning）</p><h4 id="直接法"><a href="#直接法" class="headerlink" title="直接法"></a>直接法</h4><p>监督式学习：行为克隆+Data Augmentation</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/ppt19.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL12.png" alt=""><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL13.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL14.png" alt=""></p><h4 id="间接法"><a href="#间接法" class="headerlink" title="间接法"></a>间接法</h4><p>学习奖励机制。</p><p>逆向强化学习IRL,从专家轨迹中推测专家这样做的动机。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL15.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL16.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL17.png" alt=""></p><h4 id="Max-margin-分类器（SVM）"><a href="#Max-margin-分类器（SVM）" class="headerlink" title="Max-margin 分类器（SVM）"></a>Max-margin 分类器（SVM）</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL18.png" alt=""></p><p><a href="http://www.andrew.cmu.edu/course/10-703/slides/Lecture_Imitation_supervised-Nov-5-2018.pdf" target="_blank" rel="noopener">http://www.andrew.cmu.edu/course/10-703/slides/Lecture_Imitation_supervised-Nov-5-2018.pdf</a></p><h4 id="Apprenticeship-Learning学徒学习"><a href="#Apprenticeship-Learning学徒学习" class="headerlink" title="Apprenticeship Learning学徒学习"></a>Apprenticeship Learning学徒学习</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/IRL19.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h3&gt;&lt;p&gt;Reinforcement Learning: An Introduction&lt;br&gt;&lt;a href=&quot;http://inc
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="PG3" scheme="https://janvia.github.io/tags/PG3/"/>
    
      <category term="IRL" scheme="https://janvia.github.io/tags/IRL/"/>
    
  </entry>
  
  <entry>
    <title>GAN理论</title>
    <link href="https://janvia.github.io/2019/01/20/GAN%E7%90%86%E8%AE%BA/"/>
    <id>https://janvia.github.io/2019/01/20/GAN理论/</id>
    <published>2019-01-20T08:02:33.000Z</published>
    <updated>2019-01-20T09:07:47.231Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>对抗神经网络</strong>其实是<strong>两个网络</strong>的组合，可以理解为<strong>一个网络生成模拟数据</strong>，<strong>另一个网络判断生成的数据是真实的还是模拟的。</strong>生成模拟数据的网络要不断优化自己让判别的网络判断不出来，判别的网络也要优化自己让自己判断得更准确。二者关系形成对抗，因此叫对抗生成神经网络。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/GAN1.png" alt=""></p><p>GAN由generator（生成式模型）和discriminator（判别式模型）两部分构成。</p><p>$\bullet$  <strong>generator：</strong>主要是从训练数据中产生相同分布的samples，对于输入x，类别标签y，在生成式模型中估计其联合概率分布（两个及以上随机变量组成的随机向量的概率分布）。</p><p>$\bullet$  <strong>discriminator：</strong>判断输入是真实数据还是generator生成的数据，即估计样本属于某类的条件概率分布。它采用传统的监督学习的方法。　</p><h3 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h3><h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><p>生成式模型又叫<strong>生成器</strong>。它先用一个随机编码向量来输出一个模拟样本。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/GAN2.png" alt=""></p><p>一般的生成模型, 必须先初始化一个<strong>“假设分布”</strong>，即<strong>后验分布</strong>， 通过各种抽样方法<strong>抽样</strong>这个后验分布，就能知道这个分布与<strong>真实分布</strong>之间究竟有多大<strong>差异</strong>。这里的差异就要通过构造<strong>损失函数(loss function)</strong>来估算。</p><h4 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h4><p>判别式模型又叫<strong>判别器</strong>。它的输入是一个样本（可以是真实样本也可以是模拟样本），输出一个判断该样本是真样本还是模拟样本（假样本）的结果</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/GAN4.png" alt=""></p><p><strong>总结：</strong>判别器的目标是区分真假样本，生成器的目标是让判别器区分不出真假样本，两者目标相反，存在对抗。</p><p>我们可以把生成模型看作一个伪装者，而把判别模型看成一个警察。生成模型通过不断地学习来提高自己的伪装能力，从而使得生成出来的数据能够更好地“欺骗”判别模型。而判别模型则通过不断的训练来提高自己的判别能力，能够更准确地判断出数据的来源。GAN就是这样一个不断对抗的网络。</p><p>$\bullet$  生成模型以随机变量作为输入，其输出是对真实数据分布的一个估计。<br>$\bullet$  生成数据和真实数据的采样都由判别模型进行判别，并给出真假性的判断和当前的损失。<br>$\bullet$  利用反向传播，GAN对生成模型和判别模型进行交替优化。</p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>假设数据的概率分布为M，但是我们不知道具体的分布和构造是什么样的，就好像是一个黑盒子。为了了解这个黑盒子，我们就可以构建一个对抗生成网络：</p><p>$\bullet$　<strong>生成模型G：</strong>使用一种我们完全知道的概率分布N来不断学习成为我们不知道的概率分布M.<br>$\bullet$　<strong>判别模型D：</strong>用来判别这个不断学习的概率是我们知道的概率分布N还是我们不知道的概率分布M。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/选区_006.png" alt=""></p><p><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">https://arxiv.org/abs/1406.2661</a></p><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>训练两个模型的方法：<strong>单独交替迭代训练</strong><br><strong>判别模型：</strong> 希望真样本集尽可能输出1，假样本集输出0。对于判别网络，此时问题转换成一个有监督的二分类问题，直接送到神经网络模型中训练。<br><strong>生成网络：</strong>目的是生成尽可能逼真的样本。在训练生成网络的时候，需要联合判别网络才能达到训练的目的。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/GAN/GAN5.png" alt=""></p><p><strong>总结：</strong>首先固定G，单独训练D，为了让D得到充分训练，有的时候要迭代多次。D训练完毕后，固定D，训练G，如此循环。训练的方式是反向传播算法。</p><h3 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h3><h4 id="符号定义"><a href="#符号定义" class="headerlink" title="符号定义"></a>符号定义</h4><ul><li><p>$P_{data}(x)$：真实数据的分布</p></li><li><p>$P_z(Z)$：噪声数据</p></li><li><p>$P_g(x)$：生成模型生成的数据分布</p></li><li><p>D(X)：判别器</p></li><li><p>G(x)：生成器</p></li></ul><h4 id="定义生成器和判别器"><a href="#定义生成器和判别器" class="headerlink" title="定义生成器和判别器"></a>定义生成器和判别器</h4><p>`<script type="math/tex">E_{x \sim P_{data}}(x) \cdot logD(x)</script></p><p>由上式可知：当<script type="math/tex">x \sim P_{data}(x) ,D(x)=1的时，E_{x \sim P_{data}}(x)</script>取得最大值。</p><p>`<script type="math/tex">E_{x \sim P_{z}}(z) \cdot log(1-D(G(z)))</script></p><p>由上式可知：当<script type="math/tex">x \sim P_{z}(z) , D(G(z))=0时，E_{x \sim P_{z}}(z)</script>取得最大值。</p><p>所以为了我们的<strong>判别模型</strong>越来越好，能力越来越强大，定义目标函数为：</p><p>$V(G,D)=  logD(x) +  log(1-D(G(z)))$</p><p>要使<strong>判别模型</strong>取得最好，所以需要使V(G,D)V(G,D)取得最大，即：</p><p>$D = agrmax_DV(G,D)$</p><p>当<strong>判别模型</strong>最好的时候，最好的<strong>生成模型</strong>就是<strong>目标函数取得最小</strong>的时候：</p><p>$G=argmin_G(aggmax_D(V(G, D)))$</p><p>所以经过这一系列的讨论，这个问题就变成了最大最小的问题，即：</p><p>`<script type="math/tex">min_Gmax_DV(G, D)=E_{x \sim P_{data}}(x) \cdot logD(x)+ E_{x \sim P_{z}}(z) \cdot log(1-D(G(z)))</script></p><h4 id="最优判别模型"><a href="#最优判别模型" class="headerlink" title="最优判别模型"></a>最优判别模型</h4><p>最终的目标函数：</p><p>`<script type="math/tex">V(G,D)=  \int_x P_{data}(x) \cdot logD(x) +  P_g(x)log(1-D(G(z))) d(x)</script></p><p>令：$V(G,D)=f(y), P_{data}(x)=a, P_g(x)=b$</p><p>所以：$f(y)=alogy+blog(1-y)$</p><p>因为: $a+b \ne 0$</p><p>所以最大值：$\frac{a}{a+b}$</p><p>最后，我们得到的<strong>最优判别模型</strong>就是：</p><p>`<script type="math/tex">D(x)=\frac{P_{data}(X)}{P_{data}(X)+P_g(x)}</script></p><p>由于<strong>生成对抗网络</strong>的目的是：得到<strong>生成模型</strong>可以生成非常逼真的数据，也就是说是和真实数据的分布是一样的。因此最优的判别模型的输出为：</p><p>`<script type="math/tex">D(x)=\frac{P_{data}}{P_{data}+P_g}=\frac12</script></p><p>其中：<script type="math/tex">P_g和P_{data}</script>的数据分布是一样的。</p><p>也就是说当D输出为0.5时，说明鉴别模型已经完全分不清真实数据和GAN生成的数据了，此时就是得到了最优生成模型了。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>优点：</p><p>$\bullet$　模型优化只用到了反向传播，而不需要马尔科夫链。<br>$\bullet$　训练时不需要对隐变量做推断。<br>$\bullet$　理论上，只要是可微分函数都能用于构建生成模型G和判别模型D，因而能够与深度神经网络结合–&gt;深度产生式模型。<br>$\bullet$　生成模型G的参数更新不是直接来自于数据样本，而是使用来自判别模型D的反向传播梯度。</p><p>缺点：</p><p>$\bullet$　可解释性差，生成模型的分布没有显示的表达。它只是一个黑盒子一样的映射函数：输入是一个随机变量，输出是我们想要的一个数据分布。<br>$\bullet$　比较难训练，生成模型D和判别模型G之间需要很好的同步。例如，在实际中我们常常需要 D 更新 K次， G 才能更新 1 次，如果没有很好地平衡这两个部件的优化，那么G最后就极大可能会坍缩到一个鞍点。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;对抗神经网络&lt;/strong&gt;其实是&lt;strong&gt;两个网络&lt;/strong&gt;的组合，可以理解为&lt;strong&gt;一个网络生成
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="GAN" scheme="https://janvia.github.io/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>数据集</title>
    <link href="https://janvia.github.io/2019/01/20/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <id>https://janvia.github.io/2019/01/20/数据集/</id>
    <published>2019-01-20T07:50:34.000Z</published>
    <updated>2019-01-20T07:54:46.708Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一般数据集"><a href="#一般数据集" class="headerlink" title="一般数据集"></a>一般数据集</h3><p>1、Kaggle：一个包含各种外部贡献数据集的数据科学网站。你可以在其主列表中找到各种合适的数据集，从拉面评级到篮球数据，甚至是西雅图宠物许可证，应有尽有。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsrNouZF.jpg" alt="img"><a href="https://www.kaggle.com/" target="_blank" rel="noopener">https://www.kaggle.com/</a></p><p>2、UCI 机器学习库：网络上最古老的数据集源之一，是寻找有趣的数据集的第一站。虽然这里的数据集是用户贡献的，因此清洁度不一，但绝大多数都是干净的。你可以直接从 UCI 机器学习库下载数据，无需注册。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsrCzOEW.jpg" alt="img"><a href="http://mlr.cs.umass.edu/ml/" target="_blank" rel="noopener">http://mlr.cs.umass.edu/ml/</a></p><h3 id="政府公开数据集"><a href="#政府公开数据集" class="headerlink" title="政府公开数据集"></a>政府公开数据集</h3><p>3、<img src="file:////tmp/wps-steve/ksohtml/wpsGDPakd.jpg" alt="img">Data.gov：该网站可以从多个美国政府机构下载数据。数据范围从政府预算到学校绩效分数。但请注意：大部分数据有待进一步研究。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpswiSyZt.jpg" alt="img"><a href="https://www.data.gov/" target="_blank" rel="noopener">https://www.data.gov/</a></p><p>4、食物环境地图集：包含当地食物选择如何影响美国饮食的数据。</p><p><img src="file:////tmp/wps-steve/ksohtml/wps3LJYEK.jpg" alt="img"><a href="https://catalog.data.gov/dataset/food-environment-atlas-f4a22" target="_blank" rel="noopener">https://catalog.data.gov/dataset/food-environment-atlas-f4a22</a></p><p>5、学校系统财务：对美国学校系统财务状况的调查。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsdLsqk1.jpg" alt="img"><a href="https://catalog.data.gov/dataset/annual-survey-of-school-system-finances" target="_blank" rel="noopener">https://catalog.data.gov/dataset/annual-survey-of-school-system-finances</a></p><p>6、慢性病数据：美国各地区慢性病指标数据。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsCl1TZh.jpg" alt="img"><a href="https://catalog.data.gov/dataset/u-s-chronic-disease-indicators-cdi-e50c9" target="_blank" rel="noopener">https://catalog.data.gov/dataset/u-s-chronic-disease-indicators-cdi-e50c9</a></p><p>7、美国国家教育统计中心：来自美国和世界各地的教育机构和教育人口统计数据。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsSHnpFy.jpg" alt="img"><a href="https://nces.ed.gov/" target="_blank" rel="noopener">https://nces.ed.gov/</a></p><p>8、英国数据服务：英国最大的社会、经济和人口数据集。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsvquWkP.jpg" alt="img"><a href="https://www.ukdataservice.ac.uk/" target="_blank" rel="noopener">https://www.ukdataservice.ac.uk/</a></p><p>9、Data USA：美国公共数据的全面可视化。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsfzov05.jpg" alt="img"><a href="http://datausa.io/" target="_blank" rel="noopener">http://datausa.io/</a></p><h3 id="金融与经济"><a href="#金融与经济" class="headerlink" title="金融与经济"></a>金融与经济</h3><p>10、Quandl：经济和金融数据很好的数据源，有助于建立预测经济指标或股票价格模型。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsj8g6Fm.jpg" alt="img"><a href="https://www.quandl.com/" target="_blank" rel="noopener">https://www.quandl.com/</a></p><p>11、世界银行开放数据：涵盖全球人口统计数据和大量经济和发展指标的数据集。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsPnjJlD.jpg" alt="img"><a href="https://data.worldbank.org/" target="_blank" rel="noopener">https://data.worldbank.org/</a></p><p>12、国际货币基金组织数据：国际货币基金组织公布的有关国际金融、债务利率、外汇储备、商品价格和投资的数据。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsWQmo1T.jpg" alt="img"><a href="https://www.imf.org/en/Data" target="_blank" rel="noopener">https://www.imf.org/en/Data</a></p><p>13、金融时报市场数据：来自世界各地的金融市场最新信息，包括股票价格指数、商品和外汇。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsP4b5Ga.jpg" alt="img"><a href="https://markets.ft.com/data/" target="_blank" rel="noopener">https://markets.ft.com/data/</a></p><p>14、谷歌趋势：检查和分析世界各地的互联网搜索活动和热门新闻报道的数据。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsZ5LNmr.jpg" alt="img"><a href="https://trends.google.com/trends/?q=google&amp;ctab=0&amp;geo=all&amp;date=all&amp;sort=0" target="_blank" rel="noopener">https://trends.google.com/trends/?q=google&amp;ctab=0&amp;geo=all&amp;date=all&amp;sort=0</a></p><p>15、美国经济协会（AEA）：寻找美国宏观经济数据的良好来源。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsA2ay2H.jpg" alt="img"><a href="https://www.aeaweb.org/resources/data/us-macro-regional" target="_blank" rel="noopener">https://www.aeaweb.org/resources/data/us-macro-regional</a></p><h3 id="机器学习数据集"><a href="#机器学习数据集" class="headerlink" title="机器学习数据集"></a>机器学习数据集</h3><p>16、Labelme：带图像标注的大型数据集。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsbIykIY.jpg" alt="img"><a href="http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php" target="_blank" rel="noopener">http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php</a></p><p>17、ImageNet：业界最新算法图像数据集。根据 WordNet 层次结构进行组织，其中层次结构的每个节点由数百和数千个图像描述。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsvuN8nf.jpg" alt="img"><a href="http://image-net.org/" target="_blank" rel="noopener">http://image-net.org/</a></p><p>18、LSUN：有众多辅助任务的场景理解（房间布局估计、特点预测等）</p><p><img src="file:////tmp/wps-steve/ksohtml/wpswCA13v.jpg" alt="img"><a href="http://lsun.cs.princeton.edu/2016/" target="_blank" rel="noopener">http://lsun.cs.princeton.edu/2016/</a></p><p>19、MS COCO：通用图像理解和字幕。</p><p><img src="file:////tmp/wps-steve/ksohtml/wps798VJM.jpg" alt="img"><a href="http://mscoco.org/" target="_blank" rel="noopener">http://mscoco.org/</a></p><p>20、COIL100：100 个不同的物体，在 360 度旋转的每个角度成像。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsr8uSp3.jpg" alt="img"><a href="http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php" target="_blank" rel="noopener">http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php</a></p><p>21、视觉基因组：非常详细的视觉知识库，带有~100K 图像的字幕。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpspJFQ5j.jpg" alt="img"><a href="http://visualgenome.org/" target="_blank" rel="noopener">http://visualgenome.org/</a></p><p>22、谷歌的开放图像：在知识共享版权下的 900 万个图像网址集合，“超过 6000 个类别标签注释”。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsJfVQLA.jpg" alt="img"><a href="https://ai.googleblog.com/2016/09/introducing-open-images-dataset.html" target="_blank" rel="noopener">https://ai.googleblog.com/2016/09/introducing-open-images-dataset.html</a></p><p>23、Labelled Faces in the Wild：13,000 张人脸标记图像，用于开发人脸识别应用程序。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsTE1SrR.jpg" alt="img"><a href="http://vis-www.cs.umass.edu/lfw/" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/</a></p><p>24、斯坦福狗数据集：包含 20,580 张图片和 120 种不同的狗品种。</p><p><img src="file:////tmp/wps-steve/ksohtml/wps1NZW77.jpg" alt="img"><a href="http://vision.stanford.edu/aditya86/ImageNetDogs/" target="_blank" rel="noopener">http://vision.stanford.edu/aditya86/ImageNetDogs/</a></p><p>25、室内场景识别：一种非常特殊的数据集，因为大多数场景识别模型都最好建立在“室外”，这个数据集非常实用。包含 67 个室内类别，总共 15620 张图像。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsvAU2No.jpg" alt="img"><a href="http://web.mit.edu/torralba/www/indoor.html" target="_blank" rel="noopener">http://web.mit.edu/torralba/www/indoor.html</a></p><h3 id="情绪分析"><a href="#情绪分析" class="headerlink" title="情绪分析"></a>情绪分析</h3><p>26、多域情绪分析数据集：一个有点老旧的数据集，其中包含来自亚马逊的产品评论。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsVkIauF.jpg" alt="img"><a href="http://www.cs.jhu.edu/~mdredze/datasets/sentiment/" target="_blank" rel="noopener">http://www.cs.jhu.edu/~mdredze/datasets/sentiment/</a></p><p>27、IMDB 评论：一个较旧的，相对较小的二元情绪分类数据集，包含 25,000 个电影评论。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsN4kkaW.jpg" alt="img"><a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="noopener">http://ai.stanford.edu/~amaas/data/sentiment/</a></p><p>28、斯坦福情绪树库：带有情感注释的标准情绪数据集。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpssMJvQc.jpg" alt="img"><a href="http://nlp.stanford.edu/sentiment/code.html" target="_blank" rel="noopener">http://nlp.stanford.edu/sentiment/code.html</a></p><p>29、Sentiment140：一个流行的数据集，使用 160,000 条预先删除表情符号的推文。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpslYWIwt.jpg" alt="img"><a href="http://help.sentiment140.com/for-students/" target="_blank" rel="noopener">http://help.sentiment140.com/for-students/</a></p><p>30、Twitter 美国航空公司情绪：2015 年 2 月美国航空公司的 Twitter 数据，分类为正面、负面和中性推文。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsGKYXcK.jpg" alt="img"><a href="https://www.kaggle.com/crowdflower/twitter-airline-sentiment" target="_blank" rel="noopener">https://www.kaggle.com/crowdflower/twitter-airline-sentiment</a></p><h3 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h3><p>31、安然数据集：来自安然高级管理层的电子邮件数据，以文件夹形式分类存放。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpstYTeT0.jpg" alt="img"><a href="https://www.cs.cmu.edu/~./enron/" target="_blank" rel="noopener">https://www.cs.cmu.edu/~./enron/</a></p><p>32、亚马逊评论：包含亚马逊 18 年来约 3500 万条评论。数据包括产品和用户信息、评级和明文审核。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsXPCxzh.jpg" alt="img"><a href="https://snap.stanford.edu/data/web-Amazon.html" target="_blank" rel="noopener">https://snap.stanford.edu/data/web-Amazon.html</a></p><p>33、Google Books Ngrams：Google 图书中的一系列文字。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsOX7Rfy.jpg" alt="img"><a href="https://aws.amazon.com/datasets/google-books-ngrams/" target="_blank" rel="noopener">https://aws.amazon.com/datasets/google-books-ngrams/</a></p><p>34、Blogger Corpus：收集了来自 <img src="file:////tmp/wps-steve/ksohtml/wpsV8meWO.jpg" alt="img">blogger.com 的 681288 篇博文。每个博客至少包含 200 个常用英语单词。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsJ0iCC5.jpg" alt="img"><a href="http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm" target="_blank" rel="noopener">http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm</a></p><p>35、维基百科链接数据：维基百科全文。该数据集包含来自 400 多万篇文章的近 19 亿个单词。你可以按段落、短语或段落本身的一部分进行搜索。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpss651im.jpg" alt="img"><a href="https://code.google.com/archive/p/wiki-links/downloads" target="_blank" rel="noopener">https://code.google.com/archive/p/wiki-links/downloads</a></p><p>36、Gutenberg 电子书列表：Project Gutenberg 的电子书注释列表。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsTAFtZC.jpg" alt="img"><a href="http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs" target="_blank" rel="noopener">http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs</a></p><p>37、加拿大议会议事录：来自第 36 届加拿大议会记录的 130 万对文本。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsMD2WFT.jpg" alt="img"><a href="http://www.isi.edu/natural-language/download/hansard/" target="_blank" rel="noopener">http://www.isi.edu/natural-language/download/hansard/</a></p><p>38、Jeopardy：来自有奖竞猜节目 Jeopardy 的超过 200,000 个问题归档。</p><p><img src="file:////tmp/wps-steve/ksohtml/wps3Tdsma.jpg" alt="img"><a href="https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/" target="_blank" rel="noopener">https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/</a></p><p>39、英语短信垃圾邮件集：由 5574 条英文短信垃圾邮件组成的数据集。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsVzkZ2q.jpg" alt="img"><a href="http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/" target="_blank" rel="noopener">http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/</a></p><p>40、Yelp 评论：Yelp 发布的一个开放数据集，包含超过 500 万条评论。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsTBgyJH.jpg" alt="img"><a href="https://www.yelp.com/dataset" target="_blank" rel="noopener">https://www.yelp.com/dataset</a></p><p>41、UCI 垃圾邮件集：一个大型垃圾邮件数据集，对垃圾邮件过滤非常有用。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsWCX8pY.jpg" alt="img"><a href="https://archive.ics.uci.edu/ml/datasets/Spambase" target="_blank" rel="noopener">https://archive.ics.uci.edu/ml/datasets/Spambase</a></p><p>更详细列表：</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsMzqL6e.jpg" alt="img"><a href="https://gengo.ai/datasets/the-best-25-datasets-for-natural-language-processing/" target="_blank" rel="noopener">https://gengo.ai/datasets/the-best-25-datasets-for-natural-language-processing/</a></p><h3 id="自动驾驶"><a href="#自动驾驶" class="headerlink" title="自动驾驶"></a>自动驾驶</h3><p>42、Berkeley DeepDrive BDD100k：目前是自动驾驶 AI 的最大数据集。包含超过 100000 个视频，包括一天中不同时段和天气条件下超过 1100 小时的驾驶体验。带注释的图像来自纽约和旧金山地区。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsEBgqNv.jpg" alt="img"><a href="http://bdd-data.berkeley.edu/" target="_blank" rel="noopener">http://bdd-data.berkeley.edu/</a></p><p>43、百度 Apolloscapes：大型数据集，定义了 26 种不同的语义项目，如汽车、自行车、行人、建筑物、路灯等。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsbKx6tM.jpg" alt="img"><a href="http://apolloscape.auto/" target="_blank" rel="noopener">http://apolloscape.auto/</a></p><p>44、<img src="file:////tmp/wps-steve/ksohtml/wpsKV7Na3.jpg" alt="img">Comma.ai：超过 7 小时的高速公路驾驶数据。细节包括汽车的速度、加速度、转向角和 GPS 坐标。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsPO2wRj.jpg" alt="img"><a href="https://archive.org/details/comma-dataset" target="_blank" rel="noopener">https://archive.org/details/comma-dataset</a></p><p>45、牛津的机器人汽车：在英国牛津的同一条路线重复行驶 100 多次、耗时一年多收集的数据集。该数据集包含天气、交通和行人的不同组合，以及建筑和道路工程等长期变化。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsngohyA.jpg" alt="img"><a href="http://robotcar-dataset.robots.ox.ac.uk/" target="_blank" rel="noopener">http://robotcar-dataset.robots.ox.ac.uk/</a></p><p>46、城市景观数据集：一个大型数据集，记录 50 个不同城市的城市街景。</p><p><img src="file:////tmp/wps-steve/ksohtml/wps4O72eR.jpg" alt="img"><a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener">https://www.cityscapes-dataset.com/</a></p><p>47、CSSAD 数据集：此数据集对于自动驾驶车辆的感知和导航非常有用。但该数据集严重偏向发达国家的道路情况。</p><p><img src="file:////tmp/wps-steve/ksohtml/wps1XgQV7.jpg" alt="img"><a href="http://aplicaciones.cimat.mx/Personal/jbhayet/ccsad-dataset" target="_blank" rel="noopener">http://aplicaciones.cimat.mx/Personal/jbhayet/ccsad-dataset</a></p><p>48、KUL 比利时交通标志数据集：比利时法兰德斯地区数以千计的物理交通标志，有超过 10000 多个交通标志注释。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsisQECo.jpg" alt="img"><a href="http://www.vision.ee.ethz.ch/~timofter/traffic_signs/" target="_blank" rel="noopener">http://www.vision.ee.ethz.ch/~timofter/traffic_signs/</a></p><p>49、麻省理工学院实验室：在 AgeLab 收集的 1000 多个小时多传感器驾驶数据集的样本。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsDgPujF.jpg" alt="img"><a href="http://lexfridman.com/automated-synchronization-of-driving-data-video-audio-telemetry-accelerometer/" target="_blank" rel="noopener">http://lexfridman.com/automated-synchronization-of-driving-data-video-audio-telemetry-accelerometer/</a></p><p>50、LISA：智能和安全汽车实验室，加州大学圣地亚哥分校数据集：该数据集包括交通标志、车辆检测、交通信号灯和轨迹模式。</p><p><img src="file:////tmp/wps-steve/ksohtml/wpsqXfm0V.jpg" alt="img"><a href="http://cvrr.ucsd.edu/LISA/datasets.html" target="_blank" rel="noopener">http://cvrr.ucsd.edu/LISA/datasets.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一般数据集&quot;&gt;&lt;a href=&quot;#一般数据集&quot; class=&quot;headerlink&quot; title=&quot;一般数据集&quot;&gt;&lt;/a&gt;一般数据集&lt;/h3&gt;&lt;p&gt;1、Kaggle：一个包含各种外部贡献数据集的数据科学网站。你可以在其主列表中找到各种合适的数据集，从拉面评级到篮球
      
    
    </summary>
    
      <category term="数据集" scheme="https://janvia.github.io/categories/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
    
      <category term="数据集" scheme="https://janvia.github.io/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>21单元语法</title>
    <link href="https://janvia.github.io/2019/01/20/21%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95/"/>
    <id>https://janvia.github.io/2019/01/20/21单元语法/</id>
    <published>2019-01-20T04:34:27.000Z</published>
    <updated>2019-01-24T00:23:52.869Z</updated>
    
    <content type="html"><![CDATA[<h2 id="～そうだ＜征兆、推测＞"><a href="#～そうだ＜征兆、推测＞" class="headerlink" title="～そうだ＜征兆、推测＞"></a>～そうだ＜征兆、推测＞</h2><h3 id="1、征兆"><a href="#1、征兆" class="headerlink" title="1、征兆"></a>1、征兆</h3><p>接续：V-R（第一连用型）+ そうだ</p><p>样态助动词，表示<strong>征兆</strong>，是说话人对<strong>即将发生</strong>的动作，变化的征兆进行的描述，一般是说话人通过自身的感官判断或觉察到的。<strong>(主観)</strong>常与<strong>｢今にも｣</strong>连用。变形之后按<strong>二类形容词</strong>活用。</p><p> ✿汉语：就要~了、快要~了</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.今にも雨が降りそうです。　</span><br><span class="line">2.寒くて死にそうだ。</span><br><span class="line">3.ポケットから財布が落ちそうだよ。(2002年真题)</span><br></pre></td></tr></table></figure><h3 id="2、推测"><a href="#2、推测" class="headerlink" title="2、推测"></a>2、推测</h3><p>接续：</p><p>$\bullet$    A1-词干(去い) 　+ そうだ</p><p>$\bullet$    A2-词干 　　　  + そうだ </p><p>$\bullet$    VーR　　　　　 + そうだ</p><p>表示<strong>推断、猜测、发生的可能性</strong>，是说话人根据事物的外表、经验等判断某事态很有可能发生或某事物具有某性质。变形之后按<strong>二类形容词</strong>活用。</p><p> ✿汉语：看上去~；看起来~；好像~<br>★：いい・ない:　　よさそうだ・なさそうだ</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.山田さんはいつも難しそうな本を読んでいる。(2006年真题)　</span><br><span class="line">2.石田さんは忙しそうだから、手伝おう。(2003年真题)</span><br><span class="line">3.あの様子では二人はもうすぐ結婚しそうです。</span><br></pre></td></tr></table></figure><h3 id="３、そうだ的否定形式"><a href="#３、そうだ的否定形式" class="headerlink" title="３、そうだ的否定形式"></a>３、そうだ的否定形式</h3><p>Vそうだ的否定为：<br>｢Vそうにもない｣</p><p>口语中常用｢そうもない｣或｢そうにない｣。即省略「に」或「も」<br>表示发生某动作的可能性极小。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.この本は売れそうもない。</span><br><span class="line">2.一人の力だけでは、とうていできそうにもない。</span><br></pre></td></tr></table></figure><p>Aそうだ的否定为：</p><p>$\bullet$    「そうではない」</p><p>$\bullet$    「A1-くなさそうだ」</p><p>$\bullet$    「A2- ではなさそうだ」</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.最近、授業は少ないから、忙しそうではない。</span><br><span class="line">  </span><br><span class="line">  最近、授業は少ないから、忙しくなさそうだ。</span><br><span class="line"></span><br><span class="line">2.彼は一週間以上も病気だから、体はあまり元気そうではない。</span><br><span class="line">  </span><br><span class="line">  彼は一週間以上も病気だから、体はあまり元気ではなさそうだ。</span><br></pre></td></tr></table></figure><h3 id="4、そうだ修饰名词或动词"><a href="#4、そうだ修饰名词或动词" class="headerlink" title="4、そうだ修饰名词或动词"></a>4、そうだ修饰名词或动词</h3><p>修饰名词时：A/V +そう+な+ N<br>修饰动词时：Aそう+に+ V</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.彼は悲しそうな顔をしている。</span><br><span class="line">2.彼は楽しそうに笑った。</span><br><span class="line">3.李さんは元気そうな声で話してくれた。</span><br><span class="line">4.雨が降りそうな天気だ。</span><br></pre></td></tr></table></figure><h2 id="授受动词"><a href="#授受动词" class="headerlink" title="授受动词"></a>授受动词</h2><h3 id="1、あげる（自谦）：さしあげる"><a href="#1、あげる（自谦）：さしあげる" class="headerlink" title="1、あげる（自谦）：さしあげる"></a>1、あげる（自谦）：さしあげる</h3><p>接续：（赠与者）N1は∕が＋（接受者）N2に＋（所赠物品）N3を＋あげる。</p><p>当接受者的身份、地位、年龄高于赠与者时：<br>あげるーさしあげる</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">先生が大学をおやめになる日、みんなで先生にアルバムをさしあげました。</span><br></pre></td></tr></table></figure><h3 id="2、くれるーくださる"><a href="#2、くれるーくださる" class="headerlink" title="2、くれるーくださる"></a>2、くれるーくださる</h3><p>接续：（赠与者）N1は∕が＋（我或我这一方的人）に＋（所赠物品）N2を＋くれる。</p><p>当赠与者的身份、地位、年龄高于接受者时：<br>くれるーくださる</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">先輩が妹にコンサートのチケットをくださいました。</span><br></pre></td></tr></table></figure><h3 id="3、もらう－いただく"><a href="#3、もらう－いただく" class="headerlink" title="3、もらう－いただく"></a>3、もらう－いただく</h3><p>接续：（接受者）N1は＋（赠与者）N2に∕から＋（所得物品）N3を＋もらう。</p><p>当赠与者的身份、地位、年龄高于接受者时：<br>もらう－いただく</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">わたしは社長に会社のぺんをいただきました。</span><br></pre></td></tr></table></figure><h3 id="補助動詞・行为的授受"><a href="#補助動詞・行为的授受" class="headerlink" title="補助動詞・行为的授受"></a>補助動詞・行为的授受</h3><p>$\bullet$    ～てあげる $\Rightarrow$ ～てさしあげる（謙譲語）</p><p>$\bullet$    ～てもらう $\Rightarrow$ ～ていただく　（謙譲語）</p><p>$\bullet$    ～てくれる $\Rightarrow$ ～てくださる　（尊敬語）</p><p>①Aは Bに Vてあげる<br>　　　　   Vて やる<br>　　　　   Vてさしあげる</p><p>表示A为B做某事。<br>A是授予者，用「は」提示；(授予者为第一人时常省略）<br>B是接受者，用「に」提示。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.これ、貸してあげるよ。(2007年真题)</span><br><span class="line">2.この写真は家族にもぜひ見せてやりたい。</span><br><span class="line">3.吉田先生を駅まで車で送って差し上げた。</span><br></pre></td></tr></table></figure><p>「～てやる」用于AB之间关系亲近，随意，或B身份、地位低于A时。<br>「～てあげる」是「～てやる」的客气说法，<br>「～てさしあげる」则比「～てあげる」更客气，常常用来叙述B是A的尊长时的授受关系。</p><p> ★：另外「～てあげる」会使行为接受者觉得这是对方施恩于自己而感到不快，用时应注意。</p><p>特殊接续：</p><p>$\bullet$    彼女の手を取ってあげる</p><p>$\bullet$    彼女の荷物を持ってあげる</p><p>$\bullet$    彼女を手伝ってあげる    </p><p>②AはBに(から)Vてもらう<br>　　　　　　　Vていただく</p><p>表示A接受B所做的事。A是接受者，用「は」提示。B是授予者，用「に」或「から」提示。B为A所做的事用「て」前面的动词表示。<br>★：「~ていただく」是「~てもらう」的谦语，<br>　　一般用于B比A身份高，或B是A所尊敬的人。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.本田先生に貸していただいた本を家に忘れた。(2012年真题)</span><br><span class="line">2.この書類を広田さんに渡しておいてもらえないか。(2012年真题)</span><br></pre></td></tr></table></figure><p>③Aは (私に) Vてくれる<br>　　　　　   Vてくださる</p><p>表示A为我（我们，我方人员）做某事。与①相反。<br>Ｂ在句中往往省略。<br>★：「 Vていただく」与「 Vてくださる」的区别在于：前者常带有“该动作是受益者要求对方进行的”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.友達がたくさん来てくれた。</span><br><span class="line">2.そちらの方が私の荷物を持ってくださいました。(2008年真题)</span><br><span class="line">3.友達が掃除を手伝ってくれた。(2006年真题)</span><br></pre></td></tr></table></figure><h3 id="变形总结"><a href="#变形总结" class="headerlink" title="变形总结"></a>变形总结</h3><div class="table-container"><table><thead><tr><th style="text-align:center">原型</th><th style="text-align:center">授受敬语</th><th style="text-align:center">行为的授受</th><th style="text-align:center">行为的授受敬语</th></tr></thead><tbody><tr><td style="text-align:center">あげる</td><td style="text-align:center">さしあげる</td><td style="text-align:center">てあげる</td><td style="text-align:center">てさしあげる</td></tr><tr><td style="text-align:center">もらう</td><td style="text-align:center">いただく</td><td style="text-align:center">てもらう</td><td style="text-align:center">ていただく</td></tr><tr><td style="text-align:center">くれる</td><td style="text-align:center">くださる</td><td style="text-align:center">てくれる</td><td style="text-align:center">てくださる</td></tr></tbody></table></div><h2 id="ようだ"><a href="#ようだ" class="headerlink" title="ようだ"></a>ようだ</h2><h3 id="ようだ-lt-比喻-gt"><a href="#ようだ-lt-比喻-gt" class="headerlink" title="ようだ&lt;比喻&gt;"></a>ようだ&lt;比喻&gt;</h3><p>比况助动词「ようだ」一般接在<strong>体言</strong>后面，表示比喻。<br>常和副词<strong>「まるで」 「ちょうど」 「あたかも」</strong>前后呼应使用。</p><p>接续：Nの～</p><p> ✿汉语：好像~、宛如~<br>★：「ようだ」作为2类形容词型活用，可作为修饰语使用。</p><ul><li>N +の+ ような + 体言</li><li>N+ の + ように + 用言</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.まるで夢のようだ。</span><br><span class="line">2.今日は寒くて、まるで冬のようだ。</span><br><span class="line">3.母は初めて飛行機に乗って、子供のように喜んだ。(2008年真题)</span><br></pre></td></tr></table></figure><h3 id="ようだ-lt-举例-gt"><a href="#ようだ-lt-举例-gt" class="headerlink" title="ようだ&lt;举例&gt;"></a>ようだ&lt;举例&gt;</h3><p>表示某一事物与作为例子举出的另一事物具有某一相同特征。<br>接续：Ｎの＋<br> ✿汉语：像~一样、例如~<br>常用形式：</p><ul><li><p>Nの+ ような + 体言</p></li><li><p>Nの+ ように + 用言</p></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.みかんのようなビタミンＣが豊かな果物を食べたい。</span><br><span class="line">2.私は田中さんのような優しい人が好きだ。</span><br><span class="line">3.みんなが子供のように元気に歌い始めた。(2005年真题)</span><br></pre></td></tr></table></figure><h2 id="みたいだ"><a href="#みたいだ" class="headerlink" title="みたいだ"></a>みたいだ</h2><h3 id="みたいだ＜比喻＞"><a href="#みたいだ＜比喻＞" class="headerlink" title="みたいだ＜比喻＞"></a>みたいだ＜比喻＞</h3><p>为「ようだ」 的随意的口语表现形式。</p><p>接续：</p><ul><li><p>N+ みたいだ</p></li><li><p>N+ みたいな + 体言</p></li><li><p>N+ みたいに + 用言</p><p>✿汉语：好像~、宛如~</p></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１.うれしい、まるで夢みたいだ。</span><br><span class="line">２.あの人は日本人みたいだ。</span><br></pre></td></tr></table></figure><h3 id="みたいだ＜举例＞"><a href="#みたいだ＜举例＞" class="headerlink" title="みたいだ＜举例＞"></a>みたいだ＜举例＞</h3><p>为「ようだ」 的随意的口语表现形式。</p><p>接続：</p><ul><li><p>Ｎ+ みたいな + 体言</p></li><li><p>Ｎ+ みたいに + 用言</p><p>✿汉语：像~一样、例如~</p></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１.君みたいなあわて者、見たことがないよ。</span><br><span class="line">２.あなたみたいに日本語が話せたらうれしいけど。</span><br></pre></td></tr></table></figure><h2 id="疑問詞＋Vたらいいか-＜询问＞"><a href="#疑問詞＋Vたらいいか-＜询问＞" class="headerlink" title="疑問詞＋Ｖたらいいか  ＜询问＞"></a>疑問詞＋Ｖたらいいか  ＜询问＞</h2><p>疑問詞＋Ｖたらいいか。<br>アドバイスを求める。<br>询问对方怎么做比较好（方式，地点，时间）<br>✿“~怎么做才好呢？”“~如何是好呢？”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１.どう説明したらいいか。</span><br><span class="line">２.誰に聞いたらいいか。</span><br><span class="line">３.風邪を引きそうなとき、何をたべたらいいか教えてください。</span><br><span class="line">４.図書館に行くとき、どの駅で降りたらいいかネットで調べましょう。</span><br></pre></td></tr></table></figure><h2 id="～すぎる＜过度＞"><a href="#～すぎる＜过度＞" class="headerlink" title="～すぎる＜过度＞"></a>～すぎる＜过度＞</h2><p>表示过度。行为、动作超过了一般的程度或范围。<br>接续：</p><ul><li><p>V第一连用形 + すぎる</p></li><li><p>A词干 + すぎる</p></li></ul><p>✿汉语：过于、过度~</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１.食べ過ぎて、お腹が痛いです。</span><br><span class="line">２.コピーの字が薄すぎて、読めない。（2004年真题）</span><br><span class="line">３.この花は、土が乾いたら水をやる必要があるが、やりすぎるのもよくない。(2013年真题)</span><br></pre></td></tr></table></figure><h2 id="～Vております＜自谦＞"><a href="#～Vております＜自谦＞" class="headerlink" title="～Ｖております＜自谦＞"></a>～Ｖております＜自谦＞</h2><p>「ております」是「ています」的自谦；<br> 也可以是正式场合的「ています」的表达。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１.今長沙に住んでおります。</span><br><span class="line">２.私のうちにもどうぞいらっしゃってください。お待ちしております。</span><br><span class="line">３.社長は今電話に出ておりますので、しばらくお待ちください。(2000年真题)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;～そうだ＜征兆、推测＞&quot;&gt;&lt;a href=&quot;#～そうだ＜征兆、推测＞&quot; class=&quot;headerlink&quot; title=&quot;～そうだ＜征兆、推测＞&quot;&gt;&lt;/a&gt;～そうだ＜征兆、推测＞&lt;/h2&gt;&lt;h3 id=&quot;1、征兆&quot;&gt;&lt;a href=&quot;#1、征兆&quot; class=&quot;
      
    
    </summary>
    
      <category term="日语" scheme="https://janvia.github.io/categories/%E6%97%A5%E8%AF%AD/"/>
    
    
      <category term="语法" scheme="https://janvia.github.io/tags/%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>PG和TD3</title>
    <link href="https://janvia.github.io/2019/01/18/PG%E5%92%8CTD3/"/>
    <id>https://janvia.github.io/2019/01/18/PG和TD3/</id>
    <published>2019-01-18T00:11:14.000Z</published>
    <updated>2019-01-18T09:17:09.400Z</updated>
    
    <content type="html"><![CDATA[<h3 id="TD3"><a href="#TD3" class="headerlink" title="TD3"></a>TD3</h3><p>TD3 = Twin Delayed DDPG：三点改进：</p><h4 id="改进１"><a href="#改进１" class="headerlink" title="改进１"></a>改进１</h4><p><strong>Twin:</strong>有两个Q值预测网络，使用输出Q值较小的那个用作计算TD error的目标值；</p><p>Double DQN:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/图片2.png" alt=""></p><p>Double q learning(Q值来自于神经网络):</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD2.png" alt=""></p><p>Clipped Double Q-learning algorithm:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD3.png" alt=""></p><h4 id="改进２"><a href="#改进２" class="headerlink" title="改进２"></a>改进２</h4><p><strong>Delayed：</strong>更新策略的频率要小于更新Q值，即训练actor网络的次数要小于训练critic网络；</p><p>在值网络估计不准确的情况下（TD error很大），更新策略会引发</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD4.png" alt=""></p><p>在更新critic网络d次之后再更新actor网络</p><h4 id="改进３"><a href="#改进３" class="headerlink" title="改进３"></a>改进３</h4><p><strong>目标策略平滑：</strong><br>Idea:相似的动作在同一个状态下的Q值也相似</p><p>Trick:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD5.png" alt=""></p><h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD6.png" alt=""></p><h4 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD7.png" alt=""></p><h3 id="TD3-vs-DDPG-参数设计"><a href="#TD3-vs-DDPG-参数设计" class="headerlink" title="TD3 vs DDPG 参数设计"></a>TD3 vs DDPG 参数设计</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD8.png" alt=""></p><h3 id="PG"><a href="#PG" class="headerlink" title="PG"></a>PG</h3><p>一个特定的回合内，其生成的轨迹概率<br>轨迹:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD9.png" alt=""></p><p>概率：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD10.png" alt=""></p><p>重要性采样比率:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_002.png" alt=""></p><p>梯度公式：</p><p>*<script type="math/tex">\nabla_{\theta}logP(\tau|\theta)=\nabla \sum_{t=0}^T  log\pi_{\theta}(a_t|s_t)</script></p><p>带入求导：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_003.png" alt=""></p><p>又：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_004.png" alt=""></p><p>所以：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_005.png" alt=""></p><p>所以：</p><p><em><script type="math/tex">\nabla_{\theta}J(\pi_\theta)=\nabla E_{\tau\sim\pi_\theta} [R(\tau)]</script></em></p><p><em><script type="math/tex">=\nabla_\theta \int_{\tau\sim\pi_\theta} P(\tau|\theta)R(\tau)</script></em></p><p><em><script type="math/tex">= \int_{\tau\sim\pi_\theta} \nabla_\theta P(\tau|\theta)R(\tau)</script></em></p><p><em><script type="math/tex">= \int_{\tau\sim\pi_\theta} P(\tau|\theta)\nabla_\theta logP(\tau|\theta)R(\tau)</script></em></p><p><em><script type="math/tex">= E_{\tau\sim\pi_\theta}[\nabla_\theta logP(\tau|\theta)R(\tau)]</script></em></p><p><em><script type="math/tex">= E_{a_t\sim\pi_\theta}[\nabla_\theta \sum_{t=0}^T log\pi_\theta(a_t|s_t)R(\tau)]</script></em></p><h4 id="过程-1"><a href="#过程-1" class="headerlink" title="过程"></a>过程</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD15.png" alt=""></p><p>蒙特卡洛估计方差太大，见下图：<br>使用神经网络来估计Q值</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/图片5.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/图片6.png" alt=""></p><p>从上图看出负的噪声影响很大，怎么办呢？</p><p>可以增加一个b值补偿</p><p>推导：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/QQ截图20190118034441.png" alt=""></p><p>方差公式和梯度公式：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/PG1.png" alt=""></p><p>梯度公式带入方差公式：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD12.png" alt=""></p><p>求导：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD13.png" alt=""></p><p>所以：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD14.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;TD3&quot;&gt;&lt;a href=&quot;#TD3&quot; class=&quot;headerlink&quot; title=&quot;TD3&quot;&gt;&lt;/a&gt;TD3&lt;/h3&gt;&lt;p&gt;TD3 = Twin Delayed DDPG：三点改进：&lt;/p&gt;
&lt;h4 id=&quot;改进１&quot;&gt;&lt;a href=&quot;#改进１&quot; clas
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="PG" scheme="https://janvia.github.io/tags/PG/"/>
    
      <category term="TD3" scheme="https://janvia.github.io/tags/TD3/"/>
    
  </entry>
  
  <entry>
    <title>RNN理论</title>
    <link href="https://janvia.github.io/2019/01/17/RNN%E7%90%86%E8%AE%BA/"/>
    <id>https://janvia.github.io/2019/01/17/RNN理论/</id>
    <published>2019-01-17T06:19:54.000Z</published>
    <updated>2019-01-17T10:46:25.312Z</updated>
    
    <content type="html"><![CDATA[<p>循环神经网络（RNN）是一类神经网络，包括一层内的加权连接，与传统前馈神经网络相比，加权连接仅反馈到后续层。因为RNN<strong>包含循环</strong>，所以RNN就可以在处理输入信息的时候同时<strong>储存信息</strong>。这种记忆使得RNN非常适合处理必须考虑事先输入的任务（比如<strong>时序数据</strong>）。所以循环神经网络在<strong>自然语言处理</strong>领域非常适合。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN1.png" alt=""></p><p>传统神经网络（包含CNN），输入和输出都是互相独立的。<br>RNN引入了“记忆”的概念</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN2.png" alt=""></p><p><strong>x</strong>：输入层的值<br><strong>U</strong>：输入层到隐层的权重参数<br><strong>s</strong>：隐层的值<br><strong>v</strong>：隐层到输出层的权重参数<br><strong>o</strong>：输出层的值<br><strong>W</strong>：递归神经网络的隐藏层的值s不仅仅取决于当前这次的输入x，还取决于上一次隐藏层的值s。权重参数W就是隐藏层上一次的值作为这一次的输入的权重。</p><p><strong>关键点</strong>：$S<em>t$的值不仅仅取决于$X_t$，还取决于$S</em>{t−1}$(就是上一状态的隐层的值)</p><p>循环神经网络的<strong>计算公式</strong>：</p><script type="math/tex; mode=display">O_t=f(V \cdot S_t) \quad (1)</script><p><code>输出层</code>的计算公式，由于输出层是一个<strong>全连接层</strong>，所以说它每个节点都和隐层的节点相连。<code>V</code>是输出层的权重参数，<code>f</code>是激活函数。</p><script type="math/tex; mode=display">S_t=f(U \cdot X_t+W \cdot S_{t-1}) \quad (2)</script><p><code>隐层</code>的计算公式，它是一个<code>循环层</code>，<code>U</code>是输入<code>x</code>的权重参数，<code>W</code>是上一次的值$S_{t−1}$作为这一次输入的权重参数，<code>f</code>是激活函数。</p><p><strong>总结</strong>：从上面的公式中，我们可以看出，<strong>循环层</strong>和<strong>全连接层</strong>的区别就是<strong>循环层</strong>多了一个<strong>权重参数</strong><code>w</code>。</p><p><code>扩展</code>：如果反复的把（1）式带入 （2）式：</p><p>${O}_t=f(V\cdot{S}_t)$</p><p> `<script type="math/tex">= V \cdot f(U \cdot X_t + W \cdot S_{t-1})</script></p><p>`<script type="math/tex">= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot S_{t-2}))</script></p><p>`<script type="math/tex">= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot f(U \cdot X_{t-2}+W \cdot S_{t-3})))</script></p><p>`<script type="math/tex">= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot f(U \cdot X_{t-2}+W \cdot f(U \cdot X_{t-3}+…))))</script></p><p><code>总结</code>：从上面可以看出，<strong>递归神经网络</strong>的输出值$o<em>t$，是受前面几次输入值$X_t、X</em>{t−1}、X<em>{t−2}、X</em>{t−3}…$影响的，这也就是为什么<strong>递归神经网络</strong>可以往前看任意多个<strong>输入值</strong>的原因。</p><h3 id="双向递归神经网络"><a href="#双向递归神经网络" class="headerlink" title="双向递归神经网络"></a>双向递归神经网络</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN4.png" alt=""></p><p>从上图可以看出，<strong>双向递归神经网络</strong>的隐层是需要保持两个值：</p><ul><li>A：参与正向计算</li><li>A′：参与反向计算</li></ul><p>所以$y_2$的值就取决于$A_2$和$A′_2$。计算方法：</p><script type="math/tex; mode=display">y_2=f(V \cdot A_2+V’ \cdot A_2’)</script><p>$A_2和A_2′$则分别计算：</p><script type="math/tex; mode=display">A_2 = f(W \cdot A_1+U \cdot X_2)</script><script type="math/tex; mode=display">A_2’=f(W’ \cdot A_3’+U’ \cdot X_2)</script><p><code>总结</code>：</p><ul><li>正向计算时：隐层的值<script type="math/tex">S_t和S_{t−1}</script>有关。</li><li>反向计算时：隐层的值<script type="math/tex">S′_t和S′_{t−1}</script>有关。</li><li>最终的输出取决于正向和反向计算的<strong>和</strong>。</li></ul><p><code>扩展</code>：我们仿照（1）和（2）那种方式：</p><script type="math/tex; mode=display">O_t =f(V \cdot S_t+V’ \cdot S_t’)</script><script type="math/tex; mode=display">S_t =f(U \cdot X_t+W \cdot S_{t-1})</script><script type="math/tex; mode=display">S_t’=f(U’ \cdot X_t+W’ \cdot S_{t+1}’)</script><p><code>注意</code>：从上面三个公式我们可以看到，正向计算和反向计算<strong>不共享权重</strong>，也就是说U和U’、W和W’、V和V’都是不同的<strong>权重矩阵</strong>。</p><h3 id="深度递归神经网络"><a href="#深度递归神经网络" class="headerlink" title="深度递归神经网络"></a>深度递归神经网络</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN5.png" alt=""></p><p>我们把第ii个隐层的值表示为$S_t^{(i)}、S_t’^{(i)}$ ,则<strong>深度递归神经网络</strong>的计算方式就可以表示为：</p><script type="math/tex; mode=display">{O}_t=f \cdot (V^{(i)} \cdot S_t^{(i)}+V’^{(i)} \cdot S_t’^{(i)})</script><script type="math/tex; mode=display">S_t^{(i)}=f(U^{(i)}\cdot S_t^{(i-1)}+W^{(i)}\cdot S_{t-1})</script><script type="math/tex; mode=display">S_t’^{(i)}=f(U’^{(i)}\cdot S_t’^{(i-1)}+W’^{(i)}\cdot S_{t+1}’)</script><script type="math/tex; mode=display">···</script><script type="math/tex; mode=display">S_t^{(1)}=f(U^{(1)} \cdot X_t+W^{(1)}\cdot S_{t-1})</script><script type="math/tex; mode=display">S_t’^{(1)}=f(U’^{(1)}\cdot X_t+W’^{(1)}\cdot S_{t+1}’)</script><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN6.png" alt=""></p><p>从上图我们可以总结出：</p><ul><li><code>one to one</code>：一个输入（单一标签）对应一个输出（单一标签）</li><li><code>one to many</code>：一个输入对应多个输出，即这个架构多用于图片的对象识别，即输入一个图片，输出一个文本序列。</li><li><code>many to one</code>： 多个输入对应一个输出，多用于文本分类或视频分类，即输入一段文本或视频片段，输出类别。</li><li><code>many to many</code>：这种结构广泛的用于机器翻译，输入一个文本，输出另一种语言的文本。</li><li><code>many to many</code>：这种广泛的用于序列标注。</li></ul><p>在众多的深度学习网络中，RNN由于能够接收序列输入，也能得到序列输出，在自然语言处理中取得了巨大的成功，并得到广泛的应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;循环神经网络（RNN）是一类神经网络，包括一层内的加权连接，与传统前馈神经网络相比，加权连接仅反馈到后续层。因为RNN&lt;strong&gt;包含循环&lt;/strong&gt;，所以RNN就可以在处理输入信息的时候同时&lt;strong&gt;储存信息&lt;/strong&gt;。这种记忆使得RNN非常适合处
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="RNN" scheme="https://janvia.github.io/tags/RNN/"/>
    
  </entry>
  
</feed>
