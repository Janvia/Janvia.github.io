<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>sylvia</title>
  
  <subtitle>Viva La Vida</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://janvia.github.io/"/>
  <updated>2019-01-20T05:49:05.443Z</updated>
  <id>https://janvia.github.io/</id>
  
  <author>
    <name>sylvia</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>21单元语法</title>
    <link href="https://janvia.github.io/2019/01/20/21%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95/"/>
    <id>https://janvia.github.io/2019/01/20/21单元语法/</id>
    <published>2019-01-20T04:34:27.000Z</published>
    <updated>2019-01-20T05:49:05.443Z</updated>
    
    <content type="html"><![CDATA[<h2 id="～そうだ＜征兆、推测＞"><a href="#～そうだ＜征兆、推测＞" class="headerlink" title="～そうだ＜征兆、推测＞"></a>～そうだ＜征兆、推测＞</h2><h3 id="1、征兆"><a href="#1、征兆" class="headerlink" title="1、征兆"></a>1、征兆</h3><p>接续：V-R（第一连用型）+ そうだ</p><p>样态助动词，表示<strong>征兆</strong>，是说话人对<strong>即将发生</strong>的动作，变化的征兆进行的描述，一般是说话人通过自身的感官判断或觉察到的。<strong>(主観)</strong>常与<strong>｢今にも｣</strong>连用。变形之后按<strong>二类形容词</strong>活用。</p><p> ✿汉语：就要~了、快要~了</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.今にも雨が降りそうです。　</span><br><span class="line">2.寒くて死にそうだ。</span><br><span class="line">3.ポケットから財布が落ちそうだよ。(2002年真题)</span><br></pre></td></tr></table></figure><h3 id="2、推测"><a href="#2、推测" class="headerlink" title="2、推测"></a>2、推测</h3><p>接续：</p><p>$\bullet$    A1-词干(去い) 　+ そうだ</p><p>$\bullet$    A2-词干 　　　  + そうだ </p><p>$\bullet$    VーR　　　　　 + そうだ</p><p>表示<strong>推断、猜测、发生的可能性</strong>，是说话人根据事物的外表、经验等判断某事态很有可能发生或某事物具有某性质。变形之后按<strong>二类形容词</strong>活用。</p><p> ✿汉语：看上去~；看起来~；好像~<br>★：いい・ない:　　よさそうだ・なさそうだ</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.山田さんはいつも難しそうな本を読んでいる。(2006年真题)　</span><br><span class="line">2.石田さんは忙しそうだから、手伝おう。(2003年真题)</span><br><span class="line">3.あの様子では二人はもうすぐ結婚しそうです。</span><br></pre></td></tr></table></figure><h3 id="３、そうだ的否定形式"><a href="#３、そうだ的否定形式" class="headerlink" title="３、そうだ的否定形式"></a>３、そうだ的否定形式</h3><p>Vそうだ的否定为：<br>｢Vそうにもない｣</p><p>口语中常用｢そうもない｣或｢そうにない｣。即省略「に」或「も」<br>表示发生某动作的可能性极小。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.この本は売れそうもない。</span><br><span class="line">2.一人の力だけでは、とうていできそうにもない。</span><br></pre></td></tr></table></figure><p>Aそうだ的否定为：</p><p>$\bullet$    「そうではない」</p><p>$\bullet$    「A1-くなさそうだ」</p><p>$\bullet$    「A2- ではなさそうだ」</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.最近、授業は少ないから、忙しそうではない。</span><br><span class="line">  </span><br><span class="line">  最近、授業は少ないから、忙しくなさそうだ。</span><br><span class="line"></span><br><span class="line">2.彼は一週間以上も病気だから、体はあまり元気そうではない。</span><br><span class="line">  </span><br><span class="line">  彼は一週間以上も病気だから、体はあまり元気ではなさそうだ。</span><br></pre></td></tr></table></figure><h3 id="4、そうだ修饰名词或动词"><a href="#4、そうだ修饰名词或动词" class="headerlink" title="4、そうだ修饰名词或动词"></a>4、そうだ修饰名词或动词</h3><p>修饰名词时：A/V +そう+な+ N<br>修饰动词时：Aそう+に+ V</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.彼は悲しそうな顔をしている。</span><br><span class="line">2.彼は楽しそうに笑った。</span><br><span class="line">3.李さんは元気そうな声で話してくれた。</span><br><span class="line">4.雨が降りそうな天気だ。</span><br></pre></td></tr></table></figure><h2 id="授受动词"><a href="#授受动词" class="headerlink" title="授受动词"></a>授受动词</h2><h3 id="1、あげる（自谦）：さしあげる"><a href="#1、あげる（自谦）：さしあげる" class="headerlink" title="1、あげる（自谦）：さしあげる"></a>1、あげる（自谦）：さしあげる</h3><p>接续：（赠与者）N1は∕が＋（接受者）N2に＋（所赠物品）N3を＋あげる。</p><p>当接受者的身份、地位、年龄高于赠与者时：<br>あげるーさしあげる</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">先生が大学をおやめになる日、みんなで先生にアルバムをさしあげました。</span><br></pre></td></tr></table></figure><h3 id="2、くれるーくださる"><a href="#2、くれるーくださる" class="headerlink" title="2、くれるーくださる"></a>2、くれるーくださる</h3><p>接续：（赠与者）N1は∕が＋（我或我这一方的人）に＋（所赠物品）N2を＋くれる。</p><p>当赠与者的身份、地位、年龄高于接受者时：<br>くれるーくださる</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">先輩が妹にコンサートのチケットをくださいました。</span><br></pre></td></tr></table></figure><h3 id="3、もらう－いただく"><a href="#3、もらう－いただく" class="headerlink" title="3、もらう－いただく"></a>3、もらう－いただく</h3><p>接续：（接受者）N1は＋（赠与者）N2に∕から＋（所得物品）N3を＋もらう。</p><p>当赠与者的身份、地位、年龄高于接受者时：<br>もらう－いただく</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">わたしは社長に会社のぺんをいただきました。</span><br></pre></td></tr></table></figure><h3 id="補助動詞・行为的授受"><a href="#補助動詞・行为的授受" class="headerlink" title="補助動詞・行为的授受"></a>補助動詞・行为的授受</h3><p>$\bullet$    ～てあげる $\Rightarrow$ ～てさしあげる（謙譲語）</p><p>$\bullet$    ～てもらう $\Rightarrow$ ～ていただく　（謙譲語）</p><p>$\bullet$    ～てくれる $\Rightarrow$ ～てくださる　（尊敬語）</p><p>①Aは Bに Vてあげる<br>　　　　   Vて やる<br>　　　　   Vてさしあげる</p><p>表示A为B做某事。<br>A是授予者，用「は」提示；(授予者为第一人时常省略）<br>B是接受者，用「に」提示。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.これ、貸してあげるよ。(2007年真题)</span><br><span class="line">2.この写真は家族にもぜひ見せてやりたい。</span><br><span class="line">3.吉田先生を駅まで車で送って差し上げた。</span><br></pre></td></tr></table></figure><p>「～てやる」用于AB之间关系亲近，随意，或B身份、地位低于A时。<br>「～てあげる」是「～てやる」的客气说法，<br>「～てさしあげる」则比「～てあげる」更客气，常常用来叙述B是A的尊长时的授受关系。</p><p> ★：另外「～てあげる」会使行为接受者觉得这是对方施恩于自己而感到不快，用时应注意。</p><p>特殊接续：</p><p>$\bullet$    彼女の手を取ってあげる</p><p>$\bullet$    彼女の荷物を持ってあげる</p><p>$\bullet$    彼女を手伝ってあげる    </p><p>②AはBに(から)Vてもらう<br>　　　　　　　Vていただく</p><p>表示A接受B所做的事。A是接受者，用「は」提示。B是授予者，用「に」或「から」提示。B为A所做的事用「て」前面的动词表示。<br>★：「~ていただく」是「~てもらう」的谦语，<br>　　一般用于B比A身份高，或B是A所尊敬的人。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.本田先生に貸していただいた本を家に忘れた。(2012年真题)</span><br><span class="line">2.この書類を広田さんに渡しておいてもらえないか。(2012年真题)</span><br></pre></td></tr></table></figure><p>③Aは (私に) Vてくれる<br>　　　　　   Vてくださる</p><p>表示A为我（我们，我方人员）做某事。与①相反。<br>Ｂ在句中往往省略。<br>★：「 Vていただく」与「 Vてくださる」的区别在于：前者常带有“该动作是受益者要求对方进行的”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.友達がたくさん来てくれた。</span><br><span class="line">2.そちらの方が私の荷物を持ってくださいました。(2008年真题)</span><br><span class="line">3.友達が掃除を手伝ってくれた。(2006年真题)</span><br></pre></td></tr></table></figure><h3 id="变形总结"><a href="#变形总结" class="headerlink" title="变形总结"></a>变形总结</h3><div class="table-container"><table><thead><tr><th style="text-align:center">原型</th><th style="text-align:center">授受敬语</th><th style="text-align:center">行为的授受</th><th style="text-align:center">行为的授受敬语</th></tr></thead><tbody><tr><td style="text-align:center">あげる</td><td style="text-align:center">さしあげる</td><td style="text-align:center">てあげる</td><td style="text-align:center">てさしあげる</td></tr><tr><td style="text-align:center">もらう</td><td style="text-align:center">いただく</td><td style="text-align:center">てもらう</td><td style="text-align:center">ていただく</td></tr><tr><td style="text-align:center">くれる</td><td style="text-align:center">くださる</td><td style="text-align:center">てくれる</td><td style="text-align:center">てくださる</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;～そうだ＜征兆、推测＞&quot;&gt;&lt;a href=&quot;#～そうだ＜征兆、推测＞&quot; class=&quot;headerlink&quot; title=&quot;～そうだ＜征兆、推测＞&quot;&gt;&lt;/a&gt;～そうだ＜征兆、推测＞&lt;/h2&gt;&lt;h3 id=&quot;1、征兆&quot;&gt;&lt;a href=&quot;#1、征兆&quot; class=&quot;
      
    
    </summary>
    
      <category term="日语" scheme="https://janvia.github.io/categories/%E6%97%A5%E8%AF%AD/"/>
    
    
      <category term="语法" scheme="https://janvia.github.io/tags/%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>PG和TD3</title>
    <link href="https://janvia.github.io/2019/01/18/PG%E5%92%8CTD3/"/>
    <id>https://janvia.github.io/2019/01/18/PG和TD3/</id>
    <published>2019-01-18T00:11:14.000Z</published>
    <updated>2019-01-18T09:17:09.400Z</updated>
    
    <content type="html"><![CDATA[<h3 id="TD3"><a href="#TD3" class="headerlink" title="TD3"></a>TD3</h3><p>TD3 = Twin Delayed DDPG：三点改进：</p><h4 id="改进１"><a href="#改进１" class="headerlink" title="改进１"></a>改进１</h4><p><strong>Twin:</strong>有两个Q值预测网络，使用输出Q值较小的那个用作计算TD error的目标值；</p><p>Double DQN:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/图片2.png" alt=""></p><p>Double q learning(Q值来自于神经网络):</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD2.png" alt=""></p><p>Clipped Double Q-learning algorithm:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD3.png" alt=""></p><h4 id="改进２"><a href="#改进２" class="headerlink" title="改进２"></a>改进２</h4><p><strong>Delayed：</strong>更新策略的频率要小于更新Q值，即训练actor网络的次数要小于训练critic网络；</p><p>在值网络估计不准确的情况下（TD error很大），更新策略会引发</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD4.png" alt=""></p><p>在更新critic网络d次之后再更新actor网络</p><h4 id="改进３"><a href="#改进３" class="headerlink" title="改进３"></a>改进３</h4><p><strong>目标策略平滑：</strong><br>Idea:相似的动作在同一个状态下的Q值也相似</p><p>Trick:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD5.png" alt=""></p><h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD6.png" alt=""></p><h4 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD7.png" alt=""></p><h3 id="TD3-vs-DDPG-参数设计"><a href="#TD3-vs-DDPG-参数设计" class="headerlink" title="TD3 vs DDPG 参数设计"></a>TD3 vs DDPG 参数设计</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD8.png" alt=""></p><h3 id="PG"><a href="#PG" class="headerlink" title="PG"></a>PG</h3><p>一个特定的回合内，其生成的轨迹概率<br>轨迹:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD9.png" alt=""></p><p>概率：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD10.png" alt=""></p><p>重要性采样比率:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_002.png" alt=""></p><p>梯度公式：</p><p>*<script type="math/tex">\nabla_{\theta}logP(\tau|\theta)=\nabla \sum_{t=0}^T  log\pi_{\theta}(a_t|s_t)</script></p><p>带入求导：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_003.png" alt=""></p><p>又：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_004.png" alt=""></p><p>所以：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/选区_005.png" alt=""></p><p>所以：</p><p><em><script type="math/tex">\nabla_{\theta}J(\pi_\theta)=\nabla E_{\tau\sim\pi_\theta} [R(\tau)]</script></em></p><p><em><script type="math/tex">=\nabla_\theta \int_{\tau\sim\pi_\theta} P(\tau|\theta)R(\tau)</script></em></p><p><em><script type="math/tex">= \int_{\tau\sim\pi_\theta} \nabla_\theta P(\tau|\theta)R(\tau)</script></em></p><p><em><script type="math/tex">= \int_{\tau\sim\pi_\theta} P(\tau|\theta)\nabla_\theta logP(\tau|\theta)R(\tau)</script></em></p><p><em><script type="math/tex">= E_{\tau\sim\pi_\theta}[\nabla_\theta logP(\tau|\theta)R(\tau)]</script></em></p><p><em><script type="math/tex">= E_{a_t\sim\pi_\theta}[\nabla_\theta \sum_{t=0}^T log\pi_\theta(a_t|s_t)R(\tau)]</script></em></p><h4 id="过程-1"><a href="#过程-1" class="headerlink" title="过程"></a>过程</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD15.png" alt=""></p><p>蒙特卡洛估计方差太大，见下图：<br>使用神经网络来估计Q值</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/图片5.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/图片6.png" alt=""></p><p>从上图看出负的噪声影响很大，怎么办呢？</p><p>可以增加一个b值补偿</p><p>推导：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/QQ截图20190118034441.png" alt=""></p><p>方差公式和梯度公式：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习TD/PG1.png" alt=""></p><p>梯度公式带入方差公式：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD12.png" alt=""></p><p>求导：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD13.png" alt=""></p><p>所以：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD14.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;TD3&quot;&gt;&lt;a href=&quot;#TD3&quot; class=&quot;headerlink&quot; title=&quot;TD3&quot;&gt;&lt;/a&gt;TD3&lt;/h3&gt;&lt;p&gt;TD3 = Twin Delayed DDPG：三点改进：&lt;/p&gt;
&lt;h4 id=&quot;改进１&quot;&gt;&lt;a href=&quot;#改进１&quot; clas
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="PG" scheme="https://janvia.github.io/tags/PG/"/>
    
      <category term="TD3" scheme="https://janvia.github.io/tags/TD3/"/>
    
  </entry>
  
  <entry>
    <title>RNN理论</title>
    <link href="https://janvia.github.io/2019/01/17/RNN%E7%90%86%E8%AE%BA/"/>
    <id>https://janvia.github.io/2019/01/17/RNN理论/</id>
    <published>2019-01-17T06:19:54.000Z</published>
    <updated>2019-01-17T10:46:25.312Z</updated>
    
    <content type="html"><![CDATA[<p>循环神经网络（RNN）是一类神经网络，包括一层内的加权连接，与传统前馈神经网络相比，加权连接仅反馈到后续层。因为RNN<strong>包含循环</strong>，所以RNN就可以在处理输入信息的时候同时<strong>储存信息</strong>。这种记忆使得RNN非常适合处理必须考虑事先输入的任务（比如<strong>时序数据</strong>）。所以循环神经网络在<strong>自然语言处理</strong>领域非常适合。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN1.png" alt=""></p><p>传统神经网络（包含CNN），输入和输出都是互相独立的。<br>RNN引入了“记忆”的概念</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN2.png" alt=""></p><p><strong>x</strong>：输入层的值<br><strong>U</strong>：输入层到隐层的权重参数<br><strong>s</strong>：隐层的值<br><strong>v</strong>：隐层到输出层的权重参数<br><strong>o</strong>：输出层的值<br><strong>W</strong>：递归神经网络的隐藏层的值s不仅仅取决于当前这次的输入x，还取决于上一次隐藏层的值s。权重参数W就是隐藏层上一次的值作为这一次的输入的权重。</p><p><strong>关键点</strong>：$S<em>t$的值不仅仅取决于$X_t$，还取决于$S</em>{t−1}$(就是上一状态的隐层的值)</p><p>循环神经网络的<strong>计算公式</strong>：</p><script type="math/tex; mode=display">O_t=f(V \cdot S_t) \quad (1)</script><p><code>输出层</code>的计算公式，由于输出层是一个<strong>全连接层</strong>，所以说它每个节点都和隐层的节点相连。<code>V</code>是输出层的权重参数，<code>f</code>是激活函数。</p><script type="math/tex; mode=display">S_t=f(U \cdot X_t+W \cdot S_{t-1}) \quad (2)</script><p><code>隐层</code>的计算公式，它是一个<code>循环层</code>，<code>U</code>是输入<code>x</code>的权重参数，<code>W</code>是上一次的值$S_{t−1}$作为这一次输入的权重参数，<code>f</code>是激活函数。</p><p><strong>总结</strong>：从上面的公式中，我们可以看出，<strong>循环层</strong>和<strong>全连接层</strong>的区别就是<strong>循环层</strong>多了一个<strong>权重参数</strong><code>w</code>。</p><p><code>扩展</code>：如果反复的把（1）式带入 （2）式：</p><p>${O}_t=f(V\cdot{S}_t)$</p><p> `<script type="math/tex">= V \cdot f(U \cdot X_t + W \cdot S_{t-1})</script></p><p>`<script type="math/tex">= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot S_{t-2}))</script></p><p>`<script type="math/tex">= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot f(U \cdot X_{t-2}+W \cdot S_{t-3})))</script></p><p>`<script type="math/tex">= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot f(U \cdot X_{t-2}+W \cdot f(U \cdot X_{t-3}+…))))</script></p><p><code>总结</code>：从上面可以看出，<strong>递归神经网络</strong>的输出值$o<em>t$，是受前面几次输入值$X_t、X</em>{t−1}、X<em>{t−2}、X</em>{t−3}…$影响的，这也就是为什么<strong>递归神经网络</strong>可以往前看任意多个<strong>输入值</strong>的原因。</p><h3 id="双向递归神经网络"><a href="#双向递归神经网络" class="headerlink" title="双向递归神经网络"></a>双向递归神经网络</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN4.png" alt=""></p><p>从上图可以看出，<strong>双向递归神经网络</strong>的隐层是需要保持两个值：</p><ul><li>A：参与正向计算</li><li>A′：参与反向计算</li></ul><p>所以$y_2$的值就取决于$A_2$和$A′_2$。计算方法：</p><script type="math/tex; mode=display">y_2=f(V \cdot A_2+V’ \cdot A_2’)</script><p>$A_2和A_2′$则分别计算：</p><script type="math/tex; mode=display">A_2 = f(W \cdot A_1+U \cdot X_2)</script><script type="math/tex; mode=display">A_2’=f(W’ \cdot A_3’+U’ \cdot X_2)</script><p><code>总结</code>：</p><ul><li>正向计算时：隐层的值<script type="math/tex">S_t和S_{t−1}</script>有关。</li><li>反向计算时：隐层的值<script type="math/tex">S′_t和S′_{t−1}</script>有关。</li><li>最终的输出取决于正向和反向计算的<strong>和</strong>。</li></ul><p><code>扩展</code>：我们仿照（1）和（2）那种方式：</p><script type="math/tex; mode=display">O_t =f(V \cdot S_t+V’ \cdot S_t’)</script><script type="math/tex; mode=display">S_t =f(U \cdot X_t+W \cdot S_{t-1})</script><script type="math/tex; mode=display">S_t’=f(U’ \cdot X_t+W’ \cdot S_{t+1}’)</script><p><code>注意</code>：从上面三个公式我们可以看到，正向计算和反向计算<strong>不共享权重</strong>，也就是说U和U’、W和W’、V和V’都是不同的<strong>权重矩阵</strong>。</p><h3 id="深度递归神经网络"><a href="#深度递归神经网络" class="headerlink" title="深度递归神经网络"></a>深度递归神经网络</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN5.png" alt=""></p><p>我们把第ii个隐层的值表示为$S_t^{(i)}、S_t’^{(i)}$ ,则<strong>深度递归神经网络</strong>的计算方式就可以表示为：</p><script type="math/tex; mode=display">{O}_t=f \cdot (V^{(i)} \cdot S_t^{(i)}+V’^{(i)} \cdot S_t’^{(i)})</script><script type="math/tex; mode=display">S_t^{(i)}=f(U^{(i)}\cdot S_t^{(i-1)}+W^{(i)}\cdot S_{t-1})</script><script type="math/tex; mode=display">S_t’^{(i)}=f(U’^{(i)}\cdot S_t’^{(i-1)}+W’^{(i)}\cdot S_{t+1}’)</script><script type="math/tex; mode=display">···</script><script type="math/tex; mode=display">S_t^{(1)}=f(U^{(1)} \cdot X_t+W^{(1)}\cdot S_{t-1})</script><script type="math/tex; mode=display">S_t’^{(1)}=f(U’^{(1)}\cdot X_t+W’^{(1)}\cdot S_{t+1}’)</script><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/深度学习/RNN6.png" alt=""></p><p>从上图我们可以总结出：</p><ul><li><code>one to one</code>：一个输入（单一标签）对应一个输出（单一标签）</li><li><code>one to many</code>：一个输入对应多个输出，即这个架构多用于图片的对象识别，即输入一个图片，输出一个文本序列。</li><li><code>many to one</code>： 多个输入对应一个输出，多用于文本分类或视频分类，即输入一段文本或视频片段，输出类别。</li><li><code>many to many</code>：这种结构广泛的用于机器翻译，输入一个文本，输出另一种语言的文本。</li><li><code>many to many</code>：这种广泛的用于序列标注。</li></ul><p>在众多的深度学习网络中，RNN由于能够接收序列输入，也能得到序列输出，在自然语言处理中取得了巨大的成功，并得到广泛的应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;循环神经网络（RNN）是一类神经网络，包括一层内的加权连接，与传统前馈神经网络相比，加权连接仅反馈到后续层。因为RNN&lt;strong&gt;包含循环&lt;/strong&gt;，所以RNN就可以在处理输入信息的时候同时&lt;strong&gt;储存信息&lt;/strong&gt;。这种记忆使得RNN非常适合处
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="RNN" scheme="https://janvia.github.io/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降</title>
    <link href="https://janvia.github.io/2019/01/17/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <id>https://janvia.github.io/2019/01/17/梯度下降/</id>
    <published>2019-01-17T03:10:33.000Z</published>
    <updated>2019-01-17T06:08:19.832Z</updated>
    
    <content type="html"><![CDATA[<h3 id="梯度下降方法"><a href="#梯度下降方法" class="headerlink" title="梯度下降方法"></a>梯度下降方法</h3><p>用负梯度作搜索方向，即令$\bigtriangleup x=-\bigtriangledown f(x)$, 是一种自然的选择。相应的方法就称梯度方法或者梯度下降方法。</p><h3 id="梯度下降算法的概念"><a href="#梯度下降算法的概念" class="headerlink" title="梯度下降算法的概念"></a>梯度下降算法的概念</h3><p><strong>梯度下降算法</strong>是一个被广泛使用的优化算法, 它可以用于寻找<strong>最小化成本函数</strong>的参数值. 也就是说: 当函数$ J(\theta)$取得最小值时, 求所对应的自变量<strong>θ</strong>的过程， 此处<strong>θ</strong>就是机器要学习的参数，$J(\theta)$就是用于参数估计的成本函数, 是关于θ的函数.</p><h3 id="梯度下降的基本步骤"><a href="#梯度下降的基本步骤" class="headerlink" title="梯度下降的基本步骤"></a>梯度下降的基本步骤</h3><p>梯度下降法的计算过程就是沿梯度下降的方向求解极小值（也可以沿梯度上升方向求解极大值）</p><p>给定 初始点:$x \in dom f$</p><p>重复进行：</p><ol><li>$\bigtriangleup x :=-\bigtriangledown f(x)$</li><li>直线搜索。通过精确或回溯直线搜索方法确实步长t.</li><li>修改 :$x =x+t\bigtriangleup x$</li></ol><p>直到：满足停止准则。</p><h4 id="换种方式："><a href="#换种方式：" class="headerlink" title="换种方式："></a>换种方式：</h4><ol><li>对成本函数进行微分, 得到其在给定点的梯度. 梯度的正负指示了成本函数值的上升或下降:$Δ(\theta)=\frac{∂J(\theta)}{∂\theta}$</li><li>选择使成本函数值减小的方向, 即梯度负方向, 乘以学习率为 α 计算得参数的更新量, 并更新参数:$\theta=\theta−αΔ(\theta)$</li><li>重复以上步骤, 直到取得最小的成本</li></ol><h3 id="批量梯度下降法（Batch-Gradient-Descent）"><a href="#批量梯度下降法（Batch-Gradient-Descent）" class="headerlink" title="批量梯度下降法（Batch Gradient Descent）"></a>批量梯度下降法（Batch Gradient Descent）</h3><p>　批量梯度下降法，是梯度下降法最常用的形式，具体做法也就是在更新参数时使用所有的样本来进行更新，这个方法对应于<strong>线性回归的梯度下降算法</strong>，也就是说线性回归的梯度下降算法就是批量梯度下降法。</p><p>具体实现过程：</p><hr><ol><li>假设函数:<script type="math/tex">h_\theta = \sum_{i=1}^n\theta_ix_i</script></li><li>成本函数:<script type="math/tex">J(\theta)=\frac{1}{2m} \sum_{i=1}^n(h_\theta(x_i)-y_i)^2</script></li><li>对成本函数进行求偏导：对每一个参数<script type="math/tex">\theta_j</script>进行分别求偏导，得出各自的梯度。<script type="math/tex">\frac{\partial J(\theta)}{\partial  \theta}=-\frac1 m  \sum_{i=1}^n(y_i-h_\theta(x_i))x_j^i</script></li><li>每个参数都按照梯度的负方向进行更新:</li></ol><script type="math/tex; mode=display">\theta_j=\theta_j+\frac a m \sum_{i=1}^n(y_i-h_\theta(x_i))x_j^i</script><hr><p>BGD伪代码：</p><hr><p>repeat{</p><script type="math/tex; mode=display">\theta_j=\theta_j+\frac a m \sum_{i=1}^n(y_i-h_\theta(x_i))x_j^i</script><p>(for every j = 0, 1, .. n)</p><p>}</p><hr><p>总结：</p><p>优点：BGD 得到的是全局最优解, 因为它总是以整个训练集来计算梯度,</p><p>缺点：因此带来了巨大的计算量, 计算迭代速度很很慢.</p><h3 id="随机梯度下降法（Stochastic-Gradient-Descent）"><a href="#随机梯度下降法（Stochastic-Gradient-Descent）" class="headerlink" title="随机梯度下降法（Stochastic Gradient Descent）"></a>随机梯度下降法（Stochastic Gradient Descent）</h3><p>随机梯度下降法，其实和批量梯度下降法原理类似，区别在于求梯度时没有用所有的m个样本的数据，而是仅仅选取一个样本j来求梯度。</p><p>具体实现过程：</p><p>SGD 每次以一个样本, 而不是整个数据集来计算梯度. 因此, SGD 从成本函数开始, 就不必再求和了, 针对单个样例的成本函数可以写成:</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2} (h_\theta(x_i)-y_i)^2</script><p>于是, SGD 的参数更新规则就可以写成 ：</p><script type="math/tex; mode=display">\theta_j=\theta_j+a (y_i-h_\theta(x_i))x_j^i</script><p>SGD伪代码：</p><hr><p>repeat {     </p><p>for i = 1, .., m{    </p><script type="math/tex; mode=display">\theta_j=\theta_j+a (y_i-h_\theta(x_i))x_j^i</script><p>           (for every j = 0, 1, .. n)    </p><p>}</p><p>}</p><hr><p>总结：</p><p>SGD 的关键点在于以随机顺序选取样本. 因为 SGD 存在局部最优困境, 若每次都以相同的顺序选取样本, 其有很大的可能会在相同的地方陷入局部最优解困境, 或者收敛减缓. 因此, 欲使 SGD 发挥更好的效果, 应充分利用<strong>随机化</strong>带来的优势: 可以<strong>在每次迭代之前 (伪代码中最外围循环), 对训练集进行随机排列. </strong></p><p>缺点：因为每次只取一个样本来进行梯度下降, SGD 的训练<strong>速度很快</strong>, 但会引入噪声, 使准确度下降</p><p>优点：可以使用<strong>在线学习</strong>. 也就是说, 在模型训练好之后, 只要有新的数据到来, 模型都可以利用新的数据进行再学习, 更新参数,以适应新的变化.</p><h3 id="BGD-vs-SGD"><a href="#BGD-vs-SGD" class="headerlink" title="ＢＧＤ vs ＳＧＤ"></a>ＢＧＤ vs ＳＧＤ</h3><p><strong>随机梯度下降法和批量梯度下降法</strong>是两个极端，一个采用所有数据来梯度下降，一个用一个样本来梯度下降。自然各自的优缺点都非常突出。对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，随机梯度下降法用于仅仅用一个样本决定梯度方向，导致解很有可能不是最优。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。</p><p><strong>MBGD</strong>就综合了这两种方法的优点。</p><h3 id="小批量梯度下降法（Mini-batch-Gradient-Descent）"><a href="#小批量梯度下降法（Mini-batch-Gradient-Descent）" class="headerlink" title="小批量梯度下降法（Mini-batch Gradient Descent）"></a>小批量梯度下降法（Mini-batch Gradient Descent）</h3><p>MBGD 是为解决 BGD 与 SGD 各自缺点而发明的折中算法, 或者说它利用了 BGD 和 SGD 各自优点. 其基本思想是: <em>每次更新参数时, 使用 n 个样本, 既不是全部, 也不是 1.</em> (SGD 可以看成是 n=1 的 MBGD 的一个特例)</p><p>MBGD 的成本函数或其求导公式或参数更新规则公式基本同 BGD 。</p><p>MBGD 的伪代码：</p><hr><p>say b=10, m=1000,</p><p>repeat {     </p><p>for i = 1, 11, 21, .., 991 {</p><script type="math/tex; mode=display">\theta_j=\theta_j+\frac a {10} \sum_{i=1}^{i+9}(y_i-h_\theta(x_i))x_j^i</script><p> (for every j = 0, 1, .. n)    </p><p> }</p><p>}</p><hr><h3 id="梯度下降算法总结"><a href="#梯度下降算法总结" class="headerlink" title="梯度下降算法总结"></a>梯度下降算法总结</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/选区_007.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;梯度下降方法&quot;&gt;&lt;a href=&quot;#梯度下降方法&quot; class=&quot;headerlink&quot; title=&quot;梯度下降方法&quot;&gt;&lt;/a&gt;梯度下降方法&lt;/h3&gt;&lt;p&gt;用负梯度作搜索方向，即令$\bigtriangleup x=-\bigtriangledown f(x)$,
      
    
    </summary>
    
      <category term="优化算法" scheme="https://janvia.github.io/categories/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="梯度下降" scheme="https://janvia.github.io/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
  </entry>
  
  <entry>
    <title>DDQN &amp; DDPG</title>
    <link href="https://janvia.github.io/2019/01/17/Double-QDN/"/>
    <id>https://janvia.github.io/2019/01/17/Double-QDN/</id>
    <published>2019-01-17T00:13:32.000Z</published>
    <updated>2019-01-18T00:16:09.230Z</updated>
    
    <content type="html"><![CDATA[<h3 id="ε-贪婪（greedy）策略"><a href="#ε-贪婪（greedy）策略" class="headerlink" title="ε-贪婪（greedy）策略"></a>ε-贪婪（greedy）策略</h3><p>目的：探索与利用<br>ε∈(0,1)，随着时间的推移逐渐减小直至0<br>产生一个(0,1)的随机数m<br>如果ε&gt;m<br>    采取随机策略，例如一共4个动作，那么选每一个动作的概率都是    0.25<br>如果ε&lt;m<br>    采取贪婪策略，计算当前网络所有输出值Q(St,a)，选择使得    Q(St,a)最大的那个at值作为下一步的动作</p><h3 id="玻尔兹曼softmax"><a href="#玻尔兹曼softmax" class="headerlink" title="玻尔兹曼softmax"></a>玻尔兹曼softmax</h3><p>$q_t(a)$为t时刻，采取动作a的Q值大小</p><p>τ表示是一个衰减系数（类似于模拟退火算法的温度项），随着训练次数的增加而逐渐减少，与ε相对应。<br>随着τ的减小，选择使Q值最大的那个动作a值的概率也越来越高。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN1.png" alt=""></p><h3 id="ε-贪婪-VS-玻尔兹曼"><a href="#ε-贪婪-VS-玻尔兹曼" class="headerlink" title="ε-贪婪 VS 玻尔兹曼"></a>ε-贪婪 VS 玻尔兹曼</h3><p>`<img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN4.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN2.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN5.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN3.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN6.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN7.png" alt=""></p><h3 id="DDQN"><a href="#DDQN" class="headerlink" title="DDQN"></a>DDQN</h3><p>DQN:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN8.png" alt=""></p><p>Double Q learning:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/选区_002.png" alt=""></p><p>Double DQN:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/选区_003.png" alt=""></p><h3 id="PRIORITIZED-EXPERIENCE-REPLAY-优先化记忆回放"><a href="#PRIORITIZED-EXPERIENCE-REPLAY-优先化记忆回放" class="headerlink" title="PRIORITIZED EXPERIENCE REPLAY(优先化记忆回放)"></a>PRIORITIZED EXPERIENCE REPLAY(优先化记忆回放)</h3><p>每一个rollout的被采样概率:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/选区_004.png" alt=""></p><p>其中:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/选区_005.png" alt=""></p><p>importance-sampling (IS) weights（重要性采样权重）:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/选区_006.png" alt=""></p><p>SumTree:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN10.png" alt=""></p><p>DDQN+PER:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN11.png" alt=""></p><h3 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h3><p>Dueling Network Architectures for Deep Reinforcement Learning<br>value和Q value：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN12.png" alt=""></p><p>优势值（Advantage function）</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN13.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN14.png" alt=""></p><p>结合方式：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN15.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN16.png" alt=""></p><h3 id="DQN性能"><a href="#DQN性能" class="headerlink" title="DQN性能"></a>DQN性能</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN17.png" alt=""></p><h3 id="DDPG"><a href="#DDPG" class="headerlink" title="DDPG"></a>DDPG</h3><p>ＤＱＮ的问题：</p><p>动作空间必须是离散的<br>能不能将DQN的思想应用到连续的动作空间？</p><p>DDPG 是一种离策略算法<br>DDPG仅可以用于连续动作空间的问题</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN18.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DDPN19.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/TD1.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;ε-贪婪（greedy）策略&quot;&gt;&lt;a href=&quot;#ε-贪婪（greedy）策略&quot; class=&quot;headerlink&quot; title=&quot;ε-贪婪（greedy）策略&quot;&gt;&lt;/a&gt;ε-贪婪（greedy）策略&lt;/h3&gt;&lt;p&gt;目的：探索与利用&lt;br&gt;ε∈(0,1)，随着
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="DDPG" scheme="https://janvia.github.io/tags/DDPG/"/>
    
      <category term="DDQN" scheme="https://janvia.github.io/tags/DDQN/"/>
    
  </entry>
  
  <entry>
    <title>DQN</title>
    <link href="https://janvia.github.io/2019/01/16/DQN/"/>
    <id>https://janvia.github.io/2019/01/16/DQN/</id>
    <published>2019-01-16T14:21:12.000Z</published>
    <updated>2019-01-16T15:15:38.230Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DQN的背景"><a href="#DQN的背景" class="headerlink" title="DQN的背景"></a>DQN的背景</h3><p>传统强化学习的局限性，无法很好的解决状态空间或者动作空间很大的实际问题<br>举例：小车使用相机进行导航，动作为向左，向前，向右，3种</p><p>100 x 100的灰度图片，状态数：</p><script type="math/tex; mode=display">256^{10000}如果使用q-learning，q(s,a)的个数为3\times256^{10000}</script><p>以现在的存储与计算能力，不可能完成</p><ul><li>首先解决状态空间很大的问题</li></ul><p>能不能根据现在的状态来估计Q(s,a)的值？</p><p><img src="/home/steve/.config/Typora/typora-user-images/1547649673355.png" alt="1547649673355"></p><h3 id="价值函数估计"><a href="#价值函数估计" class="headerlink" title="价值函数估计"></a>价值函数估计</h3><p>假设近似器参数为w,注意有些公式给的是θ，两者是一个意思</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN7.png" alt=""></p><p>回归器的选择:</p><ul><li><p>特征线性组合</p></li><li><p>神经网络</p></li><li><p>决策树</p></li><li><p>最近邻</p></li><li><p>傅里叶/小波基</p></li></ul><h3 id="DQN-VS-Q-learning"><a href="#DQN-VS-Q-learning" class="headerlink" title="DQN VS Q_learning"></a>DQN VS Q_learning</h3><p>深度Q网络(Deep Q-Network,DQN):</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN8.png" alt=""></p><p>Q-learning(离策略（Off-policy）TD控制):</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN9.png" alt=""></p><p>Q learning学习目标：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN10.png" alt=""></p><p>Q函数近似的学习目标:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN11.png" alt=""></p><p>θ可以是任何回归器的参数，如果特指深度神经网络，那么我们也称之为深度Q网络</p><p>深度Q网络(Deep Q-Network,dqn)<br>1、如何通过神经网络进行近似<br>端到端的形式<br>输入：状态或者观测<br>输出：Q值<br>２、与监督学习的异同？</p><p>不用人工标注,神经网络生成</p><h3 id="目标值"><a href="#目标值" class="headerlink" title="目标值"></a>目标值</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN3.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN4.png" alt=""></p><p>１、数据怎么来？<br>使用当下策略生成。<br>2.、有没有问题？<br>相邻两次的更新使用的样本是是相关的<br>Q（s1,a1）=0.9, 估计成了1.0, s2与s1很相似<br>Q(s2,a1) = 0.05+1*0.99=1.04，s3与s2很相似<br>……<br>3 、在训练时，打散训练样本的顺序</p><h3 id="经验回放"><a href="#经验回放" class="headerlink" title="经验回放"></a>经验回放</h3><p>定义一个replay buffer，RB, 记录下前N次的rollouts<br>在训练的时候，随机采样，进行训练</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN5.png" alt=""></p><p>DQN with experience replay ：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/DQN6.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;DQN的背景&quot;&gt;&lt;a href=&quot;#DQN的背景&quot; class=&quot;headerlink&quot; title=&quot;DQN的背景&quot;&gt;&lt;/a&gt;DQN的背景&lt;/h3&gt;&lt;p&gt;传统强化学习的局限性，无法很好的解决状态空间或者动作空间很大的实际问题&lt;br&gt;举例：小车使用相机进行导航，动
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="DQN" scheme="https://janvia.github.io/tags/DQN/"/>
    
  </entry>
  
  <entry>
    <title>TCP传输图片</title>
    <link href="https://janvia.github.io/2019/01/16/TCP%E4%BC%A0%E8%BE%93%E5%9B%BE%E7%89%87/"/>
    <id>https://janvia.github.io/2019/01/16/TCP传输图片/</id>
    <published>2019-01-16T09:03:00.000Z</published>
    <updated>2019-01-16T09:04:38.553Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import socket</span><br><span class="line">import pickle</span><br><span class="line">import numpy as np</span><br><span class="line">from PIL import Image</span><br><span class="line">import io</span><br><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">def main(img):</span><br><span class="line">#    start_svc = datetime.datetime.now()</span><br><span class="line">    try:</span><br><span class="line"></span><br><span class="line">        img = img.convert(&apos;L&apos;)</span><br><span class="line">        img = img.resize((256,256))</span><br><span class="line">        #        print(img.mode)</span><br><span class="line">        #        print(img.size)</span><br><span class="line">        arr = np.asarray(img, dtype=&quot;float32&quot;)</span><br><span class="line">       # arr = arr.flatten()</span><br><span class="line">        arr = arr.reshape(1,-1)</span><br><span class="line">        #data.append(arr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #  name = &quot;&quot; + job_name + &quot;.pkl&quot;</span><br><span class="line">        #      name = &quot;AAA.pkl&quot;</span><br><span class="line"></span><br><span class="line">        #end_svc = datetime.datetime.now()</span><br><span class="line"></span><br><span class="line">        pca_data = pca.transform(arr)</span><br><span class="line">        y_test_pred = svc.predict(pca_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #time = end_svc - start_svc</span><br><span class="line">        #print(time)</span><br><span class="line">        return y_test_pred</span><br><span class="line"></span><br><span class="line">    except Exception as err:</span><br><span class="line"></span><br><span class="line">        return str(err)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">len_rev=0</span><br><span class="line">def tcp_connected(s,addr):</span><br><span class="line">    print(&apos;Accept new connection from %s:%s...&apos; % addr)</span><br><span class="line">    while 1:</span><br><span class="line"></span><br><span class="line">        data =s.recv(1600000)</span><br><span class="line">        len_rev=len(data)</span><br><span class="line"> #   print(len_rev)</span><br><span class="line">        if len_rev&gt;=1000000:</span><br><span class="line">            image = Image.open(io.BytesIO(data))</span><br><span class="line">            result=main(image)[0]</span><br><span class="line">            s.send(result.encode())</span><br><span class="line">            print(result)</span><br><span class="line">        elif len_rev&lt;=100 and data.decode()== &apos;close&apos;:</span><br><span class="line">            sock.close()</span><br><span class="line">            sys.exit(0)</span><br><span class="line"></span><br><span class="line">arg1 = &quot;&quot; + sys.argv[1]</span><br><span class="line"></span><br><span class="line">s = socket.socket()         # 创建 socket 对象</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">all_port=[6001,42683]</span><br><span class="line">arg=int(arg1)</span><br><span class="line">port=all_port[arg]</span><br><span class="line">print(port)</span><br><span class="line"></span><br><span class="line">#path_to_watch=r&apos;image/Cam&#123;&#125;/&apos;.format(arg+1)</span><br><span class="line">s.bind((&apos;127.0.0.1&apos;, port))  # 绑定端口</span><br><span class="line"></span><br><span class="line">s.listen(2)  # 监听连接,传入连接请求的最大数5</span><br><span class="line"></span><br><span class="line">        # 接受一个新连接</span><br><span class="line">sock,ad=s.accept()</span><br><span class="line">    # 创建新线程来处理TCP连接</span><br><span class="line">name = &quot;SVC_PCA.pkl&quot;</span><br><span class="line">pca, svc = pickle.load(open(name, &apos;rb&apos;))</span><br><span class="line"></span><br><span class="line">t = threading.Thread(tcp=tcp_connected(sock, ad))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;import socket&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import pickle
      
    
    </summary>
    
      <category term="图片分类" scheme="https://janvia.github.io/categories/%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="TCP" scheme="https://janvia.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>时序差分学习</title>
    <link href="https://janvia.github.io/2019/01/16/%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E5%AD%A6%E4%B9%A0/"/>
    <id>https://janvia.github.io/2019/01/16/时序差分学习/</id>
    <published>2019-01-16T07:34:43.000Z</published>
    <updated>2019-01-16T08:25:35.171Z</updated>
    
    <content type="html"><![CDATA[<p>时序差分学习（Temporal-Difference Learning, TD learning）是强化学习中最核心与最著名的思想<br>    ‘If one had to identify one idea as central and novel to reinforcement learning, it would     undoubtedly be temporal-difference (TD) learning.’ —Richard S. Sutton&amp; Andrew G. Barto<br>TD = DP + MC<br>TD, DP都是使用下一时刻的状态函数来估计当前时刻的状态函数。<br>TD,MC都是通过经历一次一次与环境互动，产生多个episode来估计状态函数。</p><p>ＴＤ：</p><script type="math/tex; mode=display">V(S_t)\leftarrow V(S_t)+\alpha(G_t-V(S_t))</script><p>ＭＣ：</p><script type="math/tex; mode=display">V(S_t)\leftarrow V(S_t)+\alpha(R_{t+1}+V(S_{t+1})-V(S_t))</script><h3 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h3><p>在策略（On policy）ＴＤ控制</p><script type="math/tex; mode=display">Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\gamma(R_{t+1}+Q(S_{t+1},A_{t+1})-Q(S_t,A_t))</script><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf1.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf2.png" alt=""></p><h3 id="Expected-Sarsa"><a href="#Expected-Sarsa" class="headerlink" title="Expected Sarsa"></a>Expected Sarsa</h3><p>离策略（Off-policy）TD控制</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf3.png" alt=""></p><h3 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h3><p>离策略（Off-policy）TD控制</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf4.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf6.png" alt=""></p><h3 id="Q-learning-vs-Sarsa"><a href="#Q-learning-vs-Sarsa" class="headerlink" title="Q-learning vs Sarsa"></a>Q-learning vs Sarsa</h3><p>例子：悬崖行走（固定的ε=0.1）</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf7.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf8.png" alt=""></p><h3 id="Q-learning的问题"><a href="#Q-learning的问题" class="headerlink" title="Q-learning的问题"></a>Q-learning的问题</h3><p>过估计（overestimate），因此产生了Double Q learning</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf9.png" alt=""></p><h3 id="Double-Q-learning"><a href="#Double-Q-learning" class="headerlink" title="Double Q learning"></a>Double Q learning</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf10.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf11.png" alt=""></p><h3 id="Q-learning-vs-Double-Q-learning"><a href="#Q-learning-vs-Double-Q-learning" class="headerlink" title="Q learning vs. Double Q learning"></a>Q learning vs. Double Q learning</h3><p>训练参数：ε=0.1，α=0.1, γ=1</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/cf12.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;时序差分学习（Temporal-Difference Learning, TD learning）是强化学习中最核心与最著名的思想&lt;br&gt;    ‘If one had to identify one idea as central and novel to reinfor
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="TD" scheme="https://janvia.github.io/tags/TD/"/>
    
  </entry>
  
  <entry>
    <title>蒙特卡洛方法</title>
    <link href="https://janvia.github.io/2019/01/16/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/"/>
    <id>https://janvia.github.io/2019/01/16/蒙特卡洛方法/</id>
    <published>2019-01-16T00:24:29.000Z</published>
    <updated>2019-01-16T07:26:02.468Z</updated>
    
    <content type="html"><![CDATA[<h3 id="MC"><a href="#MC" class="headerlink" title="MC"></a>MC</h3><p>如何在没有模型的情况下评估一个策略？</p><p>如何计算Ｖ（ｓ）和Ｑ（ｓ）？</p><p>通过采样的方式</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC1.png" alt=""></p><p>如何得到数据？</p><ul><li>On policy: 使用当下的策略生成的数据进行策略评估</li><li>Off policy: 使用其他策略生成的数据进行策略评估</li></ul><p>首次访问蒙特卡洛预测（评估）：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC2.png" alt=""></p><p>Every-Visit Monte-Carlo Policy Evaluation:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC3.png" alt=""></p><p>Incremental Mean:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC4.png" alt=""></p><p>Incremental Monte-Carlo Updates</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC5.png" alt=""></p><h4 id="随机策略"><a href="#随机策略" class="headerlink" title="随机策略"></a>随机策略</h4><p>在预测完成当前策略下的V和Q之后，我们需要对当下的策略进行改进<br>可以采用完全贪婪的策略提升吗？</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC6.png" alt=""></p><p>s4-&gt;s3; s3-&gt;s2;s2-&gt;s2;s2-&gt;s1;<br>s4-&gt;s3; s3-&gt;s2;s2-&gt;s1;</p><p>V(s)，Q(s,a)<br>0,1,1,1,0,0,0<br>Q(s2,a=左)= Q(s3,a=左)= Q(s4,a=左)=1，Q(s4,a=右)=0<br>一直向左走？</p><h3 id="ε-贪婪（greedy）策略"><a href="#ε-贪婪（greedy）策略" class="headerlink" title="ε-贪婪（greedy）策略"></a>ε-贪婪（greedy）策略</h3><p>目的： Exploration（探索）与Exploitation（利用）</p><p>ε∈(0,1)，随着时间的推移逐渐减小直至0</p><p>产生一个(0,1)的随机数m</p><p>如果ε&gt;m<br>    采取随机策略，例如一共4个动作，那么选每一个动作的概率都是    0.25<br>如果ε&lt;m<br>    采取贪婪策略，计算当前网络所有输出值Q(St,a)，选择使得Q(St,a)最大的那个at值作为下一步的动作</p><p>On-pokicy first-visit 蒙特卡洛方法：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC7.png" alt=""></p><h4 id="重要性采样"><a href="#重要性采样" class="headerlink" title="重要性采样"></a>重要性采样</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC8.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/图片1.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC10.png" alt=""></p><p>一个特定的回合内，其生成的轨迹概率：</p><p>轨迹：<img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC11.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC12.png" alt=""></p><p>重要性采样比率：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC13.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC14.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC15.png" alt=""></p><p>使用重要性采样的蒙特卡洛方法：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/MC16.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;MC&quot;&gt;&lt;a href=&quot;#MC&quot; class=&quot;headerlink&quot; title=&quot;MC&quot;&gt;&lt;/a&gt;MC&lt;/h3&gt;&lt;p&gt;如何在没有模型的情况下评估一个策略？&lt;/p&gt;
&lt;p&gt;如何计算Ｖ（ｓ）和Ｑ（ｓ）？&lt;/p&gt;
&lt;p&gt;通过采样的方式&lt;/p&gt;
&lt;p&gt;&lt;img sr
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="MC" scheme="https://janvia.github.io/tags/MC/"/>
    
  </entry>
  
  <entry>
    <title>图片分类-pca_svc</title>
    <link href="https://janvia.github.io/2019/01/15/%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E4%B9%8Bpca-svc/"/>
    <id>https://janvia.github.io/2019/01/15/图片分类之pca-svc/</id>
    <published>2019-01-15T14:59:45.000Z</published>
    <updated>2019-01-16T09:21:24.420Z</updated>
    
    <content type="html"><![CDATA[<h3 id="PCA-SVC训练"><a href="#PCA-SVC训练" class="headerlink" title="PCA_SVC训练"></a>PCA_SVC训练</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">import time</span><br><span class="line">import datetime</span><br><span class="line">def load_Img(imgDir):</span><br><span class="line">    lable = os.listdir(imgDir)</span><br><span class="line">    #print(lable)</span><br><span class="line">    OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0])</span><br><span class="line">    NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1])</span><br><span class="line">    #print(NG_name)</span><br><span class="line"></span><br><span class="line">    label=[]</span><br><span class="line">    data=[]</span><br><span class="line"></span><br><span class="line">    for i in range(len(OK_name)):</span><br><span class="line">        start = datetime.datetime.now()</span><br><span class="line"></span><br><span class="line">        OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1]</span><br><span class="line">        OK_img = Image.open(OK_path)</span><br><span class="line"></span><br><span class="line">        OK_img=OK_img.convert(&apos;L&apos;)</span><br><span class="line">     #   print(OK_img.size)</span><br><span class="line">        end = datetime.datetime.now()</span><br><span class="line">        print(end - start)</span><br><span class="line"></span><br><span class="line">        OK_img = OK_img.resize((64,64))</span><br><span class="line"></span><br><span class="line">        OK_arr = np.asarray(OK_img, dtype=&quot;float32&quot;)</span><br><span class="line"></span><br><span class="line">        OK_arr = OK_arr.flatten()</span><br><span class="line"></span><br><span class="line">        data.append(OK_arr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        label.append(lable[0])</span><br><span class="line">  #      label.append(1)</span><br><span class="line"></span><br><span class="line">    for j in range(len(NG_name)):</span><br><span class="line"></span><br><span class="line">        NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1]</span><br><span class="line">        NG_img = Image.open(NG_path)</span><br><span class="line">        NG_img=NG_img.convert(&apos;L&apos;)</span><br><span class="line">      #  print(NG_img.size)</span><br><span class="line">        NG_img = NG_img.resize((64,64))</span><br><span class="line"></span><br><span class="line">        NG_arr = np.asarray(NG_img, dtype=&quot;float32&quot;)</span><br><span class="line"></span><br><span class="line">        NG_arr = NG_arr.flatten()</span><br><span class="line"></span><br><span class="line">        data.append(NG_arr)</span><br><span class="line"></span><br><span class="line"> #       label.append(0)</span><br><span class="line">        label.append(lable[1])</span><br><span class="line">    return label ,data</span><br><span class="line">craterDir = &quot;E:\image\Result&quot;</span><br><span class="line"></span><br><span class="line">label,data = load_Img(craterDir)</span><br><span class="line">#print(label)</span><br><span class="line">#print(data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#将数据分割训练数据与测试数据</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"># 随机采样20%的数据构建测试样本，其余作为训练样本</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data,label , random_state=33, test_size=0.2)</span><br><span class="line"></span><br><span class="line"># 一个参数点（PCA维数为n）的模型训练和测试，得到该参数下模型在校验集上的预测性能</span><br><span class="line">def n_component_analysis(n,C,gamma, X_train, y_train, X_val, y_val):</span><br><span class="line">    #start = time.time()</span><br><span class="line">    start = datetime.datetime.now()</span><br><span class="line">    pca = PCA(n_components=n)</span><br><span class="line">    print(&quot;PCA begin with n_components: &#123;&#125;&quot;.format(n));</span><br><span class="line">    pca.fit(X_train)</span><br><span class="line"></span><br><span class="line">    # 在训练集和测试集降维</span><br><span class="line">    X_train_pca = pca.transform(X_train)</span><br><span class="line">    X_val_pca = pca.transform(X_val)</span><br><span class="line"></span><br><span class="line">    # 利用SVC训练</span><br><span class="line">    print(&apos;SVC begin&apos;)</span><br><span class="line">    clf1 = SVC(C=C,gamma=gamma)</span><br><span class="line">   # clf1 = SVC(C=C,kernel=&apos;rbf&apos;,gamma=gamma)</span><br><span class="line">    clf1.fit(X_train_pca, y_train)</span><br><span class="line"></span><br><span class="line">    # 返回accuracy</span><br><span class="line">    accuracy = clf1.score(X_val_pca, y_val)</span><br><span class="line">    end = datetime.datetime.now()</span><br><span class="line">  #  end = time.time()</span><br><span class="line">    print(&quot;accuracy: &#123;&#125;,C:&#123;&#125;,gamma:&#123;&#125; time elaps:&#123;&#125;&quot;.format(accuracy,C,gamma ,end - start))</span><br><span class="line">    return accuracy</span><br><span class="line"></span><br><span class="line"># 设置超参数（PCA维数）搜索范围</span><br><span class="line">n_s = np.linspace(0.70, 0.85, num=3)</span><br><span class="line">#需要调优的参数</span><br><span class="line">C_s = np.logspace(4,6, 3)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份</span><br><span class="line">gamma_s = np.logspace(-8, -6, 3)</span><br><span class="line"></span><br><span class="line">accuracy = []</span><br><span class="line"></span><br><span class="line">if __name__==&apos;__main__&apos;:</span><br><span class="line">    for n in n_s:</span><br><span class="line">        for i, oneC in enumerate(C_s):</span><br><span class="line">            for j, gamma in enumerate(gamma_s):</span><br><span class="line">                tmp = n_component_analysis(n, oneC, gamma,X_train, y_train, X_test, y_test)</span><br><span class="line">                accuracy.append(tmp)</span><br></pre></td></tr></table></figure><h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding=utf-8</span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">import pickle</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">#将数据分割训练数据与测试数据</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"># 随机采样20%的数据构建测试样本，其余作为训练样本</span><br><span class="line">def Gain_Img(imgDir):</span><br><span class="line">    lable = os.listdir(imgDir)</span><br><span class="line">    OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0])</span><br><span class="line">    NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1])</span><br><span class="line">    print(lable)</span><br><span class="line">    for i in range(len(OK_name)):</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1]</span><br><span class="line">        OK_img = Image.open(OK_path)</span><br><span class="line">        OK_img=OK_img.convert(&apos;L&apos;)</span><br><span class="line">        OK_img = OK_img.resize((256,256))</span><br><span class="line">        out1 = OK_img.rotate(90)  # 逆时针旋转45度</span><br><span class="line">        if not os.path.exists(&apos;rotation/&#123;&#125;&apos;.format(lable[0])):</span><br><span class="line">            os.makedirs(&apos;rotation/&#123;&#125;&apos;.format(lable[0]))</span><br><span class="line">        if not os.path.exists(&apos;rotation/&#123;&#125;&apos;.format(lable[1])):</span><br><span class="line">            os.makedirs(&apos;rotation/&#123;&#125;&apos;.format(lable[1]))</span><br><span class="line">        out1.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i))</span><br><span class="line">        OK_img.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i))</span><br><span class="line"></span><br><span class="line">    for j in range(len(NG_name)):</span><br><span class="line"></span><br><span class="line">        NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1]</span><br><span class="line">        NG_img = Image.open(NG_path)</span><br><span class="line">        NG_img = NG_img.convert(&apos;L&apos;)</span><br><span class="line">        NG_img = NG_img.resize((256,256))</span><br><span class="line">        out2 = NG_img.rotate(90)  # 逆时针旋转45度</span><br><span class="line">        out2.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j))</span><br><span class="line">        NG_img.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_Img(imgDir):</span><br><span class="line">    lable = os.listdir(imgDir)</span><br><span class="line"></span><br><span class="line">    OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0])</span><br><span class="line">    NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1])</span><br><span class="line"></span><br><span class="line">    label=[]</span><br><span class="line">    data=[]</span><br><span class="line"></span><br><span class="line">    for i in range(len(OK_name)):</span><br><span class="line"></span><br><span class="line">        OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1]</span><br><span class="line">        OK_img = Image.open(OK_path)</span><br><span class="line">      #  OK_img = OK_img.convert(&apos;L&apos;)</span><br><span class="line">      #  OK_img = OK_img.resize((64, 64))</span><br><span class="line"></span><br><span class="line">        OK_arr = np.asarray(OK_img, dtype=&quot;float32&quot;)</span><br><span class="line"></span><br><span class="line">        OK_arr = OK_arr.flatten()</span><br><span class="line"></span><br><span class="line">        data.append(OK_arr)</span><br><span class="line"></span><br><span class="line">        label.append(lable[0])</span><br><span class="line"></span><br><span class="line">    for j in range(len(NG_name)):</span><br><span class="line"></span><br><span class="line">        NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1]</span><br><span class="line">        NG_img = Image.open(NG_path)</span><br><span class="line">       # NG_img = NG_img.convert(&apos;L&apos;)</span><br><span class="line">       # NG_img = NG_img.resize((64, 64))</span><br><span class="line"></span><br><span class="line">        NG_arr = np.asarray(NG_img, dtype=&quot;float32&quot;)</span><br><span class="line"></span><br><span class="line">        NG_arr = NG_arr.flatten()</span><br><span class="line"></span><br><span class="line">        data.append(NG_arr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        label.append(lable[1])</span><br><span class="line">    return label ,data</span><br><span class="line"></span><br><span class="line">def main(path,job_name):</span><br><span class="line">   try:</span><br><span class="line">        label, data = load_Img(path)</span><br><span class="line">        X_train, X_test, y_train, y_test = train_test_split(data,label , random_state=33, test_size=0.2)</span><br><span class="line">        pca = PCA(n_components=0.7)</span><br><span class="line"></span><br><span class="line">        pca.fit(X_train)</span><br><span class="line"></span><br><span class="line">        # 在训练集和测试集降维</span><br><span class="line">        X_train_pca = pca.transform(X_train)</span><br><span class="line">        X_test_pca = pca.transform(X_test)</span><br><span class="line"></span><br><span class="line">        SVC4=SVC(C=10000,gamma=1e-06)</span><br><span class="line">        SVC4 = SVC4.fit(X_train_pca, y_train)</span><br><span class="line">        accuracy = SVC4.score(X_test_pca, y_test)</span><br><span class="line">    #保存模型</span><br><span class="line">        name=&quot;&quot;+job_name+&quot;.pkl&quot;</span><br><span class="line"></span><br><span class="line">        pickle.dump((pca,SVC4),open(name, &apos;wb&apos;))</span><br><span class="line">        return str(accuracy)</span><br><span class="line"></span><br><span class="line">   except Exception as err:</span><br><span class="line"></span><br><span class="line">       return str(err)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">   # print(main(&quot;E:\image\SVM&quot;))</span><br><span class="line">    arg1=&quot;&quot;+sys.argv[1]</span><br><span class="line">    arg2=&quot;&quot;+sys.argv[2]</span><br><span class="line"></span><br><span class="line">    gain = Gain_Img(arg1)</span><br><span class="line"></span><br><span class="line">    print(main(&quot;rotation&quot;,arg2))</span><br></pre></td></tr></table></figure><h3 id="实时测试"><a href="#实时测试" class="headerlink" title="实时测试"></a>实时测试</h3><p>见ＴＣＰ传输图片</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;PCA-SVC训练&quot;&gt;&lt;a href=&quot;#PCA-SVC训练&quot; class=&quot;headerlink&quot; title=&quot;PCA_SVC训练&quot;&gt;&lt;/a&gt;PCA_SVC训练&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;t
      
    
    </summary>
    
      <category term="图片分类" scheme="https://janvia.github.io/categories/%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="SVC" scheme="https://janvia.github.io/tags/SVC/"/>
    
      <category term="PCA" scheme="https://janvia.github.io/tags/PCA/"/>
    
  </entry>
  
  <entry>
    <title>PIL简单应用</title>
    <link href="https://janvia.github.io/2019/01/15/PIL%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/"/>
    <id>https://janvia.github.io/2019/01/15/PIL简单应用/</id>
    <published>2019-01-15T14:30:50.000Z</published>
    <updated>2019-01-15T14:43:41.519Z</updated>
    
    <content type="html"><![CDATA[<h3 id="PIL简介"><a href="#PIL简介" class="headerlink" title="PIL简介"></a>PIL简介</h3><p>PIL是python自带的图像处理库</p><p>安装：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install pillow</span><br></pre></td></tr></table></figure><h3 id="扩充数据－旋转"><a href="#扩充数据－旋转" class="headerlink" title="扩充数据－旋转"></a>扩充数据－旋转</h3><p>准备：新建Train文件夹，将ＮＧ和ＯＫ图片分别放在命名为ＮＧ和ＯＫ的文件夹，新建rotation文件夹，或者修改路径</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def load_Img(imgDir):</span><br><span class="line">    lable = os.listdir(imgDir)</span><br><span class="line">    OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0])</span><br><span class="line">    NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1])</span><br><span class="line">    print(lable)</span><br><span class="line">    for i in range(len(OK_name)):</span><br><span class="line">        OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1]</span><br><span class="line">        OK_img = Image.open(OK_path)</span><br><span class="line">        OK_img=OK_img.convert(&apos;L&apos;)</span><br><span class="line">        OK_img = OK_img.resize((256,256))</span><br><span class="line">        out1 = OK_img.rotate(90)  # 逆时针旋转90度</span><br><span class="line">        out1.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i))</span><br><span class="line">        OK_img.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i))</span><br><span class="line"></span><br><span class="line">    for j in range(len(NG_name)):</span><br><span class="line"></span><br><span class="line">        NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1]</span><br><span class="line">        NG_img = Image.open(NG_path)</span><br><span class="line">        NG_img = NG_img.convert(&apos;L&apos;)#L为灰度</span><br><span class="line">        NG_img = NG_img.resize((256,256))#改变大小</span><br><span class="line">        out2 = NG_img.rotate(90)  # 逆时针旋转90度</span><br><span class="line">        out2.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j))</span><br><span class="line">        NG_img.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">craterDir = &quot;E:\image\Train&quot;</span><br><span class="line">rotation=load_Img(craterDir)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;PIL简介&quot;&gt;&lt;a href=&quot;#PIL简介&quot; class=&quot;headerlink&quot; title=&quot;PIL简介&quot;&gt;&lt;/a&gt;PIL简介&lt;/h3&gt;&lt;p&gt;PIL是python自带的图像处理库&lt;/p&gt;
&lt;p&gt;安装：&lt;/p&gt;
&lt;figure class=&quot;highlight
      
    
    </summary>
    
      <category term="计算机视觉" scheme="https://janvia.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="PIL" scheme="https://janvia.github.io/tags/PIL/"/>
    
  </entry>
  
  <entry>
    <title>强化学习基础</title>
    <link href="https://janvia.github.io/2019/01/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    <id>https://janvia.github.io/2019/01/15/强化学习基础/</id>
    <published>2019-01-15T05:55:18.000Z</published>
    <updated>2019-01-16T07:28:48.775Z</updated>
    
    <content type="html"><![CDATA[<h3 id="强化学习的作用"><a href="#强化学习的作用" class="headerlink" title="强化学习的作用"></a>强化学习的作用</h3><p>Reinforcement learning is learning what to do—how to map situations to actions—so as to maximize a numerical reward signal.<br>强化学习是学习做什么（决策），即基于当前的场景，学习如何做出一个可以最大化回报的动作。</p><h3 id="深度学习与强化学习的关系"><a href="#深度学习与强化学习的关系" class="headerlink" title="深度学习与强化学习的关系"></a>深度学习与强化学习的关系</h3><p>multiple layers of nonlinear processing units for feature extraction and transformation.<br>深度学习（DL）:用多层非线性处理单元学习从输入到输出的特征提取和变换</p><p>深度强化学习（DRL）：在强化学习的框架下，用深度神经网络来近似策略</p><h3 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习１.png" alt=""></p><ul><li><p>状态集：s ∈　S</p></li><li><p>动作集：a ∈　A</p></li><li><p>策略π： s =&gt; a</p></li><li><p>转移函数：Ｔ(s,a,s’)</p></li></ul><p>或者：转移概率： P(s’|s,a)</p><ul><li>奖励函数： R(s,a,s’)</li></ul><h3 id="MDP"><a href="#MDP" class="headerlink" title="MDP"></a>MDP</h3><p>策略：在状态 s 下采取什么动作 a ，找到一个最优策略 π*</p><p>π（a|s）:表示策略　π　下，在状态　s　下采取行动　a　的概率</p><p>方式：通过定义每一个状态的好坏，以及或者该状态下采取某一个动作后的好坏，来寻找最优策略</p><h4 id="价值函数"><a href="#价值函数" class="headerlink" title="价值函数"></a>价值函数</h4><p>状态s，在策略π下的价值函数：</p><script type="math/tex; mode=display">v_\pi(s)=E_\pi[G_t|S_t=s]=E_\pi[\sum_{k=0}^\infty\gamma^kR_{t+k+1}|S_t=s]</script><p>状态s,在执行动作a情况下，策略π的价值函数：</p><script type="math/tex; mode=display">q_\pi(s,a)=E_\pi[G_t|S_t=s,A_t=a]=E_\pi[\sum_{k=0}^\infty\gamma^kR_{t+k+1}|S_t=s,A_t=a]</script><h4 id="贝尔曼方程"><a href="#贝尔曼方程" class="headerlink" title="贝尔曼方程"></a>贝尔曼方程</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习2.png" alt=""></p><p>描述了当前状态下的价值函数与其下一时刻状态下的价值函数的关系</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习3.png" alt=""></p><h3 id="DP"><a href="#DP" class="headerlink" title="DP"></a>DP</h3><p>“The term dynamic programming (DP) refers to a collection of algorithms that can be used to compute optimal policies given a perfect model of the environment as a Markov decision process (MDP).”<br>动态规划是在给定模型情况下求解最优策略的马尔科夫决策过程的一系列算法的统称。</p><p>动态规划主要分为：策略迭代与值迭代（Policy iteration vs Value iteration）</p><p>前提条件：转移概率p(s’,r|s,a)已知</p><p>贝尔曼最优性方程：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习4.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习5.png" alt=""></p><h3 id="值迭代"><a href="#值迭代" class="headerlink" title="值迭代"></a>值迭代</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习6.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习7.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习8.png" alt=""></p><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习10.png" alt=""></p><p>运用公式：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习9.png" alt=""></p><p>结果：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习11.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习12.png" alt=""></p><h3 id="策略迭代"><a href="#策略迭代" class="headerlink" title="策略迭代"></a>策略迭代</h3><p>策略迭代＝策略评估＋策略提升</p><h4 id="策略评估"><a href="#策略评估" class="headerlink" title="策略评估"></a>策略评估</h4><p>目标：通过执行策略π，计算每个状态对应的状态函数值</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习13.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习15.png" alt=""></p><p>实例：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习16.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习17.png" alt=""></p><h4 id="策略提升"><a href="#策略提升" class="headerlink" title="策略提升"></a>策略提升</h4><p>在策略评估之后，采用贪婪策略进行策略更新</p><script type="math/tex; mode=display">v_\pi=E_{a\sim\pi}(q_\pi(s,a))</script><p>将策略改成：</p><script type="math/tex; mode=display">\pi'=argmax_a(q_\pi(s,a))</script><p>则：</p><script type="math/tex; mode=display">v_\pi'>v_\pi</script><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习18.png" alt=""></p><h4 id="VI和PI的联系"><a href="#VI和PI的联系" class="headerlink" title="VI和PI的联系"></a>VI和PI的联系</h4><p>策略评估：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习19.png" alt=""></p><p>策略提升：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习20.png" alt=""></p><p>值迭代：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/强化学习21.png" alt=""></p><h3 id="PMDP"><a href="#PMDP" class="headerlink" title="ＰＭＤＰ"></a>ＰＭＤＰ</h3><p>ＭＤＰ假设中，状态是完全已知的。实际生活中，由于传感器的局限性。往往难以得到当前状态的准确状态值。</p><p>但我们可以估计当前的状态分布belief: b(s)</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/图片1.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/图片2.png" alt=""></p><p>更新belief:</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/图片3.png" alt=""></p><h4 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/实例.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/图片8.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/图片9.png" alt=""></p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/强化学习/图片10.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;强化学习的作用&quot;&gt;&lt;a href=&quot;#强化学习的作用&quot; class=&quot;headerlink&quot; title=&quot;强化学习的作用&quot;&gt;&lt;/a&gt;强化学习的作用&lt;/h3&gt;&lt;p&gt;Reinforcement learning is learning what to do—how 
      
    
    </summary>
    
      <category term="强化学习" scheme="https://janvia.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="强化学习" scheme="https://janvia.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络理论</title>
    <link href="https://janvia.github.io/2019/01/15/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA/"/>
    <id>https://janvia.github.io/2019/01/15/卷积神经网络理论/</id>
    <published>2019-01-15T01:38:55.000Z</published>
    <updated>2019-01-15T05:45:22.287Z</updated>
    
    <content type="html"><![CDATA[<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><h4 id="任务：对输入的图像进行特征提取"><a href="#任务：对输入的图像进行特征提取" class="headerlink" title="任务：对输入的图像进行特征提取"></a><code>任务</code>：对输入的图像进行特征提取</h4><ul><li><p>用一个小的权重矩阵去覆盖输入数据，对应位置元素加权相乘，其和作为结果的一个像素点。</p></li><li><p>这个权重在输入数据上滑动，形成一张新的矩阵</p></li><li><p>这个权重矩阵就被称为<code>卷积核</code>（convolution kernel）</p></li><li><p>其覆盖的位置称为<code>感受野</code>（receptive fileld ）</p></li><li><p>生成的新矩阵叫做<code>特征图</code>（feature map）</p></li></ul><p>如下图所示：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/卷积1.png" alt=""></p><p>步长（stride）：</p><ul><li><p>步长为1，表示跳过1个像素</p></li><li><p>步长为2，就表示跳过2个像素</p></li></ul><p>补齐（padding）方式:</p><ul><li><p>valid方式</p></li><li><p>same方式（会在图像的边缘用0补齐）</p></li></ul><p>输出维度计算公式：</p><ul><li><p>VALID:  W-F+1/S</p></li><li><p>SAME: W/S</p></li></ul><p>注意：彩色图像的卷积核是三阶的，所有的通道的结果要做累加。</p><p>实例：</p><p>padding=same；步长设置为2</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/卷积2.png" alt=""></p><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>｀任务`：对特征进行采样，即用一个数值替代一块区域，主要是为了降低网络训练参数及模型的过拟合程度。以及降低计算量。</p><p>池化/采样的方式通常有以下两种：</p><ol><li>最大池化（Max Pooling: 选择Pooling窗口中的最大值作为采样值；</li><li>均值池化（Mean Pooling）: 将Pooling窗口中的所有值相加取平均，以平均值作为采样值</li><li>高斯池化：借鉴高斯模糊的方法。不常用。</li><li>可训练池化：使用一个训练函数y=f(x)y=f(x)。不常用。</li></ol><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/卷积4.png" alt=""></p><h3 id="全链接层"><a href="#全链接层" class="headerlink" title="全链接层"></a>全链接层</h3><p>任务：全连接层的每一个结点都与上一层的所有结点相连，用来把前边提取到的特征综合起来。<br>由于其全相连的特性，一般全连接层的参数也是最多的。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/反向传播7.png" alt=""></p><h3 id="dropout层"><a href="#dropout层" class="headerlink" title="dropout层"></a>dropout层</h3><p><code>任务</code>：在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了。主要是为了<strong>防止过拟合</strong>。</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/反向传播6.png" alt=""></p><h3 id="激活层"><a href="#激活层" class="headerlink" title="激活层"></a>激活层</h3><p><code>任务</code>：卷积后的结果压缩到某一个固定的范围做非线性映射，这样可以一直保持一层一层下去的数值范围是可控的。</p><h4 id="激活函数："><a href="#激活函数：" class="headerlink" title="激活函数："></a>激活函数：</h4><ul><li><code>Sigmoid</code></li><li><code>Tanh</code>（双曲正切）</li><li><code>ReLU</code></li><li><code>Leaky ReLU</code></li><li><code>ELU</code></li><li><code>Maxout</code></li></ul><p>卷积神经网络一般采用的激活函数是ReLU(The Rectified Linear Unit/修正线性单元)，它的特点是收敛快，求梯度简单，但较脆弱，图像如下：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/relu.png" alt=""></p><h4 id="激活层的实践经验："><a href="#激活层的实践经验：" class="headerlink" title="激活层的实践经验： 　　"></a>激活层的实践经验： 　　</h4><ul><li>不要用sigmoid！不要用sigmoid！不要用sigmoid！ 　　</li><li>首先试RELU，因为快，但要小心点 　　、</li><li>如果2失效，请用Leaky ReLU或者Maxout 　　</li><li>某些情况下tanh倒是有不错的结果，但是很少</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;卷积层&quot;&gt;&lt;a href=&quot;#卷积层&quot; class=&quot;headerlink&quot; title=&quot;卷积层&quot;&gt;&lt;/a&gt;卷积层&lt;/h3&gt;&lt;h4 id=&quot;任务：对输入的图像进行特征提取&quot;&gt;&lt;a href=&quot;#任务：对输入的图像进行特征提取&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="卷积神经网络" scheme="https://janvia.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>经典卷积神经网络</title>
    <link href="https://janvia.github.io/2019/01/15/%E7%BB%8F%E5%85%B8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://janvia.github.io/2019/01/15/经典神经网络/</id>
    <published>2019-01-15T01:10:59.000Z</published>
    <updated>2019-01-15T01:27:26.008Z</updated>
    
    <content type="html"><![CDATA[<h3 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h3><p>这是最早用于数字识别的CNN </p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/LeNet.png" alt=""></p><p>LeNet5特征能够总结为如下几点：</p><p>1）卷积神经网络使用三个层作为一个系列： 卷积，池化，非线性</p><p>2） 使用卷积提取空间特征</p><p>3）使用映射到空间均值下采样（subsample）</p><p>4）双曲线（tanh）或S型（sigmoid）形式的非线性</p><p>5）多层神经网络（MLP）作为最后的分类器</p><p>6）层与层之间的稀疏连接矩阵避免大的计算成本</p><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>2012 ILSVRC比赛远超第2名的CNN，比 LeNet更深，用多层小卷积层叠加替换单大卷积层。</p><p>AlexNet的结构模型如下：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/AlexNet.png" alt=""></p><h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><p>2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好</p><p>VGG各版本结构如下：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/卷积神经网络/VGG.png" alt=""></p><h3 id="经典卷积网络实现"><a href="#经典卷积网络实现" class="headerlink" title="经典卷积网络实现"></a>经典卷积网络实现</h3><p>详见：<a href="https://jiangvia.cn/2019/01/13/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" target="_blank" rel="noopener">卷积神经网络实现</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;LeNet&quot;&gt;&lt;a href=&quot;#LeNet&quot; class=&quot;headerlink&quot; title=&quot;LeNet&quot;&gt;&lt;/a&gt;LeNet&lt;/h3&gt;&lt;p&gt;这是最早用于数字识别的CNN &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://jiangvia.oss-cn-s
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="VGG" scheme="https://janvia.github.io/tags/VGG/"/>
    
      <category term="LeNet" scheme="https://janvia.github.io/tags/LeNet/"/>
    
      <category term="AlexNet" scheme="https://janvia.github.io/tags/AlexNet/"/>
    
  </entry>
  
  <entry>
    <title>反向传播</title>
    <link href="https://janvia.github.io/2019/01/14/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    <id>https://janvia.github.io/2019/01/14/反向传播/</id>
    <published>2019-01-14T12:54:32.000Z</published>
    <updated>2019-01-15T00:58:55.153Z</updated>
    
    <content type="html"><![CDATA[<h4 id=""><a href="#" class="headerlink" title=" "></a> </h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/反向传播/反向传播１.png" alt=""></p><h4 id="定义损失函数："><a href="#定义损失函数：" class="headerlink" title="定义损失函数："></a>定义损失函数：</h4><script type="math/tex; mode=display">E_{total}=\frac12 (y-outo)^2</script><h4 id="定义激活函数："><a href="#定义激活函数：" class="headerlink" title="定义激活函数："></a>定义激活函数：</h4><script type="math/tex; mode=display">\sigma(x)=sigmod(x)</script><h4 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h4><h5 id="第一层-输入层-："><a href="#第一层-输入层-：" class="headerlink" title="第一层(输入层)："></a>第一层(输入层)：</h5><script type="math/tex; mode=display">x_1\ \ \ x_2\ \ \ b_1</script><h5 id="加权和："><a href="#加权和：" class="headerlink" title="加权和："></a>加权和：</h5><ul><li><script type="math/tex; mode=display">net h_1=x_1w_1+x_2w_2+b_1</script></li></ul><h5 id="第二层-隐层-："><a href="#第二层-隐层-：" class="headerlink" title="第二层(隐层)："></a>第二层(隐层)：</h5><ul><li><script type="math/tex; mode=display">outh_1=sigmod(neth_1)</script></li></ul><h5 id="加权和：-1"><a href="#加权和：-1" class="headerlink" title="加权和："></a>加权和：</h5><ul><li><script type="math/tex; mode=display">neto_1=outh_1w_3+outh_2w_4+b_2</script></li></ul><h5 id="第三层-输出层-："><a href="#第三层-输出层-：" class="headerlink" title="第三层(输出层)："></a>第三层(输出层)：</h5><ul><li><script type="math/tex; mode=display">outo_1=sigmod(neto_1)</script></li></ul><h5 id="计算误差值："><a href="#计算误差值：" class="headerlink" title="计算误差值："></a>计算误差值：</h5><ul><li><script type="math/tex; mode=display">Eo_1 = \frac12 (y_1-outo_1)^2</script></li></ul><ul><li><script type="math/tex; mode=display">Eo_2 = \frac12 (y_2-outo_2)^2</script></li></ul><ul><li><script type="math/tex; mode=display">E_{total}=Eo_1+Eo_2</script></li></ul><p><code>总结</code>：要是使误差值最小，就需要<code>误差反向传播算法</code>，更新得到最小误差的权重参数<code>w和b</code>。</p><h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><p><code>须知</code>：我们需要反向传递回去更新每一层对应的权重参数<code>w和b</code>。</p><p>我们使用<code>链式法则</code>来<code>反向模式求导</code>。</p><h5 id="更新第三层（输出层）的权重参数："><a href="#更新第三层（输出层）的权重参数：" class="headerlink" title="更新第三层（输出层）的权重参数："></a><strong>更新第三层（输出层）的权重参数：</strong></h5><p>更新参数<code>w</code>：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w_3}=\frac{\partial E_{total}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial w_3}</script><script type="math/tex; mode=display">= \frac{\partial \frac12(y_1-outo_1)^2}{\partial outo_1} \cdot \frac{\partial sigmod(neto_1)}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial w_3}</script><script type="math/tex; mode=display">=(outo_1-y_1)\cdot outo_1(1-outo_1)\cdot outh_1</script><script type="math/tex; mode=display">w_{3new}=w_{3old}-\eta \frac{\partial E_{total}}{\partial w_3}，η是学习率</script><p>更新参数<code>b</code>：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial b_2}=\frac{\partial E_{total}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial b_2}</script><script type="math/tex; mode=display">= \frac{\partial \frac12(y_1-outo_1)^2}{\partial outo_1} \cdot \frac{\partial sigmod(neto_1)}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial b_2}</script><script type="math/tex; mode=display">=(outo_1-y_1)\cdot outo_1(1-outo_1)</script><script type="math/tex; mode=display">b_{2new}=b_{2old}-\eta \frac{\partial E_{total}}{\partial b_2}, η是学习率</script><p>同理可得：<code>w4</code>：也就是同一层的<code>w</code>都可以用这种方式更新。</p><h5 id="更新上一层-隐层-的权重参数："><a href="#更新上一层-隐层-的权重参数：" class="headerlink" title="更新上一层(隐层)的权重参数："></a><strong>更新上一层(隐层)的权重参数</strong>：</h5><p>更新权重参数<code>w和b</code>：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w_1}=\frac{\partial E_{total}}{\partial outh_1} \cdot \frac{\partial outh_1}{\partial neth_1} \cdot \frac{\partial neth_1}{\partial w_1}</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial b_1}=\frac{\partial E_{total}}{\partial outh_1} \cdot \frac{\partial outh_1}{\partial neth_1} \cdot \frac{\partial neth_1}{\partial b_1}</script><p>其中：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial outh_1} = \frac{\partial Eo_1}{\partial outh_1}+ \frac{\partial Eo_2}{\partial outh_1}</script><script type="math/tex; mode=display">\frac{\partial Eo_1}{\partial outh_1} = \frac{\partial Eo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial outh_1}</script><script type="math/tex; mode=display">\frac{\partial Eo_1}{\partial neto_1} = \frac{\partial E_{o_1}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1}</script><script type="math/tex; mode=display">= (outo_1-y_1)\cdot outo_1(1-outo_1)</script><script type="math/tex; mode=display">\frac{\partial neto_1}{\partial outh_1} = \frac{\partial (outh_1w_3+outo_2w_4+b_2)}{\partial outh_1} = w_3</script><p>同理可得：</p><script type="math/tex; mode=display">\frac{\partial Eo_2}{\partial outh_1} = \frac{\partial Eo_2}{\partial neto_2} \cdot \frac{\partial neto_2}{\partial outh_1}</script><script type="math/tex; mode=display">\frac{\partial Eo_2}{\partial neto_2} = \frac{\partial E_{o_2}}{\partial outo_2} \cdot \frac{\partial outo_2}{\partial neto_2}</script><script type="math/tex; mode=display">= (outo_2-y_2)\cdot outo_2(1-outo_2)</script><script type="math/tex; mode=display">\frac{\partial neto_2}{\partial outh_1} = w_5（outh1连接outo2的权重，暂定为w5）</script><p>综合上式：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w_1}= [w_3 (outo_1-y_1)\cdot outo_1(1-outo_1)</script><script type="math/tex; mode=display">+ w_5(outo_2-y_2)\cdot outo_2(1-outo_2)] \cdot outh_1(1-outh_1) \cdot x_1</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial b_1}= [w_3 (outo_1-y_1)\cdot outo_1(1-outo_1)</script><script type="math/tex; mode=display">+w_5(outo_2-y_2)\cdot outo_2(1-outo_2)] \cdot outh_1(1-outh_1)</script><p>更新：</p><script type="math/tex; mode=display">w_{1new}=w_{1old}-\eta \frac{\partial E_{total}}{\partial w_1}</script><script type="math/tex; mode=display">b_{1new}=b_{1old}-\eta \frac{\partial E_{total}}{\partial b_1}</script><p>同理可得：<code>w2</code>：也就是同一层的<code>w</code>都可以用这种方式更新。</p><h4 id="推广"><a href="#推广" class="headerlink" title="推广"></a>推广</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/反向传播/反向传播2.png" alt=""></p><p>我们定义第<code>L</code>层的第<code>i</code>个神经元更新权重参数时(上标表示层数，下标表示神经元)：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial net_i^{(L)}} = \delta_i^{(L)}</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)}，其中w_{ij}^{(l)}</script><p>表示第l层的第i个神经元连接第l−1层的第j的神经元的相连的权重参数w。如下图所示：</p><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/反向传播/反向传播3.png" alt=""></p><h4 id="推广总结"><a href="#推广总结" class="headerlink" title="推广总结"></a>推广总结</h4><p>根据前面所定义的：</p><script type="math/tex; mode=display">E_{total}=\frac12 (y-outo)^2</script><script type="math/tex; mode=display">\sigma(x)=sigmod(x)</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)}</script><script type="math/tex; mode=display">\delta_i^{(L)}=\frac{\partial E_{total}}{\partial net_i^{(L)}}</script><script type="math/tex; mode=display">= \frac{\partial E_{total}}{\partial outh_i} \cdot \frac{\partial outh_i}{\partial net_i^{(L)}}</script><script type="math/tex; mode=display">= \bigtriangledown_{out} E_{total} \times   \sigma^{\prime}(net_i^{(L)})</script><p>对于第ll层：</p><script type="math/tex; mode=display">\delta^{(l)}=\frac{\partial E_{total}}{\partial net^{(l)}}</script><script type="math/tex; mode=display">= \frac{\partial E_{total}}{\partial net^{(l+1)}} \cdot \frac{\partial net^{(l+1)}}{\partial net^{(l)}}</script><script type="math/tex; mode=display">= \delta^{(l+1)} \times  \frac{\partial net^{(l+1)}}{\partial net^{(l)}}</script><script type="math/tex; mode=display">= \delta^{(l+1)} \times  \frac{\partial (w^{(l+1)}\sigma (net^{(l)}))}{\partial net^{(l)}}</script><script type="math/tex; mode=display">= \delta^{(l+1)} w^{(l+1)}  \sigma^{\prime}(net^{(L)})</script><p>对于偏置项<code>bias</code>：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial bias_i^{(l)}}=\delta_i^{(l)}</script><h4 id="四项基本原则"><a href="#四项基本原则" class="headerlink" title="四项基本原则"></a>四项基本原则</h4><h5 id="基本形式"><a href="#基本形式" class="headerlink" title="基本形式"></a>基本形式</h5><script type="math/tex; mode=display">\delta_i^{(L)}= \bigtriangledown_{out} E_{total} \times   \sigma^{\prime}(net_i^{(L)})</script><script type="math/tex; mode=display">\delta^{(l)} = \sum_j \delta_j^{(l+1)} w_{ji}^{(l+1)}  \sigma^{\prime}(net_i^{(l)})</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial bias_i^{(l)}}=\delta_i^{(l)}</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)}</script><h5 id="矩阵形式"><a href="#矩阵形式" class="headerlink" title="矩阵形式"></a>矩阵形式</h5><script type="math/tex; mode=display">\delta_i^{(L)}= \bigtriangledown_{out} E_{total} \bigodot   \sigma^{\prime}(net_i^{(L)})</script><p>其中 ⨀是Hadamard乘积（对应位置相乘）</p><script type="math/tex; mode=display">\delta^{(l)} = (w^{(l+1)})^T \delta^{(l+1)} \bigodot  \sigma^{\prime}(net^{(l)})</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial bias^{(l)}}=\delta^{(l)}</script><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w^{(l)}}=\delta^{(l)}(outh^{(l-1)})^T</script><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/反向传播/反向传播4.png" alt=""></p><p>因为：</p><script type="math/tex; mode=display">\delta_i^{(L)}= \bigtriangledown_{out} E_{total} \bigodot   \sigma^{\prime}(net_i^{(L)})</script><p>所以：</p><script type="math/tex; mode=display">\delta^{(1)} = (w^{(2)})^T \delta^{(2)} \bigodot  \sigma^{\prime}(net^{(1)})</script><script type="math/tex; mode=display">=(\begin{bmatrix} 0.6 & 0.8 \\ 0.7 & 0.9\end{bmatrix}^T \cdot \begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix}) \bigodot \begin{bmatrix} 0.20977282 \\ 0.19661193\end{bmatrix}</script><script type="math/tex; mode=display">=\begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix}</script><p>因为：</p><script type="math/tex; mode=display">\frac{\partial E_{total}}{\partial w^{(l)}}=\delta^{(l)}(outh^{(l-1)})^T</script><p>所以：</p><script type="math/tex; mode=display">\Delta w^{(2)} = \delta^{(2)}(outh^{(1)})^T</script><script type="math/tex; mode=display">=\begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix} \cdot \begin{bmatrix} 0.70056714\\ 0.73105858 \end{bmatrix}^T</script><script type="math/tex; mode=display">= \begin{bmatrix} -0.00869356 & -0.00907194 \\ 0.5870176 & 0.612567 \end{bmatrix}</script><script type="math/tex; mode=display">\Delta w^{(1)} = \delta^{(1)}x^T</script><script type="math/tex; mode=display">=\begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix} \cdot \begin{bmatrix} 0.5\\ 1\end{bmatrix}^T</script><script type="math/tex; mode=display">= \begin{bmatrix} 0.00537109& 0.01074218\\ 0.00643758 & 0.01287516 \end{bmatrix}</script><p>权重更新：</p><script type="math/tex; mode=display">w_{new}^2 = w_{old}^2-\Delta w^{(2)}</script><script type="math/tex; mode=display">= {\begin{bmatrix} 0.6 & 0.8 \\ 0.7 & 0.9\end{bmatrix}}-\begin{bmatrix} -0.00869356 & 0.00907194 \\ 0.5870176 & 0.612567 \end{bmatrix}</script><script type="math/tex; mode=display">= \begin{bmatrix} 0.60869356 & 0.80907194 \\ 0.64129824& 0.8387433 \end{bmatrix}</script><script type="math/tex; mode=display">b_{new}^2=b_{old}^2-\Delta b^2</script><script type="math/tex; mode=display">= \begin{bmatrix} 1 \\ 1  \end{bmatrix}-\begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix}</script><script type="math/tex; mode=display">=\begin{bmatrix} 1.01240932\\ 0.91620823\end{bmatrix}</script><script type="math/tex; mode=display">w_{new}^1= w_{old}^1-\Delta w^{(1)}</script><script type="math/tex; mode=display">=\begin{bmatrix} 0.1 & 0.3 \\ 0.2 & 0.4\end{bmatrix} -  \begin{bmatrix} 0.00537109& 0.01074218\\ 0.00643758 & 0.01287516 \end{bmatrix}</script><script type="math/tex; mode=display">= \begin{bmatrix} 0.09462891& 0.28925782\\ 0.19356242& 0.38712484\end{bmatrix}</script><script type="math/tex; mode=display">b_{new}^1=b_{old}^1-\Delta b^1</script><script type="math/tex; mode=display">=\begin{bmatrix} 0.5 \\ 0.5  \end{bmatrix} - \begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix}</script><script type="math/tex; mode=display">=\begin{bmatrix} 0.48925782\\ 0.48712484\end{bmatrix}</script><h4 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h4><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/反向传播/反向传播5.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;&quot;&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title=&quot; &quot;&gt;&lt;/a&gt; &lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;https://jiangvia.oss-cn-shenzhen.aliyuncs.com/反向传播/反向传播１.png&quot; alt=
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="反向传播" scheme="https://janvia.github.io/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
  </entry>
  
  <entry>
    <title>图床</title>
    <link href="https://janvia.github.io/2019/01/14/%E5%9B%BE%E5%BA%8A/"/>
    <id>https://janvia.github.io/2019/01/14/图床/</id>
    <published>2019-01-14T08:11:01.000Z</published>
    <updated>2019-01-14T08:27:17.857Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装picgo"><a href="#安装picgo" class="headerlink" title="安装picgo"></a>安装picgo</h2><p>下载地址: <a href="https://github.com/Molunerfinn/PicGo/releases" target="_blank" rel="noopener">https://github.com/Molunerfinn/PicGo/releases</a></p><ul><li><p>linux下载AppImage文件</p></li><li><p>右键属性，将权限设为允许为启动程序</p></li></ul><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>以阿里云为例：</p><ul><li><p>点击右上角头像，找到accessKeyId和accessKeySecret</p></li><li><p>创建对象存储，类型设为公共，记住存储空间名和地域（比如华南为oss-cn-shenzhen）</p></li><li><p>右键点击picgo，选择主窗口；将以上对应信息配置到图床配置，保存并应用</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装picgo&quot;&gt;&lt;a href=&quot;#安装picgo&quot; class=&quot;headerlink&quot; title=&quot;安装picgo&quot;&gt;&lt;/a&gt;安装picgo&lt;/h2&gt;&lt;p&gt;下载地址: &lt;a href=&quot;https://github.com/Molunerfinn/PicG
      
    
    </summary>
    
      <category term="工具" scheme="https://janvia.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="图床" scheme="https://janvia.github.io/tags/%E5%9B%BE%E5%BA%8A/"/>
    
  </entry>
  
  <entry>
    <title>感知器与激活函数</title>
    <link href="https://janvia.github.io/2019/01/14/%E6%84%9F%E7%9F%A5%E5%99%A8%E4%B8%8E%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>https://janvia.github.io/2019/01/14/感知器与激活函数/</id>
    <published>2019-01-14T00:48:40.000Z</published>
    <updated>2019-01-15T00:20:20.231Z</updated>
    
    <content type="html"><![CDATA[<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>感知器是激活函数为阶跃函数的神经元。感知器的模型如下：<br><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/神经元.png" alt=""><br>·　输入(inputs)：一个感知器可以接收多个输入(x1,x2,…,xn|xi∈R)<br>·　权值(weights)：每一个输入上都有一个权值wi∈R，此外还有一个偏置项b∈R，也就是上图的w0。<br>·　加权和(weighted sum)：就是<strong>输入权值 x</strong> x <strong>权值 w</strong> + <strong>偏置项 b</strong>的总和。<br>·　激活函数(step function)：感知器的激活函数：</p><script type="math/tex; mode=display">f(x) =\begin{cases}0,  & \text{x>0} \\1, & \text{x≤0}\end{cases}</script><p>·　输出(output)：感知器的输出由加权值用激活函数做非线性变换。也就是这个公式：y=f(w⋅x+b)<br>我们使用unit激活函数结合上图就有：</p><p>y=f(w⋅x+b)=f(w1x1+w2x2+w3x3+bias)</p><p>其中f(x)就是激活函数 f(x)={1x&gt;0 0x≤0 ，图像如下图所示:<br><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/unit.png" alt=""></p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><script type="math/tex; mode=display">x_1=[-1.0, 3.0, 2.0] \\ x_2=[2.0, -1.0, 5.0] \\ x_3=[-2.0, 0.0, 3.0 ] \\ x_4=[4.0, 1.0, 6.0] \\ w=[4.0, -3.0, 5.0 ] \\ b=2.0</script><p>则：</p><script type="math/tex; mode=display">X=\begin{bmatrix}  -1.0 & 3.0 & 2.0 \\ 2.0 & -1.0& 5.0 \\ -2.0& 0.0& 3.0 \\ 4.0& 1.0 & 6.0  \end{bmatrix}</script><script type="math/tex; mode=display">w^T =\begin{bmatrix} 4.0 \\ -3.0 \\ 5.0 \end{bmatrix}</script><p>所以：</p><script type="math/tex; mode=display">logits =  X\cdot w^T + b</script><script type="math/tex; mode=display">= \begin{bmatrix}  -1.0 & 3.0 & 2.0 \\ 2.0 & -1.0& 5.0 \\ -2.0& 0.0& 3.0 \\ 4.0& 1.0 & 6.0  \end{bmatrix} \cdot \begin{bmatrix} 4.0 \\ -3.0 \\ 5.0 \end{bmatrix} + 2.0 \\ =[-1.0 \ \ \  38.0 \ \ \ 7.0 \ \ \ 43.0 ]</script><p>带入激活函数：</p><script type="math/tex; mode=display">output = f(x)=[0\ \ \ 1 \ \ \ 1 \ \ \ 1 ]</script><h3 id="隐层"><a href="#隐层" class="headerlink" title="隐层"></a>隐层</h3><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/yincen.png" alt=""></p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>unit激活函数：</p><script type="math/tex; mode=display">f(x) =\begin{cases}0,  & \text{x>0} \\1, & \text{x≤0}\end{cases}</script><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/unit.png" alt=""></p><p>sigmod激活函数：</p><script type="math/tex; mode=display">f(x)=sigmod(x)=\frac{1}{1+e^{-x}}</script><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/sigmod.png" alt=""></p><p>tanh激活函数：</p><script type="math/tex; mode=display">f(x)=tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}</script><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/tanh.png" alt=""></p><p>relu激活函数：</p><script type="math/tex; mode=display">f(x) =\begin{cases}x,  & \text{x>0} \\0, & \text{x≤0}\end{cases}</script><p><img src="https://jiangvia.oss-cn-shenzhen.aliyuncs.com/感知器/relu.png" alt=""></p><h4 id="激活函数的作用"><a href="#激活函数的作用" class="headerlink" title="激活函数的作用"></a>激活函数的作用</h4><ul><li><p><strong>引入非线性因素。</strong></p><p>在我们面对线性可分的数据集的时候，简单的用线性分类器即可解决分类问题。但是现实生活中的数据往往不是线性可分的，面对这样的数据，一般有两个方法：引入非线性函数、线性变换。</p></li><li><h4 id="线性变换"><a href="#线性变换" class="headerlink" title="线性变换"></a>线性变换</h4><p>就是把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类</p></li></ul><h4 id="激活函数的特点"><a href="#激活函数的特点" class="headerlink" title="激活函数的特点"></a>激活函数的特点</h4><ul><li><p><code>unit</code>：线性分界</p><p>– 几乎已经不用了</p></li><li><p><code>sigmoid</code>：非线性分界</p><p>– 两端软饱和，输出为 (0,1)区间</p><p>– 两端有梯度消失问题</p><p>– 因为输出恒正，可能有 zig现象</p></li><li><p><code>tanh</code>：非线性分界 ：非线性分界</p><p>– 两端软饱和，输出为 (-1, 1) 区间</p><p>– 仍然存在梯度消失问题</p><p>– 没有 zig，收敛更快 (LeCun 1989)</p></li><li><p><code>ReLU</code>：非线性分界 – 左侧硬饱和，右无输出为 [0,+∞)区间</p><p>– 左侧会出现梯度一直为 0的情况，导致神经元 不再更新（死亡）</p><p>– 改善了梯度弥散</p><p>– 同样存在 zig</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;定义&quot;&gt;&lt;a href=&quot;#定义&quot; class=&quot;headerlink&quot; title=&quot;定义&quot;&gt;&lt;/a&gt;定义&lt;/h3&gt;&lt;p&gt;感知器是激活函数为阶跃函数的神经元。感知器的模型如下：&lt;br&gt;&lt;img src=&quot;https://jiangvia.oss-cn-shenz
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="感知器" scheme="https://janvia.github.io/tags/%E6%84%9F%E7%9F%A5%E5%99%A8/"/>
    
      <category term="激活函数" scheme="https://janvia.github.io/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络实现</title>
    <link href="https://janvia.github.io/2019/01/13/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0/"/>
    <id>https://janvia.github.io/2019/01/13/卷积神经网络实现/</id>
    <published>2019-01-13T13:20:44.000Z</published>
    <updated>2019-01-15T01:40:28.251Z</updated>
    
    <content type="html"><![CDATA[<h2 id="net"><a href="#net" class="headerlink" title="net"></a>net</h2><p>新建netWork.py,添加以下代码</p><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import config</span><br><span class="line"></span><br><span class="line"># 卷积操作</span><br><span class="line">def conv2d(name, l_input, w, b):</span><br><span class="line">    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(l_input, w, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;), b), name=name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 最大下采样操作</span><br><span class="line">def max_pool(name, l_input, k):</span><br><span class="line">    return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=&apos;SAME&apos;, name=name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 归一化操作</span><br><span class="line">def norm(name, l_input, lsize=4):</span><br><span class="line">    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name)</span><br></pre></td></tr></table></figure><h3 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def LeNet(inputs):</span><br><span class="line"></span><br><span class="line">    mu = 0</span><br><span class="line">    sigma = 0.1</span><br><span class="line">    print(inputs.shape)</span><br><span class="line">    # TODO: 第一层卷积：输入=32x32x3, 输出=28x28x6</span><br><span class="line">    conv1_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 6], mean=mu, stddev=sigma))</span><br><span class="line">    conv1_b = tf.Variable(tf.zeros(6))</span><br><span class="line"></span><br><span class="line">    conv1 = tf.nn.conv2d(inputs, conv1_w, strides=[1, 1, 1, 1], padding=&apos;VALID&apos;) + conv1_b</span><br><span class="line">    print(conv1.shape)</span><br><span class="line">    # 激活函数</span><br><span class="line">    conv1_out = tf.nn.relu(conv1)</span><br><span class="line"></span><br><span class="line">    # 池化层， 输入=28x28x6, 输出=14x14x6</span><br><span class="line">    pool_1 = tf.nn.max_pool(conv1_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;VALID&apos;)</span><br><span class="line">    print(pool_1.shape)</span><br><span class="line"></span><br><span class="line">    # TODO: 第二层卷积： 输入=14x14x6， 输出=10x10x16</span><br><span class="line">    conv2_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 6, 16], mean=mu, stddev=sigma))</span><br><span class="line">    conv2_b = tf.Variable(tf.zeros(16))</span><br><span class="line"></span><br><span class="line">    conv2 = tf.nn.conv2d(pool_1, conv2_w, strides=[1, 1, 1, 1], padding=&apos;VALID&apos;) + conv2_b</span><br><span class="line">    print(conv2.shape)</span><br><span class="line">    # 激活函数</span><br><span class="line">    conv2_out = tf.nn.relu(conv2)</span><br><span class="line"></span><br><span class="line">    # 池化层， 输入=10x10x16, 输出=5x5x16</span><br><span class="line">    pool_2 = tf.nn.max_pool(conv2_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;VALID&apos;)</span><br><span class="line">    print(pool_2.shape)</span><br><span class="line">    # Flatten 输入=5x5x16， 输出=400</span><br><span class="line">    pool_2_flat = tf.reshape(pool_2, [-1, 400])</span><br><span class="line"></span><br><span class="line">    # TODO: 第三层全连接层， 输入=400， 输出=120</span><br><span class="line">    fc1_w = tf.Variable(tf.truncated_normal(shape=[400, 120], mean=mu, stddev=sigma))</span><br><span class="line">    fc1_b = tf.Variable(tf.zeros(120))</span><br><span class="line"></span><br><span class="line">    fc1 = tf.matmul(pool_2_flat, fc1_w) + fc1_b</span><br><span class="line"></span><br><span class="line">    # 激活函数</span><br><span class="line">    fc1_out = tf.nn.relu(fc1)</span><br><span class="line">    print(fc1_out.shape)</span><br><span class="line"></span><br><span class="line">    # TODO: 第四层全连接层： 输入=120， 输出=84</span><br><span class="line">    fc2_w = tf.Variable(tf.truncated_normal(shape=[120, 84], mean=mu, stddev=sigma))</span><br><span class="line">    fc2_b = tf.Variable(tf.zeros(84))</span><br><span class="line"></span><br><span class="line">    fc2 = tf.matmul(fc1_out, fc2_w) + fc2_b</span><br><span class="line"></span><br><span class="line">    # 激活函数</span><br><span class="line">    fc2_out = tf.nn.relu(fc2)</span><br><span class="line">    print(fc2_out.shape)</span><br><span class="line"></span><br><span class="line">    # TODO: 第五层全连接层： 输入=84， 输出=10</span><br><span class="line">    fc3_w = tf.Variable(tf.truncated_normal(shape=[84, 10], mean=mu, stddev=sigma))</span><br><span class="line">    fc3_b = tf.Variable(tf.zeros(10))</span><br><span class="line"></span><br><span class="line">    fc3_out = tf.matmul(fc2_out, fc3_w) + fc3_b</span><br><span class="line">    print(fc3_out.shape)</span><br><span class="line"></span><br><span class="line">    return fc3_out</span><br></pre></td></tr></table></figure><h3 id="alex-net"><a href="#alex-net" class="headerlink" title="alex_net"></a>alex_net</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def alex_net(_X, _weights, _biases, _dropout):</span><br><span class="line">    # 向量转为矩阵</span><br><span class="line">    # _X = tf.reshape(_X, shape=[-1, 28, 28, 3])</span><br><span class="line">    print(_X.shape)</span><br><span class="line">    # TODO: 第一层卷积：</span><br><span class="line">    conv1 = conv2d(&apos;conv1&apos;, _X, _weights[&apos;wc1&apos;], _biases[&apos;bc1&apos;])</span><br><span class="line">    # 下采样层</span><br><span class="line">    pool1 = max_pool(&apos;pool1&apos;, conv1, k=2)</span><br><span class="line">    # 归一化层</span><br><span class="line">    norm1 = norm(&apos;norm1&apos;, pool1, lsize=4)</span><br><span class="line">    print(norm1.shape)</span><br><span class="line">    # TODO: 第二层卷积：</span><br><span class="line">    conv2 = conv2d(&apos;conv2&apos;, norm1, _weights[&apos;wc2&apos;], _biases[&apos;bc2&apos;])</span><br><span class="line">    # 下采样</span><br><span class="line">    pool2 = max_pool(&apos;pool2&apos;, conv2, k=2)</span><br><span class="line">    # 归一化</span><br><span class="line">    norm2 = norm(&apos;norm2&apos;, pool2, lsize=4)</span><br><span class="line">    print(norm2.shape)</span><br><span class="line">    # TODO: 第三层卷积：</span><br><span class="line">    conv3 = conv2d(&apos;conv3&apos;, norm2, _weights[&apos;wc3&apos;], _biases[&apos;bc3&apos;])</span><br><span class="line">    # 归一化</span><br><span class="line">    norm3 = norm(&apos;norm3&apos;, conv3, lsize=4)</span><br><span class="line">    print(norm3.shape)</span><br><span class="line">    # TODO: 第四层卷积</span><br><span class="line">    # 卷积</span><br><span class="line">    conv4 = conv2d(&apos;conv4&apos;, norm3, _weights[&apos;wc4&apos;], _biases[&apos;bc4&apos;])</span><br><span class="line">    # 归一化</span><br><span class="line">    norm4 = norm(&apos;norm4&apos;, conv4, lsize=4)</span><br><span class="line">    print(norm4.shape)</span><br><span class="line">    # TODO: 第五层卷积</span><br><span class="line">    # 卷积</span><br><span class="line">    conv5 = conv2d(&apos;conv5&apos;, norm4, _weights[&apos;wc5&apos;], _biases[&apos;bc5&apos;])</span><br><span class="line">    # 下采样</span><br><span class="line">    pool5 = max_pool(&apos;pool5&apos;, conv5, k=2)</span><br><span class="line">    # 归一化</span><br><span class="line">    norm5 = norm(&apos;norm5&apos;, pool5, lsize=4)</span><br><span class="line">    print(norm5.shape)</span><br><span class="line">    # TODO: 第六层全连接层</span><br><span class="line">    # 先把特征图转为向量</span><br><span class="line">    dense1 = tf.reshape(norm5, [-1, _weights[&apos;wd1&apos;].get_shape().as_list()[0]])</span><br><span class="line">    dense1 = tf.nn.relu(tf.matmul(dense1, _weights[&apos;wd1&apos;]) + _biases[&apos;bd1&apos;], name=&apos;fc1&apos;)</span><br><span class="line">    dense1 = tf.nn.dropout(dense1, _dropout)</span><br><span class="line">    print(dense1.shape)</span><br><span class="line">    # TODO: 第七层全连接层：</span><br><span class="line">    dense2 = tf.nn.relu(tf.matmul(dense1, _weights[&apos;wd2&apos;]) + _biases[&apos;bd2&apos;], name=&apos;fc2&apos;)  # Relu activation</span><br><span class="line">    dense2 = tf.nn.dropout(dense2, _dropout)</span><br><span class="line">    print(dense2.shape)</span><br><span class="line">    # TODO: 第八层全连接层：</span><br><span class="line">    # 网络输出层</span><br><span class="line">    out = tf.matmul(dense2, _weights[&apos;out&apos;]) + _biases[&apos;out&apos;]</span><br><span class="line">    print(out.shape)</span><br><span class="line">    return out</span><br></pre></td></tr></table></figure><h3 id="cnn-1"><a href="#cnn-1" class="headerlink" title="cnn_1"></a>cnn_1</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def CNN_1(inputs):</span><br><span class="line">    # (32x32x3)--&gt;(32x32x64)</span><br><span class="line">    with tf.name_scope(&apos;conv1&apos;):</span><br><span class="line">        h_conv1 = tf.layers.conv2d(inputs, 64, [2, 2], padding=&apos;SAME&apos;, activation=tf.nn.relu,</span><br><span class="line">                                   kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(h_conv1.shape)</span><br><span class="line">    # 构建池化层--采用最大池化</span><br><span class="line">    # (32X32X64)--&gt;(16X16X64)</span><br><span class="line">    with tf.name_scope(&apos;pool1&apos;):</span><br><span class="line">        h_pool1 = tf.layers.max_pooling2d(h_conv1, pool_size=[2, 2], strides=[2, 2], padding=&apos;SAME&apos;)</span><br><span class="line">    print(h_pool1.shape)</span><br><span class="line">    # 构建第二层卷积计算层--(16x16x64)--&gt;(16x16x128).</span><br><span class="line">    with tf.name_scope(&apos;conv2&apos;):</span><br><span class="line">        h_conv2 = tf.layers.conv2d(h_pool1, 128, [4, 4], padding=&apos;SAME&apos;, activation=tf.nn.relu,</span><br><span class="line">                                   kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(h_conv2.shape)</span><br><span class="line">    # 构建第二个池化层(16x16x128)--&gt;(8x8x128)</span><br><span class="line">    with tf.name_scope(&apos;pool2&apos;):</span><br><span class="line">        h_pool2 = tf.layers.max_pooling2d(h_conv2, pool_size=[2, 2], strides=[2, 2], padding=&apos;SAME&apos;)</span><br><span class="line">    print(h_pool2.shape)</span><br><span class="line"></span><br><span class="line">    # 构建全连接层--(8x8x128)--&gt;(1024)</span><br><span class="line">    with tf.name_scope(&apos;fc1&apos;):</span><br><span class="line">        h_pool2_flat = tf.layers.flatten(h_pool2)</span><br><span class="line">        h_fc1 = tf.layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu)</span><br><span class="line">    print(h_fc1.shape)</span><br><span class="line">    # Dropout--防止过拟合</span><br><span class="line">    with tf.name_scope(&apos;dropout&apos;):</span><br><span class="line">        # keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">        h_fc_drop = tf.nn.dropout(h_fc1, keep_prob=config.keep_prob)</span><br><span class="line"></span><br><span class="line">    # 构建全连接层--1024--&gt;512</span><br><span class="line">    with tf.name_scope(&apos;fc2&apos;):</span><br><span class="line">        fc2 = tf.layers.dense(h_fc_drop, 512, activation=tf.nn.relu)</span><br><span class="line">    print(fc2.shape)</span><br><span class="line">    # 构建全连接层--512--&gt;10</span><br><span class="line">    with tf.name_scope(&apos;fc3&apos;):</span><br><span class="line">        out = tf.layers.dense(fc2, 10, activation=None)</span><br><span class="line">    print(out.shape)</span><br><span class="line">    return out</span><br></pre></td></tr></table></figure><h2 id="VGG16"><a href="#VGG16" class="headerlink" title="VGG16"></a>VGG16</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">def VGG16(inputs):</span><br><span class="line">    print(inputs.shape)</span><br><span class="line">    # (32x32x3) --&gt; (32x32x64)</span><br><span class="line">    with tf.name_scope(&apos;conv_1&apos;):</span><br><span class="line">         conv_1_out = tf.layers.conv2d(inputs, 64, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_1_out.shape)</span><br><span class="line">    # (32x32x64) --&gt; (32x32x64)</span><br><span class="line">    with tf.name_scope(&apos;conv_2&apos;):</span><br><span class="line">        conv_2_out = tf.layers.conv2d(conv_1_out, 64, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_2_out.shape)</span><br><span class="line">    # (32x32x64) --&gt; (16x16x64)</span><br><span class="line">    with tf.name_scope(&apos;pool_1&apos;):</span><br><span class="line">        pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_1_out.shape)</span><br><span class="line">    # (16x16x64) --&gt; (16x16x128)</span><br><span class="line">    with tf.name_scope(&apos;conv_3&apos;):</span><br><span class="line">         conv_3_out = tf.layers.conv2d(pool_1_out, 128, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_3_out.shape)</span><br><span class="line">    # (16x16x128) --&gt; (16x16x128)</span><br><span class="line">    with tf.name_scope(&apos;conv_4&apos;):</span><br><span class="line">         conv_4_out = tf.layers.conv2d(conv_3_out, 128, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_4_out.shape)</span><br><span class="line">    # (16x16x128) --&gt; (8x8x128)</span><br><span class="line">    with tf.name_scope(&apos;pool_2&apos;):</span><br><span class="line">        pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_2_out.shape)</span><br><span class="line">    # (8x8x128) --&gt; (8x8x256)</span><br><span class="line">    with tf.name_scope(&apos;conv_5&apos;):</span><br><span class="line">         conv_5_out = tf.layers.conv2d(pool_2_out, 256, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_5_out.shape)</span><br><span class="line">    # (8x8x256) --&gt; (8x8x256)</span><br><span class="line">    with tf.name_scope(&apos;conv_6&apos;):</span><br><span class="line">         conv_6_out = tf.layers.conv2d(conv_5_out, 256, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_6_out.shape)</span><br><span class="line">    # (8x8x256) --&gt; (8x8x256)</span><br><span class="line">    with tf.name_scope(&apos;conv_7&apos;):</span><br><span class="line">        conv_7_out = tf.layers.conv2d(conv_6_out, 256, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_7_out.shape)</span><br><span class="line">    # (8x8x256) --&gt; (4x4x256)</span><br><span class="line">    with tf.name_scope(&apos;pool_3&apos;):</span><br><span class="line">        pool_3_out = tf.layers.max_pooling2d(conv_7_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_3_out.shape)</span><br><span class="line">    # (4x4x256) --&gt; (4x4x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_8&apos;):</span><br><span class="line">        conv_8_out = tf.layers.conv2d(pool_3_out, 512, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_8_out.shape)</span><br><span class="line">    # (4x4x512) --&gt; (4x4x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_9&apos;):</span><br><span class="line">        conv_9_out = tf.layers.conv2d(conv_8_out, 512, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_9_out.shape)</span><br><span class="line">    # (4x4x512) --&gt; (4x4x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_10&apos;):</span><br><span class="line">        conv_10_out = tf.layers.conv2d(conv_9_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_10_out.shape)</span><br><span class="line">    # (4x4x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;pool_4&apos;):</span><br><span class="line">        pool_4_out = tf.layers.max_pooling2d(conv_10_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_4_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_11&apos;):</span><br><span class="line">        conv_11_out = tf.layers.conv2d(pool_4_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_11_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_12&apos;):</span><br><span class="line">        conv_12_out = tf.layers.conv2d(conv_11_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_12_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_13&apos;):</span><br><span class="line">        conv_13_out = tf.layers.conv2d(conv_12_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_13_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (1x1x512)</span><br><span class="line">    with tf.name_scope(&apos;pool_5&apos;):</span><br><span class="line">        pool_5_out = tf.layers.max_pooling2d(conv_13_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_5_out.shape)</span><br><span class="line">    # (1x1x512) --&gt; 512</span><br><span class="line">    with tf.name_scope(&apos;fc_1&apos;):</span><br><span class="line">        pool_5_outz_flat = tf.layers.flatten(pool_5_out)</span><br><span class="line">        fc_1_out = tf.layers.dense(pool_5_outz_flat, 512, activation=tf.nn.relu)</span><br><span class="line">        fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob)</span><br><span class="line">    print(fc_1_drop.shape)</span><br><span class="line">    # 512 --&gt; 512</span><br><span class="line">    with tf.name_scope(&apos;fc_2&apos;):</span><br><span class="line">        fc_2_out = tf.layers.dense(fc_1_drop, 512, activation=tf.nn.relu)</span><br><span class="line">        fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob)</span><br><span class="line">    print(fc_2_drop.shape)</span><br><span class="line">    # 512 --&gt; 10</span><br><span class="line">    with tf.name_scope(&apos;fc_3&apos;):</span><br><span class="line">        fc_3_out = tf.layers.dense(fc_2_drop, 10, activation=None)</span><br><span class="line">    print(fc_3_out.shape)</span><br><span class="line"></span><br><span class="line">    return fc_3_out</span><br></pre></td></tr></table></figure><h3 id="vgg19"><a href="#vgg19" class="headerlink" title="vgg19"></a>vgg19</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def VGG19(inputs):</span><br><span class="line">    print(inputs.shape)</span><br><span class="line">    # (32x32x3) --&gt; (32x32x64)</span><br><span class="line">    with tf.name_scope(&apos;conv_1&apos;):</span><br><span class="line">         conv_1_out = tf.layers.conv2d(inputs, 64, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_1_out.shape)</span><br><span class="line">    # (32x32x64) --&gt; (32x32x64)</span><br><span class="line">    with tf.name_scope(&apos;conv_2&apos;):</span><br><span class="line">        conv_2_out = tf.layers.conv2d(conv_1_out, 64, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_2_out.shape)</span><br><span class="line">    # (32x32x64) --&gt; (16x16x64)</span><br><span class="line">    with tf.name_scope(&apos;pool_1&apos;):</span><br><span class="line">        pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_1_out.shape)</span><br><span class="line">    # (16x16x64) --&gt; (16x16x128)</span><br><span class="line">    with tf.name_scope(&apos;conv_3&apos;):</span><br><span class="line">         conv_3_out = tf.layers.conv2d(pool_1_out, 128, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_3_out.shape)</span><br><span class="line">    # (16x16x128) --&gt; (16x16x128)</span><br><span class="line">    with tf.name_scope(&apos;conv_4&apos;):</span><br><span class="line">         conv_4_out = tf.layers.conv2d(conv_3_out, 128, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_4_out.shape)</span><br><span class="line">    # (16x16x128) --&gt; (8x8x128)</span><br><span class="line">    with tf.name_scope(&apos;pool_2&apos;):</span><br><span class="line">        pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_2_out.shape)</span><br><span class="line">    # (8x8x128) --&gt; (8x8x256)</span><br><span class="line">    with tf.name_scope(&apos;conv_5&apos;):</span><br><span class="line">         conv_5_out = tf.layers.conv2d(pool_2_out, 256, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_5_out.shape)</span><br><span class="line">    # (8x8x256) --&gt; (8x8x256)</span><br><span class="line">    with tf.name_scope(&apos;conv_6&apos;):</span><br><span class="line">         conv_6_out = tf.layers.conv2d(conv_5_out, 256, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_6_out.shape)</span><br><span class="line">    # (8x8x256) --&gt; (8x8x256)</span><br><span class="line">    with tf.name_scope(&apos;conv_7&apos;):</span><br><span class="line">        conv_7_out = tf.layers.conv2d(conv_6_out, 256, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_7_out.shape)</span><br><span class="line">    # (8x8x256) --&gt; (8x8x256)</span><br><span class="line">    with tf.name_scope(&apos;conv_8&apos;):</span><br><span class="line">        conv_8_out = tf.layers.conv2d(conv_7_out, 256, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_8_out.shape)</span><br><span class="line">    # (8x8x256) --&gt; (4x4x256)</span><br><span class="line">    with tf.name_scope(&apos;pool_3&apos;):</span><br><span class="line">        pool_3_out = tf.layers.max_pooling2d(conv_8_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_3_out.shape)</span><br><span class="line">    # (4x4x256) --&gt; (4x4x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_9&apos;):</span><br><span class="line">        conv_9_out = tf.layers.conv2d(pool_3_out, 512, [3, 3],</span><br><span class="line">                                      padding=&apos;same&apos;,</span><br><span class="line">                                      activation=tf.nn.relu,</span><br><span class="line">                                      kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_9_out.shape)</span><br><span class="line">    # (4x4x512) --&gt; (4x4x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_10&apos;):</span><br><span class="line">        conv_10_out = tf.layers.conv2d(conv_9_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_10_out.shape)</span><br><span class="line">    # (4x4x512) --&gt; (4x4x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_11&apos;):</span><br><span class="line">        conv_11_out = tf.layers.conv2d(conv_10_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_11_out.shape)</span><br><span class="line">    # (4x4x512) --&gt; (4x4x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_12&apos;):</span><br><span class="line">        conv_12_out = tf.layers.conv2d(conv_11_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_12_out.shape)</span><br><span class="line">    # (4x4x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;pool_4&apos;):</span><br><span class="line">        pool_4_out = tf.layers.max_pooling2d(conv_12_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_4_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_13&apos;):</span><br><span class="line">        conv_13_out = tf.layers.conv2d(pool_4_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_13_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_14&apos;):</span><br><span class="line">        conv_14_out = tf.layers.conv2d(conv_13_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_14_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_15&apos;):</span><br><span class="line">        conv_15_out = tf.layers.conv2d(conv_14_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_15_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (2x2x512)</span><br><span class="line">    with tf.name_scope(&apos;conv_16&apos;):</span><br><span class="line">        conv_16_out = tf.layers.conv2d(conv_15_out, 512, [3, 3],</span><br><span class="line">                                       padding=&apos;same&apos;,</span><br><span class="line">                                       activation=tf.nn.relu,</span><br><span class="line">                                       kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1))</span><br><span class="line">    print(conv_16_out.shape)</span><br><span class="line">    # (2x2x512) --&gt; (1x1x512)</span><br><span class="line">    with tf.name_scope(&apos;pool_5&apos;):</span><br><span class="line">        pool_5_out = tf.layers.max_pooling2d(conv_16_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;)</span><br><span class="line"></span><br><span class="line">    print(pool_5_out.shape)</span><br><span class="line">    # (1x1x512) --&gt; 512</span><br><span class="line">    with tf.name_scope(&apos;fc_1&apos;):</span><br><span class="line">        pool_5_outz_flat = tf.layers.flatten(pool_5_out)</span><br><span class="line">        fc_1_out = tf.layers.dense(pool_5_outz_flat, 512, activation=tf.nn.relu)</span><br><span class="line">        fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob)</span><br><span class="line">    print(fc_1_drop.shape)</span><br><span class="line">    # 512 --&gt; 512</span><br><span class="line">    with tf.name_scope(&apos;fc_2&apos;):</span><br><span class="line">        fc_2_out = tf.layers.dense(fc_1_drop, 512, activation=tf.nn.relu)</span><br><span class="line">        fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob)</span><br><span class="line">    print(fc_2_drop.shape)</span><br><span class="line">    # 512 --&gt; 10</span><br><span class="line">    with tf.name_scope(&apos;fc_3&apos;):</span><br><span class="line">        fc_3_out = tf.layers.dense(fc_2_drop, 10, activation=None)</span><br><span class="line">    print(fc_3_out.shape)</span><br><span class="line"></span><br><span class="line">    return fc_3_out</span><br></pre></td></tr></table></figure><h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pickle</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler, LabelBinarizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_cifar10_batch(path, batch_id):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    加载batch的数据</span><br><span class="line">    :param path: 数据存储的目录</span><br><span class="line">    :param batch_id:batch的编号</span><br><span class="line">    :return:features and labels</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    with open(path + &apos;/data_batch_&apos; + str(batch_id), mode=&apos;rb&apos;) as file:</span><br><span class="line">        batch = pickle.load(file, encoding=&apos;latin1&apos;)</span><br><span class="line"></span><br><span class="line">    # features and labels</span><br><span class="line">    features = batch[&apos;data&apos;].reshape((len(batch[&apos;data&apos;]), 3, 32, 32)).transpose(0, 2, 3, 1)</span><br><span class="line">    labels = batch[&apos;labels&apos;]</span><br><span class="line"></span><br><span class="line">    return features, labels</span><br></pre></td></tr></table></figure><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def pre_processing_data(x_train, y_train, x_test, y_test):</span><br><span class="line">    # features</span><br><span class="line">    minmax = MinMaxScaler()</span><br><span class="line">    # 重塑数据</span><br><span class="line">    # (50000, 32, 32, 3) --&gt; (50000, 32*32*3)</span><br><span class="line">    x_train_rows = x_train.reshape(x_train.shape[0], 32*32*3)</span><br><span class="line">    # (10000, 32, 32, 3) --&gt; (10000, 32*32*3)</span><br><span class="line">    x_test_rows = x_test.reshape(x_test.shape[0], 32*32*3)</span><br><span class="line">    # 归一化</span><br><span class="line">    x_train_norm = minmax.fit_transform(x_train_rows)</span><br><span class="line">    x_test_norm = minmax.fit_transform(x_test_rows)</span><br><span class="line">    # 重塑数据</span><br><span class="line">    x_train = x_train_norm.reshape(x_train_norm.shape[0], 32, 32, 3)</span><br><span class="line">    x_test = x_test_norm.reshape(x_test_norm.shape[0], 32, 32, 3)</span><br><span class="line"></span><br><span class="line">    # labels</span><br><span class="line">    # 对标签进行one-hot</span><br><span class="line">    n_class = 10</span><br><span class="line">    label_binarizer = LabelBinarizer().fit(np.array(range(n_class)))</span><br><span class="line">    y_train = label_binarizer.transform(y_train)</span><br><span class="line">    y_test = label_binarizer.transform(y_test)</span><br><span class="line"></span><br><span class="line">    return x_train, y_train, x_test, y_test</span><br></pre></td></tr></table></figure><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>新建Read_date.py<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def cifar10_data():</span><br><span class="line">    # 加载训练数据</span><br><span class="line">    cifar10_path = &apos;data&apos;</span><br><span class="line">    # 一共是有5个batch的训练数据</span><br><span class="line">    x_train, y_train = load_cifar10_batch(cifar10_path, 1)</span><br><span class="line">    for n in range(2, 6):</span><br><span class="line">        features, labels = load_cifar10_batch(cifar10_path, n)</span><br><span class="line">        x_train = np.concatenate([x_train, features])</span><br><span class="line">        y_train = np.concatenate([y_train, labels])</span><br><span class="line"></span><br><span class="line">    # 加载测试数据</span><br><span class="line">    with open(cifar10_path + &apos;/test_batch&apos;, mode=&apos;rb&apos;) as file:</span><br><span class="line">        batch = pickle.load(file, encoding=&apos;latin1&apos;)</span><br><span class="line">        x_test = batch[&apos;data&apos;].reshape((len(batch[&apos;data&apos;]), 3, 32, 32)).transpose(0, 2, 3, 1)</span><br><span class="line">        y_test = batch[&apos;labels&apos;]</span><br><span class="line"></span><br><span class="line">    x_train, y_train, x_test, y_test = pre_processing_data(x_train, y_train, x_test, y_test)</span><br><span class="line"></span><br><span class="line">    return x_train, y_train, x_test, y_test</span><br></pre></td></tr></table></figure></p><h2 id="config"><a href="#config" class="headerlink" title="config"></a>config</h2><p>新建config.py；复制以下代码</p><h3 id="初始化卷积神经网络参数"><a href="#初始化卷积神经网络参数" class="headerlink" title="初始化卷积神经网络参数"></a>初始化卷积神经网络参数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">keep_prob = 0.8</span><br><span class="line">epochs = 20</span><br><span class="line">batch_size = 128</span><br><span class="line">n_classes = 10  # 总共10类</span><br></pre></td></tr></table></figure><h3 id="定义placeholder"><a href="#定义placeholder" class="headerlink" title="定义placeholder"></a>定义placeholder</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">inputs = tf.placeholder(tf.float32, [None, 32, 32, 3], name=&apos;inputs&apos;)</span><br><span class="line">targets = tf.placeholder(tf.float32, [None, 10], name=&apos;logits&apos;)</span><br><span class="line"></span><br><span class="line">learning_rate = 0.001</span><br></pre></td></tr></table></figure><h3 id="显示图片"><a href="#显示图片" class="headerlink" title="显示图片"></a>显示图片</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">def show_images(images):</span><br><span class="line">    fig, axes = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(9, 9))</span><br><span class="line">    img = images[: 60]</span><br><span class="line">    for image, row in zip([img[: 20], img[20: 40], img[40: 60]], axes):</span><br><span class="line">        for img, ax in zip(image, row):</span><br><span class="line">            ax.imshow(img)</span><br><span class="line">            ax.get_xaxis().set_visible(False)</span><br><span class="line">            ax.get_yaxis().set_visible(False)</span><br><span class="line"></span><br><span class="line">    fig.tight_layout(pad=0.1)</span><br><span class="line">    # plt.show()</span><br></pre></td></tr></table></figure><h3 id="存储网络参数-alexnet"><a href="#存储网络参数-alexnet" class="headerlink" title="存储网络参数(alexnet)"></a>存储网络参数(alexnet)</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">weights = &#123;</span><br><span class="line">    &apos;wc1&apos;: tf.Variable(tf.random_normal(shape=[11, 11, 3, 96])),</span><br><span class="line">    &apos;wc2&apos;: tf.Variable(tf.random_normal(shape=[5, 5, 96, 256])),</span><br><span class="line">    &apos;wc3&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 256, 384])),</span><br><span class="line">    &apos;wc4&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 384, 384])),</span><br><span class="line">    &apos;wc5&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 384, 256])),</span><br><span class="line">    &apos;wd1&apos;: tf.Variable(tf.random_normal(shape=[4*4*256, 4096])),</span><br><span class="line">    &apos;wd2&apos;: tf.Variable(tf.random_normal(shape=[4096, 1024])),</span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.random_normal(shape=[1024, n_classes]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    &apos;bc1&apos;: tf.Variable(tf.random_normal([96])),</span><br><span class="line">    &apos;bc2&apos;: tf.Variable(tf.random_normal([256])),</span><br><span class="line">    &apos;bc3&apos;: tf.Variable(tf.random_normal([384])),</span><br><span class="line">    &apos;bc4&apos;: tf.Variable(tf.random_normal([384])),</span><br><span class="line">    &apos;bc5&apos;: tf.Variable(tf.random_normal([256])),</span><br><span class="line">    &apos;bd1&apos;: tf.Variable(tf.random_normal([4096])),</span><br><span class="line">    &apos;bd2&apos;: tf.Variable(tf.random_normal([1024])),</span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line">## 测试模型</span><br><span class="line">新建TestModel.py,复制以下代码</span><br><span class="line">### 模型评估</span><br><span class="line">​```</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import config</span><br><span class="line">import Read_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def evaluate(X_data, y_data, inputs, logits, targets):</span><br><span class="line">    batch_size = config.batch_size</span><br><span class="line">    </span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1))</span><br><span class="line">    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line">    num_examples = len(X_data)</span><br><span class="line">    total_accuracy = 0</span><br><span class="line">    sess = tf.get_default_session()</span><br><span class="line">    for offset in range(0, num_examples, batch_size):</span><br><span class="line">        batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]</span><br><span class="line"></span><br><span class="line">        accuracy = sess.run(accuracy_operation, feed_dict=&#123;inputs: batch_x, targets: batch_y&#125;)</span><br><span class="line">        total_accuracy += (accuracy * len(batch_x))</span><br><span class="line">    return total_accuracy / num_examples</span><br><span class="line"></span><br><span class="line">​```</span><br><span class="line">### 读取模型</span><br><span class="line">​```</span><br><span class="line">def run(inputs, logits, targets):</span><br><span class="line">    print(&apos;TESTING....&apos;)</span><br><span class="line">    x_train, y_train, x_test, y_test = Read_data.cifar10_data()</span><br><span class="line">    </span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        print(&quot;Evaluate The Model&quot;)</span><br><span class="line">        # TODO: 读取模型</span><br><span class="line">        saver.restore(sess, &apos;./model/cifar.model&apos;)</span><br><span class="line">        test_accuracy = evaluate(x_test, y_test, inputs, logits, targets)</span><br><span class="line">        print(&quot;Test Accuracy = &#123;:.3f&#125;&quot;.format(test_accuracy))</span><br><span class="line"></span><br><span class="line">​```</span><br><span class="line">## 训练</span><br><span class="line">创建TrainModel.py,复制以下代码</span><br><span class="line">​```</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import Read_data</span><br><span class="line">import config</span><br><span class="line">import TestModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def run(logits):</span><br><span class="line">    # 读取数据</span><br><span class="line">    global train_loss</span><br><span class="line">    x_train, y_train, x_test, y_test = Read_data.cifar10_data()</span><br><span class="line">    print(y_train.shape)</span><br><span class="line">    # 构造验证集和训练集</span><br><span class="line">    train_rate = 0.8</span><br><span class="line">    x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, train_size=train_rate)</span><br><span class="line"></span><br><span class="line">    # 初始化卷积神经网络参数</span><br><span class="line">    epochs = config.epochs</span><br><span class="line">    batch_size = config.batch_size</span><br><span class="line"></span><br><span class="line">    # 定义输入和标签的placeholder</span><br><span class="line">    inputs = config.inputs</span><br><span class="line">    targets = config.targets</span><br><span class="line"></span><br><span class="line">    # TODO: 计算损失值并初始化optimizer</span><br><span class="line">    learning_rate = config.learning_rate</span><br><span class="line"></span><br><span class="line">    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets)</span><br><span class="line">    loss_operation = tf.reduce_mean(cross_entropy)</span><br><span class="line"></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">    training_operation = optimizer.minimize(loss_operation)</span><br><span class="line"></span><br><span class="line">    # TODO: 初始化变量</span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    print(&quot;FUNCTION READY!!&quot;)</span><br><span class="line"></span><br><span class="line">    # TODO: 保存模型</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">    # TODO: 训练模型</span><br><span class="line"></span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        num_examples = len(x_train)</span><br><span class="line"></span><br><span class="line">        print(&quot;Training.....&quot;)</span><br><span class="line"></span><br><span class="line">        for n in range(epochs):</span><br><span class="line">            for offset in range(0, num_examples, batch_size):</span><br><span class="line">                batch_x, batch_y = x_train[offset:offset+batch_size], y_train[offset:offset+batch_size]</span><br><span class="line">                train_loss, _ = sess.run([loss_operation, training_operation],</span><br><span class="line">                                         feed_dict=&#123;inputs: batch_x, targets: batch_y&#125;)</span><br><span class="line"></span><br><span class="line">            print(&quot;EPOCH &#123;&#125; ...&quot;.format(n + 1))</span><br><span class="line">            print(&quot;Train Loss &#123;:.4f&#125;&quot; .format(train_loss))</span><br><span class="line">            print(&quot;Validation Accuracy = &#123;:.3f&#125;&quot;.format(TestModel.evaluate(x_validation,</span><br><span class="line">                                                                           y_validation,</span><br><span class="line">                                                                           inputs,</span><br><span class="line">                                                                           logits,</span><br><span class="line">                                                                           targets)))</span><br><span class="line"></span><br><span class="line">        saver.save(sess, &apos;./model/cifar.model&apos;)</span><br><span class="line">        print(&quot;Model saved&quot;)</span><br><span class="line"></span><br><span class="line">​```</span><br><span class="line">## 测试图片</span><br><span class="line">新建testPhoto.py</span><br><span class="line">​```</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from PIL import Image</span><br><span class="line">import Network</span><br><span class="line">import config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        photo_classes = &#123;0: &apos;airplane&apos;, 1: &apos;automobile&apos;, 2: &apos;bird&apos;, 3: &apos;cat&apos;, 4: &apos;deer&apos;,</span><br><span class="line">                         5: &apos;dog&apos;, 6: &apos;frog&apos;, 7: &apos;horse&apos;, 8: &apos;ship&apos;, 9: &apos;truck&apos;&#125;</span><br><span class="line">        logits = Network.VGG16(config.inputs)</span><br><span class="line">        x = config.inputs</span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line">        saver.restore(sess, &apos;./model/cifar.model&apos;)</span><br><span class="line">        # input</span><br><span class="line">        im = Image.open(&apos;image/dog-3.jpg&apos;)</span><br><span class="line">        # im.show()</span><br><span class="line">        im = im.resize((32, 32))</span><br><span class="line"></span><br><span class="line">        # print(im.size, im.mode)</span><br><span class="line"></span><br><span class="line">        im = np.array(im).astype(np.float32)</span><br><span class="line">        im = np.reshape(im, [-1, 32*32*3])</span><br><span class="line">        im = (im - (255 / 2.0)) / 255</span><br><span class="line">        batch_xs = np.reshape(im, [-1, 32, 32, 3])</span><br><span class="line"></span><br><span class="line">        output = sess.run(logits, feed_dict=&#123;x: batch_xs&#125;)</span><br><span class="line">        print(output)</span><br><span class="line">        print(&apos;the out put is :&apos;, photo_classes[np.argmax(output)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    main()</span><br><span class="line">​```</span><br><span class="line">## 主程序</span><br><span class="line">新建main.py</span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line">import TrainModel</span><br><span class="line">import TestModel</span><br><span class="line">import config</span><br><span class="line">import Network</span><br><span class="line"></span><br><span class="line"># logits = Network.LeNet(Setting.inputs)</span><br><span class="line"># logits = Network.alex_net(Setting.inputs, Setting.weights, Setting.biases, Setting.keep_prob)</span><br><span class="line">logits = Network.CNN_1(config.inputs)</span><br><span class="line"># logits = Network.VGG16(config.inputs)</span><br><span class="line"># logits = Network.VGG19(Setting.inputs)</span><br><span class="line"></span><br><span class="line">TrainModel.run(logits)</span><br><span class="line">TestModel.run(config.inputs, logits, config.targets)</span><br><span class="line"></span><br><span class="line">​```</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;net&quot;&gt;&lt;a href=&quot;#net&quot; class=&quot;headerlink&quot; title=&quot;net&quot;&gt;&lt;/a&gt;net&lt;/h2&gt;&lt;p&gt;新建netWork.py,添加以下代码&lt;/p&gt;
&lt;h3 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlin
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="卷积神经网络" scheme="https://janvia.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>keras实现CNN</title>
    <link href="https://janvia.github.io/2019/01/13/keras%E5%AE%9E%E7%8E%B0CNN/"/>
    <id>https://janvia.github.io/2019/01/13/keras实现CNN/</id>
    <published>2019-01-13T13:00:12.000Z</published>
    <updated>2019-01-13T13:05:20.331Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-导入环境"><a href="#0-导入环境" class="headerlink" title="0.导入环境"></a>0.导入环境</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">import os</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from keras.layers.core import Dense, Flatten</span><br><span class="line">from keras.layers.convolutional import Conv2D</span><br><span class="line">from keras.layers.pooling import MaxPooling2D</span><br><span class="line">from keras.objectives import categorical_crossentropy</span><br><span class="line">from keras import backend as K</span><br><span class="line">K.image_data_format()</span><br><span class="line">os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos;</span><br></pre></td></tr></table></figure><h2 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1.数据准备"></a>1.数据准备</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用tensorflow自带的工具加载MNIST手写数字集合</span><br><span class="line">mnist = input_data.read_data_sets(&apos;data&apos;, one_hot=True)</span><br><span class="line"># 查看数据的维度和target的维度</span><br><span class="line">print(mnist.train.images.shape)</span><br><span class="line">print(mnist.train.labels.shape)</span><br></pre></td></tr></table></figure><h2 id="2-准备好palceholder"><a href="#2-准备好palceholder" class="headerlink" title="2.准备好palceholder"></a>2.准备好palceholder</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x = tf.placeholder(tf.float32, [None, 784])</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10])</span><br><span class="line">learnRate = tf.placeholder(tf.float32)</span><br></pre></td></tr></table></figure><h2 id="3-构建网络计算图结构"><a href="#3-构建网络计算图结构" class="headerlink" title="3.构建网络计算图结构"></a>3.构建网络计算图结构</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 把输入数据reshape--28x28=784, 单通道， -1表示None</span><br><span class="line">with tf.name_scope(&apos;reshape&apos;):</span><br><span class="line">    x_image = tf.reshape(x, [-1, 28, 28, 1])</span><br><span class="line"></span><br><span class="line"># 构建第一层卷积计算层--将一个灰度图像映射到32个feature maps, 卷积核为5x5</span><br><span class="line">net = Conv2D(32, kernel_size=[5, 5], strides=[1, 1],</span><br><span class="line">             activation=&apos;relu&apos;, padding=&apos;same&apos;,</span><br><span class="line">             input_shape=[28, 28, 1])(x_image)</span><br><span class="line"></span><br><span class="line"># 构建池化层--采用最大池化</span><br><span class="line">net = MaxPooling2D(pool_size=[2, 2])(net)</span><br><span class="line"></span><br><span class="line"># 构建第二层卷积计算层--maps 32 feature maps to 64.</span><br><span class="line">net = Conv2D(64, kernel_size=[5, 5], strides=[1, 1],</span><br><span class="line">             activation=&apos;relu&apos;, padding=&apos;same&apos;)(net)</span><br><span class="line"></span><br><span class="line"># 构建第二层池化层--采用最大池化</span><br><span class="line">net = MaxPooling2D(pool_size=[2, 2])(net)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 构建全连接层--经过的两层的下采样（池化），28x28x1的图像--&gt;7x7x64，然后映射到1024个特征</span><br><span class="line">net = Flatten()(net)</span><br><span class="line">net = Dense(1024, activation=&apos;relu&apos;)(net)</span><br><span class="line"></span><br><span class="line"># 构建第二层全连接层--将1024个特性映射到10个类，每个类对应一个数字</span><br><span class="line">net = Dense(10, activation=&apos;softmax&apos;)(net)</span><br></pre></td></tr></table></figure><h2 id="4-计算损失值并初始化optimizer"><a href="#4-计算损失值并初始化optimizer" class="headerlink" title="4.计算损失值并初始化optimizer"></a>4.计算损失值并初始化optimizer</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(categorical_crossentropy(y, net))</span><br><span class="line"></span><br><span class="line">l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])</span><br><span class="line"></span><br><span class="line">total_loss = cross_entropy + 7e-5*l2_loss</span><br><span class="line"></span><br><span class="line">train_step = tf.train.AdamOptimizer(learnRate).minimize(total_loss)</span><br></pre></td></tr></table></figure><h2 id="5-初始化变量"><a href="#5-初始化变量" class="headerlink" title="5.初始化变量"></a>5.初始化变量</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">print(&quot;FUNCTION READY!!&quot;)</span><br></pre></td></tr></table></figure><h2 id="6-在会话中执行网络定义的运算"><a href="#6-在会话中执行网络定义的运算" class="headerlink" title="6.在会话中执行网络定义的运算"></a>6.在会话中执行网络定义的运算</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    for step in range(3000):</span><br><span class="line">        batch_xs, batch_ys = mnist.train.next_batch(100)</span><br><span class="line">        lr = 0.01</span><br><span class="line"></span><br><span class="line">        _, loss, l2_loss_value, total_loss_value = sess.run(</span><br><span class="line">            [train_step, cross_entropy, l2_loss, total_loss],</span><br><span class="line">            feed_dict=&#123;x: batch_xs, y: batch_ys, learnRate: lr&#125;)</span><br><span class="line"></span><br><span class="line">        if (step + 1) % 100 == 0:</span><br><span class="line">            print(&quot;step %d, entropy loss: %f, l2_loss: %f, total loss: %f&quot; %</span><br><span class="line">                  (step + 1, loss, l2_loss_value, total_loss_value))</span><br><span class="line"></span><br><span class="line">            # 验证训练的模型</span><br><span class="line">            correct_prediction = tf.equal(tf.argmax(net, 1), tf.argmax(y, 1))</span><br><span class="line">            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">            print(&quot;Train accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;))</span><br><span class="line"></span><br><span class="line">        if (step + 1) % 1000 == 0:</span><br><span class="line">            print(&quot;Text accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;0-导入环境&quot;&gt;&lt;a href=&quot;#0-导入环境&quot; class=&quot;headerlink&quot; title=&quot;0.导入环境&quot;&gt;&lt;/a&gt;0.导入环境&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;cod
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="CNN" scheme="https://janvia.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>深度卷积对抗生成网络-DCGAN</title>
    <link href="https://janvia.github.io/2019/01/13/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C-DCGAN/"/>
    <id>https://janvia.github.io/2019/01/13/深度卷积对抗生成网络-DCGAN/</id>
    <published>2019-01-13T12:37:42.000Z</published>
    <updated>2019-01-13T12:46:58.990Z</updated>
    
    <content type="html"><![CDATA[<h2 id="导入环境"><a href="#导入环境" class="headerlink" title="导入环境"></a>导入环境</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br></pre></td></tr></table></figure><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>运行程序下面代码，mnist数据集会自动下载<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(&apos;data&apos;)</span><br></pre></td></tr></table></figure></p><h2 id="获得输入数据"><a href="#获得输入数据" class="headerlink" title="获得输入数据"></a>获得输入数据</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_inputs(noise_dim, image_height, image_width, image_depth):</span><br><span class="line">    # 真实数据</span><br><span class="line">    inputs_real = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth], name=&apos;inputs_real&apos;)</span><br><span class="line">    # 噪声数据</span><br><span class="line">    inputs_noise = tf.placeholder(tf.float32, [None, noise_dim], name=&apos;inputs_noise&apos;)</span><br><span class="line"></span><br><span class="line">    return inputs_real, inputs_noise</span><br></pre></td></tr></table></figure><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_generator(noise_img, output_dim, is_train=True, alpha=0.01):</span><br><span class="line">    with tf.variable_scope(&quot;generator&quot;, reuse=(not is_train)):</span><br><span class="line">        # 100 x 1 to 4 x 4 x 512</span><br><span class="line">        # 全连接层</span><br><span class="line">        layer1 = tf.layers.dense(noise_img, 4 * 4 * 512)</span><br><span class="line">        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])</span><br><span class="line">        # batch normalization</span><br><span class="line">        layer1 = tf.layers.batch_normalization(layer1, training=is_train)</span><br><span class="line">        # Leaky ReLU</span><br><span class="line">        layer1 = tf.maximum(alpha * layer1, layer1)</span><br><span class="line">        # dropout</span><br><span class="line">        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 4 x 4 x 512 to 7 x 7 x 256</span><br><span class="line">        layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding=&apos;valid&apos;)</span><br><span class="line">        layer2 = tf.layers.batch_normalization(layer2, training=is_train)</span><br><span class="line">        layer2 = tf.maximum(alpha * layer2, layer2)</span><br><span class="line">        layer2 = tf.nn.dropout(layer2, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 7 x 7 256 to 14 x 14 x 128</span><br><span class="line">        layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer3 = tf.layers.batch_normalization(layer3, training=is_train)</span><br><span class="line">        layer3 = tf.maximum(alpha * layer3, layer3)</span><br><span class="line">        layer3 = tf.nn.dropout(layer3, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 14 x 14 x 128 to 28 x 28 x 1</span><br><span class="line">        logits = tf.layers.conv2d_transpose(layer3, output_dim, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        # MNIST原始数据集的像素范围在0-1，这里的生成图片范围为(-1,1)</span><br><span class="line">        # 因此在训练时，记住要把MNIST像素范围进行resize</span><br><span class="line">        outputs = tf.tanh(logits)</span><br><span class="line"></span><br><span class="line">        return outputs</span><br></pre></td></tr></table></figure><h2 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_discriminator(inputs_img, reuse=False, alpha=0.01):</span><br><span class="line">    with tf.variable_scope(&quot;discriminator&quot;, reuse=reuse):</span><br><span class="line">        # 28 x 28 x 1 to 14 x 14 x 128</span><br><span class="line">        # 第一层不加入BN</span><br><span class="line">        layer1 = tf.layers.conv2d(inputs_img, 128, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer1 = tf.maximum(alpha * layer1, layer1)</span><br><span class="line">        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 14 x 14 x 128 to 7 x 7 x 256</span><br><span class="line">        layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer2 = tf.layers.batch_normalization(layer2, training=True)</span><br><span class="line">        layer2 = tf.maximum(alpha * layer2, layer2)</span><br><span class="line">        layer2 = tf.nn.dropout(layer2, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 7 x 7 x 256 to 4 x 4 x 512</span><br><span class="line">        layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding=&apos;same&apos;)</span><br><span class="line">        layer3 = tf.layers.batch_normalization(layer3, training=True)</span><br><span class="line">        layer3 = tf.maximum(alpha * layer3, layer3)</span><br><span class="line">        layer3 = tf.nn.dropout(layer3, keep_prob=0.8)</span><br><span class="line"></span><br><span class="line">        # 4 x 4 x 512 to 4*4*512 x 1</span><br><span class="line">        flatten = tf.reshape(layer3, (-1, 4 * 4 * 512))</span><br><span class="line">        logits = tf.layers.dense(flatten, 1)</span><br><span class="line">        outputs = tf.sigmoid(logits)</span><br><span class="line"></span><br><span class="line">        return logits, outputs</span><br></pre></td></tr></table></figure><h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_loss(inputs_real, inputs_noise, image_depth, smooth=0.1):</span><br><span class="line">    g_outputs = get_generator(inputs_noise, image_depth, is_train=True)</span><br><span class="line">    d_logits_real, d_outputs_real = get_discriminator(inputs_real)</span><br><span class="line">    d_logits_fake, d_outputs_fake = get_discriminator(g_outputs, reuse=True)</span><br><span class="line"></span><br><span class="line">    # 计算Loss</span><br><span class="line">    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,</span><br><span class="line">                                                                    labels=tf.ones_like(d_outputs_fake) * (1 - smooth)))</span><br><span class="line"></span><br><span class="line">    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,</span><br><span class="line">                                                                         labels=tf.ones_like(d_outputs_real) * (</span><br><span class="line">                                                                                     1 - smooth)))</span><br><span class="line">    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,</span><br><span class="line">                                                                         labels=tf.zeros_like(d_outputs_fake)))</span><br><span class="line">    d_loss = tf.add(d_loss_real, d_loss_fake)</span><br><span class="line"></span><br><span class="line">    return g_loss, d_loss</span><br></pre></td></tr></table></figure><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_optimizer(g_loss, d_loss, learning_rate=0.001):</span><br><span class="line">    train_vars = tf.trainable_variables()</span><br><span class="line"></span><br><span class="line">    g_vars = [var for var in train_vars if var.name.startswith(&quot;generator&quot;)]</span><br><span class="line">    d_vars = [var for var in train_vars if var.name.startswith(&quot;discriminator&quot;)]</span><br><span class="line"></span><br><span class="line">    # Optimizer</span><br><span class="line">    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):</span><br><span class="line">        g_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)</span><br><span class="line">        d_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)</span><br><span class="line"></span><br><span class="line">    return g_opt, d_opt</span><br></pre></td></tr></table></figure><h2 id="显示图片"><a href="#显示图片" class="headerlink" title="显示图片"></a>显示图片</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def plot_images(samples):</span><br><span class="line">    fig, axes = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True, figsize=(7, 7))</span><br><span class="line">    for img, ax in zip(samples, axes.flatten()):</span><br><span class="line">        ax.imshow(img.reshape((28, 28)), cmap=&apos;Greys_r&apos;)</span><br><span class="line">        ax.get_xaxis().set_visible(False)</span><br><span class="line">        ax.get_yaxis().set_visible(False)</span><br><span class="line">    fig.tight_layout(pad=0)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def show_generator_output(sess, n_images, inputs_noise, output_dim):</span><br><span class="line">    noise_shape = inputs_noise.get_shape().as_list()[-1]</span><br><span class="line">    # 生成噪声图片</span><br><span class="line">    examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape])</span><br><span class="line"></span><br><span class="line">    samples = sess.run(get_generator(inputs_noise, output_dim, False),</span><br><span class="line">                       feed_dict=&#123;inputs_noise: examples_noise&#125;)</span><br><span class="line"></span><br><span class="line">    result = np.squeeze(samples, -1)</span><br><span class="line">    return result</span><br></pre></td></tr></table></figure><h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 定义参数</span><br><span class="line">batch_size = 64</span><br><span class="line">noise_size = 100</span><br><span class="line">epochs = 5</span><br><span class="line">n_samples = 25</span><br><span class="line">learning_rate = 0.001</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def train(noise_size, data_shape, batch_size, n_samples):</span><br><span class="line">    # 存储loss</span><br><span class="line">    losses = []</span><br><span class="line">    steps = 0</span><br><span class="line"></span><br><span class="line">    inputs_real, inputs_noise = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3])</span><br><span class="line">    g_loss, d_loss = get_loss(inputs_real, inputs_noise, data_shape[-1])</span><br><span class="line">    print(&quot;FUNCTION READY!!&quot;)</span><br><span class="line">    for _ in range(6):</span><br><span class="line">        g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, learning_rate)</span><br><span class="line">    print(&quot;TRAINING....&quot;)</span><br><span class="line">    #exit()</span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        # 迭代epoch</span><br><span class="line">        for e in range(epochs):</span><br><span class="line">            for batch_i in range(mnist.train.num_examples // batch_size):</span><br><span class="line">                steps += 1</span><br><span class="line">                batch = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">                batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3]))</span><br><span class="line">                # scale to -1, 1</span><br><span class="line">                batch_images = batch_images * 2 - 1</span><br><span class="line"></span><br><span class="line">                # noise</span><br><span class="line">                batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))</span><br><span class="line"></span><br><span class="line">                # run optimizer</span><br><span class="line">                sess.run(g_train_opt, feed_dict=&#123;inputs_real: batch_images,</span><br><span class="line">                                                 inputs_noise: batch_noise&#125;)</span><br><span class="line">                sess.run(d_train_opt, feed_dict=&#123;inputs_real: batch_images,</span><br><span class="line">                                                 inputs_noise: batch_noise&#125;)</span><br><span class="line"></span><br><span class="line">                if steps % 101 == 0:</span><br><span class="line">                    train_loss_d = d_loss.eval(&#123;inputs_real: batch_images,</span><br><span class="line">                                                inputs_noise: batch_noise&#125;)</span><br><span class="line">                    train_loss_g = g_loss.eval(&#123;inputs_real: batch_images,</span><br><span class="line">                                                inputs_noise: batch_noise&#125;)</span><br><span class="line">                    losses.append((train_loss_d, train_loss_g))</span><br><span class="line">                    print(&quot;Epoch &#123;&#125;/&#123;&#125;....&quot;.format(e + 1, epochs),</span><br><span class="line">                          &quot;Discriminator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_d),</span><br><span class="line">                          &quot;Generator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_g))</span><br><span class="line"></span><br><span class="line">            if e % 1 == 0:</span><br><span class="line">                # 显示图片</span><br><span class="line">                samples = show_generator_output(sess, n_samples, inputs_noise, data_shape[-1])</span><br><span class="line">                plot_images(samples)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">with tf.Graph().as_default():</span><br><span class="line">    train(noise_size, [-1, 28, 28, 1], batch_size, n_samples)</span><br><span class="line">    print(&quot;OPTIMIZER END!!&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;导入环境&quot;&gt;&lt;a href=&quot;#导入环境&quot; class=&quot;headerlink&quot; title=&quot;导入环境&quot;&gt;&lt;/a&gt;导入环境&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="DCGAN" scheme="https://janvia.github.io/tags/DCGAN/"/>
    
  </entry>
  
</feed>
