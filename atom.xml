<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>sylvia</title>
  
  <subtitle>Viva La Vida</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://janvia.github.io/"/>
  <updated>2019-01-13T10:43:54.250Z</updated>
  <id>https://janvia.github.io/</id>
  
  <author>
    <name>sylvia</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RNN写文章</title>
    <link href="https://janvia.github.io/2019/01/13/RNN/"/>
    <id>https://janvia.github.io/2019/01/13/RNN/</id>
    <published>2019-01-13T10:06:04.000Z</published>
    <updated>2019-01-13T10:43:54.250Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文章下载"><a href="#文章下载" class="headerlink" title="文章下载"></a>文章下载</h2><p>下载文章或重新找一篇文章：<br><a href="https://pan.baidu.com/s/1-dZd1oKZSawCN0R7LQWz1g" target="_blank" rel="noopener">https://pan.baidu.com/s/1-dZd1oKZSawCN0R7LQWz1g</a></p><h2 id="导入环境"><a href="#导入环境" class="headerlink" title="导入环境"></a>导入环境</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.contrib import rnn</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">train_file = &apos;words.txt&apos;</span><br></pre></td></tr></table></figure><h2 id="简单时间处理"><a href="#简单时间处理" class="headerlink" title="简单时间处理"></a>简单时间处理</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def str_time(sec):</span><br><span class="line">    if sec &lt; 60:</span><br><span class="line">        return str(sec) + &quot; sec&quot;</span><br><span class="line">    elif sec &lt; (60 * 60):</span><br><span class="line">        return str(sec / 60) + &quot; min&quot;</span><br><span class="line">    else:</span><br><span class="line">        return str(sec / (60 * 60)) + &quot; hour&quot;</span><br></pre></td></tr></table></figure><h2 id="处理汉字"><a href="#处理汉字" class="headerlink" title="处理汉字"></a>处理汉字</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def get_char(txt_file):</span><br><span class="line">    labels = str()</span><br><span class="line">    with open(file=txt_file, mode=&apos;rb&apos;) as f:</span><br><span class="line">        for label in f:</span><br><span class="line">            labels = label.decode(&quot;utf-8&quot;)</span><br><span class="line">    return labels</span><br></pre></td></tr></table></figure><h2 id="处理多个中文文件"><a href="#处理多个中文文件" class="headerlink" title="处理多个中文文件"></a>处理多个中文文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def readfile(files):</span><br><span class="line">    labels = list()</span><br><span class="line">    for txt_file in files:</span><br><span class="line">        target = get_char(txt_file)</span><br><span class="line">        labels.append(target)</span><br><span class="line">    return labels</span><br></pre></td></tr></table></figure><h2 id="将文本数组转换为向量"><a href="#将文本数组转换为向量" class="headerlink" title="将文本数组转换为向量"></a>将文本数组转换为向量</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def char_vector(files, num_map, label=None):</span><br><span class="line">    word_size = len(num_map)</span><br><span class="line">    vector = lambda word: num_map.get(word, word_size)</span><br><span class="line">    if files:</span><br><span class="line">        label = get_char(files)</span><br><span class="line">    labels_vector = list(map(vector, label))</span><br><span class="line"></span><br><span class="line">    return labels_vector</span><br></pre></td></tr></table></figure><h2 id="样本预处理"><a href="#样本预处理" class="headerlink" title="样本预处理"></a>样本预处理</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">train_data = get_char(train_file)</span><br><span class="line">print(&quot;Loading training data...&quot;)</span><br><span class="line"></span><br><span class="line">print(len(train_data))</span><br><span class="line">counter = Counter(train_data)</span><br><span class="line">words = sorted(counter)</span><br><span class="line">words_size = len(words)</span><br><span class="line">words_num_map = dict(zip(words, range(words_size)))</span><br><span class="line"></span><br><span class="line">print(&quot;字表大小：&quot;, words_size)</span><br><span class="line">word_label = char_vector(train_file, words_num_map)</span><br></pre></td></tr></table></figure><h2 id="超参数设置"><a href="#超参数设置" class="headerlink" title="超参数设置"></a>超参数设置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">learning_rate = 0.001</span><br><span class="line">epochs = 100000</span><br><span class="line">display_step = 1000</span><br><span class="line">n_input = 4  # 每次输入4个汉字， 预测第5个汉字</span><br><span class="line"></span><br><span class="line"># 隐层神经元</span><br><span class="line">n_hidden1 = 256</span><br><span class="line">n_hidden2 = 512</span><br><span class="line">n_hidden3 = 512</span><br><span class="line">keep_prob=0.8</span><br><span class="line">layer_num=3</span><br><span class="line">batch_size=1</span><br><span class="line"># 定义X, Y的placeholder</span><br><span class="line">x = tf.placeholder(&quot;float&quot;, [None, n_input, 1])</span><br><span class="line">y = tf.placeholder(&quot;float&quot;, [None, words_size])</span><br><span class="line"></span><br><span class="line"># 对 weights biases 初始值的定义</span><br><span class="line">weights = &#123;</span><br><span class="line"></span><br><span class="line">    &apos;in&apos;: tf.Variable(tf.random_normal([n_input,n_hidden1])),</span><br><span class="line"></span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden2,words_size]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    # shape (128, )</span><br><span class="line">    &apos;in&apos;: tf.Variable(tf.constant(0.1, shape=[n_hidden1,])),</span><br><span class="line">    # shape (10, )</span><br><span class="line">    &apos;out&apos;: tf.Variable(tf.constant(0.1, shape=[words_size, ]))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="TODO-定义网络结构"><a href="#TODO-定义网络结构" class="headerlink" title="# TODO: 定义网络结构"></a># TODO: 定义网络结构</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">def lstm_call():</span><br><span class="line">    cell = tf.nn.rnn_cell.LSTMCell(num_units=n_hidden1, reuse=tf.get_variable_scope().reuse)</span><br><span class="line">    return tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)</span><br><span class="line"></span><br><span class="line">def RNN(x, weights, biases):</span><br><span class="line"></span><br><span class="line">    x = tf.reshape(x, [batch_size, n_input, 1])  # (1,4,1) 相当于batch =1</span><br><span class="line">    # rnn</span><br><span class="line">    cell = tf.contrib.rnn.BasicLSTMCell(n_hidden2)</span><br><span class="line">    init_state = cell.zero_state(batch_size, dtype=tf.float32)</span><br><span class="line">    # final_state 的维度是  batch * n_hidden                       --&gt; 1 * 512</span><br><span class="line">    # outputs     的维度是  batch * n_input(time_step) * n_hidden  --&gt; 1 * 4  * 512</span><br><span class="line">    outputs, final_state = tf.nn.dynamic_rnn(cell, x, initial_state=init_state, time_major=False)</span><br><span class="line"></span><br><span class="line">    # print (&quot;before unstack , output shape : &quot;,outputs.shape)   # output shape :  (1,3,512) (batch,time_step,cell_n_hidden)</span><br><span class="line">    # unstack 更改维度</span><br><span class="line">    outputs = tf.unstack(tf.transpose(outputs, [1, 0, 2]))</span><br><span class="line">    # 这个时候 outputs 变成了list</span><br><span class="line">    # print (&quot;output shape[-1] 2: &quot;,outputs[-1].shape)           # output shape :  (3,1,512), outputs[-1] shape (1,512)</span><br><span class="line">    results = tf.matmul(outputs[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]</span><br><span class="line">    # (1,112)  这个的表示意义是一个(1,112)的onehot，112表示字典里面总共有112个词汇</span><br><span class="line">    return results</span><br></pre></td></tr></table></figure><h2 id="计算损失值并初始化optimizer"><a href="#计算损失值并初始化optimizer" class="headerlink" title="计算损失值并初始化optimizer"></a>计算损失值并初始化optimizer</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">predicted = RNN(x,weights,biases)</span><br><span class="line"># Loss optimizer</span><br><span class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predicted, labels=y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)</span><br><span class="line"></span><br><span class="line"># Model evaluation</span><br><span class="line">correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(y, 1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line"># 保存模型</span><br><span class="line">save_dir = &quot;model/&quot;</span><br><span class="line">saver = tf.train.Saver(max_to_keep=1)</span><br><span class="line"></span><br><span class="line"># 初始化所有变量</span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><h2 id="训练及测试模型"><a href="#训练及测试模型" class="headerlink" title="训练及测试模型"></a>训练及测试模型</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    # 每训练一次，取后面四个文字向量当做输入，第五个文字向量当做标签用作计算loss</span><br><span class="line">    offset = random.randint(0, n_input + 1)</span><br><span class="line">    end_offset = n_input + 1</span><br><span class="line">    step = 0</span><br><span class="line">    loss_total = 0.</span><br><span class="line">    acc_total = 0.</span><br><span class="line"></span><br><span class="line">    # 恢复模型并继续训练</span><br><span class="line">    model = tf.train.latest_checkpoint(save_dir)</span><br><span class="line">    print(&quot;model-ckpt:&quot;, model)</span><br><span class="line">    start_epoch = 0</span><br><span class="line">    if model:</span><br><span class="line">        saver.restore(sess, model)</span><br><span class="line">        ind = model.find(&quot;-&quot;)</span><br><span class="line">        start_epoch = int(model[ind + 1:])</span><br><span class="line">        print(start_epoch)</span><br><span class="line">        step = start_epoch</span><br><span class="line"></span><br><span class="line">    while step &lt; epochs:</span><br><span class="line"></span><br><span class="line">        # 随机选择一个位置</span><br><span class="line">        if offset &gt; (len(train_data) - end_offset):</span><br><span class="line">            offset = random.randint(0, n_input + 1)</span><br><span class="line"></span><br><span class="line">        # 按照指定的位置获取后四个文字向量，当做输入</span><br><span class="line">        in_words = [[word_label[word]] for word in range(offset, offset + n_input)]</span><br><span class="line">        in_words = np.reshape(np.array(in_words), [-1, n_input, 1])</span><br><span class="line"></span><br><span class="line">        out_onehot = np.zeros([words_size], dtype=float)</span><br><span class="line">        out_onehot[word_label[offset + n_input]] = 1.0</span><br><span class="line">        # 所有的字都变成onehot</span><br><span class="line">        out_onehot = np.reshape(out_onehot, [1, -1])</span><br><span class="line"></span><br><span class="line">        _, acc, loss_val, onehot_pred = sess.run([optimizer, accuracy, loss, predicted],</span><br><span class="line">                                                 feed_dict=&#123;x: in_words, y: out_onehot&#125;)</span><br><span class="line">        loss_total += loss_val</span><br><span class="line">        acc_total += acc</span><br><span class="line">        if (step + 1) % display_step == 0:</span><br><span class="line">            print(&quot;Iter= &quot; + str(step + 1) +</span><br><span class="line">                  &quot;, Average Loss= &quot; + &quot;&#123;:.6f&#125;&quot;.format(loss_total / display_step) +</span><br><span class="line">                  &quot;, Average Accuracy= &quot; + &quot;&#123;:.2f&#125;%&quot;.format(100 * acc_total / display_step))</span><br><span class="line"></span><br><span class="line">            acc_total = 0.</span><br><span class="line">            loss_total = 0.</span><br><span class="line">            in2 = [words[word_label[i]] for i in range(offset, offset + n_input)]</span><br><span class="line">            out2 = words[word_label[offset + n_input]]</span><br><span class="line">            out_pred = words[int(tf.argmax(onehot_pred, 1).eval())]</span><br><span class="line">            print(&quot;%s - [%s] vs [%s]&quot; % (in2, out2, out_pred))</span><br><span class="line">            saver.save(sess, save_dir + &quot;CharRNN.cpkt&quot;, global_step=step)</span><br><span class="line">        # 中间隔了一个，作为预测</span><br><span class="line">        offset += (n_input + 1)</span><br><span class="line">        step += 1</span><br><span class="line"></span><br><span class="line">    print(&quot;Finished!&quot;)</span><br><span class="line">    saver.save(sess, save_dir + &quot;CharRnn.cpkt&quot;, global_step=step)</span><br><span class="line">    print(&quot;Elapsed time: &quot;, str_time(time.time() - start_time))</span><br><span class="line"></span><br><span class="line">    # 测试模型</span><br><span class="line">    while True:</span><br><span class="line">        prompt = &quot;请输入%s个字: &quot; % n_input</span><br><span class="line">        sentence = input(prompt)</span><br><span class="line">        input_word = sentence.strip()</span><br><span class="line"></span><br><span class="line">        if len(input_word) != n_input:</span><br><span class="line">            print(&quot;您输入的字符长度为：&quot;, len(input_word), &quot;请输入4个字&quot;)</span><br><span class="line">            continue</span><br><span class="line">        try:</span><br><span class="line">            input_word = char_vector(None, words_num_map, input_word)</span><br><span class="line"></span><br><span class="line">            for i in range(100):</span><br><span class="line">                keys = np.reshape(np.array(input_word), [-1, n_input, 1])</span><br><span class="line">                onehot_pred = sess.run(predicted, feed_dict=&#123;x: keys&#125;)</span><br><span class="line">                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())</span><br><span class="line">                sentence = &quot;%s%s&quot; % (sentence, words[onehot_pred_index])</span><br><span class="line">                input_word = input_word[1:]</span><br><span class="line">                input_word.append(onehot_pred_index)</span><br><span class="line">            print(sentence)</span><br><span class="line"></span><br><span class="line">        except:</span><br><span class="line">            print(&quot;该字我还没学会&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;文章下载&quot;&gt;&lt;a href=&quot;#文章下载&quot; class=&quot;headerlink&quot; title=&quot;文章下载&quot;&gt;&lt;/a&gt;文章下载&lt;/h2&gt;&lt;p&gt;下载文章或重新找一篇文章：&lt;br&gt;&lt;a href=&quot;https://pan.baidu.com/s/1-dZd1oKZSaw
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="RNN" scheme="https://janvia.github.io/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>循环神经网络RNN-写诗</title>
    <link href="https://janvia.github.io/2019/01/13/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-%E5%86%99%E8%AF%97/"/>
    <id>https://janvia.github.io/2019/01/13/循环神经网络RNN-写诗/</id>
    <published>2019-01-13T08:12:06.000Z</published>
    <updated>2019-01-13T10:42:25.585Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据下载"><a href="#数据下载" class="headerlink" title="数据下载"></a>数据下载</h2><p>下载地址：<a href="https://pan.baidu.com/s/19fAqY0_ajkTiKfOBbpY_Sg" target="_blank" rel="noopener">https://pan.baidu.com/s/19fAqY0_ajkTiKfOBbpY_Sg</a></p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import collections</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">poetry_file = &apos;data/poetry.txt&apos;</span><br><span class="line"></span><br><span class="line"># 数据清洗，生成诗集</span><br><span class="line">poetrys = []</span><br><span class="line">with open(poetry_file, &quot;r&quot;, encoding=&apos;utf-8&apos;) as f:</span><br><span class="line">    for line in f:</span><br><span class="line">        try:</span><br><span class="line">            line = line.strip(u&apos;\n&apos;)          #strip() 方法用于移除字符串头尾指定的字符</span><br><span class="line">            title, content = line.strip(u&apos; &apos;).split(u&apos;:&apos;)</span><br><span class="line">            content = content.replace(u&apos; &apos;, u&apos;&apos;)</span><br><span class="line">            if u&apos;_&apos; in content or u&apos;(&apos; in content or u&apos;（&apos; in content or u&apos;《&apos; in content or u&apos;[&apos; in content:</span><br><span class="line">                continue</span><br><span class="line">            if len(content) &lt; 5 or len(content) &gt; 79:</span><br><span class="line">                continue</span><br><span class="line">            content = u&apos;[&apos; + content + u&apos;]&apos;</span><br><span class="line">            poetrys.append(content)</span><br><span class="line">        except Exception as e:</span><br><span class="line">            pass</span><br><span class="line"># print(poetrys[0])</span><br><span class="line"></span><br><span class="line"># 按诗的字数排序</span><br><span class="line">poetrys = sorted(poetrys, key=lambda lines: len(lines))</span><br><span class="line">print(&apos;唐诗总数: &apos;, len(poetrys))</span><br><span class="line"></span><br><span class="line"># 统计每个字出现次数</span><br><span class="line">all_words = []</span><br><span class="line">for poetry in poetrys:</span><br><span class="line">    all_words += [word for word in poetry]</span><br><span class="line">counter = collections.Counter(all_words)    #Counter是一个无序的容器类型，以字典的键值对形式存储，其中元素作为key，其计数作为value。</span><br><span class="line">count_pairs = sorted(counter.items(), key=lambda x: -x[1])</span><br><span class="line">words, _ = zip(*count_pairs)</span><br><span class="line"></span><br><span class="line"># 取前多少个常用字</span><br><span class="line">words = words[:len(words)] + (&apos; &apos;,)</span><br><span class="line"># 每个字映射为一个数字ID</span><br><span class="line">word_num_map = dict(zip(words, range(len(words))))</span><br><span class="line"># 把诗转换为向量形式.</span><br><span class="line">trans_to_num = lambda word: word_num_map.get(word, len(words))</span><br><span class="line">poetrys_vector = [list(map(trans_to_num, poetry)) for poetry in poetrys]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DataSet(object):</span><br><span class="line">    def __init__(self, data_size):</span><br><span class="line">        self._data_size = data_size</span><br><span class="line">        self._epochs_completed = 0</span><br><span class="line">        self._index_in_epoch = 0</span><br><span class="line">        self._data_index = np.arange(data_size)</span><br><span class="line"></span><br><span class="line">    def next_batch(self, batch_size):</span><br><span class="line">        start = self._index_in_epoch</span><br><span class="line">        if start + batch_size &gt; self._data_size:</span><br><span class="line">            np.random.shuffle(self._data_index)</span><br><span class="line">            self._epochs_completed = self._epochs_completed + 1</span><br><span class="line">            self._index_in_epoch = batch_size</span><br><span class="line">            full_batch_features, full_batch_labels = self.data_batch(0, batch_size)</span><br><span class="line">            return full_batch_features, full_batch_labels</span><br><span class="line"></span><br><span class="line">        else:</span><br><span class="line">            self._index_in_epoch += batch_size</span><br><span class="line">            end = self._index_in_epoch</span><br><span class="line">            full_batch_features, full_batch_labels = self.data_batch(start, end)</span><br><span class="line">            if self._index_in_epoch == self._data_size:</span><br><span class="line">                self._index_in_epoch = 0</span><br><span class="line">                self._epochs_completed = self._epochs_completed + 1</span><br><span class="line">                np.random.shuffle(self._data_index)</span><br><span class="line">            return full_batch_features, full_batch_labels</span><br><span class="line"></span><br><span class="line">    def data_batch(self, start, end):</span><br><span class="line">        batches = []</span><br><span class="line">        for i in range(start, end):</span><br><span class="line">            batches.append(poetrys_vector[self._data_index[i]])</span><br><span class="line"></span><br><span class="line">        length = max(map(len, batches))</span><br><span class="line"></span><br><span class="line">        xdata = np.full((end - start, length), word_num_map[&apos; &apos;], np.int32)</span><br><span class="line">        for row in range(end - start):</span><br><span class="line">            xdata[row, :len(batches[row])] = batches[row]</span><br><span class="line">        ydata = np.copy(xdata)</span><br><span class="line">        ydata[:, :-1] = xdata[:, 1:]</span><br><span class="line">        return xdata, ydata</span><br></pre></td></tr></table></figure><h3 id="构建RNN网络计算图"><a href="#构建RNN网络计算图" class="headerlink" title="构建RNN网络计算图"></a>构建RNN网络计算图</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 每次取64首诗进行训练</span><br><span class="line">batch_size = 64</span><br><span class="line">n_chunk = len(poetrys_vector) // batch_size</span><br><span class="line"></span><br><span class="line">input_data = tf.placeholder(tf.int32, [batch_size, None])</span><br><span class="line">output_targets = tf.placeholder(tf.int32, [batch_size, None])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义RNN</span><br><span class="line">def neural_network(model=&apos;lstm&apos;, rnn_size=128, num_layers=2):</span><br><span class="line">    global cell_fun</span><br><span class="line">    if model == &apos;rnn&apos;:</span><br><span class="line">        cell_fun = tf.nn.rnn_cell.BasicRNNCell</span><br><span class="line">    elif model == &apos;gru&apos;:</span><br><span class="line">        cell_fun = tf.nn.rnn_cell.GRUCell</span><br><span class="line">    elif model == &apos;lstm&apos;:</span><br><span class="line">        cell_fun = tf.nn.rnn_cell.BasicLSTMCell</span><br><span class="line"></span><br><span class="line">    cell = cell_fun(rnn_size, state_is_tuple=True)</span><br><span class="line">    cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)</span><br><span class="line"></span><br><span class="line">    initial_state = cell.zero_state(batch_size, tf.float32)</span><br><span class="line"></span><br><span class="line">    with tf.variable_scope(&apos;rnnlm&apos;):</span><br><span class="line">        softmax_w = tf.get_variable(&quot;softmax_w&quot;, [rnn_size, len(words)])</span><br><span class="line">        softmax_b = tf.get_variable(&quot;softmax_b&quot;, [len(words)])</span><br><span class="line">        with tf.device(&quot;/cpu:0&quot;):</span><br><span class="line">            embedding = tf.get_variable(&quot;embedding&quot;, [len(words), rnn_size])</span><br><span class="line">            inputs = tf.nn.embedding_lookup(embedding, input_data)</span><br><span class="line"></span><br><span class="line">    outputs, last_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, scope=&apos;rnnlm&apos;)</span><br><span class="line">    output = tf.reshape(outputs, [-1, rnn_size])</span><br><span class="line"></span><br><span class="line">    logits = tf.matmul(output, softmax_w) + softmax_b</span><br><span class="line">    probs = tf.nn.softmax(logits)</span><br><span class="line">    return logits, last_state, probs, cell, initial_state</span><br></pre></td></tr></table></figure><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def load_model(sess, saver, ckpt_path):</span><br><span class="line">    latest_ckpt = tf.train.latest_checkpoint(ckpt_path)</span><br><span class="line">    if latest_ckpt:</span><br><span class="line">        print(&apos;resume from&apos;, latest_ckpt)</span><br><span class="line">        saver.restore(sess, latest_ckpt)</span><br><span class="line">        return int(latest_ckpt[latest_ckpt.rindex(&apos;-&apos;) + 1:])</span><br><span class="line">    else:</span><br><span class="line">        print(&apos;building model from Training....&apos;)</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        return -1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 训练</span><br><span class="line">def train_neural_network():</span><br><span class="line">    logits, last_state, _, _, _ = neural_network()</span><br><span class="line">    targets = tf.reshape(output_targets, [-1])</span><br><span class="line">    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [targets],</span><br><span class="line">                                                              [tf.ones_like(targets, dtype=tf.float32)],</span><br><span class="line">                                                              len(words))</span><br><span class="line">##这个函数用于计算所有examples（假设一句话有n个单词，一个单词及单词所对应的label就是一个example,所有example就是一句话中所有单词）的加权交叉熵损失</span><br><span class="line">    cost = tf.reduce_mean(loss)</span><br><span class="line">    tf.summary.scalar(&apos;loss&apos;, tf.reshape(cost, []))##画损失图</span><br><span class="line"></span><br><span class="line">    learning_rate = tf.Variable(0.0, trainable=False)</span><br><span class="line">    tvars = tf.trainable_variables()##返回的是需要训练的变量列表</span><br><span class="line">    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), 5)##tf.gradients：计算梯度；tf.clip_by_global_norm（t_list 是梯度张量， clip_norm 是截取的比率）让权重的更新限制在一个合适的范围</span><br><span class="line"></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate)</span><br><span class="line">    train_op = optimizer.apply_gradients(zip(grads, tvars))</span><br><span class="line"></span><br><span class="line">    Session_config = tf.ConfigProto(allow_soft_placement=True)</span><br><span class="line">    Session_config.gpu_options.allow_growth = True</span><br><span class="line"></span><br><span class="line">    trainds = DataSet(len(poetrys_vector))</span><br><span class="line"></span><br><span class="line">    with tf.Session(config=Session_config) as sess:</span><br><span class="line">        merged = tf.summary.merge_all()##tensorflow的可视化是使用summary和tensorboard合作完成的.###########tf.summary.merge_all: 将之前定义的所有summary op整合到一起</span><br><span class="line">        log_writer = tf.summary.FileWriter(&quot;logs&quot;, sess.graph)</span><br><span class="line">        sess.run(tf.initialize_all_variables())</span><br><span class="line">        saver = tf.train.Saver(tf.all_variables())</span><br><span class="line">        last_epoch = load_model(sess, saver, &apos;model/&apos;)</span><br><span class="line">        for epoch in range(last_epoch + 1, 1000):</span><br><span class="line">            sess.run(tf.assign(learning_rate, 0.002 * (0.97 ** epoch))) #tf.assign(A, new_number): 这个函数的功能主要是把A的值变为new_number</span><br><span class="line">            all_loss = 0.0</span><br><span class="line">            for batche in range(n_chunk):</span><br><span class="line">                x, y = trainds.next_batch(batch_size)</span><br><span class="line">                train_loss, _, _, merged_summary = sess.run([cost, last_state, train_op, merged],</span><br><span class="line">                                            feed_dict=&#123;input_data: x, output_targets: y&#125;)</span><br><span class="line">                all_loss = all_loss + train_loss</span><br><span class="line">                if batche % 50 == 1:</span><br><span class="line">                    log_writer.add_summary(merged_summary, batche)</span><br><span class="line">                    print(&quot;epoch:&#123;&#125; \n&quot;.format(epoch),</span><br><span class="line">                          &quot;batch:&#123;&#125; \n&quot;.format(batche),</span><br><span class="line">                          &quot;Learning_rate:&#123;&#125; \n&quot;.format(0.002 * (0.97 ** epoch)),</span><br><span class="line">                          &quot;train_loss:&#123;&#125; \n&quot;.format(train_loss))</span><br><span class="line"></span><br><span class="line">            print(epoch, &apos; Loss: &apos;, all_loss * 1.0 / n_chunk)</span><br><span class="line">            saver.save(sess, &apos;model/poetry.module-%d&apos; % epoch)</span><br><span class="line">        log_writer.close()</span><br><span class="line"></span><br><span class="line">train_neural_network()</span><br></pre></td></tr></table></figure><h2 id="生成古诗"><a href="#生成古诗" class="headerlink" title="生成古诗"></a>生成古诗</h2><h3 id="数据预处理-1"><a href="#数据预处理-1" class="headerlink" title="数据预处理"></a>数据预处理</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import collections</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">poetry_file = &apos;data/poetry.txt&apos;</span><br><span class="line"></span><br><span class="line"># 诗集</span><br><span class="line">poetrys = []</span><br><span class="line">with open(poetry_file, &quot;r&quot;, encoding=&apos;utf-8&apos;) as f:</span><br><span class="line">    for line in f:</span><br><span class="line">        try:</span><br><span class="line">            line = line.strip(u&apos;\n&apos;)</span><br><span class="line">            title, content = line.strip(u&apos; &apos;).split(u&apos;:&apos;)</span><br><span class="line">            content = content.replace(u&apos; &apos;, u&apos;&apos;)</span><br><span class="line">            if u&apos;_&apos; in content or u&apos;(&apos; in content or u&apos;（&apos; in content or u&apos;《&apos; in content or u&apos;[&apos; in content:</span><br><span class="line">                continue</span><br><span class="line">            if len(content) &lt; 5 or len(content) &gt; 79:</span><br><span class="line">                continue</span><br><span class="line">            content = u&apos;[&apos; + content + u&apos;]&apos;</span><br><span class="line">            poetrys.append(content)</span><br><span class="line">        except Exception as e:</span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">        # 按诗的字数排序</span><br><span class="line">poetrys = sorted(poetrys, key=lambda line: len(line))</span><br><span class="line">print(&apos;唐诗总数: &apos;, len(poetrys))</span><br><span class="line"></span><br><span class="line"># 统计每个字出现次数</span><br><span class="line">all_words = []</span><br><span class="line">for poetry in poetrys:</span><br><span class="line">    all_words += [word for word in poetry]</span><br><span class="line">counter = collections.Counter(all_words)</span><br><span class="line">count_pairs = sorted(counter.items(), key=lambda x: -x[1])</span><br><span class="line">words, _ = zip(*count_pairs)</span><br><span class="line"></span><br><span class="line"># 取前多少个常用字</span><br><span class="line">words = words[:len(words)] + (&apos; &apos;,)</span><br><span class="line"># 每个字映射为一个数字ID</span><br><span class="line">word_num_map = dict(zip(words, range(len(words))))</span><br><span class="line"># 把诗转换为向量形式</span><br><span class="line">to_num = lambda word: word_num_map.get(word, len(words))</span><br><span class="line">poetrys_vector = [list(map(to_num, poetry)) for poetry in poetrys]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 每次取64首诗进行训练</span><br><span class="line">batch_size = 1</span><br><span class="line">n_chunk = len(poetrys_vector) // batch_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ---------------------------------------RNN--------------------------------------#</span><br><span class="line"></span><br><span class="line">input_data = tf.placeholder(tf.int32, [batch_size, None])</span><br><span class="line">output_targets = tf.placeholder(tf.int32, [batch_size, None])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义RNN</span><br><span class="line">def neural_network(model=&apos;lstm&apos;, rnn_size=128, num_layers=2):</span><br><span class="line">    global cell_fun</span><br><span class="line">    if model == &apos;rnn&apos;:</span><br><span class="line">        cell_fun = tf.nn.rnn_cell.BasicRNNCell</span><br><span class="line">    elif model == &apos;gru&apos;:</span><br><span class="line">        cell_fun = tf.nn.rnn_cell.GRUCell</span><br><span class="line">    elif model == &apos;lstm&apos;:</span><br><span class="line">        cell_fun = tf.nn.rnn_cell.BasicLSTMCell</span><br><span class="line"></span><br><span class="line">    cell = cell_fun(rnn_size, state_is_tuple=True)</span><br><span class="line">    cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)</span><br><span class="line"></span><br><span class="line">    initial_state = cell.zero_state(batch_size, tf.float32)</span><br><span class="line"></span><br><span class="line">    with tf.variable_scope(&apos;rnnlm&apos;):</span><br><span class="line">        softmax_w = tf.get_variable(&quot;softmax_w&quot;, [rnn_size, len(words)])</span><br><span class="line">        softmax_b = tf.get_variable(&quot;softmax_b&quot;, [len(words)])</span><br><span class="line">        with tf.device(&quot;/cpu:0&quot;):</span><br><span class="line">            embedding = tf.get_variable(&quot;embedding&quot;, [len(words), rnn_size])</span><br><span class="line">            inputs = tf.nn.embedding_lookup(embedding, input_data)</span><br><span class="line"></span><br><span class="line">    outputs, last_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, scope=&apos;rnnlm&apos;)</span><br><span class="line">    output = tf.reshape(outputs, [-1, rnn_size])</span><br><span class="line"></span><br><span class="line">    logits = tf.matmul(output, softmax_w) + softmax_b</span><br><span class="line">    probs = tf.nn.softmax(logits)</span><br><span class="line">    return logits, last_state, probs, cell, initial_state</span><br></pre></td></tr></table></figure><h3 id="用训练完成的模型生成古诗"><a href="#用训练完成的模型生成古诗" class="headerlink" title="用训练完成的模型生成古诗"></a>用训练完成的模型生成古诗</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def gen_head_poetry(heads, type):</span><br><span class="line">    if type != 5 and type != 7:</span><br><span class="line">        print(&apos;The second para has to be 5 or 7!&apos;)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    def to_word(weights):</span><br><span class="line">        t = np.cumsum(weights)#a = np.array([[1,2,3], [4,5,6]])### np.cumsum(a)###array([ 1,  3,  6, 10, 15, 21])####array([1，1+2=3，1+2+3=6，1+2+3+4=10，1+2+3+4+5=15，1+2+3+4+5+6=21]）</span><br><span class="line">        s = np.sum(weights)</span><br><span class="line">        sample = int(np.searchsorted(t, np.random.rand(1) * s))##np.random.rand(3,2)##括号中为shape##np.searchsorted:寻找某个数应该插在数组的什么位置上，这个数组必须是按序排列的</span><br><span class="line">        return words[sample]</span><br><span class="line"></span><br><span class="line">    _, last_state, probs, cell, initial_state = neural_network()</span><br><span class="line">    Session_config = tf.ConfigProto(allow_soft_placement=True)</span><br><span class="line">    Session_config.gpu_options.allow_growth = True</span><br><span class="line"></span><br><span class="line">    with tf.Session(config=Session_config) as sess:</span><br><span class="line">        with tf.device(&apos;/gpu:1&apos;):</span><br><span class="line"></span><br><span class="line">            sess.run(tf.initialize_all_variables())</span><br><span class="line"></span><br><span class="line">            saver = tf.train.Saver(tf.all_variables())</span><br><span class="line">            saver.restore(sess, &apos;model/poetry.module-99&apos;)</span><br><span class="line">            poem = &apos;&apos;</span><br><span class="line">            for head in heads:</span><br><span class="line">                flag = True</span><br><span class="line">                while flag:</span><br><span class="line"></span><br><span class="line">                    state_ = sess.run(cell.zero_state(1, tf.float32))</span><br><span class="line"></span><br><span class="line">                    x = np.array([list(map(word_num_map.get, u&apos;[&apos;))])</span><br><span class="line">                    [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;)</span><br><span class="line"></span><br><span class="line">                    sentence = head</span><br><span class="line"></span><br><span class="line">                    x = np.zeros((1, 1))</span><br><span class="line">                    x[0, 0] = word_num_map[sentence]</span><br><span class="line">                    [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;)</span><br><span class="line">                    word = to_word(probs_)</span><br><span class="line">                    sentence += word</span><br><span class="line"></span><br><span class="line">                    while word != u&apos;。&apos;:</span><br><span class="line">                        x = np.zeros((1, 1))</span><br><span class="line">                        x[0, 0] = word_num_map[word]</span><br><span class="line">                        [probs_, state_] = sess.run([probs, last_state],</span><br><span class="line">                                                    feed_dict=&#123;input_data: x, initial_state: state_&#125;)</span><br><span class="line">                        word = to_word(probs_)</span><br><span class="line">                        sentence += word</span><br><span class="line"></span><br><span class="line">                    if len(sentence) == 2 + 2 * type:</span><br><span class="line">                        sentence += u&apos;\n&apos;</span><br><span class="line">                        poem += sentence</span><br><span class="line">                        flag = False</span><br><span class="line"></span><br><span class="line">            return poem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gen_poetry():</span><br><span class="line">    def to_word(weights):</span><br><span class="line">        t = np.cumsum(weights)</span><br><span class="line">        s = np.sum(weights)</span><br><span class="line">        sample = int(np.searchsorted(t, np.random.rand(1) * s))</span><br><span class="line">        return words[sample]</span><br><span class="line"></span><br><span class="line">    _, last_state, probs, cell, initial_state = neural_network()</span><br><span class="line"></span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.initialize_all_variables())</span><br><span class="line">        saver = tf.train.Saver(tf.all_variables())</span><br><span class="line">        saver.restore(sess, &apos;model/poetry.module-99&apos;)</span><br><span class="line">        state_ = sess.run(cell.zero_state(1, tf.float32))</span><br><span class="line">        x = np.array([list(map(word_num_map.get, &apos;[&apos;))])</span><br><span class="line">        [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;)</span><br><span class="line">        word = to_word(probs_)</span><br><span class="line">        poem = &apos;&apos;</span><br><span class="line">        while word != &apos;[&apos;:</span><br><span class="line">            poem += word</span><br><span class="line">            x = np.zeros((1, 1))</span><br><span class="line">            x[0, 0] = word_num_map[word]</span><br><span class="line">            [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;)</span><br><span class="line">            word = to_word(probs_)</span><br><span class="line">        return poem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#print(gen_poetry())</span><br><span class="line">print(gen_head_poetry(u&apos;言叶之庭&apos;, 5))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;数据下载&quot;&gt;&lt;a href=&quot;#数据下载&quot; class=&quot;headerlink&quot; title=&quot;数据下载&quot;&gt;&lt;/a&gt;数据下载&lt;/h2&gt;&lt;p&gt;下载地址：&lt;a href=&quot;https://pan.baidu.com/s/19fAqY0_ajkTiKfOBbpY_Sg&quot;
      
    
    </summary>
    
      <category term="深度学习" scheme="https://janvia.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="LSTM" scheme="https://janvia.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow-基础语法</title>
    <link href="https://janvia.github.io/2019/01/12/tensorflow-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"/>
    <id>https://janvia.github.io/2019/01/12/tensorflow-基础语法/</id>
    <published>2019-01-12T08:09:54.000Z</published>
    <updated>2019-01-12T08:24:04.040Z</updated>
    
    <content type="html"><![CDATA[<p>数学公式API：<a href="https://github.com/tensorflow/docs/blob/master/site/en/api_guides/python" target="_blank" rel="noopener">https://github.com/tensorflow/docs/blob/master/site/en/api_guides/python</a></p><h2 id="constant"><a href="#constant" class="headerlink" title="constant"></a>constant</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a = tf.constant(0, name=&apos;B&apos;)</span><br><span class="line">b = tf.constant(1)</span><br></pre></td></tr></table></figure><h2 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x = tf.zeros([2, 3], tf.int32)</span><br><span class="line">y = tf.zeros_like(x, optimize=True)</span><br></pre></td></tr></table></figure><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">with tf.variable_scope(&apos;meh&apos;) as scope:</span><br><span class="line">    a = tf.get_variable(&apos;a&apos;, [10])</span><br><span class="line">    b = tf.get_variable(&apos;b&apos;, [100])</span><br><span class="line"></span><br><span class="line">writer = tf.summary.FileWriter(&apos;./graphs/test&apos;, tf.get_default_graph())</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h2 id="placeholdder占位符"><a href="#placeholdder占位符" class="headerlink" title="placeholdder占位符"></a>placeholdder占位符</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line">output = tf.multiply(input1, input2)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    print(sess.run([output], feed_dict=&#123;input1:[7.], input2:[2.]&#125;))</span><br></pre></td></tr></table></figure><h2 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tf.cast(tf.constant(2.0), tf.int32)</span><br></pre></td></tr></table></figure><h2 id="把numpy转换成Tensor"><a href="#把numpy转换成Tensor" class="headerlink" title="把numpy转换成Tensor"></a>把numpy转换成Tensor</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a = np.zeros((3,3))</span><br><span class="line">print(a)</span><br><span class="line">print(&apos;----------------&apos;)</span><br><span class="line">ta = tf.convert_to_tensor(a)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">     print(sess.run(ta))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数学公式API：&lt;a href=&quot;https://github.com/tensorflow/docs/blob/master/site/en/api_guides/python&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.
      
    
    </summary>
    
      <category term="tensorflow" scheme="https://janvia.github.io/categories/tensorflow/"/>
    
    
      <category term="语法" scheme="https://janvia.github.io/tags/%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow-可视化</title>
    <link href="https://janvia.github.io/2019/01/12/tensorflow-%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <id>https://janvia.github.io/2019/01/12/tensorflow-可视化/</id>
    <published>2019-01-12T07:30:35.000Z</published>
    <updated>2019-01-12T08:08:05.141Z</updated>
    
    <content type="html"><![CDATA[<h2 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure><h2 id="设置生成的图像尺寸和去除警告"><a href="#设置生成的图像尺寸和去除警告" class="headerlink" title="设置生成的图像尺寸和去除警告"></a>设置生成的图像尺寸和去除警告</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos;</span><br><span class="line">plt.rcParams[&quot;figure.figsize&quot;] = (14, 8)  # 生成的图像尺寸</span><br></pre></td></tr></table></figure><h2 id="随机生成一个线性的数据"><a href="#随机生成一个线性的数据" class="headerlink" title="随机生成一个线性的数据"></a>随机生成一个线性的数据</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n_observations = 100</span><br><span class="line">xs = np.linspace(-3, 3, n_observations)    #生成-3到3的n为100等差数列</span><br><span class="line">ys = 0.8*xs + 0.1 + np.random.uniform(-0.5, 0.5, n_observations)</span><br><span class="line">plt.scatter(xs, ys) #画图</span><br><span class="line">plt.show() #画图</span><br></pre></td></tr></table></figure><h2 id="准备placeholder"><a href="#准备placeholder" class="headerlink" title="准备placeholder"></a>准备placeholder</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">X = tf.placeholder(tf.float32, name=&apos;X&apos;)</span><br><span class="line">Y = tf.placeholder(tf.float32, name=&apos;Y&apos;)</span><br></pre></td></tr></table></figure><h2 id="初始化参数-权重"><a href="#初始化参数-权重" class="headerlink" title="初始化参数/权重"></a>初始化参数/权重</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">W = tf.Variable(tf.random_normal([1]), name=&apos;weight&apos;)</span><br><span class="line">tf.summary.histogram(&apos;weight&apos;, W) #画图</span><br><span class="line">b = tf.Variable(tf.random_normal([1]), name=&apos;bias&apos;)</span><br><span class="line">tf.summary.histogram(&apos;bias&apos;, b)#画图</span><br></pre></td></tr></table></figure><h2 id="计算预测结果"><a href="#计算预测结果" class="headerlink" title="计算预测结果"></a>计算预测结果</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Y_pred = tf.add(tf.multiply(X, W), b)</span><br></pre></td></tr></table></figure><h2 id="计算损失值"><a href="#计算损失值" class="headerlink" title="计算损失值"></a>计算损失值</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">loss = tf.square(Y - Y_pred, name=&apos;loss&apos;)  #tf.square:平方</span><br><span class="line"></span><br><span class="line">tf.summary.scalar(&apos;loss&apos;, tf.reshape(loss, []))#画图</span><br></pre></td></tr></table></figure><h2 id="初始化optimizer"><a href="#初始化optimizer" class="headerlink" title="初始化optimizer"></a>初始化optimizer</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">learning_rate = 0.01</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)</span><br></pre></td></tr></table></figure><h2 id="指定迭代次数，并在session里执行graph"><a href="#指定迭代次数，并在session里执行graph" class="headerlink" title="指定迭代次数，并在session里执行graph"></a>指定迭代次数，并在session里执行graph</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n_samples = xs.shape[0]</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    # 记得初始化所有变量</span><br><span class="line">    sess.run(init)</span><br><span class="line">    merged = tf.summary.merge_all()#画图</span><br><span class="line">    log_writer = tf.summary.FileWriter(&quot;./logs/linear_regression&quot;, sess.graph)</span><br><span class="line"></span><br><span class="line">    # 训练模型</span><br><span class="line">    for i in range(50):</span><br><span class="line">        total_loss = 0</span><br><span class="line">        for x, y in zip(xs, ys):</span><br><span class="line">            # 通过feed_dic把数据灌进去</span><br><span class="line">            _, loss_value, merged_summary = sess.run([optimizer, loss, merged], feed_dict=&#123;X: x, Y: y&#125;)</span><br><span class="line">            total_loss += loss_value</span><br><span class="line"></span><br><span class="line">        if i % 5 == 0:</span><br><span class="line">            print(&apos;Epoch &#123;0&#125;: &#123;1&#125;&apos;.format(i, total_loss / n_samples))</span><br><span class="line">            log_writer.add_summary(merged_summary, i)#画图</span><br><span class="line"></span><br><span class="line">    # 关闭writer</span><br><span class="line">    log_writer.close()#画图</span><br><span class="line"></span><br><span class="line">    # 取出w和b的值</span><br><span class="line">    W, b = sess.run([W, b])</span><br><span class="line"></span><br><span class="line">print(W, b)</span><br><span class="line">print(&quot;W:&quot;+str(W[0]))</span><br><span class="line">print(&quot;b:&quot;+str(b[0]))</span><br></pre></td></tr></table></figure><h2 id="画出线性回归线"><a href="#画出线性回归线" class="headerlink" title="画出线性回归线"></a>画出线性回归线</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plt.plot(xs, ys, &apos;bo&apos;, label=&apos;Real data&apos;)</span><br><span class="line">plt.plot(xs, xs * W + b, &apos;r&apos;, label=&apos;Predicted data&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="Tensorboard查看图形数据"><a href="#Tensorboard查看图形数据" class="headerlink" title="Tensorboard查看图形数据"></a>Tensorboard查看图形数据</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir path/to/logs(你保存文件所在位置)</span><br></pre></td></tr></table></figure><p>如：（log_writer = tf.summary.FileWriter(“./logs/linear_regression”, sess.graph)保存的地址）：</p><p>tensorboard –logdir ./logs/linear_regression </p><p>输出：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TensorBoard x.x.x at http://(你的用户名):6006 (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure></p><p>然后打开网页：<code>http://localhost:6006</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;导入包&quot;&gt;&lt;a href=&quot;#导入包&quot; class=&quot;headerlink&quot; title=&quot;导入包&quot;&gt;&lt;/a&gt;导入包&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;spa
      
    
    </summary>
    
      <category term="tensorflow" scheme="https://janvia.github.io/categories/tensorflow/"/>
    
    
      <category term="可视化" scheme="https://janvia.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>20单元语法</title>
    <link href="https://janvia.github.io/2019/01/11/20%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95/"/>
    <id>https://janvia.github.io/2019/01/11/20单元语法/</id>
    <published>2019-01-11T13:49:36.000Z</published>
    <updated>2019-01-12T01:32:12.980Z</updated>
    
    <content type="html"><![CDATA[<h2 id="N-なら（ば）＜凸显、条件＞"><a href="#N-なら（ば）＜凸显、条件＞" class="headerlink" title="N + なら（ば）＜凸显、条件＞"></a>N + なら（ば）＜凸显、条件＞</h2><h3 id="用法一"><a href="#用法一" class="headerlink" title="用法一"></a>用法一</h3><p>接在体言后面，凸显、强调所指事物，作提示助词，<strong>提出主题</strong>，<br>并用自信、有把握的语气进行叙述，如果以此为主题的话。<br>接续：N+<br>  ✿汉语：就~方面来说、~的话</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、お金なら心配は要りません。</span><br><span class="line">2、花なら桜です。</span><br></pre></td></tr></table></figure><h3 id="用法2"><a href="#用法2" class="headerlink" title="用法2"></a>用法2</h3><p>以<strong>假设的形式提出话题</strong>，前项为前提，后项为说话人<strong>判断、决定或建议</strong>；<br>接续： N ・ A ・ V ・ Na <strong>直接裸接</strong>　なら<br>  ✿汉语：要是~的话~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、私ならそんなことを言いませんよ。</span><br><span class="line">2、海が静かならいいですが。</span><br><span class="line">3、彼が出席するなら、私は行きません。</span><br></pre></td></tr></table></figure></p><h2 id="～場合は＜假设＞"><a href="#～場合は＜假设＞" class="headerlink" title="～場合は＜假设＞"></a>～場合は＜假设＞</h2><p>表示<strong>假设</strong>的情况。当假设出现了前项情况时，后项一般为针对此情况所采取的方法或对策。<br>接续：N ・ A ・ V ・ Na 连体形+場合は<br>  ✿汉语：当~时、在~的情况下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、王さんの都合が悪い場合は、ほかの日にしましょう。</span><br><span class="line">2、電話が通じない場合はどうしたらいいですか。</span><br><span class="line">3、雨が降った場合は、運動会を中止します。</span><br></pre></td></tr></table></figure><h2 id="Vたらどうですか＜建议＞"><a href="#Vたらどうですか＜建议＞" class="headerlink" title="Vたらどうですか＜建议＞"></a>Vたらどうですか＜建议＞</h2><p>表示<strong>建议或劝诱</strong>的惯用表达，<br>  ✿汉语：~怎么样、~如何<br>★：礼貌表达方式为：~たらどうですか。<br>　　　　　　　　　　~たらいかがですか。<br>　　　　　　　　　　~たらいかがでしょうか<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、ABC病院に行ってみたらどうでしょう。(2011年真题)</span><br><span class="line">2、朝からずっと勉強していますね。少し休んだらどうですか。</span><br><span class="line">3、ネクタイでも買ってあげたらどう？(2010年真题)</span><br></pre></td></tr></table></figure></p><h2 id="くらい＜程度＞"><a href="#くらい＜程度＞" class="headerlink" title="くらい＜程度＞"></a>くらい＜程度＞</h2><p>接在分句后面表示程度。举出具体的事例来说明其程度。也可写做ぐらい。基本可与「ほど」互换。<br>接续：裸接分句后</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、怖くて怖くて、大声で叫びたいくらいだった。(2009年真题)</span><br><span class="line">2、涙が出るくらい痛いです。</span><br></pre></td></tr></table></figure><h2 id="「ほど」VS「くらい」"><a href="#「ほど」VS「くらい」" class="headerlink" title="「ほど」VS「くらい」"></a>「ほど」VS「くらい」</h2><p>在表示某种程度时:</p><ul><li><p>如果说话人心目中对其程度<strong>没有进行高低取向</strong>时，くらい和ほど有时可以互换使用，表示相同的意思。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、日曜は足が痛くなる**ぐらい**（〇ほど）歩いた。</span><br></pre></td></tr></table></figure></li><li><p>如果有高低取向，则くらい表示低，而ほど表示高，</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、彼**くらい**（Ｘほど）のレベルでは通訳はできない。</span><br><span class="line">2、党の御恩は山**ほど**（Ｘくらい）高く、海**ほど**（Ｘくらい）深い。</span><br><span class="line">3、死ぬ**ほど**（×くらい）疲れた。</span><br></pre></td></tr></table></figure></li></ul><h2 id="Vてくださいませんか＜客气的请求＞"><a href="#Vてくださいませんか＜客气的请求＞" class="headerlink" title="Vてくださいませんか＜客气的请求＞"></a>Vてくださいませんか＜客气的请求＞</h2><p>表示请求别人做某事。比｢Vてくれませんか｣更加委婉、客气，是一种尊他，客气的表达。<br>  ✿ 汉语：能不能请您（为我做)～</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１、先生のお写真を見せてくださいませんか。</span><br><span class="line">２、もう少し説明してくださいませんか。</span><br></pre></td></tr></table></figure><h2 id="Vてしまった"><a href="#Vてしまった" class="headerlink" title="Vてしまった"></a>Vてしまった</h2><h3 id="Vてしまった＜感慨＞"><a href="#Vてしまった＜感慨＞" class="headerlink" title="Vてしまった＜感慨＞"></a>Vてしまった＜感慨＞</h3><p>表示说话人对意外发生的事（无法挽回的事情、消极的结果等）感到很遗憾、后悔的语气。常与副词「もう」搭配<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１、バスで財布を落としてしまった。</span><br><span class="line">２、急いで来たから、財布を忘れてしまった。(2005年真题)</span><br></pre></td></tr></table></figure></p><h3 id="Vてしまった＜完了＞"><a href="#Vてしまった＜完了＞" class="headerlink" title="Vてしまった＜完了＞"></a>Vてしまった＜完了＞</h3><p>表示动作过程的完了。<br>用于表示持续动作的动词时，与｢V第一连用－おわる｣意思相近。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１、この宿題をしてしまったら、遊びに行ける。</span><br><span class="line">２、この本はもう読んでしまったから、図書館に返します。</span><br></pre></td></tr></table></figure></p><h2 id="N-の＋うち＜范围＞"><a href="#N-の＋うち＜范围＞" class="headerlink" title="N+の＋うち＜范围＞"></a>N+の＋うち＜范围＞</h2><p>表示限定范围。<br>  ✿ 汉语：~当中、~之中<br>★在表示从某范围中挑选某事物时，可与｢Ｎのなか｣替换。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">１、三人のうち、林さんが一番若いです。</span><br><span class="line">２、クラスメートのうち、6人が男性です。</span><br><span class="line">３、相撲とサッカーと野球のうちで、一番人気があるのはやはり野球だそうだ。</span><br></pre></td></tr></table></figure></p><h2 id="N1-または-N2＜选择＞"><a href="#N1-または-N2＜选择＞" class="headerlink" title="N1 または N2＜选择＞"></a>N1 または N2＜选择＞</h2><p>表示两者择一，多用于书面语，表示要求、指示等场合。<br>  ✿ 汉语：~或是~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、3番の部屋、または4番の部屋に行ってください。(2008年真题)</span><br><span class="line">2、漢字または仮名で書いてください。</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;N-なら（ば）＜凸显、条件＞&quot;&gt;&lt;a href=&quot;#N-なら（ば）＜凸显、条件＞&quot; class=&quot;headerlink&quot; title=&quot;N + なら（ば）＜凸显、条件＞&quot;&gt;&lt;/a&gt;N + なら（ば）＜凸显、条件＞&lt;/h2&gt;&lt;h3 id=&quot;用法一&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="日语" scheme="https://janvia.github.io/categories/%E6%97%A5%E8%AF%AD/"/>
    
    
      <category term="语法" scheme="https://janvia.github.io/tags/%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>19单元语法</title>
    <link href="https://janvia.github.io/2019/01/11/19%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95/"/>
    <id>https://janvia.github.io/2019/01/11/19单元语法/</id>
    <published>2019-01-11T12:23:24.000Z</published>
    <updated>2019-01-11T13:33:24.016Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Nとは～という意味だ"><a href="#Nとは～という意味だ" class="headerlink" title="Nとは～という意味だ"></a>Nとは～という意味だ</h2><p>汉语：~是~的意思<br>★口语：Ｎというのは、～<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿帰省とは故郷に帰るという意味です。</span><br><span class="line">✿下水とは台所などで使った汚れた水のことである。</span><br><span class="line">✿進入禁止とは入ってはいけないという意味です。</span><br></pre></td></tr></table></figure></p><h2 id="うちに＜时段＞"><a href="#うちに＜时段＞" class="headerlink" title="~うちに＜时段＞"></a>~うちに＜时段＞</h2><p>前接表示状态的词，表示在该 <strong>状态持续期间</strong> 内，发生了某件事或做某件事（有尽快进行该动作的语感）。<br>接续：<br>  ✿  N  + の                     + うちに<br>  ✿  Na + な                     + うちに<br>  ✿  A  - い                     + うちに<br>  ✿  V  - る / V-ている  V-ない　 + うちに</p><p>汉语 ：趁着~、~时候、在~之内<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿どうぞ、温かいうちに食べてください。（2008年真题）</span><br><span class="line">✿父が元気なうちに、一度一緒に温泉に行きたいと思います。</span><br></pre></td></tr></table></figure></p><h2 id="V-（よ）うか＜犹豫＞"><a href="#V-（よ）うか＜犹豫＞" class="headerlink" title="V-（よ）うか＜犹豫＞"></a>V-（よ）うか＜犹豫＞</h2><p>用于简体的会话。 <strong>自言自语</strong> 或是 <strong>与对方商量</strong> 的语气。<br>表示说话人对是否要做某动作而 <strong>犹豫不决、踌躇不定</strong> 的心情。<br>接续：动词意志形+か<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿もう時間だから、行こうか。</span><br><span class="line">✿結果はどうなるかわからないけど、やってみようか。</span><br><span class="line">✿いくら考えてもわからないから、しばらく休んで、後にしようか。</span><br></pre></td></tr></table></figure></p><h2 id="ても・でも＜让步＞"><a href="#ても・でも＜让步＞" class="headerlink" title="ても・でも＜让步＞"></a>ても・でも＜让步＞</h2><p>表示让步的条件。就算前项从句成立，后项主句的结果也不会改变。（同19课2单元）<br>接续：<br>  ✿N・Na    + でも<br>  ✿A-く     + ても<br>  ✿V-て     + ても<br>汉语：即使~也~、就算~都~</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿あの美術館はいつ行っても人がたくさんいる。(2007年真题)</span><br><span class="line">✿学校を卒業しても、日本語の勉強を続けていくつもりだ。 (2005年真题)</span><br><span class="line">✿今必要だから、高くても買う。</span><br><span class="line">✿先生でもわからないかもしれません</span><br></pre></td></tr></table></figure><h2 id="V-ると～た＜契机＞"><a href="#V-ると～た＜契机＞" class="headerlink" title="V-ると～た＜契机＞"></a>V-ると～た＜契机＞</h2><p>表示说话人在 <strong>前面的事情成立</strong> 的情况下，重新认识后项事物，是一些 <strong>新的发现、认识</strong> 等，具有意外性。或以此为契机 <strong>发生了后项的事物</strong> 。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿五月に入ると、急に暑くなった。</span><br><span class="line">✿外に出ると、雨が降っていた。</span><br><span class="line">✿友達が怪我で入院したと聞き、慌てて病院に行ってみると思っていたより元気で安心した。</span><br></pre></td></tr></table></figure><h2 id="「～たら～た」-VS-「～と～た」"><a href="#「～たら～た」-VS-「～と～た」" class="headerlink" title="「～たら～た」 VS　「～と～た」"></a>「～たら～た」 VS　「～と～た」</h2><h3 id="相同点："><a href="#相同点：" class="headerlink" title="相同点："></a>相同点：</h3><p>表示“以~为契机发现了~”这一用法时，两者一般可以替换使用。</p><h3 id="不同点："><a href="#不同点：" class="headerlink" title="不同点："></a>不同点：</h3><p>1、“と”常用于小说或故事等，<br>而“たら”则多用于说话人表述自己直接的经历。</p><p>2、当前后两个句子表示为 <strong>同一人物的意志可控制</strong> 的连续动词时，<br>只可以用“と”。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿男は部屋に入ると、友達に電話した。</span><br></pre></td></tr></table></figure></p><p>3、当表示 <strong>说话人身体的感觉</strong> 时，<br>只可以用“たら”，不能用“と”。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿昨夜、この薬を飲んだら、よく効いた。</span><br></pre></td></tr></table></figure></p><h2 id="でも＜极端的情况＞"><a href="#でも＜极端的情况＞" class="headerlink" title="でも＜极端的情况＞"></a>でも＜极端的情况＞</h2><p>助词でも除了表示“示例”以外，更多的是接在名词（或者部分副词、助词）后，用于举出极端的事例。</p><p>中文：“就连~都~”“即使~也~”“尽管~也~”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿この店は日本料理が本格的ですが。日本人でもこの味に満足している。</span><br><span class="line">　　</span><br><span class="line">✿先生でもわからないかもしれない。</span><br><span class="line"></span><br><span class="line">✿この仕事は病気でも休めません</span><br><span class="line"></span><br><span class="line">✿今度の日曜日、雨でもサッカーの試合を行います。</span><br></pre></td></tr></table></figure></p><h2 id="～し～-し-＜并列＞"><a href="#～し～-し-＜并列＞" class="headerlink" title="～し～(し)＜并列＞"></a>～し～(し)＜并列＞</h2><p>连接两个或两个以上的分句，列举。多用罗列于原因理由<br>接续：分句+し<br>翻译：“既~又~”“又~又~”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿お金もないし、時間もないから、遊びに行けない。(2008年真题)</span><br><span class="line">✿アパートは綺麗だし、広いし、駅からも近い。(2005年真题)</span><br></pre></td></tr></table></figure></p><h2 id="～Vばいい・よい-lt-建议＞"><a href="#～Vばいい・よい-lt-建议＞" class="headerlink" title="～Ｖばいい・よい&lt;建议＞"></a>～Ｖばいい・よい&lt;建议＞</h2><p>常用在表示提议时。<br>汉语：只要~就可、~就好</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿ A:どうすればいいですか。</span><br><span class="line">　  B:ちゃんと謝ればいいですよ。</span><br><span class="line">✿ お金がなければ、お父さんに借りればいいでしょう。</span><br></pre></td></tr></table></figure><h2 id="のに＜转折＞"><a href="#のに＜转折＞" class="headerlink" title="のに＜转折＞"></a>のに＜转折＞</h2><p>  ✿ V-る・V-た　　　+のに<br>  ✿ A-い・A-かった　+のに<br>  ✿ N・Na　　　　　な+のに</p><h3 id="位于句中"><a href="#位于句中" class="headerlink" title="位于句中"></a>位于句中</h3><p>起逆接作用，是接续助词。<br>连接起来的句子往往都有意外、不满、埋怨等语感<br>汉语：可是~、却~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿雨が降っているのに、傘を持たないで出かけた。</span><br><span class="line">✿知っているのに知らないと言った。</span><br></pre></td></tr></table></figure></p><h3 id="置于句末"><a href="#置于句末" class="headerlink" title="置于句末"></a>置于句末</h3><p>是终助词，表示事与愿违时的遗憾、惋惜、后悔等心情，一般多用口语。可以跟在｢ばいい｣后面。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿この部屋がもう少し広げればいいのに。</span><br><span class="line">✿注意していたのに。</span><br></pre></td></tr></table></figure></p><h2 id="たら＜条件＞"><a href="#たら＜条件＞" class="headerlink" title="たら＜条件＞"></a>たら＜条件＞</h2><p>表示 <strong>假设</strong>，属于动词的另一种条件形。接续上和动词的过去式｢た｣是一样的。表 <strong>一次性的，特定</strong> 的依存关系。表示主句的实现，<strong>建立在从句动作或变化完成的基础上</strong>。<br>汉语：　　~之后就~   ~以后~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿仕事が終わったら、お茶でも飲みにいきましょう。</span><br><span class="line">✿そんなにたくさん食べたら、おなかを壊しますよ。</span><br><span class="line">✿大学を卒業したらどんな仕事をしますか。</span><br></pre></td></tr></table></figure></p><h2 id="V-て-V-ないで-lt-伴随状态-gt"><a href="#V-て-V-ないで-lt-伴随状态-gt" class="headerlink" title="V-て/V-ないで&lt;伴随状态&gt;"></a>V-て/V-ないで&lt;伴随状态&gt;</h2><p>表示（没有）在前项的伴随状态下进行后项主体动作。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿マスクをして出かけました。</span><br><span class="line">✿ネクタイを締めないで会社に行きます。</span><br></pre></td></tr></table></figure><h2 id="V-て（は）いられない-lt-状态难以持续-gt"><a href="#V-て（は）いられない-lt-状态难以持续-gt" class="headerlink" title="V-て（は）いられない&lt;状态难以持续&gt;"></a>V-て（は）いられない&lt;状态难以持续&gt;</h2><p>表示因为在紧迫的情况下，不能继续那种状态而要急于想付诸另一种行动之意。<br>汉语：不能~，哪能~</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿もう時間がないから、遅れてくる人を待っていられない。すぐ始めよう。</span><br><span class="line">✿こんなに忙しいときに、寝ていられないよ。</span><br></pre></td></tr></table></figure><h2 id="Nによって-lt-原因-gt"><a href="#Nによって-lt-原因-gt" class="headerlink" title="Nによって&lt;原因&gt;"></a>Nによって&lt;原因&gt;</h2><p>表示“<strong>那就是原因</strong>”之意，后续表示结果的词句。讲述已经发生的事情，谓语一般为过去式，多用于书面语。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿私の不注意な発言によって、彼を傷つけた。</span><br><span class="line">✿交通事故によって、電車は三時間も遅れた。</span><br></pre></td></tr></table></figure><h2 id="N-として（は・も・の）-lt-资格性质-gt"><a href="#N-として（は・も・の）-lt-资格性质-gt" class="headerlink" title="N として（は・も・の）&lt;资格性质&gt;"></a>N として（は・も・の）&lt;资格性质&gt;</h2><p>表示动作主体进行某动作时的身份、资格、立场、性质等。<br>汉语：作为~、以~身份、以~立场、以~资格</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿通訳として、一緒に行く。(2011年真题)</span><br><span class="line">✿私としては賛成ですが、ほかの人の意見も聞いてみないと決められない。</span><br><span class="line">✿彼女は母としても妻としても完璧な素晴らしい女性です。</span><br><span class="line">✿私には私としての考えがあります。</span><br></pre></td></tr></table></figure><h2 id="と总结"><a href="#と总结" class="headerlink" title="と总结"></a>と总结</h2><ul><li><p>必然结果，自然现象</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿春になると、花が咲く</span><br><span class="line">✿雨だと明日の試合は中止になります。</span><br><span class="line">✿右に曲がると、大きな建物が見える。</span><br></pre></td></tr></table></figure></li><li><p>契机，发现（ｖたら～た也有该用法）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿デパートに行くと、休みだった。</span><br><span class="line">✿うちへ帰ると、友達が待っていた。</span><br></pre></td></tr></table></figure></li><li><p>习惯动作</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿起きると、すぐ顔を洗う</span><br><span class="line">✿彼は家に帰ると、パソコンに向かっています。</span><br></pre></td></tr></table></figure></li></ul><h2 id="ば总结"><a href="#ば总结" class="headerlink" title="ば总结"></a>ば总结</h2><ul><li><p>必然结果，自然现象（と～也有该用法）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿春になれば、花が咲く。</span><br></pre></td></tr></table></figure></li><li><p>假定条件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿このごろ日本へ行けば、桜が見える。</span><br></pre></td></tr></table></figure></li></ul><p>★注意：<br>1、当假定式为动作或者变化时，后项不能使用ください、たい、ましょう<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">雨が降れば、窓を閉めてください。×</span><br></pre></td></tr></table></figure></p><p>2、当假定式为状态或存在时，后项可以使用ください、たい<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">暑ければ、エアコンをつけてください。〇</span><br></pre></td></tr></table></figure></p><p>3、主句一般不能使用过去式<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">窓を開けば、富士山が見えた。×</span><br></pre></td></tr></table></figure></p><h2 id="たら总结"><a href="#たら总结" class="headerlink" title="たら总结"></a>たら总结</h2><ul><li><p>假定（ば也有该用法）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿安かったら、買う</span><br><span class="line">✿困ったら、電話してね。</span><br></pre></td></tr></table></figure></li><li><p>契机，发现（と也有该用法）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿窓を開けたら、海が見えた。</span><br></pre></td></tr></table></figure></li><li><p>在～之后</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿本を読んだら貸してください。</span><br><span class="line">✿大阪に着いたら電話してください。</span><br></pre></td></tr></table></figure></li></ul><p>★注意：<br>1、たら含有明显的完成之意，特别是前后都是动词时，一定是前项先发生，后项再发生。<br>2、たら后项可使用命令、劝诱、依赖等表达。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Nとは～という意味だ&quot;&gt;&lt;a href=&quot;#Nとは～という意味だ&quot; class=&quot;headerlink&quot; title=&quot;Nとは～という意味だ&quot;&gt;&lt;/a&gt;Nとは～という意味だ&lt;/h2&gt;&lt;p&gt;汉语：~是~的意思&lt;br&gt;★口语：Ｎというのは、～&lt;br&gt;&lt;figure c
      
    
    </summary>
    
      <category term="日语" scheme="https://janvia.github.io/categories/%E6%97%A5%E8%AF%AD/"/>
    
    
      <category term="语法" scheme="https://janvia.github.io/tags/%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>wine安装qq</title>
    <link href="https://janvia.github.io/2019/01/11/wine%E5%AE%89%E8%A3%85qq/"/>
    <id>https://janvia.github.io/2019/01/11/wine安装qq/</id>
    <published>2019-01-11T09:01:02.000Z</published>
    <updated>2019-01-11T13:45:25.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装wine"><a href="#安装wine" class="headerlink" title="安装wine"></a>安装wine</h2><p>下载地址： <a href="https://github.com/wszqkzqk/deepin-wine-ubuntu" target="_blank" rel="noopener">https://github.com/wszqkzqk/deepin-wine-ubuntu</a><br>解压后安装：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo sh ./install.sh</span><br></pre></td></tr></table></figure></p><h2 id="安装QQ、微信"><a href="#安装QQ、微信" class="headerlink" title="安装QQ、微信"></a>安装QQ、微信</h2><p>wine应用下载地址： <a href="http://mirrors.aliyun.com/deepin/pool/non-free/d/" target="_blank" rel="noopener">http://mirrors.aliyun.com/deepin/pool/non-free/d/</a><br>常用下载应用：<br>QQ：      <a href="http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.qq.im/" target="_blank" rel="noopener">http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.qq.im/</a><br>微信：    <a href="http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.wechat/" target="_blank" rel="noopener">http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.wechat/</a><br>Foxmail:  <a href="http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.foxmail/" target="_blank" rel="noopener">http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.foxmail/</a></p><h2 id="异常说明"><a href="#异常说明" class="headerlink" title="异常说明"></a>异常说明</h2><p>微信无法发送图片：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt install libjpeg62:i386</span><br></pre></td></tr></table></figure></p><p>卸载：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt remove 软件包名</span><br></pre></td></tr></table></figure></p><p>比如deepin.com.qq.office_2.0.0deepin4_i386.deb的卸载命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt remove deepin.com.qq.office</span><br></pre></td></tr></table></figure></p><h2 id="托盘图标"><a href="#托盘图标" class="headerlink" title="托盘图标"></a>托盘图标</h2><p>安装icons-plus扩展<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install gnome-shell-extension-top-icons-plus gnome-tweaks</span><br></pre></td></tr></table></figure></p><p>然后在gnome-tweaks里设置</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装wine&quot;&gt;&lt;a href=&quot;#安装wine&quot; class=&quot;headerlink&quot; title=&quot;安装wine&quot;&gt;&lt;/a&gt;安装wine&lt;/h2&gt;&lt;p&gt;下载地址： &lt;a href=&quot;https://github.com/wszqkzqk/deepin-wine
      
    
    </summary>
    
      <category term="linux" scheme="https://janvia.github.io/categories/linux/"/>
    
    
      <category term="qq" scheme="https://janvia.github.io/tags/qq/"/>
    
  </entry>
  
  <entry>
    <title>opencv-图片处理及绘图</title>
    <link href="https://janvia.github.io/2019/01/11/opencv-%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E5%8F%8A%E7%BB%98%E5%9B%BE/"/>
    <id>https://janvia.github.io/2019/01/11/opencv-图片处理及绘图/</id>
    <published>2019-01-11T05:56:33.000Z</published>
    <updated>2019-01-11T08:21:06.630Z</updated>
    
    <content type="html"><![CDATA[<p>原始图片：<br><img src="/2019/01/11/opencv-图片处理及绘图/image2.jpg" title="原始图片"> </p><h2 id="彩色图片灰度化"><a href="#彩色图片灰度化" class="headerlink" title="彩色图片灰度化"></a>彩色图片灰度化</h2><p>方式1：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2  # 导入cv库</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,0)</span><br><span class="line">cv2.imwrite(&apos;gray_image.jpg&apos;,img)</span><br></pre></td></tr></table></figure></p><p>方式2：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">dst = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)# 颜色空间转换 1 data 2 BGR gray</span><br><span class="line">cv2.imshow(&apos;dst&apos;,dst)</span><br></pre></td></tr></table></figure></p><p>方式3<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#方法4 gray = r*0.299+g*0.587+b*0.114</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image0.jpg&apos;,1)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">dst = np.zeros((height,width,3),np.uint8)</span><br><span class="line">for i in range(0,height):</span><br><span class="line">    for j in range(0,width):</span><br><span class="line">        (b,g,r) = img[i,j]</span><br><span class="line">        b = int(b)</span><br><span class="line">        g = int(g)</span><br><span class="line">        r = int(r)</span><br><span class="line">        gray = r*0.299+g*0.587+b*0.114</span><br><span class="line">        dst[i,j] = np.uint8(gray)</span><br><span class="line">cv2.imshow(&apos;dst&apos;,dst)</span><br></pre></td></tr></table></figure></p><img src="/2019/01/11/opencv-图片处理及绘图/gray_image.jpg" title="灰度图片"> <h2 id="马赛克"><a href="#马赛克" class="headerlink" title="马赛克"></a>马赛克</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2 # 导入cv库</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">#cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape  # 获取图片的维度</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">for m in range(200,400):</span><br><span class="line">    for n in range(400,500):</span><br><span class="line">        # pixel -&gt;10*10</span><br><span class="line">        if m%10 == 0 and n%10==0:</span><br><span class="line">            for i in range(0,10):</span><br><span class="line">                for j in range(0,10):</span><br><span class="line">                    (b,g,r) = img[m,n]</span><br><span class="line">                    img[i+m,j+n] = (b,g,r)</span><br><span class="line">cv2.imwrite(&apos;msk.jpg&apos;,img)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片处理及绘图/msk.jpg" title="马赛克图片"> <h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><p>方式1：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import random</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">#cv2.imshow(&apos;src&apos;,img)</span><br><span class="line"></span><br><span class="line">#canny 1 gray 2 高斯 3 canny</span><br><span class="line">gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line">imgG = cv2.GaussianBlur(gray,(3,3),0)</span><br><span class="line">dst = cv2.Canny(img,50,50) #图片卷积——》th</span><br><span class="line">#cv2.imshow(&apos;dst&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;canny.jpg&apos;,dst)</span><br></pre></td></tr></table></figure></p><img src="/2019/01/11/opencv-图片处理及绘图/canny.jpg" title="边缘检查图片一"> <p>方式2：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import random</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;, 1)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">#cv2.imshow(&apos;src&apos;, img)</span><br><span class="line"></span><br><span class="line"># sobel 1 算子模版 2 图片卷积 3 阈值判决</span><br><span class="line"># [1 2 1          [ 1 0 -1</span><br><span class="line">#  0 0 0            2 0 -2</span><br><span class="line"># -1 -2 -1 ]       1 0 -1 ]</span><br><span class="line"></span><br><span class="line"># [1 2 3 4] [a b c d] a*1+b*2+c*3+d*4 = dst</span><br><span class="line"># sqrt(a*a+b*b) = f&gt;th</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">dst = np.zeros((height, width, 1), np.uint8)</span><br><span class="line">for i in range(0, height - 2):</span><br><span class="line">    for j in range(0, width - 2):</span><br><span class="line">        gy = gray[i, j] * 1 + gray[i, j + 1] * 2 + gray[i, j + 2] * 1 - gray[i + 2, j] * 1 - gray[i + 2, j + 1] * 2 - \</span><br><span class="line">             gray[i + 2, j + 2] * 1</span><br><span class="line">        gx = gray[i, j] + gray[i + 1, j] * 2 + gray[i + 2, j] - gray[i, j + 2] - gray[i + 1, j + 2] * 2 - gray[</span><br><span class="line">            i + 2, j + 2]</span><br><span class="line">        grad = math.sqrt(gx * gx + gy * gy)</span><br><span class="line">        if grad &gt; 50:</span><br><span class="line">            dst[i, j] = 255</span><br><span class="line">        else:</span><br><span class="line">            dst[i, j] = 0</span><br><span class="line">cv2.imwrite(&apos;sobel.jpg&apos;,dst)</span><br></pre></td></tr></table></figure></p><img src="/2019/01/11/opencv-图片处理及绘图/sobel.jpg" title="边缘检测图片二"> <h2 id="颜色风格变化"><a href="#颜色风格变化" class="headerlink" title="颜色风格变化"></a>颜色风格变化</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">#cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">#rgb -》RGB new “蓝色”</span><br><span class="line"># b=b*1.5</span><br><span class="line"># g = g*1.3</span><br><span class="line">dst = np.zeros((height,width,3),np.uint8)</span><br><span class="line">for i in range(0,height):</span><br><span class="line">    for j in range(0,width):</span><br><span class="line">        (b,g,r) = img[i,j]</span><br><span class="line">        b = b*1.5</span><br><span class="line">        g = g*1.3</span><br><span class="line">        if b&gt;255:</span><br><span class="line">            b = 255</span><br><span class="line">        if g&gt;255:</span><br><span class="line">            g = 255</span><br><span class="line">        dst[i,j]=(b,g,r)</span><br><span class="line">#cv2.imshow(&apos;dst&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;dst2.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片处理及绘图/dst2.jpg" title="颜色风格变化效果"> <h2 id="油画特效"><a href="#油画特效" class="headerlink" title="油画特效"></a>油画特效</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">#cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line">dst = np.zeros((height,width,3),np.uint8)</span><br><span class="line">for i in range(4,height-4):</span><br><span class="line">    for j in range(4,width-4):</span><br><span class="line">        array1 = np.zeros(8,np.uint8)</span><br><span class="line">        for m in range(-4,4):</span><br><span class="line">            for n in range(-4,4):</span><br><span class="line">                p1 = int(gray[i+m,j+n]/32)</span><br><span class="line">                array1[p1] = array1[p1]+1</span><br><span class="line">        currentMax = array1[0]</span><br><span class="line">        l = 0</span><br><span class="line">        for k in range(0,8):</span><br><span class="line">            if currentMax&lt;array1[k]:</span><br><span class="line">                currentMax = array1[k]</span><br><span class="line">                l = k</span><br><span class="line">        # 简化 均值</span><br><span class="line">        for m in range(-4,4):</span><br><span class="line">            for n in range(-4,4):</span><br><span class="line">                if gray[i+m,j+n]&gt;=(l*32) and gray[i+m,j+n]&lt;=((l+1)*32):</span><br><span class="line">                    (b,g,r) = img[i+m,j+n]</span><br><span class="line">        dst[i,j] = (b,g,r)</span><br><span class="line">cv2.imwrite(&apos;dst3.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片处理及绘图/dst3.jpg" title="油画效果"> <h2 id="线段绘制"><a href="#线段绘制" class="headerlink" title="线段绘制"></a>线段绘制</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">newImageInfo = (500,500,3)</span><br><span class="line">dst = np.zeros(newImageInfo,np.uint8)</span><br><span class="line"># line</span><br><span class="line"># 绘制线段 1 dst 2 begin 3 end 4 color</span><br><span class="line">cv2.line(dst,(100,100),(400,400),(0,0,255))</span><br><span class="line"># 5 line w</span><br><span class="line">cv2.line(dst,(100,200),(400,200),(0,255,255),20)</span><br><span class="line"># 6 line type</span><br><span class="line">cv2.line(dst,(100,300),(400,300),(0,255,0),20,cv2.LINE_AA)</span><br><span class="line"></span><br><span class="line">cv2.imwrite(&apos;line.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片处理及绘图/line.jpg" title="绘制线段"> <h2 id="绘制矩形、圆形"><a href="#绘制矩形、圆形" class="headerlink" title="绘制矩形、圆形"></a>绘制矩形、圆形</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">newImageInfo = (500,500,3)</span><br><span class="line">dst = np.zeros(newImageInfo,np.uint8)</span><br><span class="line">#  1 2 左上角 3 右下角 4 5 fill -1 &gt;0 line w</span><br><span class="line">cv2.rectangle(dst,(50,100),(200,300),(255,0,0),5)</span><br><span class="line"># 2 center 3 r</span><br><span class="line">cv2.circle(dst,(300,100),(50),(0,255,0),2)</span><br><span class="line"># 2 center 3 轴(a,b) 4 angle 5 begin 6 end 7</span><br><span class="line">cv2.ellipse(dst,(256,350),(150,100),30,0,360,(255,255,0),-1)</span><br><span class="line"></span><br><span class="line">points = np.array([[350,50],[140,140],[200,170],[250,250],[350,50]],np.int32)</span><br><span class="line">print(points.shape)</span><br><span class="line">points = points.reshape((-1,1,2))</span><br><span class="line">print(points.shape)</span><br><span class="line">cv2.polylines(dst,[points],True,(0,0,255))</span><br><span class="line">cv2.imwrite(&apos;dst4.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片处理及绘图/dst4.jpg" title="绘制形状"> <h2 id="添加文字"><a href="#添加文字" class="headerlink" title="添加文字"></a>添加文字</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">font = cv2.FONT_HERSHEY_SIMPLEX</span><br><span class="line">cv2.rectangle(img,(400,300),(950,900),(0,255,0),3)</span><br><span class="line"># 1 dst 2 文字内容 3 坐标 4 5 字体大小 6 color 7 粗细 8 line type</span><br><span class="line">cv2.putText(img,&apos;this is flower&apos;,(500,500),font,2,(200,100,255),3,cv2.LINE_AA)</span><br><span class="line">cv2.imwrite(&apos;word.jpg&apos;,img)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片处理及绘图/word.jpg" title="文字添加"> ]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原始图片：&lt;br&gt;&lt;img src=&quot;/2019/01/11/opencv-图片处理及绘图/image2.jpg&quot; title=&quot;原始图片&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;彩色图片灰度化&quot;&gt;&lt;a href=&quot;#彩色图片灰度化&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="计算机视觉" scheme="https://janvia.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像美化" scheme="https://janvia.github.io/tags/%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>opencv-图片几何变换</title>
    <link href="https://janvia.github.io/2019/01/11/opencv-%E5%9B%BE%E7%89%87%E5%87%A0%E4%BD%95%E5%8F%98%E6%8D%A2/"/>
    <id>https://janvia.github.io/2019/01/11/opencv-图片几何变换/</id>
    <published>2019-01-11T01:52:03.000Z</published>
    <updated>2019-01-11T02:42:24.091Z</updated>
    
    <content type="html"><![CDATA[<p>原始图片：<br><img src="/2019/01/11/opencv-图片几何变换/image1.jpg" title="原始图片"> </p><h2 id="图片缩放一"><a href="#图片缩放一" class="headerlink" title="图片缩放一"></a>图片缩放一</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2  # 导入cv库</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1)  # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">imgInfo = img.shape # 获取图片的维度</span><br><span class="line">print(imgInfo)</span><br><span class="line">height = imgInfo[0] </span><br><span class="line">width = imgInfo[1]</span><br><span class="line">mode = imgInfo[2]</span><br><span class="line"># 1 放大 缩小 2 等比例 非 2:3 </span><br><span class="line">dstHeight = int(height*0.5)</span><br><span class="line">dstWidth = int(width*0.5)</span><br><span class="line">#最近临域插值 双线性插值 像素关系重采样 立方插值</span><br><span class="line">dst = cv2.resize(img,(dstWidth,dstHeight))</span><br><span class="line">#cv2.imshow(&apos;image&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;resize_image.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片几何变换/resize_image.jpg" title="resize的图片"> <h2 id="图片缩放二"><a href="#图片缩放二" class="headerlink" title="图片缩放二"></a>图片缩放二</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2 # 导入cv库</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">#cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape  # 获取图片的维度</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">matScale = np.float32([[0.5,0,0],[0,0.5,0]]) # 定义缩放矩阵</span><br><span class="line">dst = cv2.warpAffine(img,matScale,(int(width/2),int(height/2))) # 原始数据，缩放矩阵，目标的宽高信息</span><br><span class="line">cv2.imwrite(&apos;warp_image.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片几何变换/warp_image.jpg" title="matScale的图片"> <h2 id="图片剪切"><a href="#图片剪切" class="headerlink" title="图片剪切"></a>图片剪切</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2  # 导入cv库</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1)  # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">#imgInfo = img.shape</span><br><span class="line">print(img.shape)</span><br><span class="line">dst = img[100:600,250:800] # 获取宽度100-600， 高度250-800的图像</span><br><span class="line"></span><br><span class="line">cv2.imwrite(&apos;cut_image.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片几何变换/cut_image.jpg" title="剪切的图片"> <h2 id="图片镜像"><a href="#图片镜像" class="headerlink" title="图片镜像"></a>图片镜像</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2 # 导入cv库</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape  # 获取图片的维度</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">deep = imgInfo[2]</span><br><span class="line">newImgInfo = (height*2,width,deep) # 新图片的维度</span><br><span class="line">dst = np.zeros(newImgInfo,np.uint8)#uint8 # 目标图片的数据维度</span><br><span class="line"># 刷新图片的数据</span><br><span class="line">for i in range(0,height):</span><br><span class="line">    for j in range(0,width):</span><br><span class="line">        dst[i,j] = img[i,j]</span><br><span class="line">        #x y = 2*h - y -1</span><br><span class="line">        dst[height*2-i-1,j] = img[i,j]</span><br><span class="line">for i in range(0,width): # 添加分割线</span><br><span class="line">    dst[height,i] = (0,0,255)#BGR</span><br><span class="line">cv2.imshow(&apos;dst&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片几何变换/dst_image.jpg" title="镜像图片"> <h2 id="图片旋转"><a href="#图片旋转" class="headerlink" title="图片旋转"></a>图片旋转</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2 # 导入cv库</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape  # 获取图片的维度</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line"># 2*3 定义旋转矩阵--旋转的中心点，旋转的角度， 缩放系数</span><br><span class="line">matRotate = cv2.getRotationMatrix2D((height*0.5,width*0.5),45,1)# mat rotate 1 center 2 angle 3 scale</span><br><span class="line">#100*100 25</span><br><span class="line">dst = cv2.warpAffine(img,matRotate,(height,width)) # 仿射方法</span><br><span class="line">#cv2.imshow(&apos;dst&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;rotate_image.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片几何变换/rotate_image.jpg" title="旋转图片"> <h2 id="图片仿射变换"><a href="#图片仿射变换" class="headerlink" title="图片仿射变换"></a>图片仿射变换</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2 # 导入cv库</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape  # 获取图片的维度</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">#src 3-&gt;dst 3 (左上角 左下角 右上角)</span><br><span class="line">matSrc = np.float32([[0,0],[0,height-1],[width-1,0]]) # 获取原图片三个点坐标</span><br><span class="line">matDst = np.float32([[50,50],[300,height-200],[width-300,100]]) # 三个点的新坐标</span><br><span class="line">#把两个矩阵组合</span><br><span class="line">matAffine = cv2.getAffineTransform(matSrc,matDst) # 获取矩阵的组合，</span><br><span class="line">dst = cv2.warpAffine(img,matAffine,(width,height)) # 仿射变换方法</span><br><span class="line">#cv2.imshow(&apos;dst&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;aft_image.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/11/opencv-图片几何变换/aft_image.jpg" title="仿射变换图片"> ]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原始图片：&lt;br&gt;&lt;img src=&quot;/2019/01/11/opencv-图片几何变换/image1.jpg&quot; title=&quot;原始图片&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;图片缩放一&quot;&gt;&lt;a href=&quot;#图片缩放一&quot; class=&quot;headerlink&quot; title=&quot;图片缩
      
    
    </summary>
    
      <category term="计算机视觉" scheme="https://janvia.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像美化" scheme="https://janvia.github.io/tags/%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>markdown</title>
    <link href="https://janvia.github.io/2019/01/09/markdown/"/>
    <id>https://janvia.github.io/2019/01/09/markdown/</id>
    <published>2019-01-09T09:06:13.000Z</published>
    <updated>2019-01-09T14:16:34.977Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h3 id="粗体、斜体"><a href="#粗体、斜体" class="headerlink" title="粗体、斜体"></a>粗体、斜体</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*这是斜体*</span><br><span class="line">**这是粗体**</span><br><span class="line">***这是粗体+斜体***</span><br></pre></td></tr></table></figure><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">~~就像这样~~</span><br></pre></td></tr></table></figure><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>通过在行首加上大于号&gt;来添加引用格式。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; This is the first level of quoting.</span><br><span class="line">&gt;</span><br><span class="line">&gt; &gt; This is nested blockquote.</span><br><span class="line">&gt;</span><br><span class="line">&gt; Back to the first level.</span><br></pre></td></tr></table></figure></p><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>无序列表使用星号、加号或是减号作为列表标记：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*   Red</span><br><span class="line">*   Green</span><br><span class="line">*   Blue</span><br></pre></td></tr></table></figure></p><h3 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">* * *</span><br><span class="line">***</span><br><span class="line">*****</span><br><span class="line">- - -</span><br><span class="line">---------------------------------------</span><br></pre></td></tr></table></figure><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[an example](http://example.com/)</span><br><span class="line">[an example](http://example.com/ &quot;Optional Title&quot;)</span><br></pre></td></tr></table></figure><h3 id="图像"><a href="#图像" class="headerlink" title="图像"></a>图像</h3><h4 id="普通方式"><a href="#普通方式" class="headerlink" title="普通方式"></a>普通方式</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">![Alt text](/path/to/img.jpg)</span><br><span class="line">![Alt text](/path/to/img.jpg &quot;Optional Title&quot;)</span><br></pre></td></tr></table></figure><h4 id="通过管理文件夹"><a href="#通过管理文件夹" class="headerlink" title="通过管理文件夹"></a>通过管理文件夹</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% asset_path slug %&#125;</span><br><span class="line">&#123;% asset_img slug [title] %&#125;</span><br><span class="line">&#123;% asset_link slug [title] %&#125;</span><br></pre></td></tr></table></figure><h4 id="通过图床引用"><a href="#通过图床引用" class="headerlink" title="通过图床引用"></a>通过图床引用</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;figure class=&quot;half&quot;&gt;</span><br><span class="line">    &lt;img src=&quot;http://address.com/images/image.png&quot; title=&quot;title1&quot;/&gt;</span><br><span class="line">    &lt;img src=&quot;http://path/image.png&quot; title=&quot;title2&quot;/&gt;</span><br><span class="line">&lt;/figure&gt;</span><br></pre></td></tr></table></figure><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Item     | Value | Qty   |</span><br><span class="line">| :------- | ----: | :---: |</span><br><span class="line">| Computer | $1600 |  5    |</span><br><span class="line">| Phone    | $12   |  12   |</span><br><span class="line">| Pipe     | $1    |  234  |</span><br></pre></td></tr></table></figure><h3 id="TeX公式"><a href="#TeX公式" class="headerlink" title="TeX公式"></a>TeX公式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">\Gamma(z) = \int_0^\infty t^&#123;z-1&#125;e^&#123;-t&#125;dt\,.</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;粗体、斜体&quot;&gt;&lt;a href=&quot;#粗体、斜体&quot; class=&quot;headerlink&quot; title=&quot;粗体、斜体&quot;&gt;&lt;/a&gt;粗体、斜体&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;
      
    
    </summary>
    
      <category term="工具" scheme="https://janvia.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="markdown" scheme="https://janvia.github.io/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>opencv图像美化</title>
    <link href="https://janvia.github.io/2019/01/09/opencv%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%8C%96/"/>
    <id>https://janvia.github.io/2019/01/09/opencv图像美化/</id>
    <published>2019-01-09T01:54:29.000Z</published>
    <updated>2019-01-09T14:40:56.158Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h2 id="直方图均衡化-灰度"><a href="#直方图均衡化-灰度" class="headerlink" title="直方图均衡化-灰度"></a>直方图均衡化-灰度</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # 图片灰度化</span><br><span class="line">cv2.imshow(&apos;gray&apos;,gray)</span><br><span class="line">cv2.imwrite(&apos;gray2.jpg&apos;,gray)</span><br><span class="line">hist = cv2.equalizeHist(gray) # api 完成直方图均衡化</span><br><span class="line">cv2.imshow(&apos;hist&apos;,hist)</span><br><span class="line">cv2.imwrite(&apos;hist2.jpg&apos;,hist)</span><br><span class="line">cv2.waitKey(0)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/gray1.jpg" title="gray"> <img src="/2019/01/09/opencv图像美化/hist1.jpg" title="hist"><h2 id="直方图均衡化-彩色"><a href="#直方图均衡化-彩色" class="headerlink" title="直方图均衡化-彩色"></a>直方图均衡化-彩色</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">(b,g,r) = cv2.split(img) # 通道分解</span><br><span class="line"># 图片单通道处理</span><br><span class="line">bH = cv2.equalizeHist(b)</span><br><span class="line">gH = cv2.equalizeHist(g)</span><br><span class="line">rH = cv2.equalizeHist(r)</span><br><span class="line">result = cv2.merge((bH,gH,rH))# 通道合成</span><br><span class="line">cv2.imshow(&apos;dst&apos;,result)</span><br><span class="line">cv2.imwrite(&apos;dst2.jpg&apos;,result)</span><br><span class="line">cv2.waitKey(0)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/image2.jpg" title="image.jpg"> <img src="/2019/01/09/opencv图像美化/dst2.jpg" title="result.jpg"><h2 id="直方图均衡化-YUV"><a href="#直方图均衡化-YUV" class="headerlink" title="直方图均衡化-YUV"></a>直方图均衡化-YUV</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">imgYUV = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb) #</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">channelYUV = cv2.split(imgYUV) # 图片分解</span><br><span class="line">channelYUV[0] = cv2.equalizeHist(channelYUV[0]) # 直方图均衡化</span><br><span class="line">channels = cv2.merge(channelYUV) # 合成</span><br><span class="line">result = cv2.cvtColor(channels,cv2.COLOR_YCrCb2BGR)</span><br><span class="line">cv2.imshow(&apos;result2&apos;,result)</span><br><span class="line">cv2.imwrite(&apos;result2.jpg&apos;,result)</span><br><span class="line">cv2.waitKey(0)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/image2.jpg" title="image.jpg"> <img src="/2019/01/09/opencv图像美化/result2.jpg" title="result.jpg"><h2 id="图片修补"><a href="#图片修补" class="headerlink" title="图片修补"></a>图片修补</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">#制作一张损坏的图片</span><br><span class="line"></span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)  # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">for i in range(1,100):  # 总共一百个像素点</span><br><span class="line">    img[500+i,500] = (255,255,255)  # 写入标准的白色</span><br><span class="line">cv2.imwrite(&apos;damaged.jpg&apos;,img)</span><br><span class="line"></span><br><span class="line">#修补损坏的图片</span><br><span class="line"></span><br><span class="line">img = cv2.imread(&apos;damaged.jpg&apos;,1)</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">paint = np.zeros((height,width,1),np.uint8)</span><br><span class="line"># 描绘图片坏的数组；进行修补</span><br><span class="line">for i in range(500,600):</span><br><span class="line">    paint[i,500] = 255</span><br><span class="line">cv2.imshow(&apos;paint&apos;,paint)</span><br><span class="line">#1 src 2 mask</span><br><span class="line">imgDst = cv2.inpaint(img,paint,3,cv2.INPAINT_TELEA)</span><br><span class="line"></span><br><span class="line">cv2.imshow(&apos;image&apos;,imgDst)</span><br><span class="line">cv2.imwrite(&apos;imgDst.jpg&apos;,imgDst)</span><br><span class="line">cv2.waitKey(0)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/damaged.jpg" title="损坏的图片"> <img src="/2019/01/09/opencv图像美化/imgDst.jpg" title="修补后的图片"><h2 id="亮度增强"><a href="#亮度增强" class="headerlink" title="亮度增强"></a>亮度增强</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image2.jpg&apos;,1)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">dst = np.zeros((height,width,3),np.uint8)</span><br><span class="line">for i in range(0,height):</span><br><span class="line">    for j in range(0,width):</span><br><span class="line">        (b,g,r) = img[i,j]</span><br><span class="line">        bb = int(b)+40</span><br><span class="line">        gg = int(g)+40</span><br><span class="line">        rr = int(r)+40</span><br><span class="line">        if bb&gt;255:</span><br><span class="line">            bb = 255</span><br><span class="line">        if gg&gt;255:</span><br><span class="line">            gg = 255</span><br><span class="line">        if rr&gt;255:</span><br><span class="line">            rr = 255</span><br><span class="line">        dst[i,j] = (bb,gg,rr)</span><br><span class="line">cv2.imshow(&apos;dst3&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;dst3.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/image2.jpg" title="原始图片"> <img src="/2019/01/09/opencv图像美化/dst3.jpg" title="增强亮度的图片"><h2 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1)</span><br><span class="line">cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">dst = cv2.GaussianBlur(img,(5,5),1.5)</span><br><span class="line">cv2.imwrite(&apos;dst4.jpg&apos;,dst)</span><br><span class="line">cv2.imshow(&apos;dst4&apos;,dst)</span><br><span class="line">cv2.waitKey(0)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/image1.jpg" title="原始图片"> <img src="/2019/01/09/opencv图像美化/dst4.jpg" title="高斯滤波后的图片"><h2 id="均值滤波"><a href="#均值滤波" class="headerlink" title="均值滤波"></a>均值滤波</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 均值 6*6 1 。 * 【6*6】/36 = mean -》P</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;, 1)</span><br><span class="line">#cv2.imshow(&apos;src&apos;, img)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">dst = np.zeros((height, width, 3), np.uint8)</span><br><span class="line">for i in range(3, height - 3):</span><br><span class="line">    for j in range(3, width - 3):</span><br><span class="line">        sum_b = int(0)</span><br><span class="line">        sum_g = int(0)</span><br><span class="line">        sum_r = int(0)</span><br><span class="line">        for m in range(-3, 3):  # -3 -2 -1 0 1 2</span><br><span class="line">            for n in range(-3, 3):</span><br><span class="line">                (b, g, r) = img[i + m, j + n]</span><br><span class="line">                sum_b = sum_b + int(b)</span><br><span class="line">                sum_g = sum_g + int(g)</span><br><span class="line">                sum_r = sum_r + int(r)</span><br><span class="line"></span><br><span class="line">        b = np.uint8(sum_b / 36)</span><br><span class="line">        g = np.uint8(sum_g / 36)</span><br><span class="line">        r = np.uint8(sum_r / 36)</span><br><span class="line">        dst[i, j] = (b, g, r)</span><br><span class="line">cv2.imshow(&apos;dst5&apos;, dst)</span><br><span class="line">cv2.imwrite(&apos;dst5.jpg&apos;, dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/image1.jpg" title="原始图片"> <img src="/2019/01/09/opencv图像美化/dst5.jpg" title="均值滤波后的图片"><h2 id="中值滤波"><a href="#中值滤波" class="headerlink" title="中值滤波"></a>中值滤波</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">img = cv2.imread(&apos;image1.jpg&apos;,1)</span><br><span class="line">imgInfo = img.shape</span><br><span class="line">height = imgInfo[0]</span><br><span class="line">width = imgInfo[1]</span><br><span class="line">img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)</span><br><span class="line">#cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">cv2.imwrite(&apos;src6.jpg&apos;,img)</span><br><span class="line">dst = np.zeros((height,width,3),np.uint8)</span><br><span class="line">collect = np.zeros(9,np.uint8)</span><br><span class="line">for i in range(1,height-1):</span><br><span class="line">    for j in range(1,width-1):</span><br><span class="line">        k = 0</span><br><span class="line">        for m in range(-1,2):</span><br><span class="line">            for n in range(-1,2):</span><br><span class="line">                gray = img[i+m,j+n]</span><br><span class="line">                collect[k] = gray</span><br><span class="line">                k = k+1</span><br><span class="line">        # 0 1 2 3 4 5 6 7 8</span><br><span class="line">        #   1 </span><br><span class="line">        for k in range(0,9):</span><br><span class="line">            p1 = collect[k]</span><br><span class="line">            for t in range(k+1,9):</span><br><span class="line">                if p1&lt;collect[t]:</span><br><span class="line">                    mid = collect[t]</span><br><span class="line">                    collect[t] = p1</span><br><span class="line">                    p1 = mid</span><br><span class="line">        dst[i,j] = collect[4]</span><br><span class="line">#cv2.imshow(&apos;dst&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;dst6.jpg&apos;,dst)</span><br></pre></td></tr></table></figure><img src="/2019/01/09/opencv图像美化/src6.jpg" title="灰度图片"> <img src="/2019/01/09/opencv图像美化/dst6.jpg" title="中值滤波后的灰度图片"><h2 id="皮肤磨皮美白-双边滤波"><a href="#皮肤磨皮美白-双边滤波" class="headerlink" title="皮肤磨皮美白-双边滤波"></a>皮肤磨皮美白-双边滤波</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">img = cv2.imread(&apos;image3.png&apos;,1)</span><br><span class="line">#cv2.imshow(&apos;src&apos;,img)</span><br><span class="line">dst = cv2.bilateralFilter(img,15,35,35) # 滤波函数</span><br><span class="line">#cv2.imshow(&apos;dst&apos;,dst)</span><br><span class="line">cv2.imwrite(&apos;dst7.png&apos;,dst)</span><br></pre></td></tr></table></figure><figure class="half"><br>    <img src="http://pkxzrpxol.bkt.clouddn.com/images/image3.png" title="美白前的图片"><br>    <img src="http://pkxzrpxol.bkt.clouddn.com/images/dst7.png" title="美白后的图片"><br></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;直方图均衡化-灰度&quot;&gt;&lt;a href=&quot;#直方图均衡化-灰度&quot; class=&quot;headerlink&quot; title=&quot;直方图均衡化-灰度&quot;&gt;&lt;/a&gt;直方图均衡化-灰度&lt;/h2&gt;&lt;figure class=&quot;highlight pl
      
    
    </summary>
    
      <category term="计算机视觉" scheme="https://janvia.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="图像美化" scheme="https://janvia.github.io/tags/%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>linux常用工具</title>
    <link href="https://janvia.github.io/2019/01/07/linux%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    <id>https://janvia.github.io/2019/01/07/linux常用工具/</id>
    <published>2019-01-07T09:07:32.000Z</published>
    <updated>2019-01-07T09:17:38.740Z</updated>
    
    <content type="html"><![CDATA[<h2 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h2><h3 id="ubantu换源"><a href="#ubantu换源" class="headerlink" title="ubantu换源"></a>ubantu换源</h3><p>阿里源<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo python3 -c &quot;d=&apos;mirrors.aliyun.com&apos;;import re;from pathlib import Path;p=Path(&apos;/etc/apt/sources.list&apos;);s=p.read_text();bak=p.with_name(p.name+&apos;.bak&apos;);bak.exists() or bak.write_text(s);p.write_text(re.sub(r&apos;(cn.archive|security|archive)\.ubuntu\.com&apos;, d, s))&quot;</span><br></pre></td></tr></table></figure></p><h3 id="pip换源"><a href="#pip换源" class="headerlink" title="pip换源"></a>pip换源</h3><p>修改或创建 ~/.pip/pip.conf ：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure></p><h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><h3 id="tar格式"><a href="#tar格式" class="headerlink" title=".tar格式"></a>.tar格式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 打包</span><br><span class="line"> tar -cvf  文件名.tar   # 要打包的文件</span><br><span class="line"></span><br><span class="line"># 解包</span><br><span class="line"> tar  -xvf  文件名.tar</span><br><span class="line"></span><br><span class="line">#查看包里的内容</span><br><span class="line">tar -tvf 包的文件名.tar</span><br></pre></td></tr></table></figure><h3 id="gz格式"><a href="#gz格式" class="headerlink" title=".gz格式"></a>.gz格式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zcvf  xxx.tar.gz  文件 # 压缩</span><br><span class="line">tar -zxvf  xxx.tar.gz 文件  # 解压</span><br><span class="line"># 解压到指定目录 </span><br><span class="line">tar -zxvf xxx.tar.gz -C dirname</span><br></pre></td></tr></table></figure><h3 id="bz2格式"><a href="#bz2格式" class="headerlink" title=".bz2格式"></a>.bz2格式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -jcvf  xxx.tar.bz2  文件  # 压缩</span><br><span class="line">tar -jxvf  xxx.tar.bz2       # 解压</span><br></pre></td></tr></table></figure><h3 id="zip格式"><a href="#zip格式" class="headerlink" title=".zip格式"></a>.zip格式</h3><p>安装<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install zip</span><br></pre></td></tr></table></figure></p><p>使用<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">压缩文件</span><br><span class="line">zip  压缩文件  源文件</span><br><span class="line"></span><br><span class="line">解压 </span><br><span class="line">unzip  压缩文件</span><br><span class="line">-d 解压到指定目录   如果目录不存在 会自动创建新目录 并压缩进去</span><br><span class="line">unzip test.zip -d filename</span><br></pre></td></tr></table></figure></p><h2 id="vim编辑器"><a href="#vim编辑器" class="headerlink" title="vim编辑器"></a>vim编辑器</h2><p>工作模式：命令模式、输入模式、末行模式</p><h3 id="模式切换"><a href="#模式切换" class="headerlink" title="模式切换"></a>模式切换</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">当打开一个文件时处于命令模式</span><br><span class="line">在命令模式下，按 i 进入输入模式</span><br><span class="line">在输入模式，按ESC回到命令模式。</span><br><span class="line">在命令模式下，按shift+; ，末行出现:冒号，则进入末行模式</span><br></pre></td></tr></table></figure><h3 id="进入与退出"><a href="#进入与退出" class="headerlink" title="进入与退出"></a>进入与退出</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">进入</span><br><span class="line">    vim   filename</span><br><span class="line">退出</span><br><span class="line">    :wq    末行模式，wq 保存退出</span><br><span class="line">    :q       末行模式，q 直接退出</span><br><span class="line">    :q!      末行模式，q! 强制退出，不保存</span><br></pre></td></tr></table></figure><h3 id="复制与粘贴"><a href="#复制与粘贴" class="headerlink" title="复制与粘贴"></a>复制与粘贴</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">复制和粘贴</span><br><span class="line">    yy    复制整行内容</span><br><span class="line">    3yy  复制3行内容</span><br><span class="line">    yw   复制当前光标到单词尾内容</span><br><span class="line"></span><br><span class="line">    p      粘贴</span><br></pre></td></tr></table></figure><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">删除</span><br><span class="line">    dd  删除光标所在行</span><br><span class="line">    dw  删除一个单词</span><br><span class="line">    x     删除光标所在字符</span><br><span class="line">    u    撤销上一次操作</span><br><span class="line">    s     替换</span><br><span class="line">    ctrl + r    撤销</span><br></pre></td></tr></table></figure><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查找</span><br><span class="line">    /    命令模式下输入：/   向前搜索     不能空格</span><br><span class="line">    ?    命令模式下输入：?   向后搜索</span><br><span class="line"># / 方式</span><br><span class="line">    n    向下查找</span><br><span class="line">    N   向上查找</span><br><span class="line"># ? 方式</span><br><span class="line">    n    向上查找</span><br><span class="line">    N   向下查找</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;换源&quot;&gt;&lt;a href=&quot;#换源&quot; class=&quot;headerlink&quot; title=&quot;换源&quot;&gt;&lt;/a&gt;换源&lt;/h2&gt;&lt;h3 id=&quot;ubantu换源&quot;&gt;&lt;a href=&quot;#ubantu换源&quot; class=&quot;headerlink&quot; title=&quot;ubantu换源&quot;
      
    
    </summary>
    
      <category term="linux" scheme="https://janvia.github.io/categories/linux/"/>
    
    
      <category term="工具" scheme="https://janvia.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>opencv基础</title>
    <link href="https://janvia.github.io/2019/01/07/opencv/"/>
    <id>https://janvia.github.io/2019/01/07/opencv/</id>
    <published>2019-01-07T06:34:19.000Z</published>
    <updated>2019-01-09T14:17:43.506Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># pip</span><br><span class="line">pip3 install opencv-python</span><br><span class="line"># conda</span><br><span class="line">conda install --channel https://conda.anaconda.org/menpo opencv3</span><br><span class="line"># conda虚拟环境</span><br><span class="line">source activate 环境名</span><br><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure><h2 id="读取与展示"><a href="#读取与展示" class="headerlink" title="读取与展示"></a>读取与展示</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2  # 导入cv库</span><br><span class="line"></span><br><span class="line">img = cv2.imread(&apos;image0.jpg&apos;,1)  # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">cv2.imshow(&apos;image&apos;,img)  # 显示图片</span><br><span class="line"></span><br><span class="line">cv2.waitKey(0) # 没有会一闪而过</span><br></pre></td></tr></table></figure><h2 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2 # 导入cv库</span><br><span class="line">img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">cv2.imwrite(&apos;image1.jpg&apos;,img) # 写入文件名字 ， 图片数据</span><br></pre></td></tr></table></figure><h2 id="有损压缩"><a href="#有损压缩" class="headerlink" title="有损压缩"></a>有损压缩</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2 # 导入cv库</span><br><span class="line">img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">cv2.imwrite(&apos;imageTest.jpg&apos;,img,[cv2.IMWRITE_JPEG_QUALITY,50]) # 写入文件名字 ， 图片数据 ， 当前jpg图片保存的质量（范围0-100）</span><br><span class="line">#1M 100k 10k 0-100 有损压缩</span><br></pre></td></tr></table></figure><h2 id="无损压缩"><a href="#无损压缩" class="headerlink" title="无损压缩"></a>无损压缩</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 1 无损 2 透明度属性</span><br><span class="line">import cv2  # 导入cv库</span><br><span class="line">img = cv2.imread(&apos;image0.jpg&apos;,1)  # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">cv2.imwrite(&apos;imageTest.png&apos;,img,[cv2.IMWRITE_PNG_COMPRESSION,0])  # 写入文件名字 ， 图片数据 ， 当前jpg图片保存的质量（范围0-100）</span><br><span class="line"># jpg 0 压缩比高0-100 png 0 压缩比低0-9</span><br></pre></td></tr></table></figure><h2 id="像素操作"><a href="#像素操作" class="headerlink" title="像素操作"></a>像素操作</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cv2  # 导入cv库 </span><br><span class="line">img = cv2.imread(&apos;image0.jpg&apos;,1)  # 读取图片文件， 1：彩色， 0：灰色</span><br><span class="line">(b,g,r) = img[100,100] # 获取图片的（100,100）坐标的像素值，按照bgr的形式读取</span><br><span class="line">print(b,g,r)# bgr</span><br><span class="line">#10 100 --- 110 100</span><br><span class="line">for i in range(1,100):  # 总共一百个像素点</span><br><span class="line">    img[10+i,100] = (255,0,0)  # 写入标准的蓝色</span><br><span class="line">cv2.imshow(&apos;image&apos;,img)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;c
      
    
    </summary>
    
      <category term="计算机视觉" scheme="https://janvia.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="opencv" scheme="https://janvia.github.io/tags/opencv/"/>
    
  </entry>
  
  <entry>
    <title>敬语</title>
    <link href="https://janvia.github.io/2019/01/06/%E6%95%AC%E8%AF%AD/"/>
    <id>https://janvia.github.io/2019/01/06/敬语/</id>
    <published>2019-01-06T04:11:05.000Z</published>
    <updated>2019-01-09T14:18:51.445Z</updated>
    
    <content type="html"><![CDATA[<p>敬语用于对会话中涉及的人物或者听话人表示敬意。现在日语的敬语大致分为四类：</p><p>①尊他语（尊敬語　そんけいご）：对他人的行为、状态及有关事物等表示敬意的语言。<br>②自谦语（謙譲語　けんじょうご）：以谦逊的态度叙述自己或自己一方的行为、状态及有关事物的语言。<br>③郑重语（丁寧語　ていねいご）：表示客气、有礼貌、文雅、郑重的态度的语言。如：です、ます、ましょう等。<br>④美化语（美化語 　びかご）：名词的接头接尾词，指令人听上去很优美很文雅的一些表达方式，给人优雅而又有教养的印象。<br><a id="more"></a></p><h2 id="尊他语"><a href="#尊他语" class="headerlink" title="尊他语"></a>尊他语</h2><h3 id="名词的尊他语"><a href="#名词的尊他语" class="headerlink" title="名词的尊他语"></a>名词的尊他语</h3><p>①加前缀或后缀：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">前缀：</span><br><span class="line">お：お手紙、お話、お宅、お電話     （和语词，日常常用词）</span><br><span class="line">ご：ご案内、ご希望、ご協力　　　　 （汉语词）</span><br><span class="line"></span><br><span class="line">后缀：</span><br><span class="line">～さん          ：　山田さん、学生さん</span><br><span class="line">～様（さま）：　田中さま、二人さま</span><br><span class="line">～殿（どの）：　吉田殿、会長殿</span><br><span class="line"></span><br><span class="line">前后缀：</span><br><span class="line">お父さん（さま）：お母さん（さま）</span><br><span class="line">お嬢さん（さま）：お客さん（さま）</span><br></pre></td></tr></table></figure></p><p>②Ｎ本身变化<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">会社：貴社　　　宅：お住まい</span><br></pre></td></tr></table></figure></p><h3 id="形容词的尊他语"><a href="#形容词的尊他语" class="headerlink" title="形容词的尊他语"></a>形容词的尊他语</h3><p>お＋形容詞<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿ 歩くのがお速いですね。</span><br><span class="line">✿ 最近お忙しいですか。</span><br><span class="line">✿ お元気ですね。</span><br><span class="line">✿ お上手ですよ。</span><br></pre></td></tr></table></figure></p><h3 id="动词的尊他语"><a href="#动词的尊他语" class="headerlink" title="动词的尊他语"></a>动词的尊他语</h3><h4 id="一般动词"><a href="#一般动词" class="headerlink" title="一般动词"></a>一般动词</h4><p>お＋マス形＋になる<br>ご＋サ変动词词干＋になる<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿ 何時ごろお帰りになりますか。</span><br><span class="line">✿ 先生がご案内になってくださったのです。</span><br></pre></td></tr></table></figure></p><h4 id="特殊动词"><a href="#特殊动词" class="headerlink" title="特殊动词"></a>特殊动词</h4><img src="/2019/01/06/敬语/特殊动词尊他.png" title="特殊动词的尊他语"><h3 id="请求的尊他表示"><a href="#请求的尊他表示" class="headerlink" title="请求的尊他表示"></a>请求的尊他表示</h3><p>用于请求对方做某事。<br>汉语：请您~<br>接续：お＋マス形＋ください<br>      ご＋サ変动词词干＋ください<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿ あしたの会議、ぜひご参加ください。</span><br><span class="line">✿ もう大丈夫ですので、どうぞご安心ください。</span><br><span class="line">✿ どうぞ、おかけください。</span><br></pre></td></tr></table></figure></p><p>★ 特殊词的接续：特殊词て型＋ください</p><h3 id="其他尊他语形式"><a href="#其他尊他语形式" class="headerlink" title="其他尊他语形式"></a>其他尊他语形式</h3><p>１、お（ご）　+　ＶＲ（サ変語幹）+　なさる<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">お帰りなさる</span><br><span class="line">ご心配なさる</span><br><span class="line">あなたが行けば、おばあさんはきっとお喜びなさるでしょう。</span><br></pre></td></tr></table></figure></p><p>２、お（ご）　+　ＶＲ（サ変語幹）+　です<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">お客さんがこちらでお待ちです。  客人们请在这里等候。</span><br><span class="line">お父さんはご在宅ですか。        您父亲在家吗。</span><br></pre></td></tr></table></figure></p><h2 id="谦让语"><a href="#谦让语" class="headerlink" title="谦让语"></a>谦让语</h2><h3 id="名词的自谦"><a href="#名词的自谦" class="headerlink" title="名词的自谦"></a>名词的自谦</h3><p>Ｎ本身变化<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">わたくし</span><br><span class="line"></span><br><span class="line">茶：粗茶（そちゃ①０）</span><br><span class="line">贈り物：つまらない物</span><br><span class="line">当社：弊社（へいしゃ①）</span><br><span class="line">妻：愚妻（ぐさい０）</span><br></pre></td></tr></table></figure></p><h3 id="动词的自谦"><a href="#动词的自谦" class="headerlink" title="动词的自谦"></a>动词的自谦</h3><h4 id="一般动词-1"><a href="#一般动词-1" class="headerlink" title="一般动词"></a>一般动词</h4><p>接续：<br>お＋マス形＋　する/いたす<br>ご＋サ変动词词干＋する/いたす </p><p>★「いたす」自谦程度更高<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿ 授業の後で　お電話します。</span><br><span class="line">✿ それでは　お願いいたします。</span><br></pre></td></tr></table></figure></p><p>★自谦句形不能用在单纯的说话人自己本身的行为动作及不涉及对方的行为动作上。<br>★必须用在与对方有关的自己的动作上。</p><h4 id="特殊动词-1"><a href="#特殊动词-1" class="headerlink" title="特殊动词"></a>特殊动词</h4><img src="/2019/01/06/敬语/特殊动词自谦.png" title="特殊动词的自谦语"><h3 id="其他自谦语形式"><a href="#其他自谦语形式" class="headerlink" title="其他自谦语形式"></a>其他自谦语形式</h3><p>１、お（ご）　+　ＶＲ（サ変語幹）+　申し上げる<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">お客様を空港までお見送り申し上げます。把客人送到机场</span><br><span class="line">ご援助申し上げるつもりでございます。   我愿意为您效劳</span><br></pre></td></tr></table></figure></p><h2 id="郑重语"><a href="#郑重语" class="headerlink" title="郑重语"></a>郑重语</h2><p>郑重语不是对话题人物的尊敬，也不是对自己的自谦，而是用郑重地说话来表示对听话人的尊重。也是表示自己有高雅教养的表现。</p><p>郑重语的最基本的表现是です和ます。</p><p>其他还有ござる、まいる、いたす、おる等。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿ これが弟の写真です。</span><br><span class="line">✿ 私の父でございます。</span><br><span class="line">✿ 雪が降ってまいりました。</span><br><span class="line">✿ 何か変な匂いがいたしますよ。</span><br><span class="line">✿ 用意が出来ておりました。</span><br></pre></td></tr></table></figure></p><h2 id="美化语"><a href="#美化语" class="headerlink" title="美化语"></a>美化语</h2><p>①加前缀：（同名词的尊他变形）<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">お：お手紙、お話、お宅、お電話     （和语词，日常常用词）</span><br><span class="line">ご：ご案内、ご希望、ご協力　　　　 （汉语词）</span><br></pre></td></tr></table></figure></p><p>②Ｎ本身变化<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">めし：ご飯</span><br><span class="line">腹（はら）：お腹（おなか）</span><br><span class="line">便所（べんじょ）：お手洗い</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;敬语用于对会话中涉及的人物或者听话人表示敬意。现在日语的敬语大致分为四类：&lt;/p&gt;
&lt;p&gt;①尊他语（尊敬語　そんけいご）：对他人的行为、状态及有关事物等表示敬意的语言。&lt;br&gt;②自谦语（謙譲語　けんじょうご）：以谦逊的态度叙述自己或自己一方的行为、状态及有关事物的语言。&lt;br&gt;③郑重语（丁寧語　ていねいご）：表示客气、有礼貌、文雅、郑重的态度的语言。如：です、ます、ましょう等。&lt;br&gt;④美化语（美化語 　びかご）：名词的接头接尾词，指令人听上去很优美很文雅的一些表达方式，给人优雅而又有教养的印象。&lt;br&gt;
    
    </summary>
    
      <category term="日语" scheme="https://janvia.github.io/categories/%E6%97%A5%E8%AF%AD/"/>
    
    
      <category term="敬语" scheme="https://janvia.github.io/tags/%E6%95%AC%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>linux基础命令</title>
    <link href="https://janvia.github.io/2019/01/05/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>https://janvia.github.io/2019/01/05/linux常用命令/</id>
    <published>2019-01-05T09:16:43.000Z</published>
    <updated>2019-01-09T14:17:00.408Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h3 id="电源管理"><a href="#电源管理" class="headerlink" title="电源管理"></a>电源管理</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shutdown now # 关机</span><br><span class="line">shutdown -h 30 # 30分钟后关机 </span><br><span class="line">shutdown -r now # 重启</span><br><span class="line">shutdown -r 05:30 # 于05:30重启</span><br><span class="line">shutdown -c # 取消关机</span><br></pre></td></tr></table></figure><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><p>/bin： bin是Binary的缩写, 这个目录存放着最经常使用的命令。</p><p>/boot： 这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。</p><p>/dev ： dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。</p><p>/etc： 这个目录用来存放所有的系统管理所需要的配置文件和子目录。</p><p>/home： 用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。</p><p>/lib： 这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。</p><p>/lost+found： 这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。</p><p>/media： linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。</p><p>/mnt： 系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。</p><p>/opt： 这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。</p><p>/proc： 这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。 这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all</span><br></pre></td></tr></table></figure></p><p>/root： 该目录为系统管理员，也称作超级权限者的用户主目录。</p><p>/sbin： s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。</p><p>/selinux： 这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。</p><p>/srv： 该目录存放一些服务启动之后需要提取的数据。</p><p>/sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。</p><p>sysfs文件系统集成了下面3种文件系统的信息：<br>针对进程信息的proc文件系统</p><p>针对设备的devfs文件系统</p><p>针对伪终端的devpts文件系统。<br>/tmp： 这个目录是用来存放一些临时文件的。<br>/usr： 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。<br>/usr/bin： 系统用户使用的应用程序。<br>/usr/sbin： 超级用户使用的比较高级的管理程序和系统守护程序。<br>/usr/src：内核源代码默认的放置目录。<br>/var： 这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。</p><h3 id="显示文件目录"><a href="#显示文件目录" class="headerlink" title="显示文件目录"></a>显示文件目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls</span><br><span class="line">-a 列出隐藏文件，文件中以“.”开头的均为隐藏文件，如：~/.bashrc</span><br><span class="line"></span><br><span class="line">-l 列出文件的详细信息</span><br><span class="line"></span><br><span class="line">-R 连同子目录中的内容一起列出</span><br></pre></td></tr></table></figure><h3 id="文件权限"><a href="#文件权限" class="headerlink" title="文件权限"></a>文件权限</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwx-rwx-rwx </span><br><span class="line"># 第一个代表文件类型</span><br><span class="line"># 代表所有者的权限 </span><br><span class="line"># 代表所属组的权限</span><br><span class="line"># 代表其他人的权限</span><br></pre></td></tr></table></figure><h3 id="改变权限"><a href="#改变权限" class="headerlink" title="改变权限"></a>改变权限</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">r 读取权限  如果没有r 就不能 ls 查看里面的内容   对应数字 4</span><br><span class="line">w 写权限    如果没有w 就不能在目录下创建新的文件  对应数字 2</span><br><span class="line">x 执行权限  如果没有x 就不能cd进入这个目录 对应数字 1</span><br><span class="line">- 没权限  对应数字 0</span><br><span class="line">chmod 777 filename</span><br><span class="line">rwx-rwx-rwx</span><br></pre></td></tr></table></figure><h3 id="切换文件夹"><a href="#切换文件夹" class="headerlink" title="切换文件夹"></a>切换文件夹</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd filename  # 进入文件-filename：文件名</span><br><span class="line"></span><br><span class="line">cd -  # 返回上一次进入的目录</span><br><span class="line"></span><br><span class="line">cd ~  # 进入根目录</span><br><span class="line"></span><br><span class="line">cd .. # 返回上级目录</span><br></pre></td></tr></table></figure><h3 id="查看当前路径"><a href="#查看当前路径" class="headerlink" title="查看当前路径"></a>查看当前路径</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pwd</span><br></pre></td></tr></table></figure><h3 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir filename # 创建一个filename的文件</span><br></pre></td></tr></table></figure><h3 id="删除空目录"><a href="#删除空目录" class="headerlink" title="删除空目录"></a>删除空目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rmdir filename # 删除一个空的filename的文件</span><br></pre></td></tr></table></figure><h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p>复制文件或目录<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp file1 file2</span><br><span class="line"></span><br><span class="line">cp file1 dir/</span><br><span class="line"></span><br><span class="line">cp file1 ../</span><br></pre></td></tr></table></figure></p><p>拷贝目录<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp dir1 dir2 -r</span><br><span class="line"></span><br><span class="line">cp dir1 ~/ -r</span><br></pre></td></tr></table></figure></p><h3 id="删除文件或目录"><a href="#删除文件或目录" class="headerlink" title="删除文件或目录"></a>删除文件或目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -r  # 递归删除文件</span><br><span class="line">rm -rf # 强制删除文件*****</span><br></pre></td></tr></table></figure><h3 id="查看文件"><a href="#查看文件" class="headerlink" title="查看文件"></a>查看文件</h3><p>从第一行开始；“-b”显示行号<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat file  # 一次查看所有的文件</span><br><span class="line">cat file1  file2   # 一次查看两个命令</span><br></pre></td></tr></table></figure></p><p>从最后一行开始<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tac filename</span><br></pre></td></tr></table></figure></p><p>显示的时候，顺道输出行号！<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nl filename</span><br></pre></td></tr></table></figure></p><p>一页一页的显示文件内容<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">more filename</span><br></pre></td></tr></table></figure></p><p>按Space键：显示文本的下一屏内容。</p><p>按Enier键：只显示文本的下一行内容。</p><p>按斜线符/：接着输入一个模式，可以在文本中寻找下一个相匹配的模式。</p><p>按H键：显示帮助屏，该屏上有相关的帮助信息。</p><p>按B键：显示上一屏内容。</p><p>按Q键：退出more命令。</p><h3 id="查找命令"><a href="#查找命令" class="headerlink" title="查找命令"></a>查找命令</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">which command  # 查看    -二进制文件</span><br><span class="line">whereis 可执行文件    # 二进制文件 、man手册</span><br><span class="line"></span><br><span class="line">帮助文档：</span><br><span class="line">1.man手册  ，帮助文档    man  ls</span><br><span class="line">2.--help   , ls --help</span><br></pre></td></tr></table></figure><h3 id="查找文件"><a href="#查找文件" class="headerlink" title="查找文件"></a>查找文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find 路径  参数</span><br><span class="line"># 常用参数 </span><br><span class="line">-name   # 按照名字</span><br><span class="line">-size   # 按照大小</span><br><span class="line">find ./  -size +100k -size -10M  # 在当前目录下找大于100k 小于 10的文件</span><br></pre></td></tr></table></figure><h3 id="文本搜索"><a href="#文本搜索" class="headerlink" title="文本搜索"></a>文本搜索</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep  &apos;content&apos;  filename</span><br><span class="line"># 常用参数</span><br><span class="line">-v    显示不包含匹配文本的所有‘行’ (求反)</span><br><span class="line">-n    显示匹配行及行号</span><br><span class="line">-i    忽略大小写</span><br><span class="line"># 内容参数</span><br><span class="line">^wu  行首 搜索以wu开头的行</span><br><span class="line">wh$  行尾 索以wh结束的行</span><br></pre></td></tr></table></figure><h3 id="创建链接文件"><a href="#创建链接文件" class="headerlink" title="创建链接文件"></a>创建链接文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln  file  hardlink # 硬链接</span><br><span class="line">ln -s  file softlink  # 软链接</span><br></pre></td></tr></table></figure><p>软链接: 相当于 window上的快捷方式 源文件删除则软链接失效</p><p>硬链接: 硬链接只能连接普通的文件 不能连接目录</p><p>注意 如果软链接文件和源文件不在同一个目录 源文件要使用绝对路径 不能使用相对路径</p><h3 id="创建别名"><a href="#创建别名" class="headerlink" title="创建别名"></a>创建别名</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alias     # 查看所有别名   alias c4=&apos;cat 4.txt&apos;</span><br><span class="line"></span><br><span class="line">unalias   # 删除别名</span><br></pre></td></tr></table></figure><p>注意 这种定义别名的方式 只在当前登录有效 如果要永久定义生效 可以通过修改~/.bashrc文件 这个修改要下次登录才能生效 想要立即生效 可以输入source ~/.bashrc</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;电源管理&quot;&gt;&lt;a href=&quot;#电源管理&quot; class=&quot;headerlink&quot; title=&quot;电源管理&quot;&gt;&lt;/a&gt;电源管理&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td 
      
    
    </summary>
    
      <category term="linux" scheme="https://janvia.github.io/categories/linux/"/>
    
    
      <category term="linux命令" scheme="https://janvia.github.io/tags/linux%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>一些忘记书名的心理学笔记</title>
    <link href="https://janvia.github.io/2019/01/04/%E4%B8%80%E4%BA%9B%E5%BF%98%E8%AE%B0%E4%B9%A6%E5%90%8D%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6%E7%AC%94%E8%AE%B0/"/>
    <id>https://janvia.github.io/2019/01/04/一些忘记书名的心理学笔记/</id>
    <published>2019-01-04T07:16:23.000Z</published>
    <updated>2019-01-09T15:05:54.232Z</updated>
    
    <content type="html"><![CDATA[<img src="/2019/01/04/一些忘记书名的心理学笔记/xinlixue.jpg"><h3 id="酒与污水定律"><a href="#酒与污水定律" class="headerlink" title="酒与污水定律"></a>酒与污水定律</h3><p>　　把一勺酒倒入一桶污水，得到的是一桶污水；把一勺污水倒入一桶酒，得到的还是一桶污水。只要酒里有污水，再多的酒都是污水。<br><a id="more"></a></p><h3 id="羊群效应"><a href="#羊群效应" class="headerlink" title="羊群效应"></a>羊群效应</h3><p>　　在组织散乱的羊群中，头羊起着关键作用，它的任何一个行动都会引起整个羊群中其他羊的关注，这些羊会效仿头羊。这是一种典型的从众心理，这种现象普遍存在于人类社会群体中。</p><h3 id="安泰效应"><a href="#安泰效应" class="headerlink" title="安泰效应"></a>安泰效应</h3><p>　　指的是每种能力都要借助一定的条件和环境，一旦失去这种条件或环境，就可能失去某种能力。它告诉我们，人要学会借力，善于运用自己周围的环境。</p><h3 id="踢猫效应"><a href="#踢猫效应" class="headerlink" title="踢猫效应"></a>踢猫效应</h3><p>　　指人的不满情绪和糟糕心情，通常会沿着等级由高到低依次传递，由金字塔尖传到金字塔底，最终将危机转嫁到弱者身上。</p><h3 id="矛盾选择定律"><a href="#矛盾选择定律" class="headerlink" title="矛盾选择定律"></a>矛盾选择定律</h3><p>　　只有一只手表，可以告诉人们准确的时间，而拥有两只手表非但不能告诉一个人准确的时间，反而会让看表的人失去对准确时间的判断，这就是“手表定律”，也称“矛盾选择定律”。</p><h3 id="贯性原理"><a href="#贯性原理" class="headerlink" title="贯性原理"></a>贯性原理</h3><p>　　你们对某样东西投入了巨大的精力，对它倾注了心血和金钱。你们投入的越多，贯性原理就越会促使你们想：“现在它必须成功。如果我再投入一点，它就会成功。”<br>　　<br>　　如何对付错误和那些改变赢面的新情况，也是你们必须掌握的知识之一。生活有时候就像扑克游戏，有时候你们即使拿到一把非常喜欢的牌，但也必须学会放弃。<br>　　<br>　　这时候，“剥夺性超级反映综合征”也会出现：如果不再投入一点，你们就要前功尽弃啦。人们就是这样破产的——因为他们不懂停下来反思，然后说：“我可以放弃这个，从头再来。我不会执迷不悟下去——那样的话我会破产的。”</p><h3 id="社会科学理论"><a href="#社会科学理论" class="headerlink" title="社会科学理论"></a>社会科学理论</h3><p>　　社会科学理论的命运取决于其传染性，而不是其正确性。</p><h3 id="预期"><a href="#预期" class="headerlink" title="预期"></a>预期</h3><p>　　假设一项计划预期在79天内完成。在第79天，假如计划还未完成，那么人们预测它还需要25天；但在第90天，假如计划还未完成，它会还需要58天；在第100天还需要89天；在第119天还需要149天；在第600天，如果计划还未完成，你会预测它还需要1590天。如你所见，你等待的时间越长，你预期还要继续等待的时间就越长。</p><h3 id="喜欢"><a href="#喜欢" class="headerlink" title="喜欢"></a>喜欢</h3><p>　　我们喜欢可触摸的东西、被证实的东西、显而易见的东西、真实的东西、可见的东西、具体的东西、已知的东西、已观察到的东西、生动的东西、视觉性的东西、有社会特点的东西、被灌输的东西、富有情感的东西、突出的东西、典型的东西、打动人心的东西、富有戏剧性的东西、传奇的东西、美化的东西、官方的东西、学术性的空话、虚有其表的高斯派经济学家、数学废话、华而不实的东西、法兰西学院、哈佛商学院、诺贝尔奖、黑西服白衬衣加领带、令人激动的演讲和耀眼的东西。而我们最喜欢的，是故事。<br>　　可惜，现存的人类天性不愿理解抽象事物，我们需要具体背景。随机性和不确定性是抽象事物。我们尊重发生的事，忽视本来可能发生的事。也就是说，我们天生肤浅，却浑然不知。这不是心理学问题，它来自信息的主要特性。人们很难看到月亮的阴面，照亮它是花费能量的。同样，照亮没有被看到的事物既费力又劳神。</p><h3 id="假想实验"><a href="#假想实验" class="headerlink" title="假想实验"></a>假想实验</h3><p>　　把一群各式各样的老鼠放进A实验室里，对它们进行越来越高的辐射。把幸存下来的老鼠放入城市B，幸存下来的老鼠在城市B老鼠中显得很强壮。看到的人于是分析为什么这些老鼠更强壮，因为他们来自A实验室，实验室把它们训练得很强壮。</p><h3 id="沉默的证据"><a href="#沉默的证据" class="headerlink" title="沉默的证据"></a>沉默的证据</h3><p>　　千多年前西塞罗讲了这样一个故事，有人把一幅画给一个无神论者看，画上画着一群正在祈祷的拜神者，他们在随后的沉船事故中幸存了下来。其寓意在于说明祈祷能保护人们不被淹死。无神论者问，‘那些祈祷后被淹死的人的画像在哪儿？’</p><p>　　淹死的拜神者已经死了，所以很难从海底出来宣扬他们的事迹。</p><p>　　沉默的证据遍及所有与历史概念有关的一切，历史是具有事后影响的全部事件。</p><h3 id="抓猴子的故事"><a href="#抓猴子的故事" class="headerlink" title="抓猴子的故事"></a>抓猴子的故事</h3><p>　　树上挂一个空椰子，上面开个洞，放上米，猴子把手伸进去，抓了米，手就出不来。</p><h3 id="长痛与短痛"><a href="#长痛与短痛" class="headerlink" title="长痛与短痛"></a>长痛与短痛</h3><p>　　短时间的巨大痛苦大于将痛苦在长时间中分散的痛苦;</p><p>　　短时间的巨大幸福小于长时间中分散的幸福。</p><h3 id="改变他人"><a href="#改变他人" class="headerlink" title="改变他人"></a>改变他人</h3><p>　　世界上唯一能影响对方的方法，就是讨论他所要的，而且还告诉他，如何才能得到。</p><p>　　也许在潜意识里，我们很希望能够通过我们的看法去左右别人的行为，因而会憎恨那些不受我们影响的人。</p><h3 id="自重感"><a href="#自重感" class="headerlink" title="自重感"></a>自重感</h3><p>　　人们渴望成为重要的人，即自重感。献出你真实，诚恳的赞赏。</p><p>　　如果你想得到仇人，你就胜过你的朋友，如果你想获得更多的朋友，就让你的朋友胜过你。</p><p>　　当朋友胜过我们，他们会获得自重感。当我们胜过朋友，他会自卑，并引起猜疑和妒忌。</p><p>　　当我们猜疑，妒忌的人，发生一桩不幸的事，会使我们有一种恶意的快感。</p><p>　　有些朋友，看你遭遇困难，比看你成功或许更为满意。</p><h3 id="批评与被批评"><a href="#批评与被批评" class="headerlink" title="批评与被批评"></a>批评与被批评</h3><p>　　批评是没有用的，因它使人增加一层防御，而且竭力地替自己辩护。批评也是危险的，它会伤害一个人的自尊，和自重的感觉，并引起他的反抗。</p><p>  被批评：<br>  1.做你认为正确的事，反正你会受到批评，会因为做了某些事被骂，也会因为什么都不做而被骂。结果都是一样的。<br>  2.如果你身居领导地位，那就注定要被批评，想办法习惯它吧！<br>  3.只要我不对任何的攻讦作出反应，那这件事就只有到此为止。</p><h3 id="了解"><a href="#了解" class="headerlink" title="了解"></a>了解</h3><p>　　你永远也不可能真正了解一个人，除非你穿上他的鞋子走来走去，站在他的角度考虑问题。</p><h3 id="从众原则"><a href="#从众原则" class="headerlink" title="从众原则"></a>从众原则</h3><p>　　大多数人好像都认为他们是对的，你是错的……</p><p>　　他们当然有权利那样想，他们的看法也有权得到充分的尊重，但是，我在接受他人之前，首先要接受自己。有一种东西不能遵循从众原则，那就是人的良心。</p><h3 id="为小事烦恼"><a href="#为小事烦恼" class="headerlink" title="为小事烦恼"></a>为小事烦恼</h3><p>　　错过列车，只有在你追赶它时才是痛苦的！同样，不能达到别人对你期望的成功，只有在它也是你所追求的东西时才是痛苦的。</p><p>　　只要是你的决定，放弃一份高薪职位带来的回报会超过金钱带给你的效用。这是向命运说“随你怎么样”的第一步。如果你确定了自己的标准，你对自己的生活会有大得多的控制。</p><p>　　我们很容易忘记我们活着本身就是极大的运气，一个可能性微小的事件，一个极大的偶然。</p><p>　　想象一个10亿倍于地球的行星边上的一粒尘埃。这粒尘埃就代表你出生的概率，庞大的行星则代表相反的概率。所以不要再为小事烦恼了。</p><h3 id="是与不"><a href="#是与不" class="headerlink" title="是与不"></a>是与不</h3><p>　　使对方很快地回答“是，是“</p><p>　　一个不字的反应，是最不容易克服的障碍。当一个人说出不字后，为了他人格的尊严，他不得不坚持到底。事后，他或许觉得他说出这个不字是错误的，可是，他必须考虑到自己的尊严。他所说的每句话，必须坚持到底，所以使人一开始，就往正面走，是非常重要的。</p><h3 id="指责"><a href="#指责" class="headerlink" title="指责"></a>指责</h3><p>　　尊重别人的意见，永远别指责对方是错误的。</p><p>　　我们不只反对有人指责我们的表错误，或者我们的汽车太旧，而是不愿意有人想要纠正我们的任何错误。</p><h3 id="争辩"><a href="#争辩" class="headerlink" title="争辩"></a>争辩</h3><p>　　永远避免正面冲突、争辩</p><p>　　为什么一定要找出证据来证明别人的错误呢？</p><p>　　这么做会让人喜欢你？</p><p>　　他并没有征求你的意见，也不要你的意见，你又何必去跟他争辩呢？</p><h3 id="让人喜欢你的方法"><a href="#让人喜欢你的方法" class="headerlink" title="让人喜欢你的方法"></a>让人喜欢你的方法</h3><p>1.真诚地对别人发生兴趣<br>2.微笑<br>3.记住你所接触中，每一个人的姓名<br>4.做一个静听的人，鼓励别人多谈谈他们自己。<br>5.就别人的兴趣谈论<br>6.使别人感觉到他的重要，必须真诚的这样做<br>深入人们心底的最佳途径，就是对那人讲他知道得最多的事物。</p><h3 id="保持愉快"><a href="#保持愉快" class="headerlink" title="保持愉快"></a>保持愉快</h3><p>1.现在你何不问问自己：“我到底在烦恼些什么呢？”你多半会发现，你所担心的事既不重要，也没有意义。<br>2.世上最好的医生，就是饮食有度、保持平和以及愉悦的心情。<br>3.罗根·史密斯有一句智慧之言：“人生有两项主要目标，第一，拥有你所向往的；第二，享受它们。只有最具智慧的人才能做到第二点。”</p><h3 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h3><p>1.如果你“假装”对工作有兴趣，一点点假装就会使你的兴趣成真，也可以减少你的疲劳。<br>2.如果你是一个脑力劳动者，使你感觉疲劳的原因很少是因为你的工作超量，相反是由于你的工作量不足。<br>3.要不停地提醒你自己，对自己的工作感兴趣，就能使你不再忧虑；而且最后还可能会给你带来升迁和加薪的机会。即使没有这么好的结果，那至少也可以使你的疲劳降到最低程度。</p><p>  养成4种良好的工作习惯：<br>第一，将你桌上所有的纸张收拾好，只留下你正要处理的问题。<br>第二，根据事情的重要程度来安排做事的先后顺序。<br>第三，当你遇到必须当场作决定的问题时，就当场解决，不要犹豫不决。<br>第四，学会如何组织、分级负责和监督。</p><p>　　你可以把自己的生活想象成一个沙漏。在沙漏的上一半有成千上万粒的沙子，它们缓慢而均匀地流过中间那条细缝。除非把沙漏弄坏，否则，你和我都不能让两粒以上的沙子同时穿过那条窄缝。我们就如同沙漏。每天清晨醒来的时候，就有许许多多的工作摆在面前，要在这一天之内完成。但我们一定要均匀地安排自己的工作和生活，如果我们每次要几件事情同时做，就像要两粒以上的沙子同时通过窄缝一样，一定会损害自己的身体和精神。</p><h3 id="表象"><a href="#表象" class="headerlink" title="表象"></a>表象</h3><p>　　我们的头脑总是被所谓的真相，错误的“常识一样明白的”虚构的故事，以及服务于特别利益集团的带有偏见的结论所填满。一个有判别力的思考者要超越已有的信息，发掘隐藏在信息表面下的真正含义，以理解信息的本质为目标而不被表面的映像和风格所迷惑。<br>技巧：<br>1.避免把相关关系推论为因果关系。<br>2.要求关键术语和概念有操作定义，并对其含义达成一致意见。<br>3.你很容易在寻求辩解时发现确定的证据，但在寻找确定的证据前，首先要考虑如何反驳某一理论、假设或信仰。<br>4.总是对已提出的明显解释寻求其他的可能解释，特别是那些有利于提案人的解释。<br>5.认识到个人偏见能歪曲对现实的理解。<br>6.怀疑对复杂问题给出的简单答案，怀疑对复杂现象和难题给出的单一理由和对策。<br>7.质疑任何关于治疗、参与、或产品效果的声明，办法是找到比较结果的基础：比较什么？<br>8.成为思想开朗而又好怀疑的人：认识到大多数结论都具有尝试性和不确定性；寻找新的证据来减少你的不确定性，同时使自己能不断变革和修正自己的观点。<br>9.向权威挑战，那些权威通常用个人的观点代替证据，而且又不接受建设性的批评。</p><h3 id="预期-1"><a href="#预期-1" class="headerlink" title="预期"></a>预期</h3><p>　　通常，人们看见的,听到的只是他们所预期的，而不是事实的本来面目。</p><h3 id="强迫"><a href="#强迫" class="headerlink" title="强迫"></a>强迫</h3><p>　　没有人喜欢强迫自己去买某样东西，或是被人派遣去做一件事。我们都喜欢随自己心愿去买东西，照自己的意思去做事情。同时希望有人跟我们谈谈我们的愿望，需要和想法。</p><h3 id="失眠"><a href="#失眠" class="headerlink" title="失眠"></a>失眠</h3><p>  下面是五条规则，可以让你不为失眠症而忧虑：<br>第一，如果睡不着的话，就起来工作或看书，直到打瞌睡为止。<br>第二，从来没有人会因为缺乏睡眠而死。因担心失眠而忧虑，通常对你的损害比失眠更厉害。<br>第三，试着祈祷，或者像珍妮·麦克唐纳一样诵读诗篇的第二十三篇。<br>第四，放松全身，看看《消除神经紧张》这本书。<br>第五，多运动，或做一些体力活，直至你累得酣然入睡。</p><h3 id="会议"><a href="#会议" class="headerlink" title="会议"></a>会议</h3><p>1.出了什么问题<br>2.问题的原因是什么？<br>3.有哪些可能解决的办法<br>4.你觉得哪种方法最合适</p><h3 id="职业"><a href="#职业" class="headerlink" title="职业"></a>职业</h3><p>  以下是我想向您请教的问题：<br>①如果您的生命从头开始，您是否愿意再做一名建筑师？<br>②在您仔细打量我之后，我想请问您，您是否认为我具备成为一名成功的建筑师的条件？<br>③建筑师这一行业是否已经人满为患？<br>④假如我学习了4年的建筑学课程，想要找到工作是否困难？我应该首先接受哪一类的工作？<br>⑤如果我的能力属于中等，在头5年中，我可以希望赚多少钱？<br>⑥当一名建筑师，有什么样的好处和坏处？<br>⑦假如我是您的儿子，您愿意鼓励我当一名建筑师吗？<br>　　古希腊哲学家艾皮科蒂塔说，哲学的精华就是：“一个人生活上的快乐，应该来自于尽可能减少对外来事物的依赖。”<br>罗马的政治家及哲学家塞尼加也说：“如果你一直都觉得不满足，那即使是给你整个世界，你也会觉得伤心。”</p><h3 id="忧虑"><a href="#忧虑" class="headerlink" title="忧虑"></a>忧虑</h3><p>1.混乱是产生忧虑的主要原因。在没有以客观的态度搜集到所有的事实之前，不要想如何解决问题。<br>2.一切和我们欲望相符合的，看来都是真理，其他的都会使我们感到愤怒。<br>  解决办法：（亚里士多德法则）<br>第一，清楚地写下我们所担心的是什么。<br>第二，写下我们可以怎么办以及可能发生的结果。<br>第三，决定该怎么办。<br>第四，马上按照决定去做。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2019/01/04/一些忘记书名的心理学笔记/xinlixue.jpg&quot;&gt;
&lt;h3 id=&quot;酒与污水定律&quot;&gt;&lt;a href=&quot;#酒与污水定律&quot; class=&quot;headerlink&quot; title=&quot;酒与污水定律&quot;&gt;&lt;/a&gt;酒与污水定律&lt;/h3&gt;&lt;p&gt;　　把一勺酒倒入一桶污水，得到的是一桶污水；把一勺污水倒入一桶酒，得到的还是一桶污水。只要酒里有污水，再多的酒都是污水。&lt;br&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="https://janvia.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="心理学" scheme="https://janvia.github.io/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>经济学笔记</title>
    <link href="https://janvia.github.io/2019/01/04/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%AC%94%E8%AE%B0/"/>
    <id>https://janvia.github.io/2019/01/04/经济学笔记/</id>
    <published>2019-01-04T07:16:04.000Z</published>
    <updated>2019-01-09T15:08:22.559Z</updated>
    
    <content type="html"><![CDATA[<img src="/2019/01/04/经济学笔记/jingji.jpg"><h2 id="复利"><a href="#复利" class="headerlink" title="复利"></a>复利</h2><p>　　如果有1万，按每年投资回报率10%计算，10年收益为1.59万，20年为5.7万，30年为16.45万，40年为44.26万。<br>所以在20岁投入10万，60岁养老金就有450万，在孩子1岁时，投入10万，孩子30岁时，就有160万。<br>　　然而国际公认平均收益率为12%，而投资自己，进行人力资源投资的投资收益最大。<br><a id="more"></a></p><h2 id="二八定律"><a href="#二八定律" class="headerlink" title="二八定律"></a>二八定律</h2><p>　　20%的客户会带来80%的收益</p><p>　　有个乞丐非常善于乞讨，每天都比同行赚得多，于是有同行就问他：“你有什么乞讨秘诀吗？” 这位乞丐说：“秘诀谈不上，不过我还是有点个人经验的。我从来不粘着顾客满街跑。如果乞讨不成，我会趁早放弃。因为他若肯给我钱，早就会给，就算他最后磨不过我，给了我钱，我也因此浪费了很多时间和精力，不如转而寻找下一个大目标。”</p><h2 id="黑洞效应"><a href="#黑洞效应" class="headerlink" title="黑洞效应"></a>黑洞效应</h2><p>　　黑洞效应：在宇宙中，一些大质量的物体在发生坍塌之后，会形成一个致密的点，由于它的质量非常大，所以产生的引力也非常大，大到光线进去之后也无法逃出来，于是就形成了一个黑洞。而且不断被吞噬进去的物质和能量又反过来成为黑洞的一部分，使得黑洞产生更大的吸引力。<br>黑洞效应就是一种自我强化效应。当一个企业达到一定的规模之后，也会像一个黑洞一样产生非常强的吞噬和自我复制能力，把它势力所及的大量资源吸引过去，而这些资源使得企业更加强大，形成一个正向加速循环的旋涡。<br>　　黑洞效应使得资源和资本聚集，是产生社会贫富差距的原因之一。</p><h2 id="沉没成本"><a href="#沉没成本" class="headerlink" title="沉没成本"></a>沉没成本</h2><p>　　沉没成本是指由于过去的决策已经发生了的，而不能由现在或将来的任何决策改变的成本。人们在决定是否去做一件事情的时候，不仅是看这件事对自己有没有好处，而且也看过去是不是已经在这件事情上有过投入。我们把这些已经发生不可收回的支出，如时间、金钱、精力等称为“沉没成本”。<br>举例来说，如果你预订了一张电影票，已经付了票款且假设不能退票。此时你付的价钱已经不能收回，就算你不看电影钱也收不回来，电影票的价钱算做你的沉没成本。<br>所以，如果你是理性的，那就不该在做决策时考虑沉没成本。</p><h2 id="参照点"><a href="#参照点" class="headerlink" title="参照点"></a>参照点</h2><p>　　我们在头脑中形成参照点，比如销售预测，然后开始基于它构造信念，因为把一个观点与一个参照点进行比较比在绝对的环境下对它进行评价所需的思维努力更小。（系统1在起作用！）我们无法在没有参照点的情况下思考。<br>　　所以在预测者头脑中设置一个参照点能够带来奇妙的结果。在讨价还价过程中设置起点是一样的道理：你先提出一个较高的数字，如“这所房子要卖100万美元”，买方会说“只能85万”——议价过程将取决于初始报价。</p><h2 id="讨价还价的故事"><a href="#讨价还价的故事" class="headerlink" title="讨价还价的故事"></a>讨价还价的故事</h2><p>　　有一天，王先生到一个做服装生意的朋友那里去聊天。一个顾客看好了一套服装，服装的标价是800元。顾客说：“你便宜点吧，500元我就买！”朋友说：“你太狠了吧，再加80元！而且也图个吉利！”顾客说：“不行，就500元！”随后，他们又进行了一番讨价还价，最终朋友说：“好吧，就520元！”<br>顾客去交款了，但是不一会儿又回来了。她有些不好意思地说：“算了，我不能买了，我带的钱不够了！”朋友又说：“有多少？”顾客说：“把零钱全算上也就只有430元了。”朋友为难地说：“那太少了，哪怕给我凑一个整数呢？”顾客说：“不是我不想买，的确是钱不够了！”最后，朋友似乎下了狠心，说：“就430元钱给你吧，算是给我开张了，说实在的，一分钱没有挣你的！”顾客满脸堆笑，兴高采烈地走了。<br>　　看着顾客远去的背影，朋友告诉王先生：“这件衣服是180元从广州进的货。”王先生听了哈哈大笑：“真是无商不奸啊，可是你有些太狠了吧？”<br>　　朋友说：“这你就是外行了，现在都时兴讲价，顾客讨价，我还价，这很正常。你要给顾客留出来讨价还价的空间，要让顾客心理上获得一种满足！其实这件衣服我300元的价格就卖，到换季的时候我本钱都往外抛。”</p><h2 id="巧借名人效应的故事"><a href="#巧借名人效应的故事" class="headerlink" title="巧借名人效应的故事"></a>巧借名人效应的故事</h2><p>　　美国一出版商有一批滞销书久久不能脱手，他忽然想出了一个主意：给总统送去一本书，并三番五次去征求意见。忙于政务的总统不愿与他多纠缠，便回了一句：“这本书不错。”出版商便借总统之名大做广告：“现有总统喜爱的书出售。”于是，这些书被一抢而空。<br>不久，这个出版商又有书卖不出去，又送一本给总统。总统上过一回当，想奚落他，就说：“这书糟透了。”出版商闻之，脑子一转，又做广告：“现有总统讨厌的书出售。”不少人出于好奇争相抢购，书又售尽。<br>　　第三次，出版商将书送给总统。总统接受了前两次的教训，便不作任何答复。出版商却大做广告：“现有令总统难以下结论的书，欲购从速。”居然又被一抢而空，总统哭笑不得，商人却善借总统之名大发其财。<br>　　~巧借名人效应，抱大腿。</p><h2 id="博弈论"><a href="#博弈论" class="headerlink" title="博弈论"></a>博弈论</h2><h3 id="智猪博弈"><a href="#智猪博弈" class="headerlink" title="智猪博弈"></a>智猪博弈</h3><p>　　假设猪圈里有一头大猪、一头小猪。猪圈的一头有猪食槽，另一头安装着控制猪食供应的按钮，按一下按钮会有一定单位的猪食进槽，两头隔得很远。假设两头猪都是理性的猪，也就是说它们都是有着认识和懂得实现自身利益的猪。<br>　　再假设猪每次按动按钮都会有10个单位的饲料进入猪槽，但是并不是白白得到饲料的，猪在按按钮以及跑到食槽的过程中要付出的劳动会消耗相当于2个单位饲料的能量。此外，当一头猪按了按钮之后再跑回食槽的时候，它吃到的东西比另一头猪要少。也就是说，按按钮的猪不但要消耗2单位饲料的能量，还比等待的那个猪吃得少。<br>再来看具体的情况，如果大猪去按按钮，小猪等待，大猪能吃到6份饲料，小猪4份，那么大猪消耗掉2份，最后大猪和小猪的收益为4∶4；如果小猪去按按钮，大猪等待，大猪能吃到9份饲料，小猪1份，那么小猪消耗掉2份，最后大猪和小猪的收益为9∶-1；若两头猪同时跑向按钮，那么大猪可以吃到7份饲料，而小猪可以吃到3份饲料，最后大猪和小猪收益为5∶1；最后一种情况就是两头猪都不动，那它们当然都吃不到东西，两头猪的收益就为0。<br>　　那么小猪努力的结果是-1，比不努力的结果4还差，所以小猪只能不动。大猪为了生存，只能来回跑。<br>　　启发：小企业可以搭大企业的便车，坐收渔翁之利。</p><h3 id="囚徒困境"><a href="#囚徒困境" class="headerlink" title="囚徒困境"></a>囚徒困境</h3><p>　　警方逮捕甲、乙两名嫌疑犯，但没有足够证据指控二人有罪。于是警方分开囚禁嫌疑犯，分别和二人见面，并向双方提供以下相同的选择：</p><p>若一人认罪并作证检控对方（相关术语称“背叛”对方），而对方保持沉默，此人将即时获释，沉默者将判监10年。<br>若二人都保持沉默（相关术语称互相“合作”），则二人同样判监半年。<br>若二人都互相检举（互相“背叛”），则二人同样判监5年。</p><p>　　囚徒困境假定每个参与者（即“囚徒”）都是利己的，即都寻求最大自身利益，而不关心另一参与者的利益。参与者某一策略所得利益，如果在任何情况下都比其他策略要低的话，此策略称为“严格劣势”，理性的参与者绝不会选择。另外，没有任何其他力量干预个人决策，参与者可完全按照自己意愿选择策略。</p><p>　　囚徒到底应该选择哪一项策略，才能将自己个人的刑期缩至最短？两名囚徒由于隔绝监禁，并不知道对方选择；而即使他们能交谈，还是未必能够尽信对方不会反口。就个人的理性选择而言，检举背叛对方所得刑期，总比沉默要来得低。试设想困境中两名理性囚徒会如何作出选择：</p><p>1、若对方沉默、我背叛会让我获释，所以会选择背叛。<br>2、若对方背叛指控我，我也要指控对方才能得到较低的刑期，所以也是会选择背叛。<br>　　二人面对的情况一样，所以二人的理性思考都会得出相同的结论——选择背叛。背叛是两种策略之中的支配性策略。因此，这场博弈中唯一可能达到的纳什均衡，就是双方参与者都背叛对方，结果二人同样服刑5年。</p><p>　　这场博弈的纳什均衡，显然不是顾及团体利益的帕累托最优解决方案。以全体利益而言，如果两个参与者都合作保持沉默，两人都只会被判刑半年，总体利益更高，结果也比两人背叛对方、判刑5年的情况较佳。但根据以上假设，二人均为理性的个人，且只追求自己个人利益。均衡状况会是两个囚徒都选择背叛，结果二人判监均比合作为高，总体利益较合作为低。这就是“困境”所在。例子有效地证明了：非零和博弈中，帕累托最优和纳什均衡是互相冲突的。</p><h3 id="斗鸡博弈"><a href="#斗鸡博弈" class="headerlink" title="斗鸡博弈"></a>斗鸡博弈</h3><p>　　两只公鸡狭路相逢，即将展开一场撕杀。结果有四种可能：两只公鸡对峙，谁也不让谁。或者两者相斗。这两种可能性的结局一样——两败俱伤，这是谁也不愿意的。另两种可能是一退一进。但退者有损失、丢面子或消耗体力，谁退谁进呢？双方都不愿退，也知道对方不愿退。在这样的博弈中，要想取胜，就要在气势上压倒对方，至少要显示出破釜沉舟、背水一战的决心来，以迫使对方退却。但到最后的关键时刻，必有一方要退下来，除非真正抱定鱼死网破的决心。但把自己放在对方的位置上考虑，如果进的一方给予退的一方以补偿？只要这种补偿与损失相当，就会有愿意退者。</p><p>　　这类博弈也不胜枚举。如两人反向过同一独木桥，一般来说，必有一人选择后退。在该种博弈中，非理性、非理智的形象塑造往往是一种可选择的策略运用。如那种看上去不把自己的生命当回事的人，或者看上去有点醉醺醺、傻乎乎的人，往往能逼退独木桥上的另一人。还有夫妻争吵也常常是一个“斗鸡博弈”，吵到最后，一般地，总有一方对于对方的唠叨、责骂装聋作哑，或者干脆妻子回娘家去冷却怒火。冷战期间，美苏两大军事集团的争斗也是一种“斗鸡博弈”。在企业经营方面，在市场容量有限的条件下，一家企业投资了某一项目，另一家企业便会放弃对该项目的觊觎。</p><p>　　斗鸡博弈强调的是，如何在博弈中采用妥协的方式取得利益。如果双方都换位思考，它们可以就补偿进行谈判，最后造成以补偿换退让的协议，问题就解决了。博弈中经常有妥协，双方能换位思考就可以较容易地达成协议。考虑自己得到多少补偿才愿意退，并用自己的想法来理解对方。只从自己立场出发考虑问题，不愿退，又不想给对方一定的补偿，僵局就难以打破。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2019/01/04/经济学笔记/jingji.jpg&quot;&gt;
&lt;h2 id=&quot;复利&quot;&gt;&lt;a href=&quot;#复利&quot; class=&quot;headerlink&quot; title=&quot;复利&quot;&gt;&lt;/a&gt;复利&lt;/h2&gt;&lt;p&gt;　　如果有1万，按每年投资回报率10%计算，10年收益为1.59万，20年为5.7万，30年为16.45万，40年为44.26万。&lt;br&gt;所以在20岁投入10万，60岁养老金就有450万，在孩子1岁时，投入10万，孩子30岁时，就有160万。&lt;br&gt;　　然而国际公认平均收益率为12%，而投资自己，进行人力资源投资的投资收益最大。&lt;br&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="https://janvia.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="经济学" scheme="https://janvia.github.io/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>《禅与摩托车维修艺术》摘录</title>
    <link href="https://janvia.github.io/2019/01/04/%E3%80%8A%E7%A6%85%E4%B8%8E%E6%91%A9%E6%89%98%E8%BD%A6%E7%BB%B4%E4%BF%AE%E8%89%BA%E6%9C%AF%E3%80%8B%E6%91%98%E5%BD%95/"/>
    <id>https://janvia.github.io/2019/01/04/《禅与摩托车维修艺术》摘录/</id>
    <published>2019-01-04T07:03:37.000Z</published>
    <updated>2019-01-09T15:07:17.576Z</updated>
    
    <content type="html"><![CDATA[<img src="/2019/01/04/《禅与摩托车维修艺术》摘录/zexue.jpg"><p>　　自我爬山者，他谈论的话题永远是别的事和别的地方。他的人虽然在这里，但是他的心却不在这里。因为他拒绝活在此时此刻，他想要赶快爬到山顶，但是一旦爬上去之后仍然不快乐，因为山顶立刻就变成了‘此地’。他追寻的，他想要的都已经围绕在他的四周，但是他并不要这一切，因为这些就在他旁边。于是在体力和精神上，他所跨出的每一步都很吃力，因为他总认为自己的目标在远方。<br><a id="more"></a></p><p>一个没有目标的人才能爬到最高。（by克伦威尔）<br>例子：取消考试成绩<br>加入良质的概念</p><p>归纳法：由个别的经验归纳出普遍的原则</p><p>演绎法:从一般的原则推论出特定的结果<br>科学式的思考：<br>问题是什么；<br>假设问题的原因；<br>证实每个问题的假设；<br>预测实验的结果。<br>观察实验的结果；<br>由实验得出结论。</p><p>古典的认知认为这个世界是由一些基本形式组成的，而浪漫的认知则是从它的表象来观察。</p><p>人在思考和感觉的时候往往会偏向于某一种形式，而且会误解和看轻另一种形式。</p><p>熟悉往往会使一个人视而不见。</p><p>　　我们观察周遭成千上万的事物，你知道他们存在，但是你并没有全部注意到它们，除非出现某些奇特的或是我们容易观察到的事物。我们几乎不可能全部意识到这些东西，而且把它们记住。那样，我们心里会充满太多无用的细枝末节，从而无法思考。从这些观察当中，我们必须加以选择，而我们所选择的和所观察到的，永远不一样，因为经由选择而产生了变化。我们从所观察到的事物当中选出一把沙子，然后称这把沙子为世界。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2019/01/04/《禅与摩托车维修艺术》摘录/zexue.jpg&quot;&gt;
&lt;p&gt;　　自我爬山者，他谈论的话题永远是别的事和别的地方。他的人虽然在这里，但是他的心却不在这里。因为他拒绝活在此时此刻，他想要赶快爬到山顶，但是一旦爬上去之后仍然不快乐，因为山顶立刻就变成了‘此地’。他追寻的，他想要的都已经围绕在他的四周，但是他并不要这一切，因为这些就在他旁边。于是在体力和精神上，他所跨出的每一步都很吃力，因为他总认为自己的目标在远方。&lt;br&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="https://janvia.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="哲学" scheme="https://janvia.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>《当我遇见一个人》摘录</title>
    <link href="https://janvia.github.io/2019/01/04/%E3%80%8A%E5%BD%93%E6%88%91%E9%81%87%E8%A7%81%E4%B8%80%E4%B8%AA%E4%BA%BA%E3%80%8B%E6%91%98%E5%BD%95/"/>
    <id>https://janvia.github.io/2019/01/04/《当我遇见一个人》摘录/</id>
    <published>2019-01-04T06:49:43.000Z</published>
    <updated>2019-01-09T15:08:19.189Z</updated>
    
    <content type="html"><![CDATA[<img src="/2019/01/04/《当我遇见一个人》摘录/lixue.jpg"><p>  当一个生命带着极大的爱和信任降临到家庭中，他最渴望的是被看见，<br>  被父母看见真实的自己，而不是通过一堆‘正确’的数据来评价和矫正自己。</p><a id="more"></a><p>  当我放下预期和目的，以我的全部本真与一个人或事物建立关系时，我就会与这个存在的全部本真相遇。</p><p>　　父母看不到孩子本身，他们看到的是孩子的功能价值。父母能否看到孩子本身的存在，而不是用外在价值去定义物质性的‘它’，这一点决定了孩子内心能否直接感受到爱。若孩子本然的存在不被看见，即使父母为孩子倾注一切，孩子也只是父母表达爱的道具。</p><p>  爱，是如他所是，非吾所愿</p><p>　　我拒绝了这件事情，不等于拒绝你这个人，不等于你提的要求不合理，不等于我不在乎你。我的拒绝仅仅是因为现在我不想这样做。拒绝的同时，我不会把自己关闭，我依然感受到你的爱，理解你的需要，理解自己的需要，让我们的需要共同创造出爱的方式。如果我答应你，一定是因为我也喜欢用这种方式爱你，而不是迫于维持关系的委曲求全，所以即使我付出再多，你也不必内疚。 不带评判地拒绝，没有委屈地付出，爱的流动如此之美。</p><p>　　规则要建立在尊重感受的基础上，一个人内心极度缺爱，同时对得到爱已经绝望，会通过牺牲自己来满足所爱的人，间接地满足自己内在的小孩，而实际上，所爱的人抢走了那个内在小孩的爱，她付出越多，也就越怨恨所爱的人。</p><p>　　最好的教育就是不教育。在爱的陪伴下，不打扰就是对专注力最好的培养。孩子的精神世界我们无须全部了解，但需要时常放下成人已被高度训练过的头脑的假想，带着敬畏之心去体验。</p><p>  我们面对痛苦时最容易做的就是直接解决掉引起痛苦的外在的人或事。真正的勇士，是直面痛苦，向内看的人。</p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2019/01/04/《当我遇见一个人》摘录/lixue.jpg&quot;&gt;
&lt;p&gt;  当一个生命带着极大的爱和信任降临到家庭中，他最渴望的是被看见，&lt;br&gt;  被父母看见真实的自己，而不是通过一堆‘正确’的数据来评价和矫正自己。&lt;/p&gt;
    
    </summary>
    
      <category term="读书笔记" scheme="https://janvia.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="心理学" scheme="https://janvia.github.io/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>语法总结（5-15）</title>
    <link href="https://janvia.github.io/2019/01/04/%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93%EF%BC%885-15%EF%BC%89/"/>
    <id>https://janvia.github.io/2019/01/04/语法总结（5-15）/</id>
    <published>2019-01-04T00:23:09.000Z</published>
    <updated>2019-01-09T14:20:05.688Z</updated>
    
    <content type="html"><![CDATA[<p>本篇记录综合日语5-15的语法，以便查询</p><h3 id="N１はN２です"><a href="#N１はN２です" class="headerlink" title="Ｎ１はＮ２です"></a>Ｎ１はＮ２です</h3><p>名词谓语句:什么是什么<br>否定形式：Ｎ１はＮ２では/じゃありません。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿问  ：Ｎ１はＮ２ですか。</span><br><span class="line">✿回答：はい、そうです。</span><br><span class="line">　　　    いいえ、違います。</span><br></pre></td></tr></table></figure></p><a id="more"></a><h3 id="N１で、N２です"><a href="#N１で、N２です" class="headerlink" title="Ｎ１で、Ｎ２です"></a>Ｎ１で、Ｎ２です</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿高橋さんは高校の後輩で、今、京華大学の語学研究生です。</span><br><span class="line">✿京華大学はそちらで、北京大学はあちらです</span><br></pre></td></tr></table></figure><h3 id="～へようこそ"><a href="#～へようこそ" class="headerlink" title="～へようこそ"></a>～へようこそ</h3><p>迎接客人时使用的寒暄语，相当于汉语中的  {欢迎来到~}<br>正式的说法是：ようこそいらっしゃいました<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿中国へようこそ。</span><br></pre></td></tr></table></figure></p><h3 id="～と申します"><a href="#～と申します" class="headerlink" title="～と申します"></a>～と申します</h3><p>用于介绍说话人自己的名字，一般用于正式场合，或对上级的人，语气比较郑重。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿高橋と申します。どうぞよろしく。</span><br></pre></td></tr></table></figure></p><h3 id="N１からN２まで"><a href="#N１からN２まで" class="headerlink" title="Ｎ１からＮ２まで"></a>Ｎ１からＮ２まで</h3><p>相当于汉语的“从什么到什么之意”<br>a:表时间范围<br>b:表处所、顺序等的范围。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿授業は木曜日から金曜日までです。</span><br><span class="line">✿授業は何時からですか。</span><br></pre></td></tr></table></figure></p><h3 id="Nじゃありませんか"><a href="#Nじゃありませんか" class="headerlink" title="Ｎじゃありませんか"></a>Ｎじゃありませんか</h3><p>不是~吗？<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿今は呉先生の中国史の授業じゃありませんか。</span><br></pre></td></tr></table></figure></p><h3 id="どんなNですか"><a href="#どんなNですか" class="headerlink" title="どんなＮですか"></a>どんなＮですか</h3><p>相当于汉语:什么样的，怎么样的<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿呉先生はどんな先生ですか。</span><br></pre></td></tr></table></figure></p><h3 id="N１やN２など"><a href="#N１やN２など" class="headerlink" title="Ｎ１やＮ２など"></a>Ｎ１やＮ２など</h3><p>用于列举两个或两个以上的事物。(など可以省略)<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿専門は中国語や中国経済、中国史などです。</span><br></pre></td></tr></table></figure></p><p>注：如果用 “Ｎ１とＮ２とＮ３と” ，必须列举出全部事物</p><h3 id="そんなにA１くないです-A２ではありません"><a href="#そんなにA１くないです-A２ではありません" class="headerlink" title="そんなにA１くないです/A２ではありません"></a>そんなにA１くないです/A２ではありません</h3><p>相当于汉语中的“并没有那么”（主观想法）<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿そんなに簡単ではありません。</span><br></pre></td></tr></table></figure></p><h3 id="あまりA１くないです-A２ではありません"><a href="#あまりA１くないです-A２ではありません" class="headerlink" title="あまりA１くないです/A２ではありません"></a>あまりA１くないです/A２ではありません</h3><p>单纯地表示程度不高，相当于汉语中的“不太，不怎么”（客观上）<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿あまり簡単ではありません。</span><br></pre></td></tr></table></figure></p><h3 id="Nはどうですか"><a href="#Nはどうですか" class="headerlink" title="Ｎはどうですか"></a>Ｎはどうですか</h3><p>用于询问事物性质，相当于汉语中的“怎么样。如何”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿问：英語はどうですか。　</span><br><span class="line">✿答：英語はやさしいです。</span><br></pre></td></tr></table></figure><p>用于表示建议，相当于汉语中的“怎么样。如何”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿６時はどうですか。</span><br></pre></td></tr></table></figure></p><h3 id="Nはどうでしたか"><a href="#Nはどうでしたか" class="headerlink" title="Ｎはどうでしたか"></a>Ｎはどうでしたか</h3><p>用于询问过去发生的事情结果或者情形<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿きのうの試験はどうでしたか。</span><br></pre></td></tr></table></figure></p><h3 id="N１もN２も"><a href="#N１もN２も" class="headerlink" title="Ｎ１もＮ２も"></a>Ｎ１もＮ２も</h3><p>表示并列，相当于“~和~都”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿中国語の聞き取りも発音もとても難しいです。</span><br></pre></td></tr></table></figure></p><h3 id="Nのとき"><a href="#Nのとき" class="headerlink" title="Ｎのとき"></a>Ｎのとき</h3><p>用于表示时间，“~时候、时”的意思。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿大学創立の時は、まだ学部は少なかったです。</span><br><span class="line">✿一年生のときの相互学習はとてもよかったですね。</span><br></pre></td></tr></table></figure></p><h3 id="時間＋ごろ"><a href="#時間＋ごろ" class="headerlink" title="時間＋ごろ"></a>時間＋ごろ</h3><p>表示大概时间点，在几点“左右、前后”</p><h3 id="Nと同じ"><a href="#Nと同じ" class="headerlink" title="Ｎと同じ"></a>Ｎと同じ</h3><p>与~相同。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿美穂さんですか。私と同じ名前ですね。</span><br></pre></td></tr></table></figure></p><h3 id="N１はN２がAです"><a href="#N１はN２がAです" class="headerlink" title="Ｎ１はＮ２がAです"></a>Ｎ１はＮ２がAです</h3><p>大小主语句，即大小主语之间一般为整体与部分<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿日本語はアクセントが難しいです。</span><br><span class="line">✿私は英語が上手です。</span><br></pre></td></tr></table></figure></p><h3 id="ほとんどVません"><a href="#ほとんどVません" class="headerlink" title="ほとんどVません"></a>ほとんどVません</h3><p>相当于汉语的“几乎没~，基本上不~”等<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿手紙はほとんど書きません。</span><br></pre></td></tr></table></figure></p><h3 id="NしかVません"><a href="#NしかVません" class="headerlink" title="ＮしかＶません"></a>ＮしかＶません</h3><p>用于限定范围，相当于汉语中的“只，仅仅”之意<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿明日しか休みません。</span><br></pre></td></tr></table></figure></p><h3 id="～とか～とか"><a href="#～とか～とか" class="headerlink" title="～とか～とか"></a>～とか～とか</h3><p>口语句，“~啦~啦”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿料理はお寿司とかケーキとかです。</span><br></pre></td></tr></table></figure></p><h3 id="Nのあとで"><a href="#Nのあとで" class="headerlink" title="Ｎのあとで"></a>Ｎのあとで</h3><p>~之后<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿あしたの授業の後、ここで宿題をします。</span><br></pre></td></tr></table></figure></p><h3 id="疑问词＋か"><a href="#疑问词＋か" class="headerlink" title="疑问词＋か"></a>疑问词＋か</h3><p>表示虚指，不确定之意。<br>回答要用はい、いいえ先说明，相当于“有没有”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿休みにどこかへ遊びに行きましたか。</span><br></pre></td></tr></table></figure></p><h3 id="疑问词-格助词-も-动词否定"><a href="#疑问词-格助词-も-动词否定" class="headerlink" title="疑问词+{格助词+}も+动词否定"></a>疑问词+{格助词+}も+动词否定</h3><p>表示全面否定。 格助词是{が}或{を}时，一般省略。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿その後は何もしませんでした。</span><br></pre></td></tr></table></figure></p><h3 id="N１かN２"><a href="#N１かN２" class="headerlink" title="Ｎ１かN２"></a>Ｎ１かN２</h3><p>表示选择性的并列，“N1或者N2”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿明日、李さんか王さんが行きます。</span><br><span class="line">✿散歩か買い物に行きます。</span><br></pre></td></tr></table></figure><h3 id="Vましょう。"><a href="#Vましょう。" class="headerlink" title="Ｖましょう。"></a>Ｖましょう。</h3><p>表示建议语气的敬体形式，用于建议对方和自己一起做某事。<br>相当于汉语中的“~吧、~怎么样”</p><h3 id="N１に｛は｝N２があります-います"><a href="#N１に｛は｝N２があります-います" class="headerlink" title="Ｎ１に｛は｝Ｎ２があります/います"></a>Ｎ１に｛は｝Ｎ２があります/います</h3><p>某地有某物</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿机の上に本があります。</span><br></pre></td></tr></table></figure><h3 id="N１はN２にあります-います"><a href="#N１はN２にあります-います" class="headerlink" title="Ｎ１はＮ２にあります/います"></a>Ｎ１はＮ２にあります/います</h3><p>某物在某地<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿王さんは教室にいます。</span><br></pre></td></tr></table></figure></p><h3 id="～んです"><a href="#～んです" class="headerlink" title="～んです"></a>～んです</h3><p>用于口语，书面语写为｛のです｝。<br>接在动词、形容词的连体形后面，用于说明情况或者询问情况。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿東京の冬はあまり寒くないですね。北京の冬は寒いんですよ。</span><br><span class="line">✿人民大会堂もここにあるんですか。</span><br></pre></td></tr></table></figure></p><h3 id="Nが見えます"><a href="#Nが見えます" class="headerlink" title="Ｎが見えます"></a>Ｎが見えます</h3><p>看得见~看得到~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿晴れの日に、星がたくさん見える。</span><br></pre></td></tr></table></figure></p><h3 id="までに"><a href="#までに" class="headerlink" title="までに"></a>までに</h3><p>期限，表示该时间之前完成某一动作。 “在~之前”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿本は１０日までに返します。</span><br></pre></td></tr></table></figure><h3 id="でも"><a href="#でも" class="headerlink" title="でも"></a>でも</h3><p>接在名词或者に、と等格助词后面；<br>提建议时举出一个例子供对方考虑，语气比较委婉。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿お茶でも飲みましょうか。</span><br><span class="line">✿公園にでも行きましょうか。</span><br></pre></td></tr></table></figure></p><h3 id="Vませんか"><a href="#Vませんか" class="headerlink" title="Ｖませんか"></a>Ｖませんか</h3><p>建议，“不一起~吗？”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿一緒に公園に行きませんか。</span><br></pre></td></tr></table></figure></p><h3 id="～でしょう"><a href="#～でしょう" class="headerlink" title="～でしょう"></a>～でしょう</h3><p>推测，“~吧”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿１時ごろからは混むでしょう。</span><br></pre></td></tr></table></figure><h3 id="Nになる-A1くなる-A2になる"><a href="#Nになる-A1くなる-A2になる" class="headerlink" title="Ｎになる/A1くなる/A2になる"></a>Ｎになる/A1くなる/A2になる</h3><p>客观事实的结果或状态<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿そろそろ１２時になりますね。</span><br><span class="line">✿肌がきれいになりますよ。</span><br></pre></td></tr></table></figure></p><h3 id="Nにする、くする、にする"><a href="#Nにする、くする、にする" class="headerlink" title="Ｎにする、くする、にする"></a>Ｎにする、くする、にする</h3><p>人为造成的变化结果或状态<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿音をもう少し大きくしてもいいですか。</span><br><span class="line">✿教室をきれいにしてください。</span><br></pre></td></tr></table></figure></p><h3 id="Nにする"><a href="#Nにする" class="headerlink" title="Ｎにする"></a>Ｎにする</h3><p>表示所选择或决定的事物，相当于 “要~，定~”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿どちらもきれいですね、じゃ、やっぱり赤にしましょう。</span><br></pre></td></tr></table></figure></p><h3 id="Vています"><a href="#Vています" class="headerlink" title="Ｖています"></a>Ｖています</h3><p>1、表示某一动作正在进行<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿今、授業をしています。</span><br></pre></td></tr></table></figure></p><p>2、表示变化结果的持续<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿もう外暗くなっています。</span><br></pre></td></tr></table></figure></p><p>3、表示习惯性的动作，反复进行的动作及长期进行的动作<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿学生の大多数は学校の寮に住んでいます。</span><br></pre></td></tr></table></figure></p><h3 id="Vていました"><a href="#Vていました" class="headerlink" title="Ｖていました"></a>Ｖていました</h3><p>表示在过去的某一时段或时点上的持续动作</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿午前中図書館で勉強していました。</span><br><span class="line">✿８時から１０時まではテレビを見ていました。</span><br></pre></td></tr></table></figure><h3 id="って"><a href="#って" class="headerlink" title="って"></a>って</h3><p>用于提出话题，在口语中使用。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿鈴木さんってどんな人ですか。</span><br></pre></td></tr></table></figure></p><h3 id="もうVました"><a href="#もうVました" class="headerlink" title="もうＶました"></a>もうＶました</h3><p>表示动作已经完成，“已经~了”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿もうタイトルは決めましたか。</span><br><span class="line">✿王さんはもう帰りました。</span><br></pre></td></tr></table></figure><h3 id="まだVていません。"><a href="#まだVていません。" class="headerlink" title="まだＶていません。"></a>まだＶていません。</h3><p>还没，尚未做某事。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿朝からまだ何も食べていません。</span><br><span class="line">✿まだ来ていません。</span><br></pre></td></tr></table></figure></p><h3 id="Vて、Vて、Vます。"><a href="#Vて、Vて、Vます。" class="headerlink" title="Ｖて、Ｖて、Ｖます。"></a>Ｖて、Ｖて、Ｖます。</h3><p>表示连续进行几个动作在时间上的先后顺序。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿朝起きて、運動をして、食事をして、会社に行きます。</span><br></pre></td></tr></table></figure></p><h3 id="Vたい"><a href="#Vたい" class="headerlink" title="Ｖたい"></a>Ｖたい</h3><p>接在动词的第一连用形后面构成愿望的派生形容词，“想做~~”。<br>使用Ｖたいですか询问第二、三人称的愿望被视为不礼貌的行为。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿おいしいものが食べたいです。</span><br><span class="line">✿有名な大学に入りたいです。</span><br></pre></td></tr></table></figure></p><p>注：当表达第三人称具有进行某一动作的愿望时，一般用Ｖたがる这种形式。这时を格不能够改为が<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿父は新しいパソコンを買いたがっています。</span><br><span class="line">✿先生は山本に会いたがっていました。</span><br></pre></td></tr></table></figure></p><h3 id="Nがほしい"><a href="#Nがほしい" class="headerlink" title="Ｎがほしい"></a>Ｎがほしい</h3><p>表示希望，想要得到某东西，其非过去式只能用于表示第一人称的愿望，直接问对方Ｎがほしいですか是不礼貌的。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿家族と友達へのお土産がほしいですが…。</span><br><span class="line">✿時間がほしいです。</span><br></pre></td></tr></table></figure><h3 id="Nができます"><a href="#Nができます" class="headerlink" title="Ｎができます"></a>Ｎができます</h3><p>表示具备某种能力，能做某事，会做某事<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿日本語で買い物ができますか。</span><br><span class="line">✿王さんはテニスができます。</span><br></pre></td></tr></table></figure></p><h3 id="Nがわかります"><a href="#Nがわかります" class="headerlink" title="Ｎがわかります"></a>Ｎがわかります</h3><p>表示对人或事物的了解,助词一般用が，否定句中多用は。相当于”明白，了解”的意思。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿店員は大体日本語がわかります。</span><br><span class="line">✿この漢字の意味がわかりますか。</span><br></pre></td></tr></table></figure><h3 id="Vてもいい"><a href="#Vてもいい" class="headerlink" title="Ｖてもいい"></a>Ｖてもいい</h3><p>表允许，同意别人做某事。或者是询问别人的同意。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿試着してもいいですか。</span><br><span class="line">✿ここに座ってもいいですか。</span><br></pre></td></tr></table></figure></p><h3 id="Nはいかがですか"><a href="#Nはいかがですか" class="headerlink" title="Ｎはいかがですか"></a>Ｎはいかがですか</h3><p>用于提出建议并征求对方意见，或询问情况。<br>表示“~怎么样  ~如何”等。是Ｎはどうですか的郑重表达方式<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿もう一杯いかがですか。</span><br><span class="line">✿今晩、日本料理はいかがですか。</span><br></pre></td></tr></table></figure></p><h3 id="数量词-も"><a href="#数量词-も" class="headerlink" title="数量词+も"></a>数量词+も</h3><p>带有说话人的主观评价色彩， “竟，足足，达”。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿駅で１時間も友達を待ちました。</span><br></pre></td></tr></table></figure></p><h3 id="だけ"><a href="#だけ" class="headerlink" title="だけ"></a>だけ</h3><p>只有，仅仅。用在格助词が、を前面时，が、を有时省略。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿これは日英だけの辞書ですか。</span><br><span class="line">✿今朝は果物だけ｛を｝食べました。</span><br></pre></td></tr></table></figure><h3 id="Vてください"><a href="#Vてください" class="headerlink" title="Ｖてください"></a>Ｖてください</h3><p>请求对方做某事，一般不对上级或长者使用。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿それを見せてください。</span><br><span class="line">✿日本語を教えてください。</span><br></pre></td></tr></table></figure></p><h3 id="动词词典形-ことができる"><a href="#动词词典形-ことができる" class="headerlink" title="动词词典形+ことができる"></a>动词词典形+ことができる</h3><p>表示：<br>①具有做某事的能力，<br>②表示某种条件下行动行为的可能性。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿図書館のパソコンは何時まで使うことができますか。</span><br><span class="line">✿金さんはフランス語を話すことができます。</span><br></pre></td></tr></table></figure></p><h3 id="ずつ"><a href="#ずつ" class="headerlink" title="ずつ"></a>ずつ</h3><p>接在表示数量词或表示数量，程度的副词后面，<br>表示数量的均等分配或者动作、变化的等量反复。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿毎日、少しずつ練習しています。</span><br><span class="line">✿りんごは一人に２つずつある。</span><br></pre></td></tr></table></figure><h3 id="Vてはいけない"><a href="#Vてはいけない" class="headerlink" title="Ｖてはいけない"></a>Ｖてはいけない</h3><p>表示禁止，相当于不许、不准，多用于规则纪律，由于语气强烈，最好不要用于当面禁止别人做某事。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿教室ではタバコを吸ってはいけない。</span><br></pre></td></tr></table></figure></p><h3 id="Vないでください"><a href="#Vないでください" class="headerlink" title="Ｖないでください"></a>Ｖないでください</h3><p>表示禁止，请不要做~、请勿~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿気にしないでください。</span><br><span class="line">✿大きい声を出さないでください。</span><br></pre></td></tr></table></figure></p><h3 id="Vている-Vないとき"><a href="#Vている-Vないとき" class="headerlink" title="Ｖている/Ｖないとき"></a>Ｖている/Ｖないとき</h3><p>~的时候<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿人が下を歩いているときに、窓からごみを捨ててはいけない。</span><br><span class="line">✿私は家に誰もいないとき、自分で料理を作ります。</span><br></pre></td></tr></table></figure></p><h3 id="Vなくてもいい"><a href="#Vなくてもいい" class="headerlink" title="Ｖなくてもいい"></a>Ｖなくてもいい</h3><p>表示不做什么也可以</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿靴を脱がなくてもいいですよ。</span><br><span class="line">✿もう薬を飲まなくてもいいですよ。</span><br></pre></td></tr></table></figure><h3 id="VるVた-とき-に"><a href="#VるVた-とき-に" class="headerlink" title="ＶるＶた/とき{に}"></a>ＶるＶた/とき{に}</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿日本へ行くとき、パソコンを買いました。去日本之前买了电脑。</span><br><span class="line">✿日本へ行ったとき、パソコンを買いました。去日本之后买了电脑。</span><br></pre></td></tr></table></figure><h3 id="Vなくては｛なければ｝いけない"><a href="#Vなくては｛なければ｝いけない" class="headerlink" title="Ｖなくては｛なければ｝いけない"></a>Ｖなくては｛なければ｝いけない</h3><p>同：Ｖなくては｛なければ｝ならない<br>表示：必须做某事，应该做某事<br>在口语中なくては经常说成なくちゃ；なければ经常说成なきゃ<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿もう、病院へ戻らなくちゃいけません。</span><br><span class="line">✿日本で家に入るとき、靴を脱がなくてはいけないんでしょう。</span><br></pre></td></tr></table></figure></p><h3 id="どうして…（ん）ですか"><a href="#どうして…（ん）ですか" class="headerlink" title="どうして…（ん）ですか"></a>どうして…（ん）ですか</h3><p>为什么~呢？<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿山本さんはどうして来ないんですか。</span><br><span class="line">✿どうして先生に話さなかったんですか。</span><br></pre></td></tr></table></figure></p><h3 id="～でしょう-1"><a href="#～でしょう-1" class="headerlink" title="～でしょう"></a>～でしょう</h3><p>表示确认，要读升调<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿もう宿題は終わったでしょう。</span><br><span class="line">✿まだいいでしょう。</span><br></pre></td></tr></table></figure></p><h3 id="Nについて-Nについての"><a href="#Nについて-Nについての" class="headerlink" title="Ｎについて/Ｎについての"></a>Ｎについて/Ｎについての</h3><p>接在名词后面表示“关于，有关”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿日本文化についての資料を集めています。</span><br></pre></td></tr></table></figure></p><h3 id="～と言う"><a href="#～と言う" class="headerlink" title="～と言う"></a>～と言う</h3><p>表示直接引语<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿食事のとき、日本は皆で「いただきます」と言う。</span><br><span class="line">✿日本人は夜寝るときに、「お休みなさい」と言う。</span><br></pre></td></tr></table></figure></p><h3 id="N１というN2"><a href="#N１というN2" class="headerlink" title="N１というＮ2"></a>N１というＮ2</h3><p>叫做~的~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿渡辺さんという人を知っていますか。</span><br><span class="line">✿これは何という花ですか。</span><br></pre></td></tr></table></figure></p><h3 id="Nが好き-嫌い"><a href="#Nが好き-嫌い" class="headerlink" title="Ｎが好き/嫌い"></a>Ｎが好き/嫌い</h3><p>喜欢，讨厌某物，表示感情的形容词助词用が<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿高橋さん、京劇が好きですよね。</span><br><span class="line">✿鈴木さんは高橋さんが好きです。</span><br></pre></td></tr></table></figure></p><h3 id="N-lt-周期-gt-に-N-lt-数量-gt"><a href="#N-lt-周期-gt-に-N-lt-数量-gt" class="headerlink" title="Ｎ &lt;周期&gt; に Ｎ &lt;数量&gt;"></a>Ｎ &lt;周期&gt; に Ｎ &lt;数量&gt;</h3><p>表示某一周期内动作的频率<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿３ヶ月に１回ぐらい何かを見ていました。</span><br><span class="line">✿この薬を一日に３回飲んでください。</span><br></pre></td></tr></table></figure></p><h3 id="V简体の"><a href="#V简体の" class="headerlink" title="Ｖ简体の"></a>Ｖ简体の</h3><p>动词名词化<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿明日、三保さんが来るのを知っていますか。</span><br></pre></td></tr></table></figure></p><h3 id="N1だけで｛じゃ｝なく、N2も"><a href="#N1だけで｛じゃ｝なく、N2も" class="headerlink" title="Ｎ1だけで｛じゃ｝なく、Ｎ2も"></a>Ｎ1だけで｛じゃ｝なく、Ｎ2も</h3><p>不仅N1~N2也~</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿あの人は英語だけでなく、日本語も話せます。</span><br><span class="line">✿肉だけでなく、野菜も食べなければならないんです。</span><br></pre></td></tr></table></figure><h3 id="NでもNでも｛いい｝"><a href="#NでもNでも｛いい｝" class="headerlink" title="ＮでもＮでも｛いい｝"></a>ＮでもＮでも｛いい｝</h3><p>~和~都可以</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿土曜日でも日曜日でも大丈夫です。</span><br><span class="line">✿男の子でも女の子でもいいんですよ。</span><br></pre></td></tr></table></figure><h3 id="なかなかV-能动态-ない"><a href="#なかなかV-能动态-ない" class="headerlink" title="なかなかＶ{能动态}ない"></a>なかなかＶ{能动态}ない</h3><p>与动词能动态否定形式搭配，表示该动作很难做到。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿みんな忙しい、なかなか会えません。</span><br><span class="line">✿この町では刺身はなかなか食べられません。</span><br></pre></td></tr></table></figure><h3 id="N1はN2より-比较"><a href="#N1はN2より-比较" class="headerlink" title="Ｎ1はＮ2より{比较}"></a>Ｎ1はＮ2より{比较}</h3><p>N1比~N2要~~~</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿母は父より朝早く起きます。</span><br><span class="line">✿月曜日は火曜日より忙しい。</span><br></pre></td></tr></table></figure><h3 id="N1よりN2のほうが～"><a href="#N1よりN2のほうが～" class="headerlink" title="Ｎ1よりＮ2のほうが～"></a>Ｎ1よりＮ2のほうが～</h3><p>比起N1 ，N2更~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿父より母のほうが朝早く起きます。</span><br><span class="line">✿火曜日より月曜日のほうが忙しい。</span><br></pre></td></tr></table></figure></p><h3 id="Nのなかで｝Nが一番～"><a href="#Nのなかで｝Nが一番～" class="headerlink" title="Ｎのなかで｝Ｎが一番～"></a>Ｎのなかで｝Ｎが一番～</h3><p>在~中~是最~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿クラスの中で、王さんが一番日本語が上手です。</span><br><span class="line">✿中華料理の中では、北京ダックが一番おいしいです。</span><br></pre></td></tr></table></figure></p><h3 id="｛N1もN2も｝どちらも｛同じくらい｝"><a href="#｛N1もN2も｝どちらも｛同じくらい｝" class="headerlink" title="｛Ｎ1もＮ2も｝どちらも｛同じくらい｝"></a>｛Ｎ1もＮ2も｝どちらも｛同じくらい｝</h3><p>～N1还是N2都一样~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿どちらも同じくらい好きです。</span><br><span class="line">✿山本さんは英語も日本語も、どちらも上手です。</span><br></pre></td></tr></table></figure></p><h3 id="N1はN2とともに"><a href="#N1はN2とともに" class="headerlink" title="Ｎ1はＮ2とともに"></a>Ｎ1はＮ2とともに</h3><p>N1和N2一样<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿英語は日本語とともに必修科目である。</span><br></pre></td></tr></table></figure></p><h3 id="～と思う"><a href="#～と思う" class="headerlink" title="～と思う"></a>～と思う</h3><h4 id="～V意志形と思う"><a href="#～V意志形と思う" class="headerlink" title="～Ｖ意志形と思う"></a>～Ｖ意志形と思う</h4><p> 表达第一人称当时的意愿，想法。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿きょうは早く帰ろうと思います。</span><br></pre></td></tr></table></figure></p><h4 id="～V意志形と思っている"><a href="#～V意志形と思っている" class="headerlink" title="～Ｖ意志形と思っている"></a>～Ｖ意志形と思っている</h4><p>表达第一人称一直以来的想法，表达其他人称的意愿，想法。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿私は将来教師になろうと思っています。</span><br><span class="line">✿王さんは日本に行こうと思っている。</span><br></pre></td></tr></table></figure></p><h4 id="～Vたいと思っている"><a href="#～Vたいと思っている" class="headerlink" title="～Ｖたいと思っている"></a>～Ｖたいと思っている</h4><p> 单纯地表达一个愿望，没有落实行动，只停留在想法上。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿私は日本に行きたいと思っている。</span><br></pre></td></tr></table></figure></p><h4 id="简体句と思う。"><a href="#简体句と思う。" class="headerlink" title="简体句と思う。"></a>简体句と思う。</h4><p>表示“我认为～，我觉得～”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿プレゼント交換がいいと思う</span><br></pre></td></tr></table></figure><h4 id="简体句と思っている"><a href="#简体句と思っている" class="headerlink" title="简体句と思っている"></a>简体句と思っている</h4><p>认为~~（无人称区别）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿英語より日本語のほうが難しいと思っている人が多いです。</span><br></pre></td></tr></table></figure><h3 id="动词词典形-予定です"><a href="#动词词典形-予定です" class="headerlink" title="动词词典形+予定です"></a>动词词典形+予定です</h3><p>表示某人的计划，客观性比较强。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿夏休みは国に帰る予定です。</span><br><span class="line">✿私たち日本語学科もコンパを開く予定です。</span><br></pre></td></tr></table></figure></p><h3 id="动词词典形-つもりです"><a href="#动词词典形-つもりです" class="headerlink" title="动词词典形+つもりです"></a>动词词典形+つもりです</h3><p>表示打算做某事，主观性比较强。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿夏休みには、小説をたくさん読むつもりです。</span><br><span class="line">✿あしたからはタバコを吸わないつもりです。</span><br></pre></td></tr></table></figure></p><h3 id="～かどうか"><a href="#～かどうか" class="headerlink" title="～かどうか"></a>～かどうか</h3><p>接续：动词、形1简体，名词、形2词干  ~还是不~<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿東京の冬は寒いかどうか、日本人の友達に聞きます。</span><br><span class="line">✿このことは、あの人が知っているかどうか、わかりません。</span><br></pre></td></tr></table></figure></p><h3 id="だろう"><a href="#だろう" class="headerlink" title="だろう"></a>だろう</h3><p>だろう接在动词、形容词的简体形式以及形容动词的词干，名词后面<br>表示推测，是的でしょう简体。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿その辞書は高いだろうと思う。</span><br><span class="line">✿あそこへは電車よりバスのほうが便利だろう。</span><br></pre></td></tr></table></figure></p><h3 id="Vたことがある"><a href="#Vたことがある" class="headerlink" title="Ｖたことがある"></a>Ｖたことがある</h3><p>表示曾经有做过某事的经历<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿私は富士山に登ったことがあります。</span><br><span class="line">✿私は一度も飛行機に乗ったことがありません。</span><br></pre></td></tr></table></figure></p><h3 id="动词词典形-ことがある"><a href="#动词词典形-ことがある" class="headerlink" title="动词词典形+ことがある"></a>动词词典形+ことがある</h3><p>有时、偶尔做某事<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿私はははと喧嘩するこがある</span><br></pre></td></tr></table></figure></p><h3 id="ばかり"><a href="#ばかり" class="headerlink" title="ばかり"></a>ばかり</h3><p>接在名词或格助词后面，用于限定，带有消极的感情色彩。<br>表示： “光做某事，净做某事”<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿あの人は毎日テレビばかり見て、何もしません。</span><br></pre></td></tr></table></figure></p><h3 id="授受动词"><a href="#授受动词" class="headerlink" title="授受动词"></a>授受动词</h3><h4 id="给"><a href="#给" class="headerlink" title="给"></a>给</h4><p>给我<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿句型：Aは｛私に｝～をくれる。</span><br><span class="line">✿意思：A给我某物。</span><br><span class="line">✿注：私に可以省略。</span><br></pre></td></tr></table></figure></p><p>给其他人<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿句型：A（我或我方的人）はBに～をあげる。</span><br><span class="line">✿意思：A给B某物。</span><br></pre></td></tr></table></figure></p><h4 id="收"><a href="#收" class="headerlink" title="收"></a>收</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">✿句型：AはBに/から～をもらう。</span><br><span class="line">✿意思：A从B那里得到某物。</span><br><span class="line">✿注：这个句子中的B一般不用わたし。</span><br></pre></td></tr></table></figure><h4 id="具体用法"><a href="#具体用法" class="headerlink" title="具体用法"></a>具体用法</h4><p><img src="/images/授受动词.png" alt=""></p><h3 id="动词"><a href="#动词" class="headerlink" title="动词"></a>动词</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   ✿Ｖます：动词敬体（礼貌体），第一连用形。</span><br><span class="line">#V变形后去掉的形态为动词的第一连用形，它用于句子的中顿，</span><br><span class="line">#大多表示两个或两个以上的动词并列，也可以表示动作先后顺序，</span><br><span class="line">#通常用于书面语。</span><br><span class="line">   ✿Ｖない动词未然形（动词的简体否定）</span><br><span class="line">   ✿Ｖた动词简体过去时</span><br><span class="line">   ✿Ｖて形表示动作的中顿，语法活用</span><br><span class="line">   ✿动词能动态</span><br><span class="line">#表示“可能”的意义。</span><br><span class="line">#既可以表示人具有某种能力，也可以表示在某种状态下行为动作的可能性。</span><br><span class="line">   ✿Ｖ（よ）う   意志形</span><br><span class="line">#动词后接表示意志、建议后缀的事构成动词的意志，建议形。</span><br></pre></td></tr></table></figure><p>详见 <a href="https://janvia.github.io/2018/12/31/%E6%97%A5%E8%AF%AD%E5%8F%98%E5%BD%A2/">动词总结</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇记录综合日语5-15的语法，以便查询&lt;/p&gt;
&lt;h3 id=&quot;N１はN２です&quot;&gt;&lt;a href=&quot;#N１はN２です&quot; class=&quot;headerlink&quot; title=&quot;Ｎ１はＮ２です&quot;&gt;&lt;/a&gt;Ｎ１はＮ２です&lt;/h3&gt;&lt;p&gt;名词谓语句:什么是什么&lt;br&gt;否定形式：Ｎ１はＮ２では/じゃありません。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;✿问  ：Ｎ１はＮ２ですか。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;✿回答：はい、そうです。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;　　　    いいえ、違います。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="日语" scheme="https://janvia.github.io/categories/%E6%97%A5%E8%AF%AD/"/>
    
    
      <category term="语法" scheme="https://janvia.github.io/tags/%E8%AF%AD%E6%B3%95/"/>
    
  </entry>
  
</feed>
