<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[反向传播]]></title>
    <url>%2F2019%2F01%2F14%2F%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%2F</url>
    <content type="text"><![CDATA[定义损失函数： E_{total}=\frac12 (y-outo)^2定义激活函数： \sigma(x)=sigmod(x)前向传播第一层(输入层)： x_1\ \ \ x_2\ \ \ b_1加权和： net h_1=x_1w_1+x_2w_2+b_1 第二层(隐层)： outh_1=sigmod(neth_1) 加权和： neto_1=outh_1w_3+outh_2w_4+b_2 第三层(输出层)： outo_1=sigmod(neto_1) 计算误差值： Eo_1 = \frac12 (y_1-outo_1)^2 Eo_2 = \frac12 (y_2-outo_2)^2 E_{total}=Eo_1+Eo_2 总结：要是使误差值最小，就需要误差反向传播算法，更新得到最小误差的权重参数w和b。 反向传播须知：我们需要反向传递回去更新每一层对应的权重参数w和b。 我们使用链式法则来反向模式求导。 更新第三层（输出层）的权重参数：更新参数w： \frac{\partial E_{total}}{\partial w_3}=\frac{\partial E_{total}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial w_3} = \frac{\partial \frac12(y_1-outo_1)^2}{\partial outo_1} \cdot \frac{\partial sigmod(neto_1)}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial w_3} =(outo_1-y_1)\cdot outo_1(1-outo_1)\cdot outh_1 w_{3new}=w_{3old}-\eta \frac{\partial E_{total}}{\partial w_3}，η是学习率更新参数b： \frac{\partial E_{total}}{\partial b_2}=\frac{\partial E_{total}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial b_2} = \frac{\partial \frac12(y_1-outo_1)^2}{\partial outo_1} \cdot \frac{\partial sigmod(neto_1)}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial b_2} =(outo_1-y_1)\cdot outo_1(1-outo_1) b_{2new}=b_{2old}-\eta \frac{\partial E_{total}}{\partial b_2}, η是学习率同理可得：w4：也就是同一层的w都可以用这种方式更新。 更新上一层(隐层)的权重参数：更新权重参数w和b： \frac{\partial E_{total}}{\partial w_1}=\frac{\partial E_{total}}{\partial outh_1} \cdot \frac{\partial outh_1}{\partial neth_1} \cdot \frac{\partial neth_1}{\partial w_1} \frac{\partial E_{total}}{\partial b_1}=\frac{\partial E_{total}}{\partial outh_1} \cdot \frac{\partial outh_1}{\partial neth_1} \cdot \frac{\partial neth_1}{\partial b_1}其中： \frac{\partial E_{total}}{\partial outh_1} = \frac{\partial Eo_1}{\partial outh_1}+ \frac{\partial Eo_2}{\partial outh_1} \frac{\partial Eo_1}{\partial outh_1} = \frac{\partial Eo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial outh_1} \frac{\partial Eo_1}{\partial neto_1} = \frac{\partial E_{o_1}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} = (outo_1-y_1)\cdot outo_1(1-outo_1) \frac{\partial neto_1}{\partial outh_1} = \frac{\partial (outh_1w_3+outo_2w_4+b_2)}{\partial outh_1} = w_3同理可得： \frac{\partial Eo_2}{\partial outh_1} = \frac{\partial Eo_2}{\partial neto_2} \cdot \frac{\partial neto_2}{\partial outh_1} \frac{\partial Eo_2}{\partial neto_2} = \frac{\partial E_{o_2}}{\partial outo_2} \cdot \frac{\partial outo_2}{\partial neto_2} = (outo_2-y_2)\cdot outo_2(1-outo_2) \frac{\partial neto_2}{\partial outh_1} = w_5（(outh1连接outo2的权重，暂定为w5,）综合上式： \frac{\partial E_{total}}{\partial w_1}= [w_3 (outo_1-y_1)\cdot outo_1(1-outo_1) + w_5(outo_2-y_2)\cdot outo_2(1-outo_2)] \cdot outh_1(1-outh_1) \cdot x_1 \frac{\partial E_{total}}{\partial b_1}= [w_3 (outo_1-y_1)\cdot outo_1(1-outo_1) +w_5(outo_2-y_2)\cdot outo_2(1-outo_2)] \cdot outh_1(1-outh_1)更新： w_{1new}=w_{1old}-\eta \frac{\partial E_{total}}{\partial w_1} b_{1new}=b_{1old}-\eta \frac{\partial E_{total}}{\partial b_1}同理可得：w2：也就是同一层的w都可以用这种方式更新。 推广 我们定义第L层的第i个神经元更新权重参数时(上标表示层数，下标表示神经元)： \frac{\partial E_{total}}{\partial net_i^{(L)}} = \delta_i^{(L)} \frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)}，其中w_{ij}^{(l)}表示第l层的第i个神经元连接第l−1层的第j的神经元的相连的权重参数w。如下图所示： 推广总结根据前面所定义的： E_{total}=\frac12 (y-outo)^2 \sigma(x)=sigmod(x) \frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)} \delta_i^{(L)}=\frac{\partial E_{total}}{\partial net_i^{(L)}} = \frac{\partial E_{total}}{\partial outh_i} \cdot \frac{\partial outh_i}{\partial net_i^{(L)}} = \bigtriangledown_{out} E_{total} \times \sigma^{\prime}(net_i^{(L)})对于第ll层： \delta^{(l)}=\frac{\partial E_{total}}{\partial net^{(l)}} = \frac{\partial E_{total}}{\partial net^{(l+1)}} \cdot \frac{\partial net^{(l+1)}}{\partial net^{(l)}} = \delta^{(l+1)} \times \frac{\partial net^{(l+1)}}{\partial net^{(l)}} = \delta^{(l+1)} \times \frac{\partial (w^{(l+1)}\sigma (net^{(l)}))}{\partial net^{(l)}} = \delta^{(l+1)} w^{(l+1)} \sigma^{\prime}(net^{(L)})对于偏置项bias： \frac{\partial E_{total}}{\partial bias_i^{(l)}}=\delta_i^{(l)}四项基本原则基本形式 \delta_i^{(L)}= \bigtriangledown_{out} E_{total} \times \sigma^{\prime}(net_i^{(L)}) \delta^{(l)} = \sum_j \delta_j^{(l+1)} w_{ji}^{(l+1)} \sigma^{\prime}(net_i^{(l)}) \frac{\partial E_{total}}{\partial bias_i^{(l)}}=\delta_i^{(l)} \frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)}矩阵形式 \delta_i^{(L)}= \bigtriangledown_{out} E_{total} \bigodot \sigma^{\prime}(net_i^{(L)})其中 ⨀是Hadamard乘积（对应位置相乘） \delta^{(l)} = (w^{(l+1)})^T \delta^{(l+1)} \bigodot \sigma^{\prime}(net^{(l)}) \frac{\partial E_{total}}{\partial bias^{(l)}}=\delta^{(l)} \frac{\partial E_{total}}{\partial w^{(l)}}=\delta^{(l)}(outh^{(l-1)})^T实例 因为： \delta_i^{(L)}= \bigtriangledown_{out} E_{total} \bigodot \sigma^{\prime}(net_i^{(L)})所以： \delta^{(1)} = (w^{(2)})^T \delta^{(2)} \bigodot \sigma^{\prime}(net^{(1)}) =(\begin{bmatrix} 0.6 & 0.8 \\ 0.7 & 0.9\end{bmatrix}^T \cdot \begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix}) \bigodot \begin{bmatrix} 0.20977282 \\ 0.19661193\end{bmatrix} =\begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix}因为： \frac{\partial E_{total}}{\partial w^{(l)}}=\delta^{(l)}(outh^{(l-1)})^T所以： \Delta w^{(2)} = \delta^{(2)}(outh^{(1)})^T =\begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix} \cdot \begin{bmatrix} 0.70056714\\ 0.73105858 \end{bmatrix}^T = \begin{bmatrix} -0.00869356 & -0.00907194 \\ 0.5870176 & 0.612567 \end{bmatrix} \Delta w^{(1)} = \delta^{(1)}x^T =\begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix} \cdot \begin{bmatrix} 0.5\\ 1\end{bmatrix}^T = \begin{bmatrix} 0.00537109& 0.01074218\\ 0.00643758 & 0.01287516 \end{bmatrix}权重更新： w_{new}^2 = w_{old}^2-\Delta w^{(2)} = {\begin{bmatrix} 0.6 & 0.8 \\ 0.7 & 0.9\end{bmatrix}}-\begin{bmatrix} -0.00869356 & 0.00907194 \\ 0.5870176 & 0.612567 \end{bmatrix} = \begin{bmatrix} 0.60869356 & 0.80907194 \\ 0.64129824& 0.8387433 \end{bmatrix} b_{new}^2=b_{old}^2-\Delta b^2 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}-\begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix} =\begin{bmatrix} 1.01240932\\ 0.91620823\end{bmatrix} w_{new}^1= w_{old}^1-\Delta w^{(1)} =\begin{bmatrix} 0.1 & 0.3 \\ 0.2 & 0.4\end{bmatrix} - \begin{bmatrix} 0.00537109& 0.01074218\\ 0.00643758 & 0.01287516 \end{bmatrix} = \begin{bmatrix} 0.09462891& 0.28925782\\ 0.19356242& 0.38712484\end{bmatrix} b_{new}^1=b_{old}^1-\Delta b^1 =\begin{bmatrix} 0.5 \\ 0.5 \end{bmatrix} - \begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix} =\begin{bmatrix} 0.48925782\\ 0.48712484\end{bmatrix}权重初始化]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>反向传播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图床]]></title>
    <url>%2F2019%2F01%2F14%2F%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[安装picgo下载地址: https://github.com/Molunerfinn/PicGo/releases linux下载AppImage文件 右键属性，将权限设为允许为启动程序 配置以阿里云为例： 点击右上角头像，找到accessKeyId和accessKeySecret 创建对象存储，类型设为公共，记住存储空间名和地域（比如华南为oss-cn-shenzhen） 右键点击picgo，选择主窗口；将以上对应信息配置到图床配置，保存并应用]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>图床</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[感知器与激活函数]]></title>
    <url>%2F2019%2F01%2F14%2F%E6%84%9F%E7%9F%A5%E5%99%A8%E4%B8%8E%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[定义感知器是激活函数为阶跃函数的神经元。感知器的模型如下：· 输入(inputs)：一个感知器可以接收多个输入(x1,x2,…,xn|xi∈R)· 权值(weights)：每一个输入上都有一个权值wi∈R，此外还有一个偏置项b∈R，也就是上图的w0。· 加权和(weighted sum)：就是输入权值 x x 权值 w + 偏置项 b的总和。· 激活函数(step function)：感知器的激活函数： f(x) = \begin{cases} 0, & \text{x>0} \\ 1, & \text{x≤0} \end{cases}· 输出(output)：感知器的输出由加权值用激活函数做非线性变换。也就是这个公式：y=f(w⋅x+b)我们使用unit激活函数结合上图就有： y=f(w⋅x+b)=f(w1x1+w2x2+w3x3+bias) 其中f(x)就是激活函数 f(x)={1x&gt;0 0x≤0 ，图像如下图所示: 实例 x_1=[-1.0, 3.0, 2.0] \\ x_2=[2.0, -1.0, 5.0] \\ x_3=[-2.0, 0.0, 3.0 ] \\ x_4=[4.0, 1.0, 6.0] \\ w=[4.0, -3.0, 5.0 ] \\ b=2.0则： X=\begin{bmatrix} -1.0 & 3.0 & 2.0 \\ 2.0 & -1.0& 5.0 \\ -2.0& 0.0& 3.0 \\ 4.0& 1.0 & 6.0 \end{bmatrix} w^T =\begin{bmatrix} 4.0 \\ -3.0 \\ 5.0 \end{bmatrix}所以： logits = X\cdot w^T + b = \begin{bmatrix} -1.0 & 3.0 & 2.0 \\ 2.0 & -1.0& 5.0 \\ -2.0& 0.0& 3.0 \\ 4.0& 1.0 & 6.0 \end{bmatrix} \cdot \begin{bmatrix} 4.0 \\ -3.0 \\ 5.0 \end{bmatrix} + 2.0 \\ =[-1.0 \ \ \ 38.0 \ \ \ 7.0 \ \ \ 43.0 ]带入激活函数： output = f(x)=[0\ \ \ 1 \ \ \ 1 \ \ \ 1 ]隐层 激活函数unit激活函数： f(x) = \begin{cases} 0, & \text{x>0} \\ 1, & \text{x≤0} \end{cases} sigmod激活函数： f(x)=sigmod(x)=\frac{1}{1+e^{-x}} tanh激活函数： f(x)=tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}} relu激活函数： f(x) = \begin{cases} x, & \text{x>0} \\ 0, & \text{x≤0} \end{cases} 激活函数的作用 引入非线性因素。 在我们面对线性可分的数据集的时候，简单的用线性分类器即可解决分类问题。但是现实生活中的数据往往不是线性可分的，面对这样的数据，一般有两个方法：引入非线性函数、线性变换。 线性变换就是把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类 激活函数的特点 unit：线性分界 – 几乎已经不用了 sigmoid：非线性分界 – 两端软饱和，输出为 (0,1)区间 – 两端有梯度消失问题 – 因为输出恒正，可能有 zig现象 tanh：非线性分界 ：非线性分界 – 两端软饱和，输出为 (-1, 1) 区间 – 仍然存在梯度消失问题 – 没有 zig，收敛更快 (LeCun 1989) ReLU：非线性分界 – 左侧硬饱和，右无输出为 [0,+∞)区间 – 左侧会出现梯度一直为 0的情况，导致神经元 不再更新（死亡） – 改善了梯度弥散 – 同样存在 zig]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>感知器</tag>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络]]></title>
    <url>%2F2019%2F01%2F13%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[net新建netWork.py,添加以下代码 准备import tensorflow as tfimport config# 卷积操作def conv2d(name, l_input, w, b): return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(l_input, w, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;), b), name=name)# 最大下采样操作def max_pool(name, l_input, k): return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=&apos;SAME&apos;, name=name)# 归一化操作def norm(name, l_input, lsize=4): return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name) LeNetdef LeNet(inputs): mu = 0 sigma = 0.1 print(inputs.shape) # TODO: 第一层卷积：输入=32x32x3, 输出=28x28x6 conv1_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 6], mean=mu, stddev=sigma)) conv1_b = tf.Variable(tf.zeros(6)) conv1 = tf.nn.conv2d(inputs, conv1_w, strides=[1, 1, 1, 1], padding=&apos;VALID&apos;) + conv1_b print(conv1.shape) # 激活函数 conv1_out = tf.nn.relu(conv1) # 池化层， 输入=28x28x6, 输出=14x14x6 pool_1 = tf.nn.max_pool(conv1_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;VALID&apos;) print(pool_1.shape) # TODO: 第二层卷积： 输入=14x14x6， 输出=10x10x16 conv2_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 6, 16], mean=mu, stddev=sigma)) conv2_b = tf.Variable(tf.zeros(16)) conv2 = tf.nn.conv2d(pool_1, conv2_w, strides=[1, 1, 1, 1], padding=&apos;VALID&apos;) + conv2_b print(conv2.shape) # 激活函数 conv2_out = tf.nn.relu(conv2) # 池化层， 输入=10x10x16, 输出=5x5x16 pool_2 = tf.nn.max_pool(conv2_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;VALID&apos;) print(pool_2.shape) # Flatten 输入=5x5x16， 输出=400 pool_2_flat = tf.reshape(pool_2, [-1, 400]) # TODO: 第三层全连接层， 输入=400， 输出=120 fc1_w = tf.Variable(tf.truncated_normal(shape=[400, 120], mean=mu, stddev=sigma)) fc1_b = tf.Variable(tf.zeros(120)) fc1 = tf.matmul(pool_2_flat, fc1_w) + fc1_b # 激活函数 fc1_out = tf.nn.relu(fc1) print(fc1_out.shape) # TODO: 第四层全连接层： 输入=120， 输出=84 fc2_w = tf.Variable(tf.truncated_normal(shape=[120, 84], mean=mu, stddev=sigma)) fc2_b = tf.Variable(tf.zeros(84)) fc2 = tf.matmul(fc1_out, fc2_w) + fc2_b # 激活函数 fc2_out = tf.nn.relu(fc2) print(fc2_out.shape) # TODO: 第五层全连接层： 输入=84， 输出=10 fc3_w = tf.Variable(tf.truncated_normal(shape=[84, 10], mean=mu, stddev=sigma)) fc3_b = tf.Variable(tf.zeros(10)) fc3_out = tf.matmul(fc2_out, fc3_w) + fc3_b print(fc3_out.shape) return fc3_out alex_netdef alex_net(_X, _weights, _biases, _dropout): # 向量转为矩阵 # _X = tf.reshape(_X, shape=[-1, 28, 28, 3]) print(_X.shape) # TODO: 第一层卷积： conv1 = conv2d(&apos;conv1&apos;, _X, _weights[&apos;wc1&apos;], _biases[&apos;bc1&apos;]) # 下采样层 pool1 = max_pool(&apos;pool1&apos;, conv1, k=2) # 归一化层 norm1 = norm(&apos;norm1&apos;, pool1, lsize=4) print(norm1.shape) # TODO: 第二层卷积： conv2 = conv2d(&apos;conv2&apos;, norm1, _weights[&apos;wc2&apos;], _biases[&apos;bc2&apos;]) # 下采样 pool2 = max_pool(&apos;pool2&apos;, conv2, k=2) # 归一化 norm2 = norm(&apos;norm2&apos;, pool2, lsize=4) print(norm2.shape) # TODO: 第三层卷积： conv3 = conv2d(&apos;conv3&apos;, norm2, _weights[&apos;wc3&apos;], _biases[&apos;bc3&apos;]) # 归一化 norm3 = norm(&apos;norm3&apos;, conv3, lsize=4) print(norm3.shape) # TODO: 第四层卷积 # 卷积 conv4 = conv2d(&apos;conv4&apos;, norm3, _weights[&apos;wc4&apos;], _biases[&apos;bc4&apos;]) # 归一化 norm4 = norm(&apos;norm4&apos;, conv4, lsize=4) print(norm4.shape) # TODO: 第五层卷积 # 卷积 conv5 = conv2d(&apos;conv5&apos;, norm4, _weights[&apos;wc5&apos;], _biases[&apos;bc5&apos;]) # 下采样 pool5 = max_pool(&apos;pool5&apos;, conv5, k=2) # 归一化 norm5 = norm(&apos;norm5&apos;, pool5, lsize=4) print(norm5.shape) # TODO: 第六层全连接层 # 先把特征图转为向量 dense1 = tf.reshape(norm5, [-1, _weights[&apos;wd1&apos;].get_shape().as_list()[0]]) dense1 = tf.nn.relu(tf.matmul(dense1, _weights[&apos;wd1&apos;]) + _biases[&apos;bd1&apos;], name=&apos;fc1&apos;) dense1 = tf.nn.dropout(dense1, _dropout) print(dense1.shape) # TODO: 第七层全连接层： dense2 = tf.nn.relu(tf.matmul(dense1, _weights[&apos;wd2&apos;]) + _biases[&apos;bd2&apos;], name=&apos;fc2&apos;) # Relu activation dense2 = tf.nn.dropout(dense2, _dropout) print(dense2.shape) # TODO: 第八层全连接层： # 网络输出层 out = tf.matmul(dense2, _weights[&apos;out&apos;]) + _biases[&apos;out&apos;] print(out.shape) return out cnn_1def CNN_1(inputs): # (32x32x3)--&gt;(32x32x64) with tf.name_scope(&apos;conv1&apos;): h_conv1 = tf.layers.conv2d(inputs, 64, [2, 2], padding=&apos;SAME&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(h_conv1.shape) # 构建池化层--采用最大池化 # (32X32X64)--&gt;(16X16X64) with tf.name_scope(&apos;pool1&apos;): h_pool1 = tf.layers.max_pooling2d(h_conv1, pool_size=[2, 2], strides=[2, 2], padding=&apos;SAME&apos;) print(h_pool1.shape) # 构建第二层卷积计算层--(16x16x64)--&gt;(16x16x128). with tf.name_scope(&apos;conv2&apos;): h_conv2 = tf.layers.conv2d(h_pool1, 128, [4, 4], padding=&apos;SAME&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(h_conv2.shape) # 构建第二个池化层(16x16x128)--&gt;(8x8x128) with tf.name_scope(&apos;pool2&apos;): h_pool2 = tf.layers.max_pooling2d(h_conv2, pool_size=[2, 2], strides=[2, 2], padding=&apos;SAME&apos;) print(h_pool2.shape) # 构建全连接层--(8x8x128)--&gt;(1024) with tf.name_scope(&apos;fc1&apos;): h_pool2_flat = tf.layers.flatten(h_pool2) h_fc1 = tf.layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu) print(h_fc1.shape) # Dropout--防止过拟合 with tf.name_scope(&apos;dropout&apos;): # keep_prob = tf.placeholder(tf.float32) h_fc_drop = tf.nn.dropout(h_fc1, keep_prob=config.keep_prob) # 构建全连接层--1024--&gt;512 with tf.name_scope(&apos;fc2&apos;): fc2 = tf.layers.dense(h_fc_drop, 512, activation=tf.nn.relu) print(fc2.shape) # 构建全连接层--512--&gt;10 with tf.name_scope(&apos;fc3&apos;): out = tf.layers.dense(fc2, 10, activation=None) print(out.shape) return out VGG16def VGG16(inputs): print(inputs.shape) # (32x32x3) --&gt; (32x32x64) with tf.name_scope(&apos;conv_1&apos;): conv_1_out = tf.layers.conv2d(inputs, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_1_out.shape) # (32x32x64) --&gt; (32x32x64) with tf.name_scope(&apos;conv_2&apos;): conv_2_out = tf.layers.conv2d(conv_1_out, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_2_out.shape) # (32x32x64) --&gt; (16x16x64) with tf.name_scope(&apos;pool_1&apos;): pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_1_out.shape) # (16x16x64) --&gt; (16x16x128) with tf.name_scope(&apos;conv_3&apos;): conv_3_out = tf.layers.conv2d(pool_1_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_3_out.shape) # (16x16x128) --&gt; (16x16x128) with tf.name_scope(&apos;conv_4&apos;): conv_4_out = tf.layers.conv2d(conv_3_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_4_out.shape) # (16x16x128) --&gt; (8x8x128) with tf.name_scope(&apos;pool_2&apos;): pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_2_out.shape) # (8x8x128) --&gt; (8x8x256) with tf.name_scope(&apos;conv_5&apos;): conv_5_out = tf.layers.conv2d(pool_2_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_5_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_6&apos;): conv_6_out = tf.layers.conv2d(conv_5_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_6_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_7&apos;): conv_7_out = tf.layers.conv2d(conv_6_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_7_out.shape) # (8x8x256) --&gt; (4x4x256) with tf.name_scope(&apos;pool_3&apos;): pool_3_out = tf.layers.max_pooling2d(conv_7_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_3_out.shape) # (4x4x256) --&gt; (4x4x512) with tf.name_scope(&apos;conv_8&apos;): conv_8_out = tf.layers.conv2d(pool_3_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_8_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_9&apos;): conv_9_out = tf.layers.conv2d(conv_8_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_9_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_10&apos;): conv_10_out = tf.layers.conv2d(conv_9_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_10_out.shape) # (4x4x512) --&gt; (2x2x512) with tf.name_scope(&apos;pool_4&apos;): pool_4_out = tf.layers.max_pooling2d(conv_10_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_4_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_11&apos;): conv_11_out = tf.layers.conv2d(pool_4_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_11_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_12&apos;): conv_12_out = tf.layers.conv2d(conv_11_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_12_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_13&apos;): conv_13_out = tf.layers.conv2d(conv_12_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_13_out.shape) # (2x2x512) --&gt; (1x1x512) with tf.name_scope(&apos;pool_5&apos;): pool_5_out = tf.layers.max_pooling2d(conv_13_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_5_out.shape) # (1x1x512) --&gt; 512 with tf.name_scope(&apos;fc_1&apos;): pool_5_outz_flat = tf.layers.flatten(pool_5_out) fc_1_out = tf.layers.dense(pool_5_outz_flat, 512, activation=tf.nn.relu) fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob) print(fc_1_drop.shape) # 512 --&gt; 512 with tf.name_scope(&apos;fc_2&apos;): fc_2_out = tf.layers.dense(fc_1_drop, 512, activation=tf.nn.relu) fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob) print(fc_2_drop.shape) # 512 --&gt; 10 with tf.name_scope(&apos;fc_3&apos;): fc_3_out = tf.layers.dense(fc_2_drop, 10, activation=None) print(fc_3_out.shape) return fc_3_out vgg19def VGG19(inputs): print(inputs.shape) # (32x32x3) --&gt; (32x32x64) with tf.name_scope(&apos;conv_1&apos;): conv_1_out = tf.layers.conv2d(inputs, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_1_out.shape) # (32x32x64) --&gt; (32x32x64) with tf.name_scope(&apos;conv_2&apos;): conv_2_out = tf.layers.conv2d(conv_1_out, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_2_out.shape) # (32x32x64) --&gt; (16x16x64) with tf.name_scope(&apos;pool_1&apos;): pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_1_out.shape) # (16x16x64) --&gt; (16x16x128) with tf.name_scope(&apos;conv_3&apos;): conv_3_out = tf.layers.conv2d(pool_1_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_3_out.shape) # (16x16x128) --&gt; (16x16x128) with tf.name_scope(&apos;conv_4&apos;): conv_4_out = tf.layers.conv2d(conv_3_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_4_out.shape) # (16x16x128) --&gt; (8x8x128) with tf.name_scope(&apos;pool_2&apos;): pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_2_out.shape) # (8x8x128) --&gt; (8x8x256) with tf.name_scope(&apos;conv_5&apos;): conv_5_out = tf.layers.conv2d(pool_2_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_5_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_6&apos;): conv_6_out = tf.layers.conv2d(conv_5_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_6_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_7&apos;): conv_7_out = tf.layers.conv2d(conv_6_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_7_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_8&apos;): conv_8_out = tf.layers.conv2d(conv_7_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_8_out.shape) # (8x8x256) --&gt; (4x4x256) with tf.name_scope(&apos;pool_3&apos;): pool_3_out = tf.layers.max_pooling2d(conv_8_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_3_out.shape) # (4x4x256) --&gt; (4x4x512) with tf.name_scope(&apos;conv_9&apos;): conv_9_out = tf.layers.conv2d(pool_3_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_9_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_10&apos;): conv_10_out = tf.layers.conv2d(conv_9_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_10_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_11&apos;): conv_11_out = tf.layers.conv2d(conv_10_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_11_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_12&apos;): conv_12_out = tf.layers.conv2d(conv_11_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_12_out.shape) # (4x4x512) --&gt; (2x2x512) with tf.name_scope(&apos;pool_4&apos;): pool_4_out = tf.layers.max_pooling2d(conv_12_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_4_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_13&apos;): conv_13_out = tf.layers.conv2d(pool_4_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_13_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_14&apos;): conv_14_out = tf.layers.conv2d(conv_13_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_14_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_15&apos;): conv_15_out = tf.layers.conv2d(conv_14_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_15_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_16&apos;): conv_16_out = tf.layers.conv2d(conv_15_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_16_out.shape) # (2x2x512) --&gt; (1x1x512) with tf.name_scope(&apos;pool_5&apos;): pool_5_out = tf.layers.max_pooling2d(conv_16_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_5_out.shape) # (1x1x512) --&gt; 512 with tf.name_scope(&apos;fc_1&apos;): pool_5_outz_flat = tf.layers.flatten(pool_5_out) fc_1_out = tf.layers.dense(pool_5_outz_flat, 512, activation=tf.nn.relu) fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob) print(fc_1_drop.shape) # 512 --&gt; 512 with tf.name_scope(&apos;fc_2&apos;): fc_2_out = tf.layers.dense(fc_1_drop, 512, activation=tf.nn.relu) fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob) print(fc_2_drop.shape) # 512 --&gt; 10 with tf.name_scope(&apos;fc_3&apos;): fc_3_out = tf.layers.dense(fc_2_drop, 10, activation=None) print(fc_3_out.shape) return fc_3_out 读取数据加载数据import pickleimport numpy as npfrom sklearn.preprocessing import MinMaxScaler, LabelBinarizerdef load_cifar10_batch(path, batch_id): &quot;&quot;&quot; 加载batch的数据 :param path: 数据存储的目录 :param batch_id:batch的编号 :return:features and labels &quot;&quot;&quot; with open(path + &apos;/data_batch_&apos; + str(batch_id), mode=&apos;rb&apos;) as file: batch = pickle.load(file, encoding=&apos;latin1&apos;) # features and labels features = batch[&apos;data&apos;].reshape((len(batch[&apos;data&apos;]), 3, 32, 32)).transpose(0, 2, 3, 1) labels = batch[&apos;labels&apos;] return features, labels 数据预处理def pre_processing_data(x_train, y_train, x_test, y_test): # features minmax = MinMaxScaler() # 重塑数据 # (50000, 32, 32, 3) --&gt; (50000, 32*32*3) x_train_rows = x_train.reshape(x_train.shape[0], 32*32*3) # (10000, 32, 32, 3) --&gt; (10000, 32*32*3) x_test_rows = x_test.reshape(x_test.shape[0], 32*32*3) # 归一化 x_train_norm = minmax.fit_transform(x_train_rows) x_test_norm = minmax.fit_transform(x_test_rows) # 重塑数据 x_train = x_train_norm.reshape(x_train_norm.shape[0], 32, 32, 3) x_test = x_test_norm.reshape(x_test_norm.shape[0], 32, 32, 3) # labels # 对标签进行one-hot n_class = 10 label_binarizer = LabelBinarizer().fit(np.array(range(n_class))) y_train = label_binarizer.transform(y_train) y_test = label_binarizer.transform(y_test) return x_train, y_train, x_test, y_test 数据准备新建Read_date.pydef cifar10_data(): # 加载训练数据 cifar10_path = &apos;data&apos; # 一共是有5个batch的训练数据 x_train, y_train = load_cifar10_batch(cifar10_path, 1) for n in range(2, 6): features, labels = load_cifar10_batch(cifar10_path, n) x_train = np.concatenate([x_train, features]) y_train = np.concatenate([y_train, labels]) # 加载测试数据 with open(cifar10_path + &apos;/test_batch&apos;, mode=&apos;rb&apos;) as file: batch = pickle.load(file, encoding=&apos;latin1&apos;) x_test = batch[&apos;data&apos;].reshape((len(batch[&apos;data&apos;]), 3, 32, 32)).transpose(0, 2, 3, 1) y_test = batch[&apos;labels&apos;] x_train, y_train, x_test, y_test = pre_processing_data(x_train, y_train, x_test, y_test) return x_train, y_train, x_test, y_test config新建config.py；复制以下代码 初始化卷积神经网络参数import tensorflow as tfimport matplotlib.pyplot as pltkeep_prob = 0.8epochs = 20batch_size = 128n_classes = 10 # 总共10类 定义placeholderinputs = tf.placeholder(tf.float32, [None, 32, 32, 3], name=&apos;inputs&apos;)targets = tf.placeholder(tf.float32, [None, 10], name=&apos;logits&apos;)learning_rate = 0.001 显示图片def show_images(images): fig, axes = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(9, 9)) img = images[: 60] for image, row in zip([img[: 20], img[20: 40], img[40: 60]], axes): for img, ax in zip(image, row): ax.imshow(img) ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) fig.tight_layout(pad=0.1) # plt.show() 存储网络参数(alexnet)weights = &#123; &apos;wc1&apos;: tf.Variable(tf.random_normal(shape=[11, 11, 3, 96])), &apos;wc2&apos;: tf.Variable(tf.random_normal(shape=[5, 5, 96, 256])), &apos;wc3&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 256, 384])), &apos;wc4&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 384, 384])), &apos;wc5&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 384, 256])), &apos;wd1&apos;: tf.Variable(tf.random_normal(shape=[4*4*256, 4096])), &apos;wd2&apos;: tf.Variable(tf.random_normal(shape=[4096, 1024])), &apos;out&apos;: tf.Variable(tf.random_normal(shape=[1024, n_classes]))&#125;biases = &#123; &apos;bc1&apos;: tf.Variable(tf.random_normal([96])), &apos;bc2&apos;: tf.Variable(tf.random_normal([256])), &apos;bc3&apos;: tf.Variable(tf.random_normal([384])), &apos;bc4&apos;: tf.Variable(tf.random_normal([384])), &apos;bc5&apos;: tf.Variable(tf.random_normal([256])), &apos;bd1&apos;: tf.Variable(tf.random_normal([4096])), &apos;bd2&apos;: tf.Variable(tf.random_normal([1024])), &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))&#125; 测试模型新建TestModel.py,复制以下代码 模型评估import tensorflow as tfimport configimport Read_datadef evaluate(X_data, y_data, inputs, logits, targets): batch_size = config.batch_size correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1)) accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) num_examples = len(X_data) total_accuracy = 0 sess = tf.get_default_session() for offset in range(0, num_examples, batch_size): batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size] accuracy = sess.run(accuracy_operation, feed_dict=&#123;inputs: batch_x, targets: batch_y&#125;) total_accuracy += (accuracy * len(batch_x)) return total_accuracy / num_examples 读取模型def run(inputs, logits, targets): print(&apos;TESTING....&apos;) x_train, y_train, x_test, y_test = Read_data.cifar10_data() saver = tf.train.Saver() with tf.Session() as sess: print(&quot;Evaluate The Model&quot;) # TODO: 读取模型 saver.restore(sess, &apos;./model/cifar.model&apos;) test_accuracy = evaluate(x_test, y_test, inputs, logits, targets) print(&quot;Test Accuracy = &#123;:.3f&#125;&quot;.format(test_accuracy)) 训练创建TrainModel.py,复制以下代码from sklearn.model_selection import train_test_splitimport tensorflow as tfimport Read_dataimport configimport TestModeldef run(logits): # 读取数据 global train_loss x_train, y_train, x_test, y_test = Read_data.cifar10_data() print(y_train.shape) # 构造验证集和训练集 train_rate = 0.8 x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, train_size=train_rate) # 初始化卷积神经网络参数 epochs = config.epochs batch_size = config.batch_size # 定义输入和标签的placeholder inputs = config.inputs targets = config.targets # TODO: 计算损失值并初始化optimizer learning_rate = config.learning_rate cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets) loss_operation = tf.reduce_mean(cross_entropy) optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) training_operation = optimizer.minimize(loss_operation) # TODO: 初始化变量 init = tf.global_variables_initializer() print(&quot;FUNCTION READY!!&quot;) # TODO: 保存模型 saver = tf.train.Saver() # TODO: 训练模型 with tf.Session() as sess: sess.run(init) num_examples = len(x_train) print(&quot;Training.....&quot;) for n in range(epochs): for offset in range(0, num_examples, batch_size): batch_x, batch_y = x_train[offset:offset+batch_size], y_train[offset:offset+batch_size] train_loss, _ = sess.run([loss_operation, training_operation], feed_dict=&#123;inputs: batch_x, targets: batch_y&#125;) print(&quot;EPOCH &#123;&#125; ...&quot;.format(n + 1)) print(&quot;Train Loss &#123;:.4f&#125;&quot; .format(train_loss)) print(&quot;Validation Accuracy = &#123;:.3f&#125;&quot;.format(TestModel.evaluate(x_validation, y_validation, inputs, logits, targets))) saver.save(sess, &apos;./model/cifar.model&apos;) print(&quot;Model saved&quot;) 测试图片新建testPhoto.pyimport numpy as npimport tensorflow as tffrom PIL import Imageimport Networkimport configdef main(): with tf.Session() as sess: photo_classes = &#123;0: &apos;airplane&apos;, 1: &apos;automobile&apos;, 2: &apos;bird&apos;, 3: &apos;cat&apos;, 4: &apos;deer&apos;, 5: &apos;dog&apos;, 6: &apos;frog&apos;, 7: &apos;horse&apos;, 8: &apos;ship&apos;, 9: &apos;truck&apos;&#125; logits = Network.VGG16(config.inputs) x = config.inputs saver = tf.train.Saver() saver.restore(sess, &apos;./model/cifar.model&apos;) # input im = Image.open(&apos;image/dog-3.jpg&apos;) # im.show() im = im.resize((32, 32)) # print(im.size, im.mode) im = np.array(im).astype(np.float32) im = np.reshape(im, [-1, 32*32*3]) im = (im - (255 / 2.0)) / 255 batch_xs = np.reshape(im, [-1, 32, 32, 3]) output = sess.run(logits, feed_dict=&#123;x: batch_xs&#125;) print(output) print(&apos;the out put is :&apos;, photo_classes[np.argmax(output)])if __name__ == &apos;__main__&apos;: main() 主程序新建main.pyimport TrainModelimport TestModelimport configimport Network# logits = Network.LeNet(Setting.inputs)# logits = Network.alex_net(Setting.inputs, Setting.weights, Setting.biases, Setting.keep_prob)logits = Network.CNN_1(config.inputs)# logits = Network.VGG16(config.inputs)# logits = Network.VGG19(Setting.inputs)TrainModel.run(logits)TestModel.run(config.inputs, logits, config.targets)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keras实现CNN]]></title>
    <url>%2F2019%2F01%2F13%2Fkeras%E5%AE%9E%E7%8E%B0CNN%2F</url>
    <content type="text"><![CDATA[0.导入环境import osfrom tensorflow.examples.tutorials.mnist import input_dataimport tensorflow as tffrom keras.layers.core import Dense, Flattenfrom keras.layers.convolutional import Conv2Dfrom keras.layers.pooling import MaxPooling2Dfrom keras.objectives import categorical_crossentropyfrom keras import backend as KK.image_data_format()os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos; 1.数据准备# 使用tensorflow自带的工具加载MNIST手写数字集合mnist = input_data.read_data_sets(&apos;data&apos;, one_hot=True)# 查看数据的维度和target的维度print(mnist.train.images.shape)print(mnist.train.labels.shape) 2.准备好palceholderx = tf.placeholder(tf.float32, [None, 784])y = tf.placeholder(tf.float32, [None, 10])learnRate = tf.placeholder(tf.float32) 3.构建网络计算图结构# 把输入数据reshape--28x28=784, 单通道， -1表示Nonewith tf.name_scope(&apos;reshape&apos;): x_image = tf.reshape(x, [-1, 28, 28, 1])# 构建第一层卷积计算层--将一个灰度图像映射到32个feature maps, 卷积核为5x5net = Conv2D(32, kernel_size=[5, 5], strides=[1, 1], activation=&apos;relu&apos;, padding=&apos;same&apos;, input_shape=[28, 28, 1])(x_image)# 构建池化层--采用最大池化net = MaxPooling2D(pool_size=[2, 2])(net)# 构建第二层卷积计算层--maps 32 feature maps to 64.net = Conv2D(64, kernel_size=[5, 5], strides=[1, 1], activation=&apos;relu&apos;, padding=&apos;same&apos;)(net)# 构建第二层池化层--采用最大池化net = MaxPooling2D(pool_size=[2, 2])(net)# 构建全连接层--经过的两层的下采样（池化），28x28x1的图像--&gt;7x7x64，然后映射到1024个特征net = Flatten()(net)net = Dense(1024, activation=&apos;relu&apos;)(net)# 构建第二层全连接层--将1024个特性映射到10个类，每个类对应一个数字net = Dense(10, activation=&apos;softmax&apos;)(net) 4.计算损失值并初始化optimizercross_entropy = tf.reduce_mean(categorical_crossentropy(y, net))l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])total_loss = cross_entropy + 7e-5*l2_losstrain_step = tf.train.AdamOptimizer(learnRate).minimize(total_loss) 5.初始化变量init = tf.global_variables_initializer()print(&quot;FUNCTION READY!!&quot;) 6.在会话中执行网络定义的运算with tf.Session() as sess: sess.run(init) for step in range(3000): batch_xs, batch_ys = mnist.train.next_batch(100) lr = 0.01 _, loss, l2_loss_value, total_loss_value = sess.run( [train_step, cross_entropy, l2_loss, total_loss], feed_dict=&#123;x: batch_xs, y: batch_ys, learnRate: lr&#125;) if (step + 1) % 100 == 0: print(&quot;step %d, entropy loss: %f, l2_loss: %f, total loss: %f&quot; % (step + 1, loss, l2_loss_value, total_loss_value)) # 验证训练的模型 correct_prediction = tf.equal(tf.argmax(net, 1), tf.argmax(y, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) print(&quot;Train accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)) if (step + 1) % 1000 == 0: print(&quot;Text accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;))]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度卷积对抗生成网络-DCGAN]]></title>
    <url>%2F2019%2F01%2F13%2F%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C-DCGAN%2F</url>
    <content type="text"><![CDATA[导入环境import numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltfrom tensorflow.examples.tutorials.mnist import input_data 数据准备运行程序下面代码，mnist数据集会自动下载mnist = input_data.read_data_sets(&apos;data&apos;) 获得输入数据def get_inputs(noise_dim, image_height, image_width, image_depth): # 真实数据 inputs_real = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth], name=&apos;inputs_real&apos;) # 噪声数据 inputs_noise = tf.placeholder(tf.float32, [None, noise_dim], name=&apos;inputs_noise&apos;) return inputs_real, inputs_noise 生成器def get_generator(noise_img, output_dim, is_train=True, alpha=0.01): with tf.variable_scope(&quot;generator&quot;, reuse=(not is_train)): # 100 x 1 to 4 x 4 x 512 # 全连接层 layer1 = tf.layers.dense(noise_img, 4 * 4 * 512) layer1 = tf.reshape(layer1, [-1, 4, 4, 512]) # batch normalization layer1 = tf.layers.batch_normalization(layer1, training=is_train) # Leaky ReLU layer1 = tf.maximum(alpha * layer1, layer1) # dropout layer1 = tf.nn.dropout(layer1, keep_prob=0.8) # 4 x 4 x 512 to 7 x 7 x 256 layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding=&apos;valid&apos;) layer2 = tf.layers.batch_normalization(layer2, training=is_train) layer2 = tf.maximum(alpha * layer2, layer2) layer2 = tf.nn.dropout(layer2, keep_prob=0.8) # 7 x 7 256 to 14 x 14 x 128 layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding=&apos;same&apos;) layer3 = tf.layers.batch_normalization(layer3, training=is_train) layer3 = tf.maximum(alpha * layer3, layer3) layer3 = tf.nn.dropout(layer3, keep_prob=0.8) # 14 x 14 x 128 to 28 x 28 x 1 logits = tf.layers.conv2d_transpose(layer3, output_dim, 3, strides=2, padding=&apos;same&apos;) # MNIST原始数据集的像素范围在0-1，这里的生成图片范围为(-1,1) # 因此在训练时，记住要把MNIST像素范围进行resize outputs = tf.tanh(logits) return outputs 判别器def get_discriminator(inputs_img, reuse=False, alpha=0.01): with tf.variable_scope(&quot;discriminator&quot;, reuse=reuse): # 28 x 28 x 1 to 14 x 14 x 128 # 第一层不加入BN layer1 = tf.layers.conv2d(inputs_img, 128, 3, strides=2, padding=&apos;same&apos;) layer1 = tf.maximum(alpha * layer1, layer1) layer1 = tf.nn.dropout(layer1, keep_prob=0.8) # 14 x 14 x 128 to 7 x 7 x 256 layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding=&apos;same&apos;) layer2 = tf.layers.batch_normalization(layer2, training=True) layer2 = tf.maximum(alpha * layer2, layer2) layer2 = tf.nn.dropout(layer2, keep_prob=0.8) # 7 x 7 x 256 to 4 x 4 x 512 layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding=&apos;same&apos;) layer3 = tf.layers.batch_normalization(layer3, training=True) layer3 = tf.maximum(alpha * layer3, layer3) layer3 = tf.nn.dropout(layer3, keep_prob=0.8) # 4 x 4 x 512 to 4*4*512 x 1 flatten = tf.reshape(layer3, (-1, 4 * 4 * 512)) logits = tf.layers.dense(flatten, 1) outputs = tf.sigmoid(logits) return logits, outputs 目标函数def get_loss(inputs_real, inputs_noise, image_depth, smooth=0.1): g_outputs = get_generator(inputs_noise, image_depth, is_train=True) d_logits_real, d_outputs_real = get_discriminator(inputs_real) d_logits_fake, d_outputs_fake = get_discriminator(g_outputs, reuse=True) # 计算Loss g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_outputs_fake) * (1 - smooth))) d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_outputs_real) * ( 1 - smooth))) d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_outputs_fake))) d_loss = tf.add(d_loss_real, d_loss_fake) return g_loss, d_loss 优化器def get_optimizer(g_loss, d_loss, learning_rate=0.001): train_vars = tf.trainable_variables() g_vars = [var for var in train_vars if var.name.startswith(&quot;generator&quot;)] d_vars = [var for var in train_vars if var.name.startswith(&quot;discriminator&quot;)] # Optimizer with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): g_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(g_loss, var_list=g_vars) d_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(d_loss, var_list=d_vars) return g_opt, d_opt 显示图片def plot_images(samples): fig, axes = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True, figsize=(7, 7)) for img, ax in zip(samples, axes.flatten()): ax.imshow(img.reshape((28, 28)), cmap=&apos;Greys_r&apos;) ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) fig.tight_layout(pad=0) plt.show()def show_generator_output(sess, n_images, inputs_noise, output_dim): noise_shape = inputs_noise.get_shape().as_list()[-1] # 生成噪声图片 examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape]) samples = sess.run(get_generator(inputs_noise, output_dim, False), feed_dict=&#123;inputs_noise: examples_noise&#125;) result = np.squeeze(samples, -1) return result 开始训练# 定义参数batch_size = 64noise_size = 100epochs = 5n_samples = 25learning_rate = 0.001def train(noise_size, data_shape, batch_size, n_samples): # 存储loss losses = [] steps = 0 inputs_real, inputs_noise = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3]) g_loss, d_loss = get_loss(inputs_real, inputs_noise, data_shape[-1]) print(&quot;FUNCTION READY!!&quot;) for _ in range(6): g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, learning_rate) print(&quot;TRAINING....&quot;) #exit() with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # 迭代epoch for e in range(epochs): for batch_i in range(mnist.train.num_examples // batch_size): steps += 1 batch = mnist.train.next_batch(batch_size) batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3])) # scale to -1, 1 batch_images = batch_images * 2 - 1 # noise batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size)) # run optimizer sess.run(g_train_opt, feed_dict=&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) sess.run(d_train_opt, feed_dict=&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) if steps % 101 == 0: train_loss_d = d_loss.eval(&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) train_loss_g = g_loss.eval(&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) losses.append((train_loss_d, train_loss_g)) print(&quot;Epoch &#123;&#125;/&#123;&#125;....&quot;.format(e + 1, epochs), &quot;Discriminator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_d), &quot;Generator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_g)) if e % 1 == 0: # 显示图片 samples = show_generator_output(sess, n_samples, inputs_noise, data_shape[-1]) plot_images(samples)with tf.Graph().as_default(): train(noise_size, [-1, 28, 28, 1], batch_size, n_samples) print(&quot;OPTIMIZER END!!&quot;)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>DCGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNN写文章]]></title>
    <url>%2F2019%2F01%2F13%2FRNN%2F</url>
    <content type="text"><![CDATA[文章下载下载文章或重新找一篇文章：https://pan.baidu.com/s/1-dZd1oKZSawCN0R7LQWz1g 导入环境import numpy as npimport tensorflow as tffrom tensorflow.contrib import rnnimport randomimport timefrom collections import Counterstart_time = time.time()tf.reset_default_graph()train_file = &apos;words.txt&apos; 简单时间处理def str_time(sec): if sec &lt; 60: return str(sec) + &quot; sec&quot; elif sec &lt; (60 * 60): return str(sec / 60) + &quot; min&quot; else: return str(sec / (60 * 60)) + &quot; hour&quot; 处理汉字def get_char(txt_file): labels = str() with open(file=txt_file, mode=&apos;rb&apos;) as f: for label in f: labels = label.decode(&quot;utf-8&quot;) return labels 处理多个中文文件def readfile(files): labels = list() for txt_file in files: target = get_char(txt_file) labels.append(target) return labels 将文本数组转换为向量def char_vector(files, num_map, label=None): word_size = len(num_map) vector = lambda word: num_map.get(word, word_size) if files: label = get_char(files) labels_vector = list(map(vector, label)) return labels_vector 样本预处理train_data = get_char(train_file)print(&quot;Loading training data...&quot;)print(len(train_data))counter = Counter(train_data)words = sorted(counter)words_size = len(words)words_num_map = dict(zip(words, range(words_size)))print(&quot;字表大小：&quot;, words_size)word_label = char_vector(train_file, words_num_map) 超参数设置learning_rate = 0.001epochs = 100000display_step = 1000n_input = 4 # 每次输入4个汉字， 预测第5个汉字# 隐层神经元n_hidden1 = 256n_hidden2 = 512n_hidden3 = 512keep_prob=0.8layer_num=3batch_size=1# 定义X, Y的placeholderx = tf.placeholder(&quot;float&quot;, [None, n_input, 1])y = tf.placeholder(&quot;float&quot;, [None, words_size])# 对 weights biases 初始值的定义weights = &#123; &apos;in&apos;: tf.Variable(tf.random_normal([n_input,n_hidden1])), &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden2,words_size]))&#125;biases = &#123; # shape (128, ) &apos;in&apos;: tf.Variable(tf.constant(0.1, shape=[n_hidden1,])), # shape (10, ) &apos;out&apos;: tf.Variable(tf.constant(0.1, shape=[words_size, ]))&#125; 定义网络结构def lstm_call(): cell = tf.nn.rnn_cell.LSTMCell(num_units=n_hidden1, reuse=tf.get_variable_scope().reuse) return tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)def RNN(x, weights, biases): x = tf.reshape(x, [batch_size, n_input, 1]) # (1,4,1) 相当于batch =1 # rnn cell = tf.contrib.rnn.BasicLSTMCell(n_hidden2) init_state = cell.zero_state(batch_size, dtype=tf.float32) # final_state 的维度是 batch * n_hidden --&gt; 1 * 512 # outputs 的维度是 batch * n_input(time_step) * n_hidden --&gt; 1 * 4 * 512 outputs, final_state = tf.nn.dynamic_rnn(cell, x, initial_state=init_state, time_major=False) # print (&quot;before unstack , output shape : &quot;,outputs.shape) # output shape : (1,3,512) (batch,time_step,cell_n_hidden) # unstack 更改维度 outputs = tf.unstack(tf.transpose(outputs, [1, 0, 2])) # 这个时候 outputs 变成了list # print (&quot;output shape[-1] 2: &quot;,outputs[-1].shape) # output shape : (3,1,512), outputs[-1] shape (1,512) results = tf.matmul(outputs[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;] # (1,112) 这个的表示意义是一个(1,112)的onehot，112表示字典里面总共有112个词汇 return results 计算损失值并初始化optimizerpredicted = RNN(x,weights,biases)# Loss optimizerloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predicted, labels=y))optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)# Model evaluationcorrect_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))# 保存模型save_dir = &quot;model/&quot;saver = tf.train.Saver(max_to_keep=1)# 初始化所有变量init = tf.global_variables_initializer() 训练及测试模型with tf.Session() as sess: sess.run(init) # 每训练一次，取后面四个文字向量当做输入，第五个文字向量当做标签用作计算loss offset = random.randint(0, n_input + 1) end_offset = n_input + 1 step = 0 loss_total = 0. acc_total = 0. # 恢复模型并继续训练 model = tf.train.latest_checkpoint(save_dir) print(&quot;model-ckpt:&quot;, model) start_epoch = 0 if model: saver.restore(sess, model) ind = model.find(&quot;-&quot;) start_epoch = int(model[ind + 1:]) print(start_epoch) step = start_epoch while step &lt; epochs: # 随机选择一个位置 if offset &gt; (len(train_data) - end_offset): offset = random.randint(0, n_input + 1) # 按照指定的位置获取后四个文字向量，当做输入 in_words = [[word_label[word]] for word in range(offset, offset + n_input)] in_words = np.reshape(np.array(in_words), [-1, n_input, 1]) out_onehot = np.zeros([words_size], dtype=float) out_onehot[word_label[offset + n_input]] = 1.0 # 所有的字都变成onehot out_onehot = np.reshape(out_onehot, [1, -1]) _, acc, loss_val, onehot_pred = sess.run([optimizer, accuracy, loss, predicted], feed_dict=&#123;x: in_words, y: out_onehot&#125;) loss_total += loss_val acc_total += acc if (step + 1) % display_step == 0: print(&quot;Iter= &quot; + str(step + 1) + &quot;, Average Loss= &quot; + &quot;&#123;:.6f&#125;&quot;.format(loss_total / display_step) + &quot;, Average Accuracy= &quot; + &quot;&#123;:.2f&#125;%&quot;.format(100 * acc_total / display_step)) acc_total = 0. loss_total = 0. in2 = [words[word_label[i]] for i in range(offset, offset + n_input)] out2 = words[word_label[offset + n_input]] out_pred = words[int(tf.argmax(onehot_pred, 1).eval())] print(&quot;%s - [%s] vs [%s]&quot; % (in2, out2, out_pred)) saver.save(sess, save_dir + &quot;CharRNN.cpkt&quot;, global_step=step) # 中间隔了一个，作为预测 offset += (n_input + 1) step += 1 print(&quot;Finished!&quot;) saver.save(sess, save_dir + &quot;CharRnn.cpkt&quot;, global_step=step) print(&quot;Elapsed time: &quot;, str_time(time.time() - start_time)) # 测试模型 while True: prompt = &quot;请输入%s个字: &quot; % n_input sentence = input(prompt) input_word = sentence.strip() if len(input_word) != n_input: print(&quot;您输入的字符长度为：&quot;, len(input_word), &quot;请输入4个字&quot;) continue try: input_word = char_vector(None, words_num_map, input_word) for i in range(100): keys = np.reshape(np.array(input_word), [-1, n_input, 1]) onehot_pred = sess.run(predicted, feed_dict=&#123;x: keys&#125;) onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval()) sentence = &quot;%s%s&quot; % (sentence, words[onehot_pred_index]) input_word = input_word[1:] input_word.append(onehot_pred_index) print(sentence) except: print(&quot;该字我还没学会&quot;)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循环神经网络RNN-写诗]]></title>
    <url>%2F2019%2F01%2F13%2F%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-%E5%86%99%E8%AF%97%2F</url>
    <content type="text"><![CDATA[数据下载下载地址：https://pan.baidu.com/s/19fAqY0_ajkTiKfOBbpY_Sg 训练数据预处理import collectionsimport numpy as npimport tensorflow as tfpoetry_file = &apos;data/poetry.txt&apos;# 数据清洗，生成诗集poetrys = []with open(poetry_file, &quot;r&quot;, encoding=&apos;utf-8&apos;) as f: for line in f: try: line = line.strip(u&apos;\n&apos;) #strip() 方法用于移除字符串头尾指定的字符 title, content = line.strip(u&apos; &apos;).split(u&apos;:&apos;) content = content.replace(u&apos; &apos;, u&apos;&apos;) if u&apos;_&apos; in content or u&apos;(&apos; in content or u&apos;（&apos; in content or u&apos;《&apos; in content or u&apos;[&apos; in content: continue if len(content) &lt; 5 or len(content) &gt; 79: continue content = u&apos;[&apos; + content + u&apos;]&apos; poetrys.append(content) except Exception as e: pass# print(poetrys[0])# 按诗的字数排序poetrys = sorted(poetrys, key=lambda lines: len(lines))print(&apos;唐诗总数: &apos;, len(poetrys))# 统计每个字出现次数all_words = []for poetry in poetrys: all_words += [word for word in poetry]counter = collections.Counter(all_words) #Counter是一个无序的容器类型，以字典的键值对形式存储，其中元素作为key，其计数作为value。count_pairs = sorted(counter.items(), key=lambda x: -x[1])words, _ = zip(*count_pairs)# 取前多少个常用字words = words[:len(words)] + (&apos; &apos;,)# 每个字映射为一个数字IDword_num_map = dict(zip(words, range(len(words))))# 把诗转换为向量形式.trans_to_num = lambda word: word_num_map.get(word, len(words))poetrys_vector = [list(map(trans_to_num, poetry)) for poetry in poetrys]class DataSet(object): def __init__(self, data_size): self._data_size = data_size self._epochs_completed = 0 self._index_in_epoch = 0 self._data_index = np.arange(data_size) def next_batch(self, batch_size): start = self._index_in_epoch if start + batch_size &gt; self._data_size: np.random.shuffle(self._data_index) self._epochs_completed = self._epochs_completed + 1 self._index_in_epoch = batch_size full_batch_features, full_batch_labels = self.data_batch(0, batch_size) return full_batch_features, full_batch_labels else: self._index_in_epoch += batch_size end = self._index_in_epoch full_batch_features, full_batch_labels = self.data_batch(start, end) if self._index_in_epoch == self._data_size: self._index_in_epoch = 0 self._epochs_completed = self._epochs_completed + 1 np.random.shuffle(self._data_index) return full_batch_features, full_batch_labels def data_batch(self, start, end): batches = [] for i in range(start, end): batches.append(poetrys_vector[self._data_index[i]]) length = max(map(len, batches)) xdata = np.full((end - start, length), word_num_map[&apos; &apos;], np.int32) for row in range(end - start): xdata[row, :len(batches[row])] = batches[row] ydata = np.copy(xdata) ydata[:, :-1] = xdata[:, 1:] return xdata, ydata 构建RNN网络计算图# 每次取64首诗进行训练batch_size = 64n_chunk = len(poetrys_vector) // batch_sizeinput_data = tf.placeholder(tf.int32, [batch_size, None])output_targets = tf.placeholder(tf.int32, [batch_size, None])# 定义RNNdef neural_network(model=&apos;lstm&apos;, rnn_size=128, num_layers=2): global cell_fun if model == &apos;rnn&apos;: cell_fun = tf.nn.rnn_cell.BasicRNNCell elif model == &apos;gru&apos;: cell_fun = tf.nn.rnn_cell.GRUCell elif model == &apos;lstm&apos;: cell_fun = tf.nn.rnn_cell.BasicLSTMCell cell = cell_fun(rnn_size, state_is_tuple=True) cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True) initial_state = cell.zero_state(batch_size, tf.float32) with tf.variable_scope(&apos;rnnlm&apos;): softmax_w = tf.get_variable(&quot;softmax_w&quot;, [rnn_size, len(words)]) softmax_b = tf.get_variable(&quot;softmax_b&quot;, [len(words)]) with tf.device(&quot;/cpu:0&quot;): embedding = tf.get_variable(&quot;embedding&quot;, [len(words), rnn_size]) inputs = tf.nn.embedding_lookup(embedding, input_data) outputs, last_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, scope=&apos;rnnlm&apos;) output = tf.reshape(outputs, [-1, rnn_size]) logits = tf.matmul(output, softmax_w) + softmax_b probs = tf.nn.softmax(logits) return logits, last_state, probs, cell, initial_state 训练模型def load_model(sess, saver, ckpt_path): latest_ckpt = tf.train.latest_checkpoint(ckpt_path) if latest_ckpt: print(&apos;resume from&apos;, latest_ckpt) saver.restore(sess, latest_ckpt) return int(latest_ckpt[latest_ckpt.rindex(&apos;-&apos;) + 1:]) else: print(&apos;building model from Training....&apos;) sess.run(tf.global_variables_initializer()) return -1# 训练def train_neural_network(): logits, last_state, _, _, _ = neural_network() targets = tf.reshape(output_targets, [-1]) loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [targets], [tf.ones_like(targets, dtype=tf.float32)], len(words))##这个函数用于计算所有examples（假设一句话有n个单词，一个单词及单词所对应的label就是一个example,所有example就是一句话中所有单词）的加权交叉熵损失 cost = tf.reduce_mean(loss) tf.summary.scalar(&apos;loss&apos;, tf.reshape(cost, []))##画损失图 learning_rate = tf.Variable(0.0, trainable=False) tvars = tf.trainable_variables()##返回的是需要训练的变量列表 grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), 5)##tf.gradients：计算梯度；tf.clip_by_global_norm（t_list 是梯度张量， clip_norm 是截取的比率）让权重的更新限制在一个合适的范围 optimizer = tf.train.AdamOptimizer(learning_rate) train_op = optimizer.apply_gradients(zip(grads, tvars)) Session_config = tf.ConfigProto(allow_soft_placement=True) Session_config.gpu_options.allow_growth = True trainds = DataSet(len(poetrys_vector)) with tf.Session(config=Session_config) as sess: merged = tf.summary.merge_all()##tensorflow的可视化是使用summary和tensorboard合作完成的.###########tf.summary.merge_all: 将之前定义的所有summary op整合到一起 log_writer = tf.summary.FileWriter(&quot;logs&quot;, sess.graph) sess.run(tf.initialize_all_variables()) saver = tf.train.Saver(tf.all_variables()) last_epoch = load_model(sess, saver, &apos;model/&apos;) for epoch in range(last_epoch + 1, 1000): sess.run(tf.assign(learning_rate, 0.002 * (0.97 ** epoch))) #tf.assign(A, new_number): 这个函数的功能主要是把A的值变为new_number all_loss = 0.0 for batche in range(n_chunk): x, y = trainds.next_batch(batch_size) train_loss, _, _, merged_summary = sess.run([cost, last_state, train_op, merged], feed_dict=&#123;input_data: x, output_targets: y&#125;) all_loss = all_loss + train_loss if batche % 50 == 1: log_writer.add_summary(merged_summary, batche) print(&quot;epoch:&#123;&#125; \n&quot;.format(epoch), &quot;batch:&#123;&#125; \n&quot;.format(batche), &quot;Learning_rate:&#123;&#125; \n&quot;.format(0.002 * (0.97 ** epoch)), &quot;train_loss:&#123;&#125; \n&quot;.format(train_loss)) print(epoch, &apos; Loss: &apos;, all_loss * 1.0 / n_chunk) saver.save(sess, &apos;model/poetry.module-%d&apos; % epoch) log_writer.close()train_neural_network() 生成古诗数据预处理import collectionsimport numpy as npimport tensorflow as tfpoetry_file = &apos;data/poetry.txt&apos;# 诗集poetrys = []with open(poetry_file, &quot;r&quot;, encoding=&apos;utf-8&apos;) as f: for line in f: try: line = line.strip(u&apos;\n&apos;) title, content = line.strip(u&apos; &apos;).split(u&apos;:&apos;) content = content.replace(u&apos; &apos;, u&apos;&apos;) if u&apos;_&apos; in content or u&apos;(&apos; in content or u&apos;（&apos; in content or u&apos;《&apos; in content or u&apos;[&apos; in content: continue if len(content) &lt; 5 or len(content) &gt; 79: continue content = u&apos;[&apos; + content + u&apos;]&apos; poetrys.append(content) except Exception as e: pass # 按诗的字数排序poetrys = sorted(poetrys, key=lambda line: len(line))print(&apos;唐诗总数: &apos;, len(poetrys))# 统计每个字出现次数all_words = []for poetry in poetrys: all_words += [word for word in poetry]counter = collections.Counter(all_words)count_pairs = sorted(counter.items(), key=lambda x: -x[1])words, _ = zip(*count_pairs)# 取前多少个常用字words = words[:len(words)] + (&apos; &apos;,)# 每个字映射为一个数字IDword_num_map = dict(zip(words, range(len(words))))# 把诗转换为向量形式to_num = lambda word: word_num_map.get(word, len(words))poetrys_vector = [list(map(to_num, poetry)) for poetry in poetrys]# 每次取64首诗进行训练batch_size = 1n_chunk = len(poetrys_vector) // batch_size# ---------------------------------------RNN--------------------------------------#input_data = tf.placeholder(tf.int32, [batch_size, None])output_targets = tf.placeholder(tf.int32, [batch_size, None])# 定义RNNdef neural_network(model=&apos;lstm&apos;, rnn_size=128, num_layers=2): global cell_fun if model == &apos;rnn&apos;: cell_fun = tf.nn.rnn_cell.BasicRNNCell elif model == &apos;gru&apos;: cell_fun = tf.nn.rnn_cell.GRUCell elif model == &apos;lstm&apos;: cell_fun = tf.nn.rnn_cell.BasicLSTMCell cell = cell_fun(rnn_size, state_is_tuple=True) cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True) initial_state = cell.zero_state(batch_size, tf.float32) with tf.variable_scope(&apos;rnnlm&apos;): softmax_w = tf.get_variable(&quot;softmax_w&quot;, [rnn_size, len(words)]) softmax_b = tf.get_variable(&quot;softmax_b&quot;, [len(words)]) with tf.device(&quot;/cpu:0&quot;): embedding = tf.get_variable(&quot;embedding&quot;, [len(words), rnn_size]) inputs = tf.nn.embedding_lookup(embedding, input_data) outputs, last_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, scope=&apos;rnnlm&apos;) output = tf.reshape(outputs, [-1, rnn_size]) logits = tf.matmul(output, softmax_w) + softmax_b probs = tf.nn.softmax(logits) return logits, last_state, probs, cell, initial_state 用训练完成的模型生成古诗def gen_head_poetry(heads, type): if type != 5 and type != 7: print(&apos;The second para has to be 5 or 7!&apos;) return def to_word(weights): t = np.cumsum(weights)#a = np.array([[1,2,3], [4,5,6]])### np.cumsum(a)###array([ 1, 3, 6, 10, 15, 21])####array([1，1+2=3，1+2+3=6，1+2+3+4=10，1+2+3+4+5=15，1+2+3+4+5+6=21]） s = np.sum(weights) sample = int(np.searchsorted(t, np.random.rand(1) * s))##np.random.rand(3,2)##括号中为shape##np.searchsorted:寻找某个数应该插在数组的什么位置上，这个数组必须是按序排列的 return words[sample] _, last_state, probs, cell, initial_state = neural_network() Session_config = tf.ConfigProto(allow_soft_placement=True) Session_config.gpu_options.allow_growth = True with tf.Session(config=Session_config) as sess: with tf.device(&apos;/gpu:1&apos;): sess.run(tf.initialize_all_variables()) saver = tf.train.Saver(tf.all_variables()) saver.restore(sess, &apos;model/poetry.module-99&apos;) poem = &apos;&apos; for head in heads: flag = True while flag: state_ = sess.run(cell.zero_state(1, tf.float32)) x = np.array([list(map(word_num_map.get, u&apos;[&apos;))]) [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) sentence = head x = np.zeros((1, 1)) x[0, 0] = word_num_map[sentence] [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) sentence += word while word != u&apos;。&apos;: x = np.zeros((1, 1)) x[0, 0] = word_num_map[word] [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) sentence += word if len(sentence) == 2 + 2 * type: sentence += u&apos;\n&apos; poem += sentence flag = False return poemdef gen_poetry(): def to_word(weights): t = np.cumsum(weights) s = np.sum(weights) sample = int(np.searchsorted(t, np.random.rand(1) * s)) return words[sample] _, last_state, probs, cell, initial_state = neural_network() with tf.Session() as sess: sess.run(tf.initialize_all_variables()) saver = tf.train.Saver(tf.all_variables()) saver.restore(sess, &apos;model/poetry.module-99&apos;) state_ = sess.run(cell.zero_state(1, tf.float32)) x = np.array([list(map(word_num_map.get, &apos;[&apos;))]) [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) poem = &apos;&apos; while word != &apos;[&apos;: poem += word x = np.zeros((1, 1)) x[0, 0] = word_num_map[word] [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) return poem#print(gen_poetry())print(gen_head_poetry(u&apos;言叶之庭&apos;, 5))]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow-基础语法]]></title>
    <url>%2F2019%2F01%2F12%2Ftensorflow-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[数学公式API：https://github.com/tensorflow/docs/blob/master/site/en/api_guides/python constanta = tf.constant(0, name=&apos;B&apos;)b = tf.constant(1) 常量x = tf.zeros([2, 3], tf.int32)y = tf.zeros_like(x, optimize=True) 变量with tf.variable_scope(&apos;meh&apos;) as scope: a = tf.get_variable(&apos;a&apos;, [10]) b = tf.get_variable(&apos;b&apos;, [100])writer = tf.summary.FileWriter(&apos;./graphs/test&apos;, tf.get_default_graph())writer.close() placeholdder占位符input1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)output = tf.multiply(input1, input2)with tf.Session() as sess: print(sess.run([output], feed_dict=&#123;input1:[7.], input2:[2.]&#125;)) 类型转换tf.cast(tf.constant(2.0), tf.int32) 把numpy转换成Tensorimport numpy as npa = np.zeros((3,3))print(a)print(&apos;----------------&apos;)ta = tf.convert_to_tensor(a)with tf.Session() as sess: print(sess.run(ta))]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow-可视化]]></title>
    <url>%2F2019%2F01%2F12%2Ftensorflow-%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[导入包import numpy as npimport osimport tensorflow as tfimport matplotlib.pyplot as plt 设置生成的图像尺寸和去除警告os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos;plt.rcParams[&quot;figure.figsize&quot;] = (14, 8) # 生成的图像尺寸 随机生成一个线性的数据n_observations = 100xs = np.linspace(-3, 3, n_observations) #生成-3到3的n为100等差数列ys = 0.8*xs + 0.1 + np.random.uniform(-0.5, 0.5, n_observations)plt.scatter(xs, ys) #画图plt.show() #画图 准备placeholderX = tf.placeholder(tf.float32, name=&apos;X&apos;)Y = tf.placeholder(tf.float32, name=&apos;Y&apos;) 初始化参数/权重W = tf.Variable(tf.random_normal([1]), name=&apos;weight&apos;)tf.summary.histogram(&apos;weight&apos;, W) #画图b = tf.Variable(tf.random_normal([1]), name=&apos;bias&apos;)tf.summary.histogram(&apos;bias&apos;, b)#画图 计算预测结果Y_pred = tf.add(tf.multiply(X, W), b) 计算损失值loss = tf.square(Y - Y_pred, name=&apos;loss&apos;) #tf.square:平方tf.summary.scalar(&apos;loss&apos;, tf.reshape(loss, []))#画图 初始化optimizerlearning_rate = 0.01optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss) 指定迭代次数，并在session里执行graphn_samples = xs.shape[0]init = tf.global_variables_initializer()with tf.Session() as sess: # 记得初始化所有变量 sess.run(init) merged = tf.summary.merge_all()#画图 log_writer = tf.summary.FileWriter(&quot;./logs/linear_regression&quot;, sess.graph) # 训练模型 for i in range(50): total_loss = 0 for x, y in zip(xs, ys): # 通过feed_dic把数据灌进去 _, loss_value, merged_summary = sess.run([optimizer, loss, merged], feed_dict=&#123;X: x, Y: y&#125;) total_loss += loss_value if i % 5 == 0: print(&apos;Epoch &#123;0&#125;: &#123;1&#125;&apos;.format(i, total_loss / n_samples)) log_writer.add_summary(merged_summary, i)#画图 # 关闭writer log_writer.close()#画图 # 取出w和b的值 W, b = sess.run([W, b])print(W, b)print(&quot;W:&quot;+str(W[0]))print(&quot;b:&quot;+str(b[0])) 画出线性回归线plt.plot(xs, ys, &apos;bo&apos;, label=&apos;Real data&apos;)plt.plot(xs, xs * W + b, &apos;r&apos;, label=&apos;Predicted data&apos;)plt.legend()plt.show() Tensorboard查看图形数据tensorboard --logdir path/to/logs(你保存文件所在位置) 如：（log_writer = tf.summary.FileWriter(“./logs/linear_regression”, sess.graph)保存的地址）： tensorboard —logdir ./logs/linear_regression 输出：TensorBoard x.x.x at http://(你的用户名):6006 (Press CTRL+C to quit) 然后打开网页：http://localhost:6006]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20单元语法]]></title>
    <url>%2F2019%2F01%2F11%2F20%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[N + なら（ば）＜凸显、条件＞用法一接在体言后面，凸显、强调所指事物，作提示助词，提出主题，并用自信、有把握的语气进行叙述，如果以此为主题的话。接续：N+ ✿汉语：就~方面来说、~的话 1、お金なら心配は要りません。2、花なら桜です。 用法2以假设的形式提出话题，前项为前提，后项为说话人判断、决定或建议；接续： N ・ A ・ V ・ Na 直接裸接 なら ✿汉语：要是~的话~1、私ならそんなことを言いませんよ。2、海が静かならいいですが。3、彼が出席するなら、私は行きません。 ～場合は＜假设＞表示假设的情况。当假设出现了前项情况时，后项一般为针对此情况所采取的方法或对策。接续：N ・ A ・ V ・ Na 连体形+場合は ✿汉语：当~时、在~的情况下 1、王さんの都合が悪い場合は、ほかの日にしましょう。2、電話が通じない場合はどうしたらいいですか。3、雨が降った場合は、運動会を中止します。 Vたらどうですか＜建议＞表示建议或劝诱的惯用表达， ✿汉语：~怎么样、~如何★：礼貌表达方式为：~たらどうですか。 ~たらいかがですか。 ~たらいかがでしょうか1、ABC病院に行ってみたらどうでしょう。(2011年真题)2、朝からずっと勉強していますね。少し休んだらどうですか。3、ネクタイでも買ってあげたらどう？(2010年真题) くらい＜程度＞接在分句后面表示程度。举出具体的事例来说明其程度。也可写做ぐらい。基本可与「ほど」互换。接续：裸接分句后 1、怖くて怖くて、大声で叫びたいくらいだった。(2009年真题)2、涙が出るくらい痛いです。 「ほど」VS「くらい」在表示某种程度时: 如果说话人心目中对其程度没有进行高低取向时，くらい和ほど有时可以互换使用，表示相同的意思。 1、日曜は足が痛くなる**ぐらい**（〇ほど）歩いた。 如果有高低取向，则くらい表示低，而ほど表示高， 1、彼**くらい**（Ｘほど）のレベルでは通訳はできない。2、党の御恩は山**ほど**（Ｘくらい）高く、海**ほど**（Ｘくらい）深い。3、死ぬ**ほど**（×くらい）疲れた。 Vてくださいませんか＜客气的请求＞表示请求别人做某事。比｢Vてくれませんか｣更加委婉、客气，是一种尊他，客气的表达。 ✿ 汉语：能不能请您（为我做)～ １、先生のお写真を見せてくださいませんか。２、もう少し説明してくださいませんか。 VてしまったVてしまった＜感慨＞表示说话人对意外发生的事（无法挽回的事情、消极的结果等）感到很遗憾、后悔的语气。常与副词「もう」搭配１、バスで財布を落としてしまった。２、急いで来たから、財布を忘れてしまった。(2005年真题) Vてしまった＜完了＞表示动作过程的完了。用于表示持续动作的动词时，与｢V第一连用－おわる｣意思相近。１、この宿題をしてしまったら、遊びに行ける。２、この本はもう読んでしまったから、図書館に返します。 N+の＋うち＜范围＞表示限定范围。 ✿ 汉语：~当中、~之中★在表示从某范围中挑选某事物时，可与｢Ｎのなか｣替换。１、三人のうち、林さんが一番若いです。２、クラスメートのうち、6人が男性です。３、相撲とサッカーと野球のうちで、一番人気があるのはやはり野球だそうだ。 N1 または N2＜选择＞表示两者择一，多用于书面语，表示要求、指示等场合。 ✿ 汉语：~或是~1、3番の部屋、または4番の部屋に行ってください。(2008年真题)2、漢字または仮名で書いてください。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19单元语法]]></title>
    <url>%2F2019%2F01%2F11%2F19%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Nとは～という意味だ汉语：~是~的意思★口语：Ｎというのは、～✿帰省とは故郷に帰るという意味です。✿下水とは台所などで使った汚れた水のことである。✿進入禁止とは入ってはいけないという意味です。 ~うちに＜时段＞前接表示状态的词，表示在该 状态持续期间 内，发生了某件事或做某件事（有尽快进行该动作的语感）。接续： ✿ N + の + うちに ✿ Na + な + うちに ✿ A - い + うちに ✿ V - る / V-ている V-ない + うちに 汉语 ：趁着~、~时候、在~之内✿どうぞ、温かいうちに食べてください。（2008年真题）✿父が元気なうちに、一度一緒に温泉に行きたいと思います。 V-（よ）うか＜犹豫＞用于简体的会话。 自言自语 或是 与对方商量 的语气。表示说话人对是否要做某动作而 犹豫不决、踌躇不定 的心情。接续：动词意志形+か✿もう時間だから、行こうか。✿結果はどうなるかわからないけど、やってみようか。✿いくら考えてもわからないから、しばらく休んで、後にしようか。 ても・でも＜让步＞表示让步的条件。就算前项从句成立，后项主句的结果也不会改变。（同19课2单元）接续： ✿N・Na + でも ✿A-く + ても ✿V-て + ても汉语：即使~也~、就算~都~ ✿あの美術館はいつ行っても人がたくさんいる。(2007年真题)✿学校を卒業しても、日本語の勉強を続けていくつもりだ。 (2005年真题)✿今必要だから、高くても買う。✿先生でもわからないかもしれません V-ると～た＜契机＞表示说话人在 前面的事情成立 的情况下，重新认识后项事物，是一些 新的发现、认识 等，具有意外性。或以此为契机 发生了后项的事物 。 ✿五月に入ると、急に暑くなった。✿外に出ると、雨が降っていた。✿友達が怪我で入院したと聞き、慌てて病院に行ってみると思っていたより元気で安心した。 「～たら～た」 VS 「～と～た」相同点：表示“以~为契机发现了~”这一用法时，两者一般可以替换使用。 不同点：1、“と”常用于小说或故事等，而“たら”则多用于说话人表述自己直接的经历。 2、当前后两个句子表示为 同一人物的意志可控制 的连续动词时，只可以用“と”。✿男は部屋に入ると、友達に電話した。 3、当表示 说话人身体的感觉 时，只可以用“たら”，不能用“と”。✿昨夜、この薬を飲んだら、よく効いた。 でも＜极端的情况＞助词でも除了表示“示例”以外，更多的是接在名词（或者部分副词、助词）后，用于举出极端的事例。 中文：“就连~都~”“即使~也~”“尽管~也~”✿この店は日本料理が本格的ですが。日本人でもこの味に満足している。 ✿先生でもわからないかもしれない。✿この仕事は病気でも休めません✿今度の日曜日、雨でもサッカーの試合を行います。 ～し～(し)＜并列＞连接两个或两个以上的分句，列举。多用罗列于原因理由接续：分句+し翻译：“既~又~”“又~又~”✿お金もないし、時間もないから、遊びに行けない。(2008年真题)✿アパートは綺麗だし、広いし、駅からも近い。(2005年真题) ～Ｖばいい・よい&lt;建议＞常用在表示提议时。汉语：只要~就可、~就好 ✿ A:どうすればいいですか。 B:ちゃんと謝ればいいですよ。✿ お金がなければ、お父さんに借りればいいでしょう。 のに＜转折＞ ✿ V-る・V-た +のに ✿ A-い・A-かった +のに ✿ N・Na な+のに 位于句中起逆接作用，是接续助词。连接起来的句子往往都有意外、不满、埋怨等语感汉语：可是~、却~✿雨が降っているのに、傘を持たないで出かけた。✿知っているのに知らないと言った。 置于句末是终助词，表示事与愿违时的遗憾、惋惜、后悔等心情，一般多用口语。可以跟在｢ばいい｣后面。✿この部屋がもう少し広げればいいのに。✿注意していたのに。 たら＜条件＞表示 假设，属于动词的另一种条件形。接续上和动词的过去式｢た｣是一样的。表 一次性的，特定 的依存关系。表示主句的实现，建立在从句动作或变化完成的基础上。汉语： ~之后就~ ~以后~✿仕事が終わったら、お茶でも飲みにいきましょう。✿そんなにたくさん食べたら、おなかを壊しますよ。✿大学を卒業したらどんな仕事をしますか。 V-て/V-ないで&lt;伴随状态&gt;表示（没有）在前项的伴随状态下进行后项主体动作。 ✿マスクをして出かけました。✿ネクタイを締めないで会社に行きます。 V-て（は）いられない&lt;状态难以持续&gt;表示因为在紧迫的情况下，不能继续那种状态而要急于想付诸另一种行动之意。汉语：不能~，哪能~ ✿もう時間がないから、遅れてくる人を待っていられない。すぐ始めよう。✿こんなに忙しいときに、寝ていられないよ。 Nによって&lt;原因&gt;表示“那就是原因”之意，后续表示结果的词句。讲述已经发生的事情，谓语一般为过去式，多用于书面语。 ✿私の不注意な発言によって、彼を傷つけた。✿交通事故によって、電車は三時間も遅れた。 N として（は・も・の）&lt;资格性质&gt;表示动作主体进行某动作时的身份、资格、立场、性质等。汉语：作为~、以~身份、以~立场、以~资格 ✿通訳として、一緒に行く。(2011年真题)✿私としては賛成ですが、ほかの人の意見も聞いてみないと決められない。✿彼女は母としても妻としても完璧な素晴らしい女性です。✿私には私としての考えがあります。 と总结 必然结果，自然现象 ✿春になると、花が咲く✿雨だと明日の試合は中止になります。✿右に曲がると、大きな建物が見える。 契机，发现（ｖたら～た也有该用法） ✿デパートに行くと、休みだった。✿うちへ帰ると、友達が待っていた。 习惯动作 ✿起きると、すぐ顔を洗う✿彼は家に帰ると、パソコンに向かっています。 ば总结 必然结果，自然现象（と～也有该用法） ✿春になれば、花が咲く。 假定条件 ✿このごろ日本へ行けば、桜が見える。 ★注意：1、当假定式为动作或者变化时，后项不能使用ください、たい、ましょう雨が降れば、窓を閉めてください。× 2、当假定式为状态或存在时，后项可以使用ください、たい暑ければ、エアコンをつけてください。〇 3、主句一般不能使用过去式窓を開けば、富士山が見えた。× たら总结 假定（ば也有该用法） ✿安かったら、買う✿困ったら、電話してね。 契机，发现（と也有该用法） ✿窓を開けたら、海が見えた。 在～之后 ✿本を読んだら貸してください。✿大阪に着いたら電話してください。 ★注意：1、たら含有明显的完成之意，特别是前后都是动词时，一定是前项先发生，后项再发生。2、たら后项可使用命令、劝诱、依赖等表达。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wine安装qq]]></title>
    <url>%2F2019%2F01%2F11%2Fwine%E5%AE%89%E8%A3%85qq%2F</url>
    <content type="text"><![CDATA[安装wine下载地址： https://github.com/wszqkzqk/deepin-wine-ubuntu解压后安装：sudo sh ./install.sh 安装QQ、微信wine应用下载地址： http://mirrors.aliyun.com/deepin/pool/non-free/d/常用下载应用：QQ： http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.qq.im/微信： http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.wechat/Foxmail: http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.foxmail/ 异常说明微信无法发送图片：sudo apt install libjpeg62:i386 卸载：sudo apt remove 软件包名 比如deepin.com.qq.office_2.0.0deepin4_i386.deb的卸载命令：sudo apt remove deepin.com.qq.office 托盘图标安装icons-plus扩展sudo apt-get install gnome-shell-extension-top-icons-plus gnome-tweaks 然后在gnome-tweaks里设置]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>qq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-图片处理及绘图]]></title>
    <url>%2F2019%2F01%2F11%2Fopencv-%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E5%8F%8A%E7%BB%98%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[原始图片： 彩色图片灰度化方式1：import cv2 # 导入cv库img = cv2.imread(&apos;image2.jpg&apos;,0)cv2.imwrite(&apos;gray_image.jpg&apos;,img) 方式2：import cv2img = cv2.imread(&apos;image2.jpg&apos;,1)dst = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)# 颜色空间转换 1 data 2 BGR graycv2.imshow(&apos;dst&apos;,dst) 方式3#方法4 gray = r*0.299+g*0.587+b*0.114import cv2import numpy as npimg = cv2.imread(&apos;image0.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]dst = np.zeros((height,width,3),np.uint8)for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = int(b) g = int(g) r = int(r) gray = r*0.299+g*0.587+b*0.114 dst[i,j] = np.uint8(gray)cv2.imshow(&apos;dst&apos;,dst) 马赛克import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]for m in range(200,400): for n in range(400,500): # pixel -&gt;10*10 if m%10 == 0 and n%10==0: for i in range(0,10): for j in range(0,10): (b,g,r) = img[m,n] img[i+m,j+n] = (b,g,r)cv2.imwrite(&apos;msk.jpg&apos;,img) 边缘检测方式1：import cv2import numpy as npimport randomimg = cv2.imread(&apos;image2.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]#cv2.imshow(&apos;src&apos;,img)#canny 1 gray 2 高斯 3 cannygray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)imgG = cv2.GaussianBlur(gray,(3,3),0)dst = cv2.Canny(img,50,50) #图片卷积——》th#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;canny.jpg&apos;,dst) 方式2：import cv2import numpy as npimport randomimport mathimg = cv2.imread(&apos;image2.jpg&apos;, 1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]#cv2.imshow(&apos;src&apos;, img)# sobel 1 算子模版 2 图片卷积 3 阈值判决# [1 2 1 [ 1 0 -1# 0 0 0 2 0 -2# -1 -2 -1 ] 1 0 -1 ]# [1 2 3 4] [a b c d] a*1+b*2+c*3+d*4 = dst# sqrt(a*a+b*b) = f&gt;thgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)dst = np.zeros((height, width, 1), np.uint8)for i in range(0, height - 2): for j in range(0, width - 2): gy = gray[i, j] * 1 + gray[i, j + 1] * 2 + gray[i, j + 2] * 1 - gray[i + 2, j] * 1 - gray[i + 2, j + 1] * 2 - \ gray[i + 2, j + 2] * 1 gx = gray[i, j] + gray[i + 1, j] * 2 + gray[i + 2, j] - gray[i, j + 2] - gray[i + 1, j + 2] * 2 - gray[ i + 2, j + 2] grad = math.sqrt(gx * gx + gy * gy) if grad &gt; 50: dst[i, j] = 255 else: dst[i, j] = 0cv2.imwrite(&apos;sobel.jpg&apos;,dst) 颜色风格变化import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]#rgb -》RGB new “蓝色”# b=b*1.5# g = g*1.3dst = np.zeros((height,width,3),np.uint8)for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = b*1.5 g = g*1.3 if b&gt;255: b = 255 if g&gt;255: g = 255 dst[i,j]=(b,g,r)#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;dst2.jpg&apos;,dst) 油画特效import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)dst = np.zeros((height,width,3),np.uint8)for i in range(4,height-4): for j in range(4,width-4): array1 = np.zeros(8,np.uint8) for m in range(-4,4): for n in range(-4,4): p1 = int(gray[i+m,j+n]/32) array1[p1] = array1[p1]+1 currentMax = array1[0] l = 0 for k in range(0,8): if currentMax&lt;array1[k]: currentMax = array1[k] l = k # 简化 均值 for m in range(-4,4): for n in range(-4,4): if gray[i+m,j+n]&gt;=(l*32) and gray[i+m,j+n]&lt;=((l+1)*32): (b,g,r) = img[i+m,j+n] dst[i,j] = (b,g,r)cv2.imwrite(&apos;dst3.jpg&apos;,dst) 线段绘制import cv2import numpy as npnewImageInfo = (500,500,3)dst = np.zeros(newImageInfo,np.uint8)# line# 绘制线段 1 dst 2 begin 3 end 4 colorcv2.line(dst,(100,100),(400,400),(0,0,255))# 5 line wcv2.line(dst,(100,200),(400,200),(0,255,255),20)# 6 line typecv2.line(dst,(100,300),(400,300),(0,255,0),20,cv2.LINE_AA)cv2.imwrite(&apos;line.jpg&apos;,dst) 绘制矩形、圆形import cv2import numpy as npnewImageInfo = (500,500,3)dst = np.zeros(newImageInfo,np.uint8)# 1 2 左上角 3 右下角 4 5 fill -1 &gt;0 line wcv2.rectangle(dst,(50,100),(200,300),(255,0,0),5)# 2 center 3 rcv2.circle(dst,(300,100),(50),(0,255,0),2)# 2 center 3 轴(a,b) 4 angle 5 begin 6 end 7cv2.ellipse(dst,(256,350),(150,100),30,0,360,(255,255,0),-1)points = np.array([[350,50],[140,140],[200,170],[250,250],[350,50]],np.int32)print(points.shape)points = points.reshape((-1,1,2))print(points.shape)cv2.polylines(dst,[points],True,(0,0,255))cv2.imwrite(&apos;dst4.jpg&apos;,dst) 添加文字import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)font = cv2.FONT_HERSHEY_SIMPLEXcv2.rectangle(img,(400,300),(950,900),(0,255,0),3)# 1 dst 2 文字内容 3 坐标 4 5 字体大小 6 color 7 粗细 8 line typecv2.putText(img,&apos;this is flower&apos;,(500,500),font,2,(200,100,255),3,cv2.LINE_AA)cv2.imwrite(&apos;word.jpg&apos;,img)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-图片几何变换]]></title>
    <url>%2F2019%2F01%2F11%2Fopencv-%E5%9B%BE%E7%89%87%E5%87%A0%E4%BD%95%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[原始图片： 图片缩放一import cv2 # 导入cv库img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色imgInfo = img.shape # 获取图片的维度print(imgInfo)height = imgInfo[0] width = imgInfo[1]mode = imgInfo[2]# 1 放大 缩小 2 等比例 非 2:3 dstHeight = int(height*0.5)dstWidth = int(width*0.5)#最近临域插值 双线性插值 像素关系重采样 立方插值dst = cv2.resize(img,(dstWidth,dstHeight))#cv2.imshow(&apos;image&apos;,dst)cv2.imwrite(&apos;resize_image.jpg&apos;,dst) 图片缩放二import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]matScale = np.float32([[0.5,0,0],[0,0.5,0]]) # 定义缩放矩阵dst = cv2.warpAffine(img,matScale,(int(width/2),int(height/2))) # 原始数据，缩放矩阵，目标的宽高信息cv2.imwrite(&apos;warp_image.jpg&apos;,dst) 图片剪切import cv2 # 导入cv库img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色#imgInfo = img.shapeprint(img.shape)dst = img[100:600,250:800] # 获取宽度100-600， 高度250-800的图像cv2.imwrite(&apos;cut_image.jpg&apos;,dst) 图片镜像import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]deep = imgInfo[2]newImgInfo = (height*2,width,deep) # 新图片的维度dst = np.zeros(newImgInfo,np.uint8)#uint8 # 目标图片的数据维度# 刷新图片的数据for i in range(0,height): for j in range(0,width): dst[i,j] = img[i,j] #x y = 2*h - y -1 dst[height*2-i-1,j] = img[i,j]for i in range(0,width): # 添加分割线 dst[height,i] = (0,0,255)#BGRcv2.imshow(&apos;dst&apos;,dst) 图片旋转import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]# 2*3 定义旋转矩阵--旋转的中心点，旋转的角度， 缩放系数matRotate = cv2.getRotationMatrix2D((height*0.5,width*0.5),45,1)# mat rotate 1 center 2 angle 3 scale#100*100 25dst = cv2.warpAffine(img,matRotate,(height,width)) # 仿射方法#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;rotate_image.jpg&apos;,dst) 图片仿射变换import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]#src 3-&gt;dst 3 (左上角 左下角 右上角)matSrc = np.float32([[0,0],[0,height-1],[width-1,0]]) # 获取原图片三个点坐标matDst = np.float32([[50,50],[300,height-200],[width-300,100]]) # 三个点的新坐标#把两个矩阵组合matAffine = cv2.getAffineTransform(matSrc,matDst) # 获取矩阵的组合，dst = cv2.warpAffine(img,matAffine,(width,height)) # 仿射变换方法#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;aft_image.jpg&apos;,dst)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown]]></title>
    <url>%2F2019%2F01%2F09%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[粗体、斜体*这是斜体***这是粗体*****这是粗体+斜体*** 删除线~~就像这样~~ 引用通过在行首加上大于号&gt;来添加引用格式。&gt; This is the first level of quoting.&gt;&gt; &gt; This is nested blockquote.&gt;&gt; Back to the first level. 列表无序列表使用星号、加号或是减号作为列表标记：* Red* Green* Blue 分隔线* * *********- - ---------------------------------------- 链接[an example](http://example.com/)[an example](http://example.com/ &quot;Optional Title&quot;) 图像普通方式![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg &quot;Optional Title&quot;) 通过管理文件夹&#123;% asset_path slug %&#125;&#123;% asset_img slug [title] %&#125;&#123;% asset_link slug [title] %&#125; 通过图床引用&lt;figure class=&quot;half&quot;&gt; &lt;img src=&quot;http://address.com/images/image.png&quot; title=&quot;title1&quot;/&gt; &lt;img src=&quot;http://path/image.png&quot; title=&quot;title2&quot;/&gt;&lt;/figure&gt; 表格| Item | Value | Qty || :------- | ----: | :---: || Computer | $1600 | 5 || Phone | $12 | 12 || Pipe | $1 | 234 | TeX公式更换渲染器： $ npm uninstall hexo-renderer-marked --save$ npm install hexo-renderer-kramed --save 插入公式形式： $$\Gamma(z) = \int_0^\infty t^&#123;z-1&#125;e^&#123;-t&#125;dt\,.$$ 公式说明文档： https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference typora编辑器#for Linux# or run:# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAEwget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add -# add Typora&apos;s repositorysudo add-apt-repository &apos;deb https://typora.io/linux ./&apos;sudo apt-get update# install typorasudo apt-get install typora]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv图像美化]]></title>
    <url>%2F2019%2F01%2F09%2Fopencv%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%8C%96%2F</url>
    <content type="text"><![CDATA[直方图均衡化-灰度import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # 图片灰度化cv2.imshow(&apos;gray&apos;,gray)cv2.imwrite(&apos;gray2.jpg&apos;,gray)hist = cv2.equalizeHist(gray) # api 完成直方图均衡化cv2.imshow(&apos;hist&apos;,hist)cv2.imwrite(&apos;hist2.jpg&apos;,hist)cv2.waitKey(0) 直方图均衡化-彩色import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)cv2.imshow(&apos;src&apos;,img)(b,g,r) = cv2.split(img) # 通道分解# 图片单通道处理bH = cv2.equalizeHist(b)gH = cv2.equalizeHist(g)rH = cv2.equalizeHist(r)result = cv2.merge((bH,gH,rH))# 通道合成cv2.imshow(&apos;dst&apos;,result)cv2.imwrite(&apos;dst2.jpg&apos;,result)cv2.waitKey(0) 直方图均衡化-YUVimport cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)imgYUV = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb) #cv2.imshow(&apos;src&apos;,img)channelYUV = cv2.split(imgYUV) # 图片分解channelYUV[0] = cv2.equalizeHist(channelYUV[0]) # 直方图均衡化channels = cv2.merge(channelYUV) # 合成result = cv2.cvtColor(channels,cv2.COLOR_YCrCb2BGR)cv2.imshow(&apos;result2&apos;,result)cv2.imwrite(&apos;result2.jpg&apos;,result)cv2.waitKey(0) 图片修补import cv2import numpy as np#制作一张损坏的图片img = cv2.imread(&apos;image2.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色for i in range(1,100): # 总共一百个像素点 img[500+i,500] = (255,255,255) # 写入标准的白色cv2.imwrite(&apos;damaged.jpg&apos;,img)#修补损坏的图片img = cv2.imread(&apos;damaged.jpg&apos;,1)cv2.imshow(&apos;src&apos;,img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]paint = np.zeros((height,width,1),np.uint8)# 描绘图片坏的数组；进行修补for i in range(500,600): paint[i,500] = 255cv2.imshow(&apos;paint&apos;,paint)#1 src 2 maskimgDst = cv2.inpaint(img,paint,3,cv2.INPAINT_TELEA)cv2.imshow(&apos;image&apos;,imgDst)cv2.imwrite(&apos;imgDst.jpg&apos;,imgDst)cv2.waitKey(0) 亮度增强import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]cv2.imshow(&apos;src&apos;,img)dst = np.zeros((height,width,3),np.uint8)for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] bb = int(b)+40 gg = int(g)+40 rr = int(r)+40 if bb&gt;255: bb = 255 if gg&gt;255: gg = 255 if rr&gt;255: rr = 255 dst[i,j] = (bb,gg,rr)cv2.imshow(&apos;dst3&apos;,dst)cv2.imwrite(&apos;dst3.jpg&apos;,dst) 高斯滤波import cv2import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1)cv2.imshow(&apos;src&apos;,img)dst = cv2.GaussianBlur(img,(5,5),1.5)cv2.imwrite(&apos;dst4.jpg&apos;,dst)cv2.imshow(&apos;dst4&apos;,dst)cv2.waitKey(0) 均值滤波# 均值 6*6 1 。 * 【6*6】/36 = mean -》Pimport cv2import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;, 1)#cv2.imshow(&apos;src&apos;, img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]dst = np.zeros((height, width, 3), np.uint8)for i in range(3, height - 3): for j in range(3, width - 3): sum_b = int(0) sum_g = int(0) sum_r = int(0) for m in range(-3, 3): # -3 -2 -1 0 1 2 for n in range(-3, 3): (b, g, r) = img[i + m, j + n] sum_b = sum_b + int(b) sum_g = sum_g + int(g) sum_r = sum_r + int(r) b = np.uint8(sum_b / 36) g = np.uint8(sum_g / 36) r = np.uint8(sum_r / 36) dst[i, j] = (b, g, r)cv2.imshow(&apos;dst5&apos;, dst)cv2.imwrite(&apos;dst5.jpg&apos;, dst) 中值滤波import cv2import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)#cv2.imshow(&apos;src&apos;,img)cv2.imwrite(&apos;src6.jpg&apos;,img)dst = np.zeros((height,width,3),np.uint8)collect = np.zeros(9,np.uint8)for i in range(1,height-1): for j in range(1,width-1): k = 0 for m in range(-1,2): for n in range(-1,2): gray = img[i+m,j+n] collect[k] = gray k = k+1 # 0 1 2 3 4 5 6 7 8 # 1 for k in range(0,9): p1 = collect[k] for t in range(k+1,9): if p1&lt;collect[t]: mid = collect[t] collect[t] = p1 p1 = mid dst[i,j] = collect[4]#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;dst6.jpg&apos;,dst) 皮肤磨皮美白-双边滤波import cv2img = cv2.imread(&apos;image3.png&apos;,1)#cv2.imshow(&apos;src&apos;,img)dst = cv2.bilateralFilter(img,15,35,35) # 滤波函数#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;dst7.png&apos;,dst)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用工具]]></title>
    <url>%2F2019%2F01%2F07%2Flinux%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[换源ubantu换源阿里源sudo python3 -c &quot;d=&apos;mirrors.aliyun.com&apos;;import re;from pathlib import Path;p=Path(&apos;/etc/apt/sources.list&apos;);s=p.read_text();bak=p.with_name(p.name+&apos;.bak&apos;);bak.exists() or bak.write_text(s);p.write_text(re.sub(r&apos;(cn.archive|security|archive)\.ubuntu\.com&apos;, d, s))&quot; pip换源修改或创建 ~/.pip/pip.conf ：[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple 解压.tar格式# 打包 tar -cvf 文件名.tar # 要打包的文件# 解包 tar -xvf 文件名.tar#查看包里的内容tar -tvf 包的文件名.tar .gz格式tar -zcvf xxx.tar.gz 文件 # 压缩tar -zxvf xxx.tar.gz 文件 # 解压# 解压到指定目录 tar -zxvf xxx.tar.gz -C dirname .bz2格式tar -jcvf xxx.tar.bz2 文件 # 压缩tar -jxvf xxx.tar.bz2 # 解压 .zip格式安装sudo apt-get install zip 使用压缩文件 zip 压缩文件 源文件解压 unzip 压缩文件-d 解压到指定目录 如果目录不存在 会自动创建新目录 并压缩进去unzip test.zip -d filename vim编辑器工作模式：命令模式、输入模式、末行模式 模式切换当打开一个文件时处于命令模式在命令模式下，按 i 进入输入模式在输入模式，按ESC回到命令模式。在命令模式下，按shift+; ，末行出现:冒号，则进入末行模式 进入与退出进入 vim filename退出 :wq 末行模式，wq 保存退出 :q 末行模式，q 直接退出 :q! 末行模式，q! 强制退出，不保存 复制与粘贴复制和粘贴 yy 复制整行内容 3yy 复制3行内容 yw 复制当前光标到单词尾内容 p 粘贴 删除删除 dd 删除光标所在行 dw 删除一个单词 x 删除光标所在字符 u 撤销上一次操作 s 替换 ctrl + r 撤销 查找查找 / 命令模式下输入：/ 向前搜索 不能空格 ? 命令模式下输入：? 向后搜索# / 方式 n 向下查找 N 向上查找# ? 方式 n 向上查找 N 向下查找]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv基础]]></title>
    <url>%2F2019%2F01%2F07%2Fopencv%2F</url>
    <content type="text"><![CDATA[安装# pippip3 install opencv-python# condaconda install --channel https://conda.anaconda.org/menpo opencv3# conda虚拟环境source activate 环境名pip install opencv-python 读取与展示import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;image&apos;,img) # 显示图片cv2.waitKey(0) # 没有会一闪而过 写入import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imwrite(&apos;image1.jpg&apos;,img) # 写入文件名字 ， 图片数据 有损压缩import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imwrite(&apos;imageTest.jpg&apos;,img,[cv2.IMWRITE_JPEG_QUALITY,50]) # 写入文件名字 ， 图片数据 ， 当前jpg图片保存的质量（范围0-100）#1M 100k 10k 0-100 有损压缩 无损压缩# 1 无损 2 透明度属性import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imwrite(&apos;imageTest.png&apos;,img,[cv2.IMWRITE_PNG_COMPRESSION,0]) # 写入文件名字 ， 图片数据 ， 当前jpg图片保存的质量（范围0-100）# jpg 0 压缩比高0-100 png 0 压缩比低0-9 像素操作import cv2 # 导入cv库 img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色(b,g,r) = img[100,100] # 获取图片的（100,100）坐标的像素值，按照bgr的形式读取print(b,g,r)# bgr#10 100 --- 110 100for i in range(1,100): # 总共一百个像素点 img[10+i,100] = (255,0,0) # 写入标准的蓝色cv2.imshow(&apos;image&apos;,img)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[敬语]]></title>
    <url>%2F2019%2F01%2F06%2F%E6%95%AC%E8%AF%AD%2F</url>
    <content type="text"><![CDATA[敬语用于对会话中涉及的人物或者听话人表示敬意。现在日语的敬语大致分为四类： ①尊他语（尊敬語 そんけいご）：对他人的行为、状态及有关事物等表示敬意的语言。②自谦语（謙譲語 けんじょうご）：以谦逊的态度叙述自己或自己一方的行为、状态及有关事物的语言。③郑重语（丁寧語 ていねいご）：表示客气、有礼貌、文雅、郑重的态度的语言。如：です、ます、ましょう等。④美化语（美化語 びかご）：名词的接头接尾词，指令人听上去很优美很文雅的一些表达方式，给人优雅而又有教养的印象。 尊他语名词的尊他语①加前缀或后缀：前缀：お：お手紙、お話、お宅、お電話 （和语词，日常常用词）ご：ご案内、ご希望、ご協力 （汉语词）后缀：～さん ： 山田さん、学生さん～様（さま）： 田中さま、二人さま～殿（どの）： 吉田殿、会長殿前后缀：お父さん（さま）：お母さん（さま）お嬢さん（さま）：お客さん（さま） ②Ｎ本身变化会社：貴社 宅：お住まい 形容词的尊他语お＋形容詞✿ 歩くのがお速いですね。✿ 最近お忙しいですか。✿ お元気ですね。✿ お上手ですよ。 动词的尊他语一般动词お＋マス形＋になるご＋サ変动词词干＋になる✿ 何時ごろお帰りになりますか。✿ 先生がご案内になってくださったのです。 特殊动词 请求的尊他表示用于请求对方做某事。汉语：请您~接续：お＋マス形＋ください ご＋サ変动词词干＋ください✿ あしたの会議、ぜひご参加ください。✿ もう大丈夫ですので、どうぞご安心ください。✿ どうぞ、おかけください。 ★ 特殊词的接续：特殊词て型＋ください 其他尊他语形式１、お（ご） + ＶＲ（サ変語幹）+ なさるお帰りなさるご心配なさるあなたが行けば、おばあさんはきっとお喜びなさるでしょう。 ２、お（ご） + ＶＲ（サ変語幹）+ ですお客さんがこちらでお待ちです。 客人们请在这里等候。お父さんはご在宅ですか。 您父亲在家吗。 谦让语名词的自谦Ｎ本身变化わたくし茶：粗茶（そちゃ①０）贈り物：つまらない物当社：弊社（へいしゃ①）妻：愚妻（ぐさい０） 动词的自谦一般动词接续：お＋マス形＋ する/いたすご＋サ変动词词干＋する/いたす ★「いたす」自谦程度更高✿ 授業の後で お電話します。✿ それでは お願いいたします。 ★自谦句形不能用在单纯的说话人自己本身的行为动作及不涉及对方的行为动作上。★必须用在与对方有关的自己的动作上。 特殊动词 其他自谦语形式１、お（ご） + ＶＲ（サ変語幹）+ 申し上げるお客様を空港までお見送り申し上げます。把客人送到机场ご援助申し上げるつもりでございます。 我愿意为您效劳 郑重语郑重语不是对话题人物的尊敬，也不是对自己的自谦，而是用郑重地说话来表示对听话人的尊重。也是表示自己有高雅教养的表现。 郑重语的最基本的表现是です和ます。 其他还有ござる、まいる、いたす、おる等。✿ これが弟の写真です。✿ 私の父でございます。✿ 雪が降ってまいりました。✿ 何か変な匂いがいたしますよ。✿ 用意が出来ておりました。 美化语①加前缀：（同名词的尊他变形）お：お手紙、お話、お宅、お電話 （和语词，日常常用词）ご：ご案内、ご希望、ご協力 （汉语词） ②Ｎ本身变化めし：ご飯腹（はら）：お腹（おなか）便所（べんじょ）：お手洗い]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>敬语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础命令]]></title>
    <url>%2F2019%2F01%2F05%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[电源管理shutdown now # 关机shutdown -h 30 # 30分钟后关机 shutdown -r now # 重启shutdown -r 05:30 # 于05:30重启shutdown -c # 取消关机 目录结构/bin： bin是Binary的缩写, 这个目录存放着最经常使用的命令。 /boot： 这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ： dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。 /etc： 这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home： 用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib： 这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found： 这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media： linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。 /mnt： 系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /opt： 这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc： 这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。 这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器：echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all /root： 该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin： s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /selinux： 这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv： 该目录存放一些服务启动之后需要提取的数据。 /sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。 sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统 针对设备的devfs文件系统 针对伪终端的devpts文件系统。/tmp： 这个目录是用来存放一些临时文件的。/usr： 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。/usr/bin： 系统用户使用的应用程序。/usr/sbin： 超级用户使用的比较高级的管理程序和系统守护程序。/usr/src：内核源代码默认的放置目录。/var： 这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 显示文件目录ls-a 列出隐藏文件，文件中以“.”开头的均为隐藏文件，如：~/.bashrc-l 列出文件的详细信息-R 连同子目录中的内容一起列出 文件权限-rwx-rwx-rwx # 第一个代表文件类型# 代表所有者的权限 # 代表所属组的权限# 代表其他人的权限 改变权限r 读取权限 如果没有r 就不能 ls 查看里面的内容 对应数字 4w 写权限 如果没有w 就不能在目录下创建新的文件 对应数字 2x 执行权限 如果没有x 就不能cd进入这个目录 对应数字 1- 没权限 对应数字 0chmod 777 filenamerwx-rwx-rwx 切换文件夹cd filename # 进入文件-filename：文件名cd - # 返回上一次进入的目录cd ~ # 进入根目录cd .. # 返回上级目录 查看当前路径pwd 创建目录mkdir filename # 创建一个filename的文件 删除空目录rmdir filename # 删除一个空的filename的文件 复制复制文件或目录cp file1 file2cp file1 dir/cp file1 ../ 拷贝目录cp dir1 dir2 -rcp dir1 ~/ -r 删除文件或目录rm -r # 递归删除文件rm -rf # 强制删除文件***** 查看文件从第一行开始；“-b”显示行号cat file # 一次查看所有的文件cat file1 file2 # 一次查看两个命令 从最后一行开始tac filename 显示的时候，顺道输出行号！nl filename 一页一页的显示文件内容more filename 按Space键：显示文本的下一屏内容。 按Enier键：只显示文本的下一行内容。 按斜线符/：接着输入一个模式，可以在文本中寻找下一个相匹配的模式。 按H键：显示帮助屏，该屏上有相关的帮助信息。 按B键：显示上一屏内容。 按Q键：退出more命令。 查找命令which command # 查看 -二进制文件whereis 可执行文件 # 二进制文件 、man手册帮助文档： 1.man手册 ，帮助文档 man ls 2.--help , ls --help 查找文件find 路径 参数# 常用参数 -name # 按照名字-size # 按照大小find ./ -size +100k -size -10M # 在当前目录下找大于100k 小于 10的文件 文本搜索grep &apos;content&apos; filename# 常用参数-v 显示不包含匹配文本的所有‘行’ (求反)-n 显示匹配行及行号-i 忽略大小写# 内容参数^wu 行首 搜索以wu开头的行wh$ 行尾 索以wh结束的行 创建链接文件ln file hardlink # 硬链接ln -s file softlink # 软链接 软链接: 相当于 window上的快捷方式 源文件删除则软链接失效 硬链接: 硬链接只能连接普通的文件 不能连接目录 注意 如果软链接文件和源文件不在同一个目录 源文件要使用绝对路径 不能使用相对路径 创建别名alias # 查看所有别名 alias c4=&apos;cat 4.txt&apos;unalias # 删除别名 注意 这种定义别名的方式 只在当前登录有效 如果要永久定义生效 可以通过修改~/.bashrc文件 这个修改要下次登录才能生效 想要立即生效 可以输入source ~/.bashrc]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些忘记书名的心理学笔记]]></title>
    <url>%2F2019%2F01%2F04%2F%E4%B8%80%E4%BA%9B%E5%BF%98%E8%AE%B0%E4%B9%A6%E5%90%8D%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[酒与污水定律 把一勺酒倒入一桶污水，得到的是一桶污水；把一勺污水倒入一桶酒，得到的还是一桶污水。只要酒里有污水，再多的酒都是污水。 羊群效应 在组织散乱的羊群中，头羊起着关键作用，它的任何一个行动都会引起整个羊群中其他羊的关注，这些羊会效仿头羊。这是一种典型的从众心理，这种现象普遍存在于人类社会群体中。 安泰效应 指的是每种能力都要借助一定的条件和环境，一旦失去这种条件或环境，就可能失去某种能力。它告诉我们，人要学会借力，善于运用自己周围的环境。 踢猫效应 指人的不满情绪和糟糕心情，通常会沿着等级由高到低依次传递，由金字塔尖传到金字塔底，最终将危机转嫁到弱者身上。 矛盾选择定律 只有一只手表，可以告诉人们准确的时间，而拥有两只手表非但不能告诉一个人准确的时间，反而会让看表的人失去对准确时间的判断，这就是“手表定律”，也称“矛盾选择定律”。 贯性原理 你们对某样东西投入了巨大的精力，对它倾注了心血和金钱。你们投入的越多，贯性原理就越会促使你们想：“现在它必须成功。如果我再投入一点，它就会成功。” 如何对付错误和那些改变赢面的新情况，也是你们必须掌握的知识之一。生活有时候就像扑克游戏，有时候你们即使拿到一把非常喜欢的牌，但也必须学会放弃。 这时候，“剥夺性超级反映综合征”也会出现：如果不再投入一点，你们就要前功尽弃啦。人们就是这样破产的——因为他们不懂停下来反思，然后说：“我可以放弃这个，从头再来。我不会执迷不悟下去——那样的话我会破产的。” 社会科学理论 社会科学理论的命运取决于其传染性，而不是其正确性。 预期 假设一项计划预期在79天内完成。在第79天，假如计划还未完成，那么人们预测它还需要25天；但在第90天，假如计划还未完成，它会还需要58天；在第100天还需要89天；在第119天还需要149天；在第600天，如果计划还未完成，你会预测它还需要1590天。如你所见，你等待的时间越长，你预期还要继续等待的时间就越长。 喜欢 我们喜欢可触摸的东西、被证实的东西、显而易见的东西、真实的东西、可见的东西、具体的东西、已知的东西、已观察到的东西、生动的东西、视觉性的东西、有社会特点的东西、被灌输的东西、富有情感的东西、突出的东西、典型的东西、打动人心的东西、富有戏剧性的东西、传奇的东西、美化的东西、官方的东西、学术性的空话、虚有其表的高斯派经济学家、数学废话、华而不实的东西、法兰西学院、哈佛商学院、诺贝尔奖、黑西服白衬衣加领带、令人激动的演讲和耀眼的东西。而我们最喜欢的，是故事。 可惜，现存的人类天性不愿理解抽象事物，我们需要具体背景。随机性和不确定性是抽象事物。我们尊重发生的事，忽视本来可能发生的事。也就是说，我们天生肤浅，却浑然不知。这不是心理学问题，它来自信息的主要特性。人们很难看到月亮的阴面，照亮它是花费能量的。同样，照亮没有被看到的事物既费力又劳神。 假想实验 把一群各式各样的老鼠放进A实验室里，对它们进行越来越高的辐射。把幸存下来的老鼠放入城市B，幸存下来的老鼠在城市B老鼠中显得很强壮。看到的人于是分析为什么这些老鼠更强壮，因为他们来自A实验室，实验室把它们训练得很强壮。 沉默的证据 千多年前西塞罗讲了这样一个故事，有人把一幅画给一个无神论者看，画上画着一群正在祈祷的拜神者，他们在随后的沉船事故中幸存了下来。其寓意在于说明祈祷能保护人们不被淹死。无神论者问，‘那些祈祷后被淹死的人的画像在哪儿？’ 淹死的拜神者已经死了，所以很难从海底出来宣扬他们的事迹。 沉默的证据遍及所有与历史概念有关的一切，历史是具有事后影响的全部事件。 抓猴子的故事 树上挂一个空椰子，上面开个洞，放上米，猴子把手伸进去，抓了米，手就出不来。 长痛与短痛 短时间的巨大痛苦大于将痛苦在长时间中分散的痛苦; 短时间的巨大幸福小于长时间中分散的幸福。 改变他人 世界上唯一能影响对方的方法，就是讨论他所要的，而且还告诉他，如何才能得到。 也许在潜意识里，我们很希望能够通过我们的看法去左右别人的行为，因而会憎恨那些不受我们影响的人。 自重感 人们渴望成为重要的人，即自重感。献出你真实，诚恳的赞赏。 如果你想得到仇人，你就胜过你的朋友，如果你想获得更多的朋友，就让你的朋友胜过你。 当朋友胜过我们，他们会获得自重感。当我们胜过朋友，他会自卑，并引起猜疑和妒忌。 当我们猜疑，妒忌的人，发生一桩不幸的事，会使我们有一种恶意的快感。 有些朋友，看你遭遇困难，比看你成功或许更为满意。 批评与被批评 批评是没有用的，因它使人增加一层防御，而且竭力地替自己辩护。批评也是危险的，它会伤害一个人的自尊，和自重的感觉，并引起他的反抗。 被批评： 1.做你认为正确的事，反正你会受到批评，会因为做了某些事被骂，也会因为什么都不做而被骂。结果都是一样的。 2.如果你身居领导地位，那就注定要被批评，想办法习惯它吧！ 3.只要我不对任何的攻讦作出反应，那这件事就只有到此为止。 了解 你永远也不可能真正了解一个人，除非你穿上他的鞋子走来走去，站在他的角度考虑问题。 从众原则 大多数人好像都认为他们是对的，你是错的…… 他们当然有权利那样想，他们的看法也有权得到充分的尊重，但是，我在接受他人之前，首先要接受自己。有一种东西不能遵循从众原则，那就是人的良心。 为小事烦恼 错过列车，只有在你追赶它时才是痛苦的！同样，不能达到别人对你期望的成功，只有在它也是你所追求的东西时才是痛苦的。 只要是你的决定，放弃一份高薪职位带来的回报会超过金钱带给你的效用。这是向命运说“随你怎么样”的第一步。如果你确定了自己的标准，你对自己的生活会有大得多的控制。 我们很容易忘记我们活着本身就是极大的运气，一个可能性微小的事件，一个极大的偶然。 想象一个10亿倍于地球的行星边上的一粒尘埃。这粒尘埃就代表你出生的概率，庞大的行星则代表相反的概率。所以不要再为小事烦恼了。 是与不 使对方很快地回答“是，是“ 一个不字的反应，是最不容易克服的障碍。当一个人说出不字后，为了他人格的尊严，他不得不坚持到底。事后，他或许觉得他说出这个不字是错误的，可是，他必须考虑到自己的尊严。他所说的每句话，必须坚持到底，所以使人一开始，就往正面走，是非常重要的。 指责 尊重别人的意见，永远别指责对方是错误的。 我们不只反对有人指责我们的表错误，或者我们的汽车太旧，而是不愿意有人想要纠正我们的任何错误。 争辩 永远避免正面冲突、争辩 为什么一定要找出证据来证明别人的错误呢？ 这么做会让人喜欢你？ 他并没有征求你的意见，也不要你的意见，你又何必去跟他争辩呢？ 让人喜欢你的方法1.真诚地对别人发生兴趣2.微笑3.记住你所接触中，每一个人的姓名4.做一个静听的人，鼓励别人多谈谈他们自己。5.就别人的兴趣谈论6.使别人感觉到他的重要，必须真诚的这样做深入人们心底的最佳途径，就是对那人讲他知道得最多的事物。 保持愉快1.现在你何不问问自己：“我到底在烦恼些什么呢？”你多半会发现，你所担心的事既不重要，也没有意义。2.世上最好的医生，就是饮食有度、保持平和以及愉悦的心情。3.罗根·史密斯有一句智慧之言：“人生有两项主要目标，第一，拥有你所向往的；第二，享受它们。只有最具智慧的人才能做到第二点。” 工作1.如果你“假装”对工作有兴趣，一点点假装就会使你的兴趣成真，也可以减少你的疲劳。2.如果你是一个脑力劳动者，使你感觉疲劳的原因很少是因为你的工作超量，相反是由于你的工作量不足。3.要不停地提醒你自己，对自己的工作感兴趣，就能使你不再忧虑；而且最后还可能会给你带来升迁和加薪的机会。即使没有这么好的结果，那至少也可以使你的疲劳降到最低程度。 养成4种良好的工作习惯：第一，将你桌上所有的纸张收拾好，只留下你正要处理的问题。第二，根据事情的重要程度来安排做事的先后顺序。第三，当你遇到必须当场作决定的问题时，就当场解决，不要犹豫不决。第四，学会如何组织、分级负责和监督。 你可以把自己的生活想象成一个沙漏。在沙漏的上一半有成千上万粒的沙子，它们缓慢而均匀地流过中间那条细缝。除非把沙漏弄坏，否则，你和我都不能让两粒以上的沙子同时穿过那条窄缝。我们就如同沙漏。每天清晨醒来的时候，就有许许多多的工作摆在面前，要在这一天之内完成。但我们一定要均匀地安排自己的工作和生活，如果我们每次要几件事情同时做，就像要两粒以上的沙子同时通过窄缝一样，一定会损害自己的身体和精神。 表象 我们的头脑总是被所谓的真相，错误的“常识一样明白的”虚构的故事，以及服务于特别利益集团的带有偏见的结论所填满。一个有判别力的思考者要超越已有的信息，发掘隐藏在信息表面下的真正含义，以理解信息的本质为目标而不被表面的映像和风格所迷惑。技巧：1.避免把相关关系推论为因果关系。2.要求关键术语和概念有操作定义，并对其含义达成一致意见。3.你很容易在寻求辩解时发现确定的证据，但在寻找确定的证据前，首先要考虑如何反驳某一理论、假设或信仰。4.总是对已提出的明显解释寻求其他的可能解释，特别是那些有利于提案人的解释。5.认识到个人偏见能歪曲对现实的理解。6.怀疑对复杂问题给出的简单答案，怀疑对复杂现象和难题给出的单一理由和对策。7.质疑任何关于治疗、参与、或产品效果的声明，办法是找到比较结果的基础：比较什么？8.成为思想开朗而又好怀疑的人：认识到大多数结论都具有尝试性和不确定性；寻找新的证据来减少你的不确定性，同时使自己能不断变革和修正自己的观点。9.向权威挑战，那些权威通常用个人的观点代替证据，而且又不接受建设性的批评。 预期 通常，人们看见的,听到的只是他们所预期的，而不是事实的本来面目。 强迫 没有人喜欢强迫自己去买某样东西，或是被人派遣去做一件事。我们都喜欢随自己心愿去买东西，照自己的意思去做事情。同时希望有人跟我们谈谈我们的愿望，需要和想法。 失眠 下面是五条规则，可以让你不为失眠症而忧虑：第一，如果睡不着的话，就起来工作或看书，直到打瞌睡为止。第二，从来没有人会因为缺乏睡眠而死。因担心失眠而忧虑，通常对你的损害比失眠更厉害。第三，试着祈祷，或者像珍妮·麦克唐纳一样诵读诗篇的第二十三篇。第四，放松全身，看看《消除神经紧张》这本书。第五，多运动，或做一些体力活，直至你累得酣然入睡。 会议1.出了什么问题2.问题的原因是什么？3.有哪些可能解决的办法4.你觉得哪种方法最合适 职业 以下是我想向您请教的问题：①如果您的生命从头开始，您是否愿意再做一名建筑师？②在您仔细打量我之后，我想请问您，您是否认为我具备成为一名成功的建筑师的条件？③建筑师这一行业是否已经人满为患？④假如我学习了4年的建筑学课程，想要找到工作是否困难？我应该首先接受哪一类的工作？⑤如果我的能力属于中等，在头5年中，我可以希望赚多少钱？⑥当一名建筑师，有什么样的好处和坏处？⑦假如我是您的儿子，您愿意鼓励我当一名建筑师吗？ 古希腊哲学家艾皮科蒂塔说，哲学的精华就是：“一个人生活上的快乐，应该来自于尽可能减少对外来事物的依赖。”罗马的政治家及哲学家塞尼加也说：“如果你一直都觉得不满足，那即使是给你整个世界，你也会觉得伤心。” 忧虑1.混乱是产生忧虑的主要原因。在没有以客观的态度搜集到所有的事实之前，不要想如何解决问题。2.一切和我们欲望相符合的，看来都是真理，其他的都会使我们感到愤怒。 解决办法：（亚里士多德法则）第一，清楚地写下我们所担心的是什么。第二，写下我们可以怎么办以及可能发生的结果。第三，决定该怎么办。第四，马上按照决定去做。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>心理学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经济学笔记]]></title>
    <url>%2F2019%2F01%2F04%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[复利 如果有1万，按每年投资回报率10%计算，10年收益为1.59万，20年为5.7万，30年为16.45万，40年为44.26万。所以在20岁投入10万，60岁养老金就有450万，在孩子1岁时，投入10万，孩子30岁时，就有160万。 然而国际公认平均收益率为12%，而投资自己，进行人力资源投资的投资收益最大。 二八定律 20%的客户会带来80%的收益 有个乞丐非常善于乞讨，每天都比同行赚得多，于是有同行就问他：“你有什么乞讨秘诀吗？” 这位乞丐说：“秘诀谈不上，不过我还是有点个人经验的。我从来不粘着顾客满街跑。如果乞讨不成，我会趁早放弃。因为他若肯给我钱，早就会给，就算他最后磨不过我，给了我钱，我也因此浪费了很多时间和精力，不如转而寻找下一个大目标。” 黑洞效应 黑洞效应：在宇宙中，一些大质量的物体在发生坍塌之后，会形成一个致密的点，由于它的质量非常大，所以产生的引力也非常大，大到光线进去之后也无法逃出来，于是就形成了一个黑洞。而且不断被吞噬进去的物质和能量又反过来成为黑洞的一部分，使得黑洞产生更大的吸引力。黑洞效应就是一种自我强化效应。当一个企业达到一定的规模之后，也会像一个黑洞一样产生非常强的吞噬和自我复制能力，把它势力所及的大量资源吸引过去，而这些资源使得企业更加强大，形成一个正向加速循环的旋涡。 黑洞效应使得资源和资本聚集，是产生社会贫富差距的原因之一。 沉没成本 沉没成本是指由于过去的决策已经发生了的，而不能由现在或将来的任何决策改变的成本。人们在决定是否去做一件事情的时候，不仅是看这件事对自己有没有好处，而且也看过去是不是已经在这件事情上有过投入。我们把这些已经发生不可收回的支出，如时间、金钱、精力等称为“沉没成本”。举例来说，如果你预订了一张电影票，已经付了票款且假设不能退票。此时你付的价钱已经不能收回，就算你不看电影钱也收不回来，电影票的价钱算做你的沉没成本。所以，如果你是理性的，那就不该在做决策时考虑沉没成本。 参照点 我们在头脑中形成参照点，比如销售预测，然后开始基于它构造信念，因为把一个观点与一个参照点进行比较比在绝对的环境下对它进行评价所需的思维努力更小。（系统1在起作用！）我们无法在没有参照点的情况下思考。 所以在预测者头脑中设置一个参照点能够带来奇妙的结果。在讨价还价过程中设置起点是一样的道理：你先提出一个较高的数字，如“这所房子要卖100万美元”，买方会说“只能85万”——议价过程将取决于初始报价。 讨价还价的故事 有一天，王先生到一个做服装生意的朋友那里去聊天。一个顾客看好了一套服装，服装的标价是800元。顾客说：“你便宜点吧，500元我就买！”朋友说：“你太狠了吧，再加80元！而且也图个吉利！”顾客说：“不行，就500元！”随后，他们又进行了一番讨价还价，最终朋友说：“好吧，就520元！”顾客去交款了，但是不一会儿又回来了。她有些不好意思地说：“算了，我不能买了，我带的钱不够了！”朋友又说：“有多少？”顾客说：“把零钱全算上也就只有430元了。”朋友为难地说：“那太少了，哪怕给我凑一个整数呢？”顾客说：“不是我不想买，的确是钱不够了！”最后，朋友似乎下了狠心，说：“就430元钱给你吧，算是给我开张了，说实在的，一分钱没有挣你的！”顾客满脸堆笑，兴高采烈地走了。 看着顾客远去的背影，朋友告诉王先生：“这件衣服是180元从广州进的货。”王先生听了哈哈大笑：“真是无商不奸啊，可是你有些太狠了吧？” 朋友说：“这你就是外行了，现在都时兴讲价，顾客讨价，我还价，这很正常。你要给顾客留出来讨价还价的空间，要让顾客心理上获得一种满足！其实这件衣服我300元的价格就卖，到换季的时候我本钱都往外抛。” 巧借名人效应的故事 美国一出版商有一批滞销书久久不能脱手，他忽然想出了一个主意：给总统送去一本书，并三番五次去征求意见。忙于政务的总统不愿与他多纠缠，便回了一句：“这本书不错。”出版商便借总统之名大做广告：“现有总统喜爱的书出售。”于是，这些书被一抢而空。不久，这个出版商又有书卖不出去，又送一本给总统。总统上过一回当，想奚落他，就说：“这书糟透了。”出版商闻之，脑子一转，又做广告：“现有总统讨厌的书出售。”不少人出于好奇争相抢购，书又售尽。 第三次，出版商将书送给总统。总统接受了前两次的教训，便不作任何答复。出版商却大做广告：“现有令总统难以下结论的书，欲购从速。”居然又被一抢而空，总统哭笑不得，商人却善借总统之名大发其财。 ~巧借名人效应，抱大腿。 博弈论智猪博弈 假设猪圈里有一头大猪、一头小猪。猪圈的一头有猪食槽，另一头安装着控制猪食供应的按钮，按一下按钮会有一定单位的猪食进槽，两头隔得很远。假设两头猪都是理性的猪，也就是说它们都是有着认识和懂得实现自身利益的猪。 再假设猪每次按动按钮都会有10个单位的饲料进入猪槽，但是并不是白白得到饲料的，猪在按按钮以及跑到食槽的过程中要付出的劳动会消耗相当于2个单位饲料的能量。此外，当一头猪按了按钮之后再跑回食槽的时候，它吃到的东西比另一头猪要少。也就是说，按按钮的猪不但要消耗2单位饲料的能量，还比等待的那个猪吃得少。再来看具体的情况，如果大猪去按按钮，小猪等待，大猪能吃到6份饲料，小猪4份，那么大猪消耗掉2份，最后大猪和小猪的收益为4∶4；如果小猪去按按钮，大猪等待，大猪能吃到9份饲料，小猪1份，那么小猪消耗掉2份，最后大猪和小猪的收益为9∶-1；若两头猪同时跑向按钮，那么大猪可以吃到7份饲料，而小猪可以吃到3份饲料，最后大猪和小猪收益为5∶1；最后一种情况就是两头猪都不动，那它们当然都吃不到东西，两头猪的收益就为0。 那么小猪努力的结果是-1，比不努力的结果4还差，所以小猪只能不动。大猪为了生存，只能来回跑。 启发：小企业可以搭大企业的便车，坐收渔翁之利。 囚徒困境 警方逮捕甲、乙两名嫌疑犯，但没有足够证据指控二人有罪。于是警方分开囚禁嫌疑犯，分别和二人见面，并向双方提供以下相同的选择： 若一人认罪并作证检控对方（相关术语称“背叛”对方），而对方保持沉默，此人将即时获释，沉默者将判监10年。若二人都保持沉默（相关术语称互相“合作”），则二人同样判监半年。若二人都互相检举（互相“背叛”），则二人同样判监5年。 囚徒困境假定每个参与者（即“囚徒”）都是利己的，即都寻求最大自身利益，而不关心另一参与者的利益。参与者某一策略所得利益，如果在任何情况下都比其他策略要低的话，此策略称为“严格劣势”，理性的参与者绝不会选择。另外，没有任何其他力量干预个人决策，参与者可完全按照自己意愿选择策略。 囚徒到底应该选择哪一项策略，才能将自己个人的刑期缩至最短？两名囚徒由于隔绝监禁，并不知道对方选择；而即使他们能交谈，还是未必能够尽信对方不会反口。就个人的理性选择而言，检举背叛对方所得刑期，总比沉默要来得低。试设想困境中两名理性囚徒会如何作出选择： 1、若对方沉默、我背叛会让我获释，所以会选择背叛。2、若对方背叛指控我，我也要指控对方才能得到较低的刑期，所以也是会选择背叛。 二人面对的情况一样，所以二人的理性思考都会得出相同的结论——选择背叛。背叛是两种策略之中的支配性策略。因此，这场博弈中唯一可能达到的纳什均衡，就是双方参与者都背叛对方，结果二人同样服刑5年。 这场博弈的纳什均衡，显然不是顾及团体利益的帕累托最优解决方案。以全体利益而言，如果两个参与者都合作保持沉默，两人都只会被判刑半年，总体利益更高，结果也比两人背叛对方、判刑5年的情况较佳。但根据以上假设，二人均为理性的个人，且只追求自己个人利益。均衡状况会是两个囚徒都选择背叛，结果二人判监均比合作为高，总体利益较合作为低。这就是“困境”所在。例子有效地证明了：非零和博弈中，帕累托最优和纳什均衡是互相冲突的。 斗鸡博弈 两只公鸡狭路相逢，即将展开一场撕杀。结果有四种可能：两只公鸡对峙，谁也不让谁。或者两者相斗。这两种可能性的结局一样——两败俱伤，这是谁也不愿意的。另两种可能是一退一进。但退者有损失、丢面子或消耗体力，谁退谁进呢？双方都不愿退，也知道对方不愿退。在这样的博弈中，要想取胜，就要在气势上压倒对方，至少要显示出破釜沉舟、背水一战的决心来，以迫使对方退却。但到最后的关键时刻，必有一方要退下来，除非真正抱定鱼死网破的决心。但把自己放在对方的位置上考虑，如果进的一方给予退的一方以补偿？只要这种补偿与损失相当，就会有愿意退者。 这类博弈也不胜枚举。如两人反向过同一独木桥，一般来说，必有一人选择后退。在该种博弈中，非理性、非理智的形象塑造往往是一种可选择的策略运用。如那种看上去不把自己的生命当回事的人，或者看上去有点醉醺醺、傻乎乎的人，往往能逼退独木桥上的另一人。还有夫妻争吵也常常是一个“斗鸡博弈”，吵到最后，一般地，总有一方对于对方的唠叨、责骂装聋作哑，或者干脆妻子回娘家去冷却怒火。冷战期间，美苏两大军事集团的争斗也是一种“斗鸡博弈”。在企业经营方面，在市场容量有限的条件下，一家企业投资了某一项目，另一家企业便会放弃对该项目的觊觎。 斗鸡博弈强调的是，如何在博弈中采用妥协的方式取得利益。如果双方都换位思考，它们可以就补偿进行谈判，最后造成以补偿换退让的协议，问题就解决了。博弈中经常有妥协，双方能换位思考就可以较容易地达成协议。考虑自己得到多少补偿才愿意退，并用自己的想法来理解对方。只从自己立场出发考虑问题，不愿退，又不想给对方一定的补偿，僵局就难以打破。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>经济学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《禅与摩托车维修艺术》摘录]]></title>
    <url>%2F2019%2F01%2F04%2F%E3%80%8A%E7%A6%85%E4%B8%8E%E6%91%A9%E6%89%98%E8%BD%A6%E7%BB%B4%E4%BF%AE%E8%89%BA%E6%9C%AF%E3%80%8B%E6%91%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[自我爬山者，他谈论的话题永远是别的事和别的地方。他的人虽然在这里，但是他的心却不在这里。因为他拒绝活在此时此刻，他想要赶快爬到山顶，但是一旦爬上去之后仍然不快乐，因为山顶立刻就变成了‘此地’。他追寻的，他想要的都已经围绕在他的四周，但是他并不要这一切，因为这些就在他旁边。于是在体力和精神上，他所跨出的每一步都很吃力，因为他总认为自己的目标在远方。 一个没有目标的人才能爬到最高。（by克伦威尔）例子：取消考试成绩加入良质的概念 归纳法：由个别的经验归纳出普遍的原则 演绎法:从一般的原则推论出特定的结果科学式的思考：问题是什么；假设问题的原因；证实每个问题的假设；预测实验的结果。观察实验的结果；由实验得出结论。 古典的认知认为这个世界是由一些基本形式组成的，而浪漫的认知则是从它的表象来观察。 人在思考和感觉的时候往往会偏向于某一种形式，而且会误解和看轻另一种形式。 熟悉往往会使一个人视而不见。 我们观察周遭成千上万的事物，你知道他们存在，但是你并没有全部注意到它们，除非出现某些奇特的或是我们容易观察到的事物。我们几乎不可能全部意识到这些东西，而且把它们记住。那样，我们心里会充满太多无用的细枝末节，从而无法思考。从这些观察当中，我们必须加以选择，而我们所选择的和所观察到的，永远不一样，因为经由选择而产生了变化。我们从所观察到的事物当中选出一把沙子，然后称这把沙子为世界。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>哲学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《当我遇见一个人》摘录]]></title>
    <url>%2F2019%2F01%2F04%2F%E3%80%8A%E5%BD%93%E6%88%91%E9%81%87%E8%A7%81%E4%B8%80%E4%B8%AA%E4%BA%BA%E3%80%8B%E6%91%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[当一个生命带着极大的爱和信任降临到家庭中，他最渴望的是被看见， 被父母看见真实的自己，而不是通过一堆‘正确’的数据来评价和矫正自己。 当我放下预期和目的，以我的全部本真与一个人或事物建立关系时，我就会与这个存在的全部本真相遇。 父母看不到孩子本身，他们看到的是孩子的功能价值。父母能否看到孩子本身的存在，而不是用外在价值去定义物质性的‘它’，这一点决定了孩子内心能否直接感受到爱。若孩子本然的存在不被看见，即使父母为孩子倾注一切，孩子也只是父母表达爱的道具。 爱，是如他所是，非吾所愿 我拒绝了这件事情，不等于拒绝你这个人，不等于你提的要求不合理，不等于我不在乎你。我的拒绝仅仅是因为现在我不想这样做。拒绝的同时，我不会把自己关闭，我依然感受到你的爱，理解你的需要，理解自己的需要，让我们的需要共同创造出爱的方式。如果我答应你，一定是因为我也喜欢用这种方式爱你，而不是迫于维持关系的委曲求全，所以即使我付出再多，你也不必内疚。 不带评判地拒绝，没有委屈地付出，爱的流动如此之美。 规则要建立在尊重感受的基础上，一个人内心极度缺爱，同时对得到爱已经绝望，会通过牺牲自己来满足所爱的人，间接地满足自己内在的小孩，而实际上，所爱的人抢走了那个内在小孩的爱，她付出越多，也就越怨恨所爱的人。 最好的教育就是不教育。在爱的陪伴下，不打扰就是对专注力最好的培养。孩子的精神世界我们无须全部了解，但需要时常放下成人已被高度训练过的头脑的假想，带着敬畏之心去体验。 我们面对痛苦时最容易做的就是直接解决掉引起痛苦的外在的人或事。真正的勇士，是直面痛苦，向内看的人。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>心理学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语法总结（5-15）]]></title>
    <url>%2F2019%2F01%2F04%2F%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93%EF%BC%885-15%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇记录综合日语5-15的语法，以便查询 Ｎ１はＮ２です名词谓语句:什么是什么否定形式：Ｎ１はＮ２では/じゃありません。✿问 ：Ｎ１はＮ２ですか。✿回答：はい、そうです。 いいえ、違います。 Ｎ１で、Ｎ２です✿高橋さんは高校の後輩で、今、京華大学の語学研究生です。✿京華大学はそちらで、北京大学はあちらです ～へようこそ迎接客人时使用的寒暄语，相当于汉语中的 {欢迎来到~}正式的说法是：ようこそいらっしゃいました✿中国へようこそ。 ～と申します用于介绍说话人自己的名字，一般用于正式场合，或对上级的人，语气比较郑重。✿高橋と申します。どうぞよろしく。 Ｎ１からＮ２まで相当于汉语的“从什么到什么之意”a:表时间范围b:表处所、顺序等的范围。✿授業は木曜日から金曜日までです。✿授業は何時からですか。 Ｎじゃありませんか不是~吗？✿今は呉先生の中国史の授業じゃありませんか。 どんなＮですか相当于汉语:什么样的，怎么样的✿呉先生はどんな先生ですか。 Ｎ１やＮ２など用于列举两个或两个以上的事物。(など可以省略)✿専門は中国語や中国経済、中国史などです。 注：如果用 “Ｎ１とＮ２とＮ３と” ，必须列举出全部事物 そんなにA１くないです/A２ではありません相当于汉语中的“并没有那么”（主观想法）✿そんなに簡単ではありません。 あまりA１くないです/A２ではありません单纯地表示程度不高，相当于汉语中的“不太，不怎么”（客观上）✿あまり簡単ではありません。 Ｎはどうですか用于询问事物性质，相当于汉语中的“怎么样。如何” ✿问：英語はどうですか。 ✿答：英語はやさしいです。 用于表示建议，相当于汉语中的“怎么样。如何”✿６時はどうですか。 Ｎはどうでしたか用于询问过去发生的事情结果或者情形✿きのうの試験はどうでしたか。 Ｎ１もＮ２も表示并列，相当于“~和~都”✿中国語の聞き取りも発音もとても難しいです。 Ｎのとき用于表示时间，“~时候、时”的意思。✿大学創立の時は、まだ学部は少なかったです。✿一年生のときの相互学習はとてもよかったですね。 時間＋ごろ表示大概时间点，在几点“左右、前后” Ｎと同じ与~相同。✿美穂さんですか。私と同じ名前ですね。 Ｎ１はＮ２がAです大小主语句，即大小主语之间一般为整体与部分✿日本語はアクセントが難しいです。✿私は英語が上手です。 ほとんどVません相当于汉语的“几乎没~，基本上不~”等✿手紙はほとんど書きません。 ＮしかＶません用于限定范围，相当于汉语中的“只，仅仅”之意✿明日しか休みません。 ～とか～とか口语句，“~啦~啦”✿料理はお寿司とかケーキとかです。 Ｎのあとで~之后✿あしたの授業の後、ここで宿題をします。 疑问词＋か表示虚指，不确定之意。回答要用はい、いいえ先说明，相当于“有没有”✿休みにどこかへ遊びに行きましたか。 疑问词+{格助词+}も+动词否定表示全面否定。 格助词是{が}或{を}时，一般省略。✿その後は何もしませんでした。 Ｎ１かN２表示选择性的并列，“N1或者N2” ✿明日、李さんか王さんが行きます。✿散歩か買い物に行きます。 Ｖましょう。表示建议语气的敬体形式，用于建议对方和自己一起做某事。相当于汉语中的“~吧、~怎么样” Ｎ１に｛は｝Ｎ２があります/います某地有某物 ✿机の上に本があります。 Ｎ１はＮ２にあります/います某物在某地✿王さんは教室にいます。 ～んです用于口语，书面语写为｛のです｝。接在动词、形容词的连体形后面，用于说明情况或者询问情况。✿東京の冬はあまり寒くないですね。北京の冬は寒いんですよ。✿人民大会堂もここにあるんですか。 Ｎが見えます看得见~看得到~✿晴れの日に、星がたくさん見える。 までに期限，表示该时间之前完成某一动作。 “在~之前” ✿本は１０日までに返します。 でも接在名词或者に、と等格助词后面；提建议时举出一个例子供对方考虑，语气比较委婉。✿お茶でも飲みましょうか。✿公園にでも行きましょうか。 Ｖませんか建议，“不一起~吗？”✿一緒に公園に行きませんか。 ～でしょう推测，“~吧” ✿１時ごろからは混むでしょう。 Ｎになる/A1くなる/A2になる客观事实的结果或状态✿そろそろ１２時になりますね。✿肌がきれいになりますよ。 Ｎにする、くする、にする人为造成的变化结果或状态✿音をもう少し大きくしてもいいですか。✿教室をきれいにしてください。 Ｎにする表示所选择或决定的事物，相当于 “要~，定~”✿どちらもきれいですね、じゃ、やっぱり赤にしましょう。 Ｖています1、表示某一动作正在进行✿今、授業をしています。 2、表示变化结果的持续✿もう外暗くなっています。 3、表示习惯性的动作，反复进行的动作及长期进行的动作✿学生の大多数は学校の寮に住んでいます。 Ｖていました表示在过去的某一时段或时点上的持续动作 ✿午前中図書館で勉強していました。✿８時から１０時まではテレビを見ていました。 って用于提出话题，在口语中使用。✿鈴木さんってどんな人ですか。 もうＶました表示动作已经完成，“已经~了” ✿もうタイトルは決めましたか。✿王さんはもう帰りました。 まだＶていません。还没，尚未做某事。✿朝からまだ何も食べていません。✿まだ来ていません。 Ｖて、Ｖて、Ｖます。表示连续进行几个动作在时间上的先后顺序。✿朝起きて、運動をして、食事をして、会社に行きます。 Ｖたい接在动词的第一连用形后面构成愿望的派生形容词，“想做~~”。使用Ｖたいですか询问第二、三人称的愿望被视为不礼貌的行为。✿おいしいものが食べたいです。✿有名な大学に入りたいです。 注：当表达第三人称具有进行某一动作的愿望时，一般用Ｖたがる这种形式。这时を格不能够改为が✿父は新しいパソコンを買いたがっています。✿先生は山本に会いたがっていました。 Ｎがほしい表示希望，想要得到某东西，其非过去式只能用于表示第一人称的愿望，直接问对方Ｎがほしいですか是不礼貌的。 ✿家族と友達へのお土産がほしいですが…。✿時間がほしいです。 Ｎができます表示具备某种能力，能做某事，会做某事✿日本語で買い物ができますか。✿王さんはテニスができます。 Ｎがわかります表示对人或事物的了解,助词一般用が，否定句中多用は。相当于”明白，了解”的意思。 ✿店員は大体日本語がわかります。✿この漢字の意味がわかりますか。 Ｖてもいい表允许，同意别人做某事。或者是询问别人的同意。✿試着してもいいですか。✿ここに座ってもいいですか。 Ｎはいかがですか用于提出建议并征求对方意见，或询问情况。表示“~怎么样 ~如何”等。是Ｎはどうですか的郑重表达方式✿もう一杯いかがですか。✿今晩、日本料理はいかがですか。 数量词+も带有说话人的主观评价色彩， “竟，足足，达”。✿駅で１時間も友達を待ちました。 だけ只有，仅仅。用在格助词が、を前面时，が、を有时省略。 ✿これは日英だけの辞書ですか。✿今朝は果物だけ｛を｝食べました。 Ｖてください请求对方做某事，一般不对上级或长者使用。✿それを見せてください。✿日本語を教えてください。 动词词典形+ことができる表示：①具有做某事的能力，②表示某种条件下行动行为的可能性。✿図書館のパソコンは何時まで使うことができますか。✿金さんはフランス語を話すことができます。 ずつ接在表示数量词或表示数量，程度的副词后面，表示数量的均等分配或者动作、变化的等量反复。 ✿毎日、少しずつ練習しています。✿りんごは一人に２つずつある。 Ｖてはいけない表示禁止，相当于不许、不准，多用于规则纪律，由于语气强烈，最好不要用于当面禁止别人做某事。✿教室ではタバコを吸ってはいけない。 Ｖないでください表示禁止，请不要做~、请勿~✿気にしないでください。✿大きい声を出さないでください。 Ｖている/Ｖないとき~的时候✿人が下を歩いているときに、窓からごみを捨ててはいけない。✿私は家に誰もいないとき、自分で料理を作ります。 Ｖなくてもいい表示不做什么也可以 ✿靴を脱がなくてもいいですよ。✿もう薬を飲まなくてもいいですよ。 ＶるＶた/とき{に}✿日本へ行くとき、パソコンを買いました。去日本之前买了电脑。✿日本へ行ったとき、パソコンを買いました。去日本之后买了电脑。 Ｖなくては｛なければ｝いけない同：Ｖなくては｛なければ｝ならない表示：必须做某事，应该做某事在口语中なくては经常说成なくちゃ；なければ经常说成なきゃ✿もう、病院へ戻らなくちゃいけません。✿日本で家に入るとき、靴を脱がなくてはいけないんでしょう。 どうして…（ん）ですか为什么~呢？✿山本さんはどうして来ないんですか。✿どうして先生に話さなかったんですか。 ～でしょう表示确认，要读升调✿もう宿題は終わったでしょう。✿まだいいでしょう。 Ｎについて/Ｎについての接在名词后面表示“关于，有关”✿日本文化についての資料を集めています。 ～と言う表示直接引语✿食事のとき、日本は皆で「いただきます」と言う。✿日本人は夜寝るときに、「お休みなさい」と言う。 N１というＮ2叫做~的~✿渡辺さんという人を知っていますか。✿これは何という花ですか。 Ｎが好き/嫌い喜欢，讨厌某物，表示感情的形容词助词用が✿高橋さん、京劇が好きですよね。✿鈴木さんは高橋さんが好きです。 Ｎ &lt;周期&gt; に Ｎ &lt;数量&gt;表示某一周期内动作的频率✿３ヶ月に１回ぐらい何かを見ていました。✿この薬を一日に３回飲んでください。 Ｖ简体の动词名词化✿明日、三保さんが来るのを知っていますか。 Ｎ1だけで｛じゃ｝なく、Ｎ2も不仅N1~N2也~ ✿あの人は英語だけでなく、日本語も話せます。✿肉だけでなく、野菜も食べなければならないんです。 ＮでもＮでも｛いい｝~和~都可以 ✿土曜日でも日曜日でも大丈夫です。✿男の子でも女の子でもいいんですよ。 なかなかＶ{能动态}ない与动词能动态否定形式搭配，表示该动作很难做到。 ✿みんな忙しい、なかなか会えません。✿この町では刺身はなかなか食べられません。 Ｎ1はＮ2より{比较}N1比~N2要~~~ ✿母は父より朝早く起きます。✿月曜日は火曜日より忙しい。 Ｎ1よりＮ2のほうが～比起N1 ，N2更~✿父より母のほうが朝早く起きます。✿火曜日より月曜日のほうが忙しい。 Ｎのなかで｝Ｎが一番～在~中~是最~✿クラスの中で、王さんが一番日本語が上手です。✿中華料理の中では、北京ダックが一番おいしいです。 ｛Ｎ1もＮ2も｝どちらも｛同じくらい｝～N1还是N2都一样~✿どちらも同じくらい好きです。✿山本さんは英語も日本語も、どちらも上手です。 Ｎ1はＮ2とともにN1和N2一样✿英語は日本語とともに必修科目である。 ～と思う～Ｖ意志形と思う 表达第一人称当时的意愿，想法。✿きょうは早く帰ろうと思います。 ～Ｖ意志形と思っている表达第一人称一直以来的想法，表达其他人称的意愿，想法。✿私は将来教師になろうと思っています。✿王さんは日本に行こうと思っている。 ～Ｖたいと思っている 单纯地表达一个愿望，没有落实行动，只停留在想法上。✿私は日本に行きたいと思っている。 简体句と思う。表示“我认为～，我觉得～” ✿プレゼント交換がいいと思う 简体句と思っている认为~~（无人称区别） ✿英語より日本語のほうが難しいと思っている人が多いです。 动词词典形+予定です表示某人的计划，客观性比较强。✿夏休みは国に帰る予定です。✿私たち日本語学科もコンパを開く予定です。 动词词典形+つもりです表示打算做某事，主观性比较强。✿夏休みには、小説をたくさん読むつもりです。✿あしたからはタバコを吸わないつもりです。 ～かどうか接续：动词、形1简体，名词、形2词干 ~还是不~✿東京の冬は寒いかどうか、日本人の友達に聞きます。✿このことは、あの人が知っているかどうか、わかりません。 だろうだろう接在动词、形容词的简体形式以及形容动词的词干，名词后面表示推测，是的でしょう简体。✿その辞書は高いだろうと思う。✿あそこへは電車よりバスのほうが便利だろう。 Ｖたことがある表示曾经有做过某事的经历✿私は富士山に登ったことがあります。✿私は一度も飛行機に乗ったことがありません。 动词词典形+ことがある有时、偶尔做某事✿私はははと喧嘩するこがある ばかり接在名词或格助词后面，用于限定，带有消极的感情色彩。表示： “光做某事，净做某事”✿あの人は毎日テレビばかり見て、何もしません。 授受动词给给我✿句型：Aは｛私に｝～をくれる。✿意思：A给我某物。✿注：私に可以省略。 给其他人✿句型：A（我或我方的人）はBに～をあげる。✿意思：A给B某物。 收✿句型：AはBに/から～をもらう。✿意思：A从B那里得到某物。✿注：这个句子中的B一般不用わたし。 具体用法 动词 ✿Ｖます：动词敬体（礼貌体），第一连用形。#V变形后去掉的形态为动词的第一连用形，它用于句子的中顿，#大多表示两个或两个以上的动词并列，也可以表示动作先后顺序，#通常用于书面语。 ✿Ｖない动词未然形（动词的简体否定） ✿Ｖた动词简体过去时 ✿Ｖて形表示动作的中顿，语法活用 ✿动词能动态#表示“可能”的意义。#既可以表示人具有某种能力，也可以表示在某种状态下行为动作的可能性。 ✿Ｖ（よ）う 意志形#动词后接表示意志、建议后缀的事构成动词的意志，建议形。 详见 动词总结]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[on_my_zsh]]></title>
    <url>%2F2019%2F01%2F03%2Fon-my-zsh%2F</url>
    <content type="text"><![CDATA[1. 安装 Oh My Zsh安装 Zsh安装:sudo apt install zsh 将 Zsh 设置为默认 Shellchsh -s /bin/zsh 安装 Oh My Zshwget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 2. 配置 Oh My Zsh配置字体git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9k autojump更快地切换目录，不受当前所在目录的限制。sudo apt install autojump# 跳转到目录j dir# 可以通过GUI文件管理器打开指定目录，执行命令:jo dir fasd快速访问文件或目录，功能比前一个插件强大。 安装：sudo apt install fasd 使用：alias f=&apos;fasd -f&apos; # 文件alias d=&apos;fasd -d&apos; # 目录alias a=&apos;fasd -a&apos; # 任意alias s=&apos;fasd -si&apos; # 显示并选择alias sd=&apos;fasd -sid&apos; # 选择目录alias sf=&apos;fasd -sif&apos; # 选择文件alias z=&apos;fasd_cd -d&apos; # 跳转至目录alias zz=&apos;fasd_cd -d -i&apos; # 选择并跳转至目录 zsh-autosuggestions命令行命令键入时的历史命令建议插件git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions zsh-syntax-highlighting语法高亮插件git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting 修改「.zshrc」文件Oh My Zsh 配置文件的完整修改结果，只有对配置文件进行如下修改，才能使上述配置生效。# 设置字体模式以及配置命令行的主题，语句顺序不能颠倒POWERLEVEL9K_MODE=&apos;nerdfont-complete&apos;ZSH_THEME=&quot;powerlevel9k/powerlevel9k&quot;# 以下内容去掉注释即可生效：# 启动错误命令自动更正ENABLE_CORRECTION=&quot;true&quot;# 在命令执行的过程中，使用小红点进行提示COMPLETION_WAITING_DOTS=&quot;true&quot;# 启用已安装的插件plugins=( git extract fasd zsh-autosuggestions zsh-syntax-highlighting) 添加环境变量打开配置文件vim ~/.zshrc 添加环境变量export PATH=/usr/local/python/bin:$PATH 注：环境变量中，各个值是以“冒号”分隔开的。上面的语句表示给PATH这个变量重新赋值，让它等于/usr/local/python/bin ；再加上原来的$PATH 使配置生效source ~/.zshrc]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Anconda常用命令总结]]></title>
    <url>%2F2019%2F01%2F02%2FAnconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[anaconda是python发行的包的管理工具，其中自带python的版本，还带很多python的包.安装它比起安装python可以省掉再安装python包的时间。并且利用 Python 进行科学计算，就需要一一安装所需的模块， 而这些模块可能又依赖于其它的软件包或库，安装和使用起来相对麻烦但是用Anaconda只需直接输入conda install &lt;包名&gt;，所有依赖的包和库会自动安装好。 下载地址官网：https://www.anaconda.com/最新版本下载地址：https://www.anaconda.com/download/历史版本：https://repo.anaconda.com/archive/ Anaconda的安装进入文件所在路径bash Anaconda3-4.4.0-Linux-x86_64.sh (下载的对应的文件名) conda的环境管理比如创建名为tensorflow的tensorflow-gpu版的python环境conda create --name tensorflow python=3.6 tensorflow-gpu 激活tensorflow环境source activate tensorflow 测试环境python --version 退出虚拟环境source deactivate tensorflow 删除虚拟环境conda remove --name tensorflow --all Conda的包管理安装包conda install -n tensorflow sklearn注：如果不用-n指定环境名称，则被安装在当前活跃环境 删除包conda remove -n tensorflow numpy 在当前环境下安装anaconda包集合conda install anaconda 添加Anaconda的TUNA镜像conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ jupter notebook添加conda环境首先安装：conda install ipykernel 激活对应的conda环境source activate 环境名称 将环境写入notebook的kernel中python -m ipykernel install --user --name 环境名称 --display-name &quot;Python (环境名称)&quot;]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>anconda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11-18句型总结]]></title>
    <url>%2F2019%2F01%2F02%2F%E5%8F%A5%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[名词化 の vs こと1、一般而言「こと」指事。表示向别人传达的内容或决定的内容、概念、以及 抽象的事情时使用。2、「の」可以指人、物、事。表示自己实际感觉到的做的事情等具体的行动或体 验时使用。有时二者可通用。 ✿ 友達に電話する こと/の を忘れた。 ✿ 明日鈴木さんが来る こと/の を知っていました。 「こと」しか使えない場合1、后续动词为传达、表达等语言行为的动词，如「話す、伝える、教える」等。 ✿ みんなに会議があることを伝えてください。2、名词化的动词直接加「です」结句。 ✿ 私の趣味は映画を見ることです。3、后续为表示意志的动词 ，「命じる、许す、决める、願う、约束する」等。 ✿ 結婚することに決めました。 「の」しか使えない場合1、后续动词是表示感觉、知觉等感官动词，如「聞こえる、見える、感じる、 聞く、見る、気がつく」等。 ✿ 誰か叫んでいるのを聞こえました。 ✿先生が車から降りるのを見ました。2、在句型「Ｖのは、～だ」中，一般不能换。 ✿ 彼女が買ったのは、この赤いかばんです。 たい VS ほしいＶたい“想做某事”１、接续：动词第一连用形+たい（只能用于第一人称） ✿ 美味しいものが食べたいです。2、「Ｖたかった」过去时可以用于第一、二，三人称，陈述已发生的事实。 ✿ 彼女はあのケーキが食べたかったです。３、第三人称一般使用「Vたがる」的形式，构成一类的派生动词。做他动词使用。 ✿ 高橋さんはアイスを食べたがります。 Nがほしい”想要某物”１、表示希望，想要得到某东西。一般只能用于第一人称。 ✿ お金が欲しいです。2、「Nがほしかった」过去时可以用于第一、二，三人称，陈述已发生的事实。 ✿ 李さんはゲーム機が欲しかったです。３、第三人称一般使用「ほしがる」的形式，构成一类的派生动词。做他动词使用。 ✿ 山田さんは休みを欲しがっています。 Vてほしい“希望别人做某事”１、动词て形+ほしい。表示说话人希望听话人采取某一行动，或者造成某种状态。 ✿ 明日の朝も来て欲しい。 ✿ 君にこの仕事を担当して欲しい。 あいだ VS あいだにあいだに&lt;时点&gt;1、表示在某状态持续的阶段或时期内的某一时点上的某一动作或变化。 ✿ 留守のあいだに、泥棒が入った。 あいだ&lt;时段&gt;1、表示在某状态持续的整个阶段，时期内持续地进行了谓语动词的动作。 常与ずっと搭配。后句一般会用到表示持续状态的ている。 ✿ 彼は会議のあいだ、ずっと居眠りをしていた。 Vたら～た&lt;契机~发现&gt;1、表示以前项为契机，紧接着发生了后项的事件或发现了后项的状态。 ✿ 本屋に行ったら、偶然学生時代の友人に会った。★ 后项事物一般为说话人意志所不能及的事物，或是一些新发现、新认识等， 具有意外性。 と～と&lt;条件&gt; “一～就～、（如果）~就~1、达成某种条件就会得到必然结果、现象。 主要用在表述：恒常性状态，真理， 指路，反复性状态，习惯等方面。 ✿ 前の交差点を右に曲がると、学校が見える。 ～と&lt;反复、习惯&gt;“一~就~ ”1、表示特定的人或物的习惯和动作的反复，常伴有“いつも、よく”等副词。 ✿ 毎年、冬になるとスキーに行く。 ～ないと～ない＜否定性条件＞1、否定性条件从句，后项常表否定性意义。口语中后项常省略。表示前项不成立 的话，后项一定会出现某消极或否定结果。 ✿ 早く行かないと、間に合わないよ。 (否定结果) ✿ 急がないと遅刻するよ。(消极结果) よにVる / Ｖないようにする1、表示设法做（或不做）某事。为实现某种状态做（或不做）某事。可以与｢でき るだけ、必ず、ちゃんと｣等构成呼应。 ✿ 夜は甘いものを食べないようにしている。 Vる / Ｖないようにしてください1、对听话人表示要求、忠告或劝告。”请尽量~、请注意~” ✿ ちゃんとメモを取るようにしてください。 句型1、Ｖましょうか/ましょう&lt;意志、征求同意&gt;2、って&lt;话题&gt;3、N/A２にする/A１くする4、どうして&lt;原因（疑问）&gt;5、でしょう&lt;确认&gt;6、Nについて/Nについての7、N１は N２より～ （比较句）8、N２よりN１のほう（方）が～ （比较句）9、N1はＮ２ほど～ない （比较句）10、N１だけで（じゃ）なくN２も～ 不光/不仅……还/而且……11、(N1の中で) Ｎ２が一番～12、Ｎ１でもＮ２でも（いい）13、Ｎ１とＮ２と（では）どちら（のほう）が～14、Ｎ１はＮ２とともに相同15、それで：因果关系16、~かどうか&lt;选择&gt;17、Ｖたことがある&lt;经历&gt;18、Vることがある&lt;频率低&gt;19、~だろう&lt;推测&gt;20、Nがする&lt;感觉&gt;21、Nによって（違う）&lt;基准&gt;22、どうやって～んですか&lt;方式&gt;23、Nにとって&lt;评价的立场和角度&gt;24、はず&lt;判断，估计&gt;25、かもしれない&lt;推测&gt;26、～途中で＜动作进行中＞27、～のは～（ ～からではなくて）からだ28、疑问词 ＋でも＋肯定句＜全面肯定＞29、～まえに＜动作的顺序＞30、～あとで＜先后顺序＞ 31、それに&lt;并列&gt;：~，而且~32、それとも&lt;选择&gt;：是~还是~33、~とおり&lt;基准 标准&gt;34、もう&lt;加强语义&gt;]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>句型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日语助词总结]]></title>
    <url>%2F2019%2F01%2F02%2F%E6%97%A5%E8%AF%AD%E5%8A%A9%E8%AF%8D%2F</url>
    <content type="text"><![CDATA[本篇主要记载日语助词用法，以便个人查询 か1、＜疑问＞ （5.1 P41） ✿ その人は王さんですか。 お元気ですか。2、疑问词 か＜虚指＞ （9.1 P152） ✿ どこかへ行きますか。3、NかN＜选择＞ （9.2 P161） ✿ 朝はミルクかジュースを飲みます4、含疑问词的简体句 か （17.2 P44） ✿ 図書館はどこか教えてください。 で1、＜处所＞（动作发生的场所） （8.1 P129） ✿ 喫茶店でコーヒーを飲みます。 2、＜工具，方式，手段＞ (8.2 P138) ✿ バスで行きます。 3、＜限定範囲，数量，主体＞ ✿ 富士山は日本で一番高い山です。 ✿ 300元ぐらいでシルクのチャイナドレスが買えます。 ✿ 二人で行きましょう。 4、＜原材料＞ （12-1 p232） ✿ 紙で飛行機を作った。（变化小：で 变化大：から） 5、＜原因＞ ✿ 事故で遅刻しました。 6、＜事件发生的场所＞ ✿ 運動場で試合がある。 と1、＜并列＞ （5.2 P55） ✿ 家族は三人です。父と母とわたしです。 2、＜比较的基准＞ （7.2 P100） ✿ 私は鈴木さんと同じ大学です。3、＜相互动作的对象、同一动作的参与者＞ （9.1 P152） ✿ 兄は私の友達と結婚しました。 （双向性） ✿ 私は友達と一緒にお酒を飲みます。４、と＜引用＞ （11.1 ｐ204） ✿ 李さんは来週帰国すると聞きました。５、と言う＜引用＞ （13-3 p274） ✿ 食事のとき、「いただきます」と言います。６、と言うＮ （14-1 p282） ✿ 浜崎あゆみという歌手7、条件 （17-1 p33） ✿ 春になると、花が咲きます。8、习惯，反复 （17-1 p33） ✿ 子供のころ、冬になると毎年スキーに行った。 は1、は＜部分否定＞ (13.3 p275) ✿ 毎日はしません。 も1、も＜主观多量＞ （12.2 p242） ✿ 3万円もするんです。 の1、＜准体＞ （12-1 p231） ✿ 美味しいのが好きです。2、＜连体修饰语从句主语＞ （14-2 p293） ✿ 母の作った料理は美味しい。3、＜名词化＞ (14-2 p293) ✿ 先生が行ったのを見ました。 に1、に＜周期＞ （14-2 p291） ✿ 一週間に2回家族に電話します。2、に＜状态、性质的对象＞ （14-2 p291） ✿ 京劇に詳しい。 ✿ 学生に優しい。 ので VS から1、接续不同：名词/2类形容词词干+なので 名词/2类形容词词干+だから2、意义不同：「ので」一般用于陈述客观的原因。 后项既定事实、客观事实、绝大多数人的看法，语气更缓和； 「から」一般用于陈述主观的理由。 后项可以是既定事实也可以是意志、推测、主张。3、语气不同：から较生硬，因此妇女和儿童一般来说为避免过分强调自己的主张 Ｎ（＋格助词）のＮA、「が/を/に/へ/で/と/から/まで」等格助词一般接名词后与动词搭配使用。B、除此之外，还可以与「の」结合后构成复合形式，用于修饰名词。 ✿ 高橋さんが留学する 高橋さんの留学 ✿ 日本語を学習する 日本語の学習 ✿ 日本に留学する 日本への留学 ✿ 学校まで案内する 学校までの案内 ✿ 海外へ出張する 海外への出張 ✿ 北京で生活する 北京での生活 ✿ 日本人と会話する 日本人との会話 ✿ 母に手紙を送る 母への手紙注意：没有がの、をの，另外にの要变成への。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>助词</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[词型总结]]></title>
    <url>%2F2018%2F12%2F31%2F%E6%97%A5%E8%AF%AD%E5%8F%98%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[本篇主要记载日语常用变形，以便个人查询 词型 词序： 词类：1、独立词:能在句子中单独使用、但需要附属词连接构成句子。2、附属词: 在句子中只能附在独立词后面起一定的语法作用。 体言/二类形容词非过去时：肯定: 私は 学生です/だ否定: 私は 学生では(じゃ)ありません/ では ないです。 过去时：表达过去曾是/不是~肯定:学生でした /だった否定:学生ではなかったです。 ではありませんでした。 形容词一类形容词おもしろい 面白い 敬体非过去时肯定：面白いです否定：おもしろくないです 敬体过去时肯定：おもしろかったです否定：おもしろくなかったです 简体直接去掉です。 二类形容词簡単 敬体非过去时肯定：簡単です否定：簡単ではありません 敬体过去时肯定：簡単でした否定：簡単ではありませんでした 简体非过去时肯定：簡単だ否定：簡単ではない 简体过去时肯定：簡単だった否定：簡単ではなかった 形容词的副词化一类形容词的副词化1: 面白くなりました2: 面白くて 二类形容词的副词化1：簡単にする2：簡単で 动词的分类I类动词 （五段动词）a、词尾是る、倒数第二个假名不在い段或え段（始まる）b、词尾在う段（行く） II类动词 （一段动词）倒数第二个假名在い段（起きる） 或え段（食べる） III类动词カ变动词：来る（只有这一个）サ变动词：a、する（实义动词） b、词干+する：勉强する 词尾是る 动词的敬体I类动词う段变成い段，再接ます：かく ＝＞ かきます II类动词去掉る接ます：みる ＝＞ みます III类动词くる ＝＞ きますする ＝＞ します 动词的て型I类动词① く、ぐ → いて、いで「特例：行く → 行って」 （聞く→ 聞いて） （防ぐ→防いで） ② う、つ、る → って （会う→ 会って） （打つ→打って）（降る→ 降って）③ む、ぶ、ぬ → んで （読む→読んで） （呼ぶ→呼んで）（死ぬ→死んで）④ す →して （探す→探して） II类动词去掉词尾「る」＋て （食べる → 食べて） III类动词来る → 来てする → して 勉強する→勉強して て型用法1、连接两个动词，表示先后/并列/因果关系（句子的时态由后面的动词决定） ✿ 手を洗ってご飯を食べます。 ✿ 町へ行って、服を買いました。2、动词+てから+动词表示先做...再做...（表示先后的动作，强调动作的顺序） ✿ 手を洗ってから、ご飯を食べます。 ✿ 宿題を終わってから、テレビを見ます。3、动词+てもいいです即使...也可以（表示假定条件/让步） ✿ バスで行ってもいいです。 ✿ このケーキを食べてもいい。4、动词+てはいけません 不许做...（轻微命令/禁止） ✿ ここは、写真を撮ってはいけません。 ✿ この本を売ってはいけません。5、动词+ている 表示正在进行的事情/状态 a、表示正在做...（强调正在进行） ✿ 今、雨が降っています。 ✿ 今、ご飯を食べています b、表示动作结果的持续 （强调句子中提到的这个动作正在持续中的一个状态） （一般接一些表示状态变化的动词：開く、行く、来る、帰る、住む、着る「穿戴动词」） ✿ 田中さんは結婚しています。 （表示田中先生现在是一个已婚，结了婚的状态） ✿ あの時、雨が降っていました。 （这里的ている表示的是一种下着雨的状态，而“那个时候”是过去，所以要用过去时态）5、动词+て行く / て来る &lt;主体的移动&gt; a、表示移动性动词动作的方向性。 ✿ 由近及远为ていく(~去)：風船が飛んでいった。 ✿ 由远及近为てくる(~来)：日本から戻ってきた。 b、表示完成V动作后再进行方向性移动，或表示保持某状态进行移动。 ✿ 携帯電話を持って行く。 ✿ 飲み物を買ってくる。 动词的简体否定型I类动词う段变成あ段，再接ない：読む ＝＞ よまない II类动词去掉る接ない：着る ＝＞ きない III类动词くる ＝＞ こないする ＝＞ しない ない型的接续和用法1、动词ない形+ないでください请不要（做某个动作） ✿ 見ないでください。 ✿ 泣かないでください。2、动词ない形+なくてもいい即使不...也不可以 ✿ この薬は飲まなくてもいいです。 ✿ 会社に行かなくてもいいです。3、动词ない形+なければなりません（或なくてはいけない） 一定，必须（比较正式，书面化） ✿ ご飯を食べなければなりません。 ✿ 薬を飲まなければなりません。4、动词ない形+ないといけません 一定，必须（比较口语化） ✿ ご飯を食べないといけません。 ✿ 薬を飲まないといけません。 动词的简体过去式I类动词く、ぐ发生“イ音变”：Vく ＝＞ Vいた； Vぐ ＝＞ Vぃだう、つ、る发生“促音变”：Vう/つ/る ＝＞ Vったぬ、ぶ、む发生“拨音变”：Vぬ/ぶ/む ＝＞ Vんだす不发生音变：Vす ＝＞ Vした特殊动词：行く ＝＞ 行った II类动词直接去掉“る”,然后接“た” III类动词くる ＝＞ きたする ＝＞ した 动词的连体形（体：体言，即名词）连体形的形式1、动词原形+名词：表示现在/即将发生的动作/状态&amp;经常性的动作/状态 電話する人。 話す人。２、动词「た」形（动词过去式）+名词：表示已经发生的动作/状态 服を買った人。 電話をした人。 连体形的接续和用法1、动词连体形+形式体言「こと」（こと一般不翻译） 魚を食べること。 吃鱼（这件事情） 魚を食べることが嫌いです。2、动词连体形+ことができる 会、能（做...） 日本語を喋ることができます。「动词连体形+ことができません 不会、不能（做...）」 日本語を喋ることができません。3、动词连体形+ことがあります表示曾经（做过...） 日本人と話したことがあります。 アメリカに行ったことがあります。4、动词连体形+ほうがいい最好（做...） 水を飲むほうがいいです。 はやく寝たほうがいいです。５、动词连体形（动词原形）+前に＋动词/句子 在做...之前，先做 テレビを見る前に、勉強します。 会社に行く前に、朝ご飯を食べました。６、动词连体形（动词过去式）+後で＋动词/句子 在做了...之后，再做... 勉強した後で、遊びに行きました。 手を洗った後で、お菓子を食べました。 动词的能动态相当于汉语的“能～，会～，可以～”等意 I类动词う段变成え段，再接る：送る ＝＞ 送れる II类动词去掉る接られる：出る ＝＞ 出られる III类动词くる ＝＞ こられるする ＝＞ できる 表示能力的几种方式1、本身具有表示能力的自动词（見える、聞こえる） ✿ 海が見える。2、Ｎができます（できる表示具备某种能力的意思）“能~，会~” ✿ 私はピアノができる。3、Ｎがわかります（わかる表示对人或事物的了解）“明白~，了解~，懂~” ✿ 私は英語はわかりません。 注意：一般用が提示，否定多用「は」4、Vる＋ことができる表示“可能”，表示本身具有某能力做某事。 ✿ 一気に十階まで登ることができます。 动词的意志型表示意志、建议 I类动词う段变成お段，再接う：かく ＝＞ かこう II类动词去掉る接ます：あつめる ＝＞ あつめよう III类动词くる ＝＞ こようする ＝＞ しよう 意志型的使用1、用于第一人称句时，表明说话人的意志； 用于第一、二人称时，表示建议对方做某事。（「Ｖましょう」的简体）2、动词的意志形后接「と思う」构成「Ｖようと思う」句型。 用于表达说话人做某事的决心、打算。“要~，决心~”。 ✿ 僕もそうしよう。 ✿ みんなと一緒に遊ぼうよ。 动词的命令型I类动词う段变成え段，再接う：行く ＝＞ 行け II类动词去掉る接ろ：食べる ＝＞ 食べろ III类动词来る ＝＞ こいする ＝＞ しろ 动词的被动型I类动词う段变成あ段，再接れる：買う → 買われる II类动词去掉る接られる：食べる → 食べられる III类动词来る→ こられる する→ される 动词的使役型I类动词う段变成あ段，再接せる：知る → 知らせる II类动词去掉る接させる：食べる → 食べさせる III类动词来る→ こさせる する→ させる 动词、形容词的条件型相当于汉语的“如果～就～、假如～、要是～”等 I类动词う段变成え段，再接ば：いそぐ ＝＞いそげば II类动词去掉る接れば：おきる ＝＞ おきれば III类动词くる ＝＞ くればする ＝＞ しれば 形容词I类：去掉i加けれ：たかい ＝＞ たかければII类：接なら，再接ば(现代日语中ば大多省略)：げんき ＝＞ げんきなら(ば) 动词的ない型Vない ＝＞ Vなければ]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>词型变换</tag>
      </tags>
  </entry>
</search>
