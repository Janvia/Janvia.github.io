<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2023%2F06%2F28%2Fsource%2F</url>
    <content type="text"><![CDATA[计算机视觉 Stanford Vision Lab - http://vision.stanford.edu CS 131 Computer Vision: Foundations and Applications - http://vision.stanford.edu/teaching/cs131_fall1617/index.html CS231n: Convolutional Neural Networks for Visual Recognition - http://cs231n.stanford.edu CS231A: Computer Vision, From 3D Reconstruction to Recognition - http://web.stanford.edu/class/cs231a/ Computer Vision: A Modern Approach - http://cmuems.com/excap/readings/forsyth-ponce-computer-vision-a-modern-approach.pdf Computer Vision: Algorithms and Applications - http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdf Computer Vision: Models, Learning, and Inference - http://www.computervisionmodels.com/ 自然语言处理 CS224n: Natural Language Processing with Deep Learning - http://web.stanford.edu/class/cs224n/ Natural Language Processing with Python - http://www.nltk.org/book/（视频：https://www.youtube.com/playlist?list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL） 《自然语言处理综论》英文版 - https://web.stanford.edu/~jurafsky/slp3/ 《统计自然语言处理》 《Python 自然语言处理》]]></content>
  </entry>
  <entry>
    <title><![CDATA[sacred]]></title>
    <url>%2F2022%2F08%2F20%2Fsacred%2F</url>
    <content type="text"><![CDATA[Sacred 安装 # 主角pip install sacred# 用于数据库连接pip install numpy pymongo MongoDB 安装MongoDB 是一个数据库管理系统，这里用作 Sacred 的存储后端。 在 ubuntu 上的 MongoDB 安装可以参考 Install MongoDB Community Edition on Ubuntu，其他系统也可以在该网站上找到对应的安装方式。 mongoDB 常用命令# 启动sudo service mongod start# 停止sudo service mongod stop# 重启sudo service mongod restart# 进入MongoDBmongosh 创建一个名为 sacred 的数据库，用作 sacred 工具的后端存储： # 进入MongoDBmongosh# 创建sacred数据库。use命令切换数据库，没有该数据就会自动创建一个use sacred Omniboard安装在 Ubuntu 机器上安装版本≥v8 的 Node.js，系统默认 apt 安装的版本不够，需要手动安装 安装node.js和npmsudo apt install nodejssudo apt install npm 新版本安装(hexo不支持) curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - &amp;&amp;\sudo apt-get install -y nodejs nvm指定版本安装 proxychains4 wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | proxychains4 bashsource ~/.zshrcexport NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node/export NVM_IOJS_ORG_MIRROR=http://npm.taobao.org/mirrors/iojsnvm install 12.16.2nvm use 12.16.2 换源 sudo npm install -g nrmnrm lsnrm use taobao # 4. 测试安装版本信息node -vnpm versionnpx -v 第二步，npm 安装 omniboard npm install -g omniboard 第三步，开启 omniboard 服务。平时也是用该命令开启 omniboard 可视化前端 # 开启用法omniboard -m hostname:port:database# 默认情况下如下，其中27017是MongoDB的端口omniboard -m localhost:27017:sacred 第四步，打开 http://localhost:9000 来查看前端，并进行管理。 添加远程查看 ssh -L 9000:127.0.0.1:9000 -p 10102 root@192.168.25.110 使用案例使用 yunjey 的一个 pytorch 教程作为演示，代码是演示用 pytorch 实现基于 CNN 的 MINIST 手写数字识别。 根据 Sacred 文档稍作修改，就可以演示如何进行实验的记录。 更多用法请去看 Sacred 文档：Welcome to Sacred’s documentation!。内容超丰富，功能超级多。 代码： from sacred import Experimentfrom sacred.observers import MongoObserverfrom sacred.utils import apply_backspaces_and_linefeedsimport torchimport torch.nn as nnimport torchvisionimport torchvision.transforms as transformsex = Experiment(&quot;mnist_cnn&quot;)ex.observers.append(MongoObserver.create(url=&apos;localhost:27017&apos;, db_name=&apos;sacred&apos;))ex.captured_out_filter = apply_backspaces_and_linefeeds# 超参数设置@ex.configdef myconfig(): # Device configuration device = torch.device(&apos;cuda:0&apos; if torch.cuda.is_available() else &apos;cpu&apos;) # Hyper parameters num_epochs = 5 num_classes = 10 batch_size = 100 learning_rate = 0.001# Convolutional neural network (two convolutional layers)class ConvNet(nn.Module): def __init__(self, num_classes=10): super(ConvNet, self).__init__() self.layer1 = nn.Sequential( nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) self.layer2 = nn.Sequential( nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) self.fc = nn.Linear(7 * 7 * 32, num_classes) def forward(self, x): out = self.layer1(x) out = self.layer2(out) out = out.reshape(out.size(0), -1) out = self.fc(out) return out# notice how we can access the message here by taking it as an argument@ex.automaindef main(device,num_epochs,num_classes,batch_size,learning_rate ): # MNIST dataset train_dataset = torchvision.datasets.MNIST(root=&apos;/home/ubuntu/Datasets/MINIST/&apos;, train=True, transform=transforms.ToTensor(), download=True) test_dataset = torchvision.datasets.MNIST(root=&apos;/home/ubuntu/Datasets/MINIST/&apos;, train=False, transform=transforms.ToTensor()) # Data loader train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False) model = ConvNet(num_classes).to(device) # Loss and optimizer criterion = nn.CrossEntropyLoss() optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Train the model total_step = len(train_loader) for epoch in range(num_epochs): for i, (images, labels) in enumerate(train_loader): images = images.to(device) labels = labels.to(device) # Forward pass outputs = model(images) loss = criterion(outputs, labels) # Backward and optimize optimizer.zero_grad() loss.backward() optimizer.step() if (i + 1) % 100 == 0: print(&apos;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;&apos; .format(epoch + 1, num_epochs, i + 1, total_step, loss.item())) # Test the model model.eval() # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance) with torch.no_grad(): correct = 0 total = 0 for images, labels in test_loader: images = images.to(device) labels = labels.to(device) outputs = model(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&apos;Test Accuracy of the model on the 10000 test images: &#123;&#125; %&apos;.format(100 * correct / total)) # Save the model checkpoint torch.save(model.state_dict(), &apos;model.ckpt&apos;) 执行完该程序后，可以打开 omniboard 前端 http://localhost:9000]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>sacred</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wsl]]></title>
    <url>%2F2022%2F08%2F20%2Fwsl%2F</url>
    <content type="text"><![CDATA[wsl安装wsl -l -o #查看版本wsl --install -d Ubuntu-20.04wsl --install -d Ubuntu-18.04wsl --shutdownwsl --set-version Ubuntu-18.04 2wsl --set-version Ubuntu-20.04 1 代理1.设置防火墙 ,不勾选wsl 2.设置代理软件allow alan 3.安装配置proxychains4,见配置proxychains4 ​ 对于wsl2,配置的地址需要是ipconfig的地址172.xx.xx.1 迁移将wsl 安装在其他盘 wsl --export Ubuntu-20.04 d:\wsl-ubuntu20.04.tar #导出wsl --unregister Ubuntu-20.04 #注销#重新导入wsl --import Ubuntu-20.04 d:\wsl-ubuntu20.04 d:\wsl-ubuntu20.04.tar --version 2ubuntu2004 config --default-user USERNAME #设置usrdel d:\wsl-ubuntu20.04.tar#删除包 网络配置查看/etc/resolv.conf 如果出现网络错误,nameserver为红色 1.在/etc/wsl.conf中加入： [network]generateResolvConf = false 2.PowerShell重启WSL wsl --shutdown 3.修改/etc/resolv.conf,去掉发红的nameserver nameserver 223.5.5.5nameserver 223.6.6.6 网络故障修复wsl --shutdownnetsh winsock resetnetsh int ip reset allnetsh winhttp reset proxyipconfig /flushdns 然后重启]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>wsl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双系统安装]]></title>
    <url>%2F2022%2F08%2F20%2F%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[需要的软件启动盘和分区软件只需要任选其一 启动盘制作软件1.rufushttps://github.com/pbatard/rufus/releases 2.软碟通UltralSOhttps://cn.ultraiso.net/uiso9_cn.exe``` 3.大白菜启动盘制作百度大白菜进入官网下载#### 分区软件1.DiskGenius https://www.diskgenius.cn/download.php2.系统自带(win11为例)右键我的电脑选择属性然后选择系统-&gt; 存储 -&gt; 磁盘和卷### 安装示例以软碟通和DiskGenius为例#### 下载ubuntu https://cn.ubuntu.com/desktop#### 制作启动盘1.插入U盘，提前备份U盘内的数据，U盘大小要足够容纳ISO文件。2.打开UltralSO，同时找到自己电脑中刚刚下好的ISO文件，直接拖拽文件到UltralSO工具中。3.双击刚刚拖拽进来的iso文件，弹出选项卡，选择“是”，就打开ISO文件了。4.单击工具栏上的“启动”-&gt;“写入硬盘映像”“，系统可能会询问管理员权限，选择“是”。然后选择硬盘驱动器为指定U盘，写入方式为USB-HDD+。5.选择“写入”，一定要确保U盘里面的重要数据都备份了！！弹出警告也会提醒你，你确定的话就选择“是”。下面软件就会进行写入操作了，写入成功。#### 分区1.打开DIskGenius，右键自己想要开辟分区的磁盘，选择“建立新分区”，然后输入自己想要开辟的分区大小，这里我开辟128G大小。2.选择“开始”，这时候可以软件就开始工作了，我们等待它完成就好。3.创建好分区后，将新建的分区删除，右键该盘块，选择“删除当前分区”，这样就会出现一个128G的空闲区域。### 系统安装#### 安装步骤1.重启电脑，按F9（暗影精灵） ，其他电脑可能是其他按钮F9-F12 ，选择U盘启动2.选择try or install ubuntu3.进入Ubuntu安装引导程序，选择中文，点击继续4.选择chinese，点击继续5.选择不连接网络，点击继续6.选择最小安装，点击继续7.选择自定义安装8.选择创建出的空间的128G的那个分区，右键点击，选择新建分区，挂载点填写`/`,表示根目录，点击确定，点击继续9.后面一路继续，填写用户信息，安装10.安装完成后，重启，根据提示，拔掉U盘#### 问题解决1.todesk无法连接，提示没有X11点击左下角，选择软件和更新，选择附加驱动，选择安装nvidia最新驱动软件，安装完成重启如果仍然不行，安装lightdm sudo apt updatesudo apt install lightdm```]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>双系统安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFmpeg常用命令]]></title>
    <url>%2F2022%2F08%2F18%2FFFmpeg%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[FFmpeg常用命令调整音量ffmpeg -i &#123;in_file&#125; -af &apos;volume=0.5&apos; &#123;out_file&#125; 截取音频ffmpeg -v 1 -y -i &#123;in_file&#125; -ss &#123;start&#125; -t 2 &#123;out_file&#125; -ss 开始时间，单位s -t 截取时间，单位s 类型转换wav 转 pcm ffmpeg -v 1 -y -i &#123;in_file&#125; -f s16le -ar 16000 -ac 1 -acodec pcm_s16le &#123;out_file&#125; pcm 转 wav ffmpeg -v 1 -y -f f32le -ar 48833 -i &#123;in_file&#125; -ar 16000 -ac 1 &#123;out_file&#125; int16: s16le float32: f32le resamplepcm ffmpeg -v 1 -y -f s16le -i &#123;&#125; -f s16le -ar 16000 -ac 1 -acodec pcm_s16le &#123;&#125;]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>ffmpeg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统代理]]></title>
    <url>%2F2022%2F08%2F18%2Flinux%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[linux系统代理安装sudo apt install proxychains4 配置sudo vim /etc/proxychains4.conf [ProxyList]# add proxy here ...# meanwile# defaults set to &quot;tor&quot;#socks4 127.0.0.1 9050# examplesocks5 127.0.0.1 8888]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matplotlib补充]]></title>
    <url>%2F2022%2F08%2F18%2Fmatplotlib%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[防止中文乱码import matplotlib as mplmpl.rcParams[&apos;font.sans-serif&apos;] = [u&apos;simHei&apos;]mpl.rcParams[&apos;axes.unicode_minus&apos;] = False 调整子图布局plt.tight_layout() 设置坐标轴axis(‘off’)#：关闭轴线和标签。axis(‘equal’)#：使x轴与y轴保持与屏幕一致的高宽比（横纵比）。axis(‘tight’)#：使x轴与y轴限制在有数据的区域。axis(‘square’)#：使x轴与y轴坐标一致。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2022%2F08%2F18%2F%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[常用命令所有权限 chmod -R 777 test_out 可以用来查看分区的文件系统 df -T 显示目前所有文件系统的可用空间及使用情形 du -h --max-depth=1 /home 命令行代理 proxychains4 curl www.google.com 服务器拷贝 rsync -avzP -e &apos;ssh -p 10101&apos; dcase2020_task2/root@192.168.25.110:/data/dcase/dcase2020_task2 打开scared omniboard -m 192.168.2.111:27017:sacred 自动安装依赖 sudo apt-get install aptitudesudo aptitude install xxx]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R配置jupyter]]></title>
    <url>%2F2022%2F08%2F07%2FR%E9%85%8D%E7%BD%AEjupyter%2F</url>
    <content type="text"><![CDATA[下载地址官网：https://www.anaconda.com/最新版本下载地址：https://www.anaconda.com/download/历史版本：https://repo.anaconda.com/archive/ Anaconda的安装进入文件所在路径bash Anaconda3-4.4.0-Linux-x86_64.sh (下载的对应的文件名) conda的环境管理比如创建名为R4的R环境conda create --name R4 r-base -c conda-forge 激活R环境conda activate R4 测试环境R 退出R环境q() 删除虚拟环境conda remove --name R4 --all jupter notebook添加R环境首先安装：conda install jupyter 进入R环境R 安装和配置kernalinstall.packages(&apos;IRkernel&apos;)IRkernel::installspec() 启动jupter notebookjupyter notebook R更换下载源查看和配置options(&quot;repos&quot;)options(repos=&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;),options(&quot;repos&quot;) R2jags的安装（windows）首先在 http://mcmc-jags.sourceforge.net/ 下载JAGS ， 注意版本问题，由于rjags依赖JAGS，rjags未必支持最新版，可下载早期稳定版本。这里下载4.3.0版本，然后安装 手动配置库目录Sys.setenv(JAGS_HOME=&quot;C:/Program Files/JAGS/JAGS-4.3.0&quot;) 安装install.packages(&apos;R2jags&apos;)]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JNA]]></title>
    <url>%2F2019%2F06%2F07%2FJNA%2F</url>
    <content type="text"><![CDATA[step1:生成动态库1、编写头文件 #hellworld.h void test(); 2、编写实现文件 #helloworld.c #include&lt;stdio.h&gt; void test()&#123; printf(&quot;helloworld\n&quot;); &#125; 3、编译生成动态库，文件名:libhello.so gcc -fpic -shared -o libhello.so helloworld.c 文件libhello.so生成。 step2:添加maven配置&lt;dependency&gt; &lt;groupId&gt;com.sun.jna&lt;/groupId&gt; &lt;artifactId&gt;jna&lt;/artifactId&gt; &lt;version&gt;3.0.9&lt;/version&gt; &lt;/dependency&gt; step3:编写测试类import com.sun.jna.Library; import com.sun.jna.Native; public class JnaTest &#123; //继承Library，用于加载库文件 public interface Clibrary extends Library&#123; //加载libhello.so链接库 Clibrary INSTANTCE = (Clibrary) Native.loadLibrary(&quot;hello&quot;, Clibrary.class); //此方法为链接库中的方法 void test(); &#125; public static void main(String[] args) &#123; //调用 Clibrary.INSTANTCE.test(); &#125; &#125; step4:解决路径问题比如复制libtest.so到公共库]]></content>
      <categories>
        <category>java调用C</category>
      </categories>
      <tags>
        <tag>java调用C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jni]]></title>
    <url>%2F2019%2F06%2F03%2Fjni%2F</url>
    <content type="text"><![CDATA[STEP1 编写java调用文件J2C.java import java.lang.management.ManagementFactory;import java.lang.management.RuntimeMXBean;public class J2C&#123; static &#123; try&#123; // 此处即为本地方法所在链接库名 System.loadLibrary(&quot;j2c&quot;); &#125; catch(UnsatisfiedLinkError e) &#123; System.err.println( &quot;Cannot load J2C library:\n &quot; + e.toString() ); &#125; &#125; //声明的本地方法 public static native int write2proc(int pid); public static void main(String[] args)&#123; //获取本进程(即主线程)的pid final RuntimeMXBean runtime = ManagementFactory.getRuntimeMXBean(); final String info = runtime.getName(); final int index = info.indexOf(&quot;@&quot;); if (index != -1) &#123; final int pid = Integer.parseInt(info.substring(0, index)); System.out.println(info); System.out.println(pid); write2proc(pid); &#125; try&#123; Thread.sleep(8000); &#125; catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;&#125; Step2 生成J2C.hbash: javac -h ./ J2C.java 以下内容为自动生成： /* DO NOT EDIT THIS FILE - it is machine generated */#include &lt;jni.h&gt;/* Header for class J2C */#ifndef _Included_J2C#define _Included_J2C#ifdef __cplusplusextern &quot;C&quot; &#123;#endif/* * Class: J2C * Method: write2proc * Signature: (I)I */JNIEXPORT jint JNICALL Java_J2C_write2proc (JNIEnv *, jclass, jint);#ifdef __cplusplus&#125;#endif#endif Step3 编写J2C.c#include &lt;stdio.h&gt;#include &quot;J2C.h&quot;JNIEXPORT int JNICALL Java_J2C_write2proc(JNIEnv * env, jobject arg, jint pid) &#123; printf(&quot;current pid is %d\n&quot;, pid); return 0;&#125; Step4 生成J2C.sobash: gcc J2C.c -fPIC -shared -o libJ2C.so 利用gcc、g++编译源文件找不到jni.h头文件: 可以在编译时利用-I选项指定jni.h头文件所在目录： gcc J2C.c -fPIC -shared -o libJ2C.so -I /usr/java/jdk-12.0.1/include/ -I /usr/java/jdk-12.0.1/include/linux/ 注意：cmake make 找不到jni.h的情况，可以将文件复制到公共库/usr/include/]]></content>
      <categories>
        <category>java调用C</category>
      </categories>
      <tags>
        <tag>java调用C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30单元]]></title>
    <url>%2F2019%2F05%2F12%2F30%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[お／ごＶです＜尊他＞动词敬语表现形式之一，用来表示对动作主体的敬意。接续：Ｖます形/サ変V词干 中文翻译成：“您~~” １.シンポジウムには遠藤先生もご出席でした。２.お客様、何かお探しですか。３.遠藤先生！今、お帰りですか。４.佐藤部長はあしたから、ご旅行で3週間いらっしゃらないそうです。 V（ら）れる＜尊他＞表示对动作主体的敬意。 １.佐藤さんは何時に帰られましたか。(2003年真题)２.この本は、遠藤先生が書かれた本です。３.昨日、胡先生が来られて、教えてくださいました。 一类动词：将词尾う段假名变成相应行的あ段假名，再加 れる。 書く 書かれる 読む 読まれる 二类动词：将词尾的る去掉，再加られる。 見る 見られる ほめる 褒められる 三类动词： 来る 来られる（こられる） する される 勉強する 勉強される Vていただけませんか＜请求＞表示请求时要使用授受动词来表示说话人受益，一种礼貌的方式。 １.明日、こちらに来ていただけませんか。２.これを翻訳していただけませんか。３.お昼頃、来ていただけませんか。４.後5分、待っていただけませんか。 如果想表示更加谦恭的请求，还可以使用：“お/ご～いただけませんか”もうすこし お待ち いただけないでしょうか。 Nのところ&lt;处所化&gt;一、表示人或物的名词后加上“のところ”才可与移动动词或存在动词等搭配使用。 1.前にお借りした本を先生のところに返しにいきました。2.図書館に入ったら、高橋さんはまずパソコンのところに行って検索してみた。 二、接在 “今、現在、この”等表示“现在”的名词后，表示“现阶段、现在时点”等现在的时间性状况。 １.今のところ応募者は約100人ほどです。２.このところ雨の日が続いている。３.お忙しいところ、申し訳ありません。 V(よ)うとする&lt;意图&gt;接意志性动词后，表示为达到某目的而努力尝试进行该动作。接续：Ｖようとする汉语：想要~ 1.彼女は25歳になる前に何とか結婚しようとしている。2.いくら思い出そうとしても、名前が思い出せない。3.寝ようとすればするほど、目がさえてきてしまった。 通常以「ｖ（よ）うとしたとき」「ｖ（よ）うとしたところ」的形式，表示正要实施该动作。“正要~（的候）” 4.電車を降りようとしたとき、財布を忘れたことに気がついた。 ~うちに &lt;发生变化的时间范围&gt;表示在某一状态持续时或某一动作（反复）进行过程中，发生了某一变化。接续： V-る / V-ている + うちに 1.彼女は話しているうちに顔が真っ赤になった。2.昨夜、部屋で小説を読んでいるうちに、寝てしまいました。3.日本人と話すうちに、日本語の発音がよくなった。 ~うちに＜时段＞前接表示状态的词，表示在该状态持续期间内，发生了某件事或做某件事（有尽快进行该动作的语感）。 接续：N + の + うちにN + な + うちにA-い + うちにV-る / V-ている V-ない + うちに汉语 ：趁着~、~时候、在~之内 1.どうぞ、温かいうちに食べてください。（2008年真题）2.父が元気なうちに、一度一緒に温泉に行きたいと思います。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29单元]]></title>
    <url>%2F2019%2F05%2F02%2F29%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[～てしかたがない＜极端的心理状态＞ 多接在表示感情、感觉或者生理现象的词后，表示产生某种感情或感觉自然产生，难以控制。主语一般为第一人称。第三人称时需在句末加「らしい」「そうだ」「ようだ」接续：Aくて・NAで・Ｖて汉语：…得不得了，…得很★也可为：～てしょうがない ～てしようがない 1. 先生に褒められて、嬉しくてしかたがない。2. 夕べ徹夜したので、眠くてしょうがない。(2008年真题)3. この映画は見るたびに、涙が出てしかたがない。 Nさえ～ば、～&lt;充分条件&gt; 强调只要具备该条件，后项就会得出某结论或进行某动作。 「が」「を」格名词后接「さえ」时，其常常省略。汉语：只要…就… 1.日本語さえ使えれば、バイト代は安くてもいいんです。2.自分さえよければいい。(2004年真题)3.新しいパソコンさえあれば、あとは何も欲しくない。4.値段さえ安ければ買うつもりです。5.手続きさえ簡単なら(ば)もっと多くの人が利用できるだろう。 （Ｎに）Ｖてほしい/Vないでほしい表说话人希望对方或他人为自己做某事。动作的主体用「に」提示。汉语：希望……/希望不要……★：＝ＮにＶてもらいたい 1.あしたの演奏会には、ぜひ多くの人に来て欲しいです。2.今忙しいから邪魔しないで欲しい。3.この歌が少し難しいから、ほかのにしてほしい。(2011年真题) 谓语动词也可用非自主动词表希望某事发生或不发生。动作的主体用「が」提示。 1.早く夏休みが始まって欲しい。2.あしたは友達と遠足に行くので、雨が降らないで欲しい。 に（表示主体）接表人的名词后，谓语为表能力的动词，表示能力的主体。谓语部分为否定时，常用「には」提示主体。★「疑问词+にも～～ない」表示全面的否定“谁也不能” 1.私にできるかな…。2.みんなにわかるように、ゆっくり話してください。3.こんな難しい文章は、学生には翻訳できない。4.こんな難しいテスト、誰にもできないだろう。 Ｎ・Aでいらっしゃる＜尊他＞「～です」的尊他表现形式，用于他人，表示尊敬。 1.こちらは鈴木さんのお母様でいらっしゃいます。2.失礼ですが、どちらさまでいらっしゃいますか。3.お元気でいらっしゃいますか。4.いつもお若くていらっしゃいます。 Ｖていらっしゃる&lt;尊他&gt;「ている」的尊他表现形式，表示对动作主体的敬意。 1.先生は今、新聞を読んでいらっしゃいます。2.お仕事は何をしていらっしゃいますか。 ～とは限らない&lt;否定性可能&gt;接在简体句后（N和AⅡ也可直接接）表示事实未必如此、不能如此断定之意，暗示存在例外的情况。常与副词「必ずしも」搭配汉语：不一定…，未必…，并非… 1.高い料理が必ずしも美味しいとは限らない。2.実力のあるチームがいつも勝つとは限らない。 (2009年真题) N+らしい&lt;风格、特征&gt;接在N后，按照A活用，表示具有该名词所示事物的特点、风格之意。 1.鈴木さんは学生らしい格好で大学に来た。2.そんなことでくよくよするなんて、君らしくない。3.学生らしくもっと勉強しなさい。(2005年真题)4.自分らしさを見出してください。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28单元]]></title>
    <url>%2F2019%2F05%2F01%2F28%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[ず(に)&lt;否定性状态&gt;「Vず(に)」是「Vないで」的书面语形式.接续方式与ない基本相同。注意「する」变为「せず」。表示动作，状态的否定，用于中顿或并列。 １.彼は今は1日も休まずに、まじめに働いてる。２.昨日は忙しくて、夜10時まで何も食べずに働いた。(2009年真题)３.辞書を使わずに日本語の新聞を読むことができるか。(2007年真题) ～Vるには＜目的＞①当主句谓语动词为非自主动词时，表示要达到该目的所必须的条件，②当主句谓语动词为自主动词时，表示为达到该目的所采用的手段、方法或是必须付出的努力。（结尾多使用~なければならない；～べきだ） 与「Vるために」同义、也可以使用「Ｖるためには」形式。接续：动词原形 1. 会議で使う資料に間違いがあったが、今から作り直すには時間が足りない。(2013年7月真题)2. 日本語が上手になるには一生懸命勉強しなければなりません。 3. 東京駅に行くには、そこの角を右に曲がったほうがいいよ。(2002年真题) Vる ようになる&lt;变化&gt;表示事物的变化。汉语：变得可以了···；逐渐会···· a. 能力的从无到有​ 表示获得了该能力，即由原来不具备该能力、变得开始具备该能力。否定形式「Vるようにならない」表示尚未获得该能力。 １.私は日本語が話せるようになった。２.日本へ来てから、日本料理が作れるようになった。 b. 现象的出现（从无到有）否定形式「Vるようにならない」表示该现象尚未出现。 １.小学校は入学したころから、だんだん風邪を引いたり熱を出したりしないようになった。(2011年真题)２.日本では、なかなか女性と男性が同じ条件で働けるようにならない。 c.动作行为的习惯化（习惯的从无到有） 否定形式「Vるようにならない」表示该习惯尚未养成 1.父は最近散歩をするようになった。2.父はなかなか散歩するようにならない。3.子供が生まれたことで、食べ物の安全を気にするようになった。(2010年真题) やる／Vてやる&lt;授受、受益&gt; 用法与「あげる」大体相同，表示说话人自己或自己这一方的人将物品赠与他人，或者为别人做某事。★仅限于人对动植物、父母对子女、夫妻之间、兄弟姐妹之间或上对下的场合 ①Ｎ1はＮ2にＮ3をやる1.花に水をやる。2.息子の誕生日に、ネクタイをやろうと思っている。 ②Ｎ1はＮ2にＶてやる1.水泳は僕が教えてやるよ。(2000年真题)2.私は弟のシャツを洗ってやる。(2004年真题) Vるといい&lt;建议&gt; 表示给对方所提的建议、劝别人进行那种行为之意。★对年长者，上级一般使用：Ｖたらいかがですか★建议不要做某事时使用： Vないほうがいい汉语：~比较好；最好是~ １.日本語の辞書はこれを使うといい。２.疲れたでしょう。少し休むといいですよ。 Ｖて来る＜客体，信息的移动＞表示物品或信息的移动是向着说话人一方进行。「が」：表示动作者，「に」：表示动作接受者。接受者是第一人称时，常常省略。 ★「Ｖていく」はない ✖電話していく。 ●電話する。★动作者是公司这样一些场所名词时用：「から」 １.注文した本はもう送ってきた。２.会社から依頼を頼んできた。３.化粧品を買った客が苦情を言ってきた。 ~Vて行く Vて来る表示事物的＜动作、变化的持续＞。①ｖてくる过去到现在（~来、~起来、一直~） 1.この伝統はもう５００年も続いてきた。2.今まで一生懸命頑張ってきたんだから、大丈夫だ。 ②ｖていく现在到将来（~下去、继续~） 1.今後もさらに進歩していくだろうと思う。2.これからも続けていきたいと思う。 表示事物，现象的出现或消失。①ｖてくる出现 1.赤ちゃんの歯が生えてきた。2.雲の間から月が出てきた。3.雨が降ってきた。 ②ｖていく消失 1.星が消えていく。2.習慣がなくなっていく。3.ボートは渦の中に沈んでいった。 Vる／Ｎ につれて/につれ＜相应的变化＞ 表示随着某一事态或情况的变化和发展，相应的其他情况也随之发生变化或发展。主句常搭配「てきた」。汉语：随着…、伴随着… 1.時間が経つにつれて、悲しみは薄らいできた。2.工業の発展につれて、大気汚染も深刻になってきた。3.技術が発達するにつれて、人々の暮らしは豊かになってきた。（2009年真题） Vる／Ｎの たびに＜同一情况的反复＞表示某种动作行为反复进行，或某种现象反复出现时所发生的情况。汉语：每当…就、每次…都… 1.近所のおばさんは、会うたびに自分の子供の自慢話をする。2.うちの犬は、私が出かけようとするたびに、寂しそうな目で私を見る。(2013年真题)3.山田さんに会うたびに素敵な人だといつも思う。(2010年真题) ながら(も)&lt;转折&gt;用于连接内容相反的两个分句，表示转折关系。从句多表示状态。接续：R／A1／A2／N + ながら汉语：虽然~，但是~ 私は、悪いと知りながら、連絡しないで仕事を休んだ。体は小さいながら、なかなか力がある。全力を出しましたが、残念ながら、優勝できませんでした。(2007年真题) Vるべきだ/べきではない&lt;义务&gt;表示行为规范、原则道理以及事物的本质来看，应该不应该去做某事。多为说话人对一般事件发表意见，用于劝告，禁止，命令等。汉语：应当……/不应当……接续：する =&gt; すべき（するべき） 1.約束は守るべきだ。そうしないと、信用を失うよ。(2008年真题)2.大学生はまず第一に勉強すべきだ。3.これからやるべきことはたくさんある。 だけ＜程度＞表示按照动作主体的能力、主观愿望或客观需要的程度以及进行后项的动作。汉语：尽量，尽可能；想~就~；能够~都 a.V-れる ＋ だけV（同一动词） 尽量、尽可能将动词反复使用，表示“尽最大程度···”的意思。 1.食べられるだけ食べた。2.頑張れるだけ頑張ってみる。 b. V-たい ＋ だけV（同一动词） 想~就~、~够将动词反复使用，表示一直做到尽兴为止的意思。 1.日曜日は寝たいだけ寝ることができる。2.遠慮しないで、食べたいだけ食べなさい。 c. A（少部分） ＋ だけV 客观需要1.そうぞ、お好きなだけ召し上がってください。2.どうしたらお金が欲しいだけ手に入るのか。3.必要なだけ取りなさい。 Nには及ばない&lt;比较&gt;表示主语所指称的事物或人在性质上或能力上比不过该名词所指称的事物或人。汉语：~不及~、~比不过~惯用表达：远不及：～には遠く及ばない ～の足元にも及ばない 1.私がどんなに頑張っても、彼の実力には及ばない。2.CDは生の演奏には遠く及ばない。3.自動車がいくら速く走れても飛行機の足元にも及ばない。 Ｎに加えて&lt;递进、累加&gt;表示在该事物、事件的基础上增加了别的事物或发生了别的事件。含有整个事件程度的加深的语感，主句常与「も」搭配。汉语：加之…、除了…以外，还… 1.夏の低温に加えて、雨が少なかった。(1999年真题)2.お祭りは見る楽しさに加えて元気も与えてくれる。3.大雨に加えて、風まで吹いてきた。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27单元]]></title>
    <url>%2F2019%2F04%2F14%2F27%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[命令句1表示绝对的命令，其使用范围比较窄，常用于发号施令、交通标志等，多为男性使用。 1.お父さんも「頑張れ。諦めるな。」って言ってるわよ。2.あそこに、「スピードを落とせ。」と書いてあります。3.危ないから部屋の中でボールを投げるのはやめろ。 Ｖ-Rなさい＜命令・敬体＞接续：动词第一连用形+なさい 一般用于大人对小孩，老师对学生，上级对下级，或者亲密关系者间。语气比动词命令形较缓和。 もっとゆっくり食べなさい。早く学校に行きなさい。 ★更为客气的命令：お・ご~なさい 薬をお飲みなさい。この本をお読みなさい。 ★口语简化为「Ｖな」,语气不太客气，用于关系非常亲密的人之间 早く起きな。早く来な。 命令句3★「テ形」也可以表达命令，用于上下级和亲密者之间。 １.ここに座って。２.これを持って。 Ｖてくれ 也是一种命令式， 教えてくれ～ 出てくれ～ Vる＋な＜动词禁止形＞接续：动词基本型+な 这种形式也可以说就是动词简体命令形的否定形式，用于表示要求对方不要做某一行为动作。多为男性使用。汉语翻译：不要~、别~ 1）そんなつまらないことを人に頼むな。2）タバコを吸うな。3）ここに車を止めるな。 Ｖて来る＜客体，信息的移动＞表示物品或信息的移动是向着说话人一方进行。「が」：表示动作者，「に」：表示动作接受者。接受者是第一人称时，常常省略。 ★「Ｖていく」はない ✖電話していく。 ●電話する。★动作者是公司这样一些场所名词时用：「から」 １.注文した本はもう送ってきた。２.会社から依頼を頼んできた。３.化粧品を買った客が苦情を言ってきた。 Vてしまう＜完成体＞①＜完了＞强调动作的结束完成；状态的完成。 １.この宿題をしてしまったら、遊びに行ける。２.もうすっかり疲れてしまって、動けない。 ②＜感慨消极结果＞表示说话人对已结束动作的“后悔，遗憾，无法挽回弥补”的感情。句尾使用过去式「Ｖてしまった」动词多为非自主动词。口语：「Ｖちゃった」第二册20课2单元4.P124 １.急いで来たから財布を落としてしまった。(2005年真题)２.また授業に遅刻してしまった。 ③＜强行做某事的意志＞表示不顾客观情况和别人的意愿，而要强行进行该动作的意志，动词多为自主动词，后项常用意志形（Ｖてしまおう・Ｖちゃおう）。 1.先生に言っちゃうよ。2.このジュース、あと少しだから、全部飲んじゃおうかな3.まだ帰らないの？先に帰っちゃうよ。 回顾对比①Vてしまう＜强行做某事的意志＞说话人不顾客观情况和他人意愿，而要强行进行某动作的意志。②ましょう(か)＜意志，征求同意＞说话人进行某动作的意志，含有征求对方同意的语气。(第一册P203) A：電話しましょうか。B：そうですね。じゃあ、私がしましょう。 あの人は何度もメールしても返事来ないから、電話しちゃおう。 ～がる&lt;形容词的动词化&gt;日语的感情、感觉形容词在句中主要用于第一人称，当要表示第三人称的状态时，就在形容词的词干后面接上该后缀「がる」。变化后该词词性也从形容词变为动词。从而感情描述变为客观叙述。接続：A・Ｎa+がる 汉语：①感到，觉得（~心情或样子） ②装作（~样子）★Ｖたい・Ｎがほしい 1.あそこで泣いて、お菓子を欲しがっているようだ。(2011年真题)2.これを見たら、皆が面白がるだろうと思います。3.最近は数学を嫌がる子供が多いようです。4.弱いものに限って強がるものだ。 比较N1はN2より～＜比较＞格助词より，表示比较的基准、对象。该句式表示N1比N2具有谓语所示的特征，相当于汉语“N1比N2更~”(第一册P291) 中国は日本より広い。 N２よりN１のほうが～ ＜比较＞比起N2 ，N1 更（具有某种倾向）(第一册P293) 日本より中国のほうが広い。 ③ Ｎ1はＮ２ほど～ない＜比较＞副助词ほど：表示比较的基准，句尾必须接否定，Ｎ1在某方面程度上不及Ｎ２汉语：……不如……（程度高） １.日本は中国ほど広くない。２.今日は昨日ほど風が強くない。(2009年真题)３.私の部屋は姉の部屋ほど広くない。(2006年真题) Ｎなら＜主题＞接在名词后面用于凸显主题，就对方提出的话题或者问题做出回答或是进一步加以解释说明；提出意见建议。汉语：就····方面说；就····来说 １A：メガネはどこかな。 B：メガネなら、たんすの上に置いてあったよ。２A：もしもし、美智子さん、いらっしゃいますか B：美智子ですか。 美智子なら、もう出かけましたけど。(2000年真题) 回顾Ｎなら(ば)&lt;凸显，条件&gt;接在名词后面用于凸显,强调所指的事物，表示前项是后项成立的前提，后项为说话人的判断或决定。如果该话题成立的话。汉语：如果是·····的话 （第二册P115） 風邪なら早く帰って休んだほうがいいよ。 は＜主题＞第一册的名词谓语句与形容词谓语句中的实质都是提示主题的作用。但本册なら＜主题＞是具有“以Ｎ为话题的话”的假定意思。不可互换。(第一册P41，P98) ①高橋は日本人だ。②日本語は難しい。③高橋は今小説を読んでいる。 で＜时间量的限定＞接在表示时间量的名词后面时，表示对时间量的限定。 1. いろいろ考えた結果、一年で休学しました。2. ３日でその仕事を仕上げた。 ①&lt;处所&gt;図書館で本を読む②&lt;范围&gt;日本でも有名だよ。③&lt;限定数量&gt;駅まで五分で行ける④&lt;原材料&gt;シルクでできたドレス。⑤&lt;工具手段&gt;バスで学校へ通う⑥&lt;限定动作主体&gt;みんなで歌おう。⑦＜动态的存在＞五階で会議がある。 ず(に)&lt;否定性状态&gt;「Vず(に)」是「Vないで」的书面语形式.接续方式与ない基本相同。注意「する」变为「せず」。表示动作，状态的否定，用于中顿或并列。 １.彼は今は1日も休まずに、まじめに働いてる。２.昨日は忙しくて、夜10時まで何も食べずに働いた。(2009年真题)３.辞書を使わずに日本語の新聞を読むことができるか。(2007年真题) ～Vるには＜目的＞①当主句谓语动词为非自主动词时，表示要达到该目的所必须的条件，②当主句谓语动词为自主动词时，表示为达到该目的所采用的手段、方法或是必须付出的努力。（结尾多使用~なければならない；～べきだ） 与「Vるために」同义、也可以使用「Ｖるためには」形式。接续：动词原形 1. 会議で使う資料に間違いがあったが、今から作り直すには時間が足りない。(2013年7月真题)2. 日本語が上手になるには一生懸命勉強しなければなりません。 3. 東京駅に行くには、そこの角を右に曲がったほうがいいよ。(2002年真题) Vるようになる&lt;变化&gt;表示事物的变化。汉语：变得可以了···；逐渐会···· a. 能力的从无到有 表示获得了该能力，即由原来不具备该能力、变得开始具备该能力。否定形式「Vるようにならない」表示尚未获得该能力。 １.私は日本語が話せるようになった。２.日本へ来てから、日本料理が作れるようになった。 b. 现象的出现（从无到有）否定形式「Vるようにならない」表示该现象尚未出现。 １.小学校は入学したころから、だんだん風邪を引いたり熱を出したりしないようになった。(2011年真题)２.日本では、なかなか女性と男性が同じ条件で働けるようにならない。 c.动作行为的习惯化（习惯的从无到有） 否定形式「Vるようにならない」表示该习惯尚未养成 1.父は最近散歩をするようになった。2.父はなかなか散歩するようにならない。3.子供が生まれたことで、食べ物の安全を気にするようになった。(2010年真题) やる／Vてやる&lt;授受、受益&gt;用法与「あげる」大体相同，表示说话人自己或自己这一方的人将物品赠与他人，或者为别人做某事。★仅限于人对动植物、父母对子女、夫妻之间、兄弟姐妹之间或上对下的场合①Ｎ1はＮ2にＮ3をやる 1.花に水をやる。2.息子の誕生日に、ネクタイをやろうと思っている。 ②Ｎ1はＮ2にＶてやる 1.水泳は僕が教えてやるよ。(2000年真题)2.私は弟のシャツを洗ってやる。(2004年真题) Vるといい&lt;建议&gt;表示给对方所提的建议、劝别人进行那种行为之意。★对年长者，上级一般使用：Ｖたらいかがですか★建议不要做某事时使用： Vないほうがいい汉语：~比较好；最好是~ １.日本語の辞書はこれを使うといい。２.疲れたでしょう。少し休むといいですよ。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26单元]]></title>
    <url>%2F2019%2F03%2F26%2F26%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[～ような気（感じ）がする用于表示说话人的某种感觉。接续： 句子的简体形 名词＋の 翻译：觉得……；好像……；放佛…… 1.あの人とどこかで会ったような気がする。2.何となく不吉なことが起こるような気がする。 Ｎ次第だ＜决定性的事物＞表示事物发展的结果取决于该名词所表示的情况或状态。翻译：全凭……；全看……；视……而定 1.万事はきみの決心次第だ。2.宝くじに当たるかどうかは運次第だ。3.結婚した相手次第で人生が決まってしまうこともある。 使动句（使役句）a.他动词使动句主语は/が 使动对象に Ｎを Vせる(他动词) １.主动句：子供がご飯を食べる。 使动句：母 は子供にご飯を食べさせる。２.主动句：学生はテープを聞く。 使动句：先生は学生にテープを聞かせる。3.主动句：お皿を洗ったり、部屋を掃除したりする。 使动句：お皿を洗わせたり、部屋を掃除させたリする。 b.自动词使动句 ​ 主语A は/が 使动对象Bに/を Vせる(自动词) 主动句：子供がアメリカに行く 使役句：b-1両親 が 子供 に アメリカに行かせるb-2両親 が 子供 を アメリカに行かせる に：表示该动作是尊重使役对象B的意愿而进行的を：与使役对象B的意愿无关，强调是使役者A的意思 b.自动词使动句 ​ 主语Aは/が 使动对象Bに/を Vせる(自动词) ※如果原句中已经有「を」就只能用「に」为避免重复，这时，和是否是遵照使役对象B的意愿无关。 主动句：学生たち が 走りました。使役句：先生 が 学生たち に/を 走らせました。主动句：学生たち が 運動場 を 走りました。 使役句：先生 は 学生たち に 運動場を走らせました。 c.由使动态构成的请求句（敬语）,表示说话人以询问的口吻，请求对方应许我想做的事情。 请让我……、请允许我……Ｖさせてもらう/いただくＶさせてくれる/くださる 1 早く帰ってもいいですか。→早く帰らせてもらえませんか。2ちょっと休んでもいいですか。→ちょっと休ませてくださいませんか。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25单元]]></title>
    <url>%2F2019%2F03%2F19%2F25%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[V-Rながら&lt;同时&gt;表示前后两个动作同时进行或持续交替进行。其中后面的动作是主要动作。翻译：一边~一边~ 1. 弟はいつもテレビを見ながら、宿題をしています。2. 音楽を聴きながら、勉強や仕事をする人のことを「ながら族」と言う。3. 働きながら、学校に通う。 ながら1.表示前后两个动作同时进行或持续交替进行。一边~一边~V-Rながら 弟はいつもテレビを見ながら、宿題をしています。 2.表示原封不动、一如既往等意思。中译时需灵活处理。名词+ながら 皮ながら食べる。生まれながらの音楽家 3.表示前后事项相互矛盾。虽然~但是~名词+ 二类形容词词干+ 一类形容词基本形 V-Rながら 知っていながら、何も教えてくれない。 ~ようだ&lt;推测&gt; ：大概~吧、好像~接续：连体形表示说话人根据自己的印象或感觉对事物作出的推测。 1. 体がだるいんです。風邪を引いてしまったようです。2. 明日は雨のようです。3. あの声は、誰かが外で喧嘩しているようだ。 このお風呂、温そうだね。 そうだ：第一印象，直觉このお風呂、温いようだね。 ようだ：感觉，思维（有依据） 「らしい」「ようだ」「そうだ」「ようだ」 自己所见，所体验。表示说话人的判断意见。 天気図を見て、 あすは雨が降るようだ 「そうだ」 多表示自己所见。表示某种状况，眼看就要发生，看起来要发生。 急に暗くなった空を見て、 今にも雨が降りそうだ 「らしい」 听说、通过书、媒体等间接得到。确信度高（有依据） 天気予報を見た人から聞いて、明日は雨が降るらしいよ 雨が降るそうだ。 传闻 まるで夢のようだ 比喻 Vたばかりだ&lt;刚刚&gt; ：刚~不久表示动作完成或某事情发生后时间不太长。（主观判断） 1.その言葉は習ったばかりで、まだ上手に使えません。2.あの頃は、私は北京に来たばかりで、中国語もあまり分からなくて… たところだ・たばかりだ不同点：（1）たところだ一般不直接接在明确表示过去某时间的词语后面。先週、結婚したばかりだ（ところだ？）。 （2）たばかりだ可以表示动作行为结束后经过了较长一段时间的事态；与此相反，たところだ一般用于表示动作结束后经过的时间较短的事态。あの二人は去年結婚したばかりだ（ところだｘ）。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24单元]]></title>
    <url>%2F2019%2F03%2F13%2F24%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[被动态定义：以中心动词的行为者以外的非积极参与者为主语进行描写的句式叫做被动态。多伴有受到危害、损害、伤害之意，但在现代日语中，主体受益、中立（既非受害也非受益）、间接受到影响时也常用被动句式来表示。 1类动词：将词尾う段假名 =&gt; あ段假名 + れる 書く =&gt; 書かれる 2类动词：去掉词尾 る + られる 食べる =&gt; 食べられる 3类动词：来（く）る 来（こ）られる する =&gt; される 被动句日语被动句根据其意义和句子结构的特点可以分为三类：A 直接被动句 B 物主被动句 C 间接被动句 直接被动句（人物）N1は/が N2 (人)にＶ(ら)れる主语一般为表人的名词，谓语动词为他动词 受到~，被~ 1 母が子供を叱る。→子供が母に叱られる。２ 犬はおばあさんを噛んだ。（噛む：かむ０）→おばあさんは犬に噛まれた。 N1(物)は/が N2(人)にＶ(ら)れる 主语一般为事物性名词，动作的主体一般为非特定的个人（某一不确定的人的群体），有时会省略，多用于客观的描述某一现象。 １.この本は多くの人に読まれている。２.きのう、駅前のデパートでネックレスが盗まれた。３.日本語能力試験は７月３日に行われる。 N1(物・こと)は/がN2(人)によってＶ(ら)れる主语：事物名词谓语是表示发明、创造、创作或发现一类（作る、発明する、設計する、書く）的动词，动作主体用によって表示。 １.この建物は有名な建築家によって設計された。２.この製品はイギリス人のデザイナーによって作られた。 N1(人)は/が (N2(人)に/から)N3(こと・もの)をＶ(ら)れる原动作主体充当补语，有时省略；原动作客体不变。一般为表示语言行为或感情、态度的他动词。 １.友達が私に将来の仕事について相談した。→友達に将来の仕事について相談された。２.周りの人が反対した。→周りの人に反対されても、自分がどうしたいかということ が一番大事だと思う。 物主被动句N1(所有者)は/が N2に N3を Ｖ（ら）れる 某事物的拥有者在被动句里做主语，而该事物在被动句里仍然充当宾语。这种被动句通常明显地表现出受害的意识。 １. 弟は私のパソコンを壊しました。→私は弟にパソコンを壊されました。２. 私は電車の中で（男の人に）足を踏まれました。 间接被动句N1(人)は/が N2に (N3を)Ｖ(ら)れる间接被动句中做主语的一般是在原主动句不曾出现的名词，谓语动词多为自动词，表示某一事态的发生间接地给另一方（多为说话人）带来了不良的影响或损害。 a.自动词作谓语１. 3年前に母親が死んだ。 →彼は3年前に母親に死なれた。２. 遠足の日に、雨に降られて困った。b.他动词作谓语１. 一年生が先に運動場を占領した。 →私たちは一年生に運動場を占領された。２. レストランで、隣のテーブルの人にタバコを吸われて、気 分が悪くなった。 没有被动形式的动词1、表示能力的动词（できる、わかる等）及动词的可能态。2、状态动词。（ある、いる等）3、本身含有被动意义的动词.(見つける、捕まる、教わる等)4、含有自发意义的动词。（聞こえる、見える、等） Ｎをきっかけに(して)&lt;契机&gt;表示以某事为机会、线索、契机等，后项发生前所未有的重大转折。汉语 ：以…为契机、以…为开端★：其他形式：～がきっかけで ～がきっかけになって 1.姉は結婚をきっかけに、仕事をやめた。2.恵まれない子供たちの姿を見たのがきっかけで、この支援活動を始めたのです。(2008年真题) らしい&lt;传闻、推测&gt;表示间接的传闻或有客观依据的推测，说话人对所述内容的确信程度相当高。程度比「ようだ」更可靠。接续： A1、Ｖ连体形 A2+、N+汉语：似乎、好像 1.天気予報によると明日は雨らしい。2.二人は来年結婚するらしい。(2007年真题)3.彼は自分で会社を作るらしい。4.明日はいい天気らしい。(2002年真题) ところだ作为形式名词接在动词的肯定简体形式后，表示动作所处的阶段。 a. Vるところだ：正要…、刚要…表示该动作行为在说话时即将开始进行 １. 今、出かけるところだ。２. ご飯を食べに行くところだ。 b. Vているところだ：现在正在…表示该动作行为在说话时正在进行中 １. 彼女は今ギョーザを作っているところだ。２. 私はちょうどお風呂に入っているところだ。 c. Vたところだ：刚刚…、刚…完表示该动作行为在说话时刚刚结束。 １. 授業が終わったところだ。２. 私が病院に駆けつけたとき、彼女は息を吹き返したところでした。 d. Vていたところだ表示从过去某一时点到说话之前该状态一直在持续。 １. なかなか連絡がないから心配していたところだ。２. 休もうかどうしようかと考えていたところだ。 Ｖるところだ・ＶるところだったVるところだ：正要…、刚要…表示该动作行为在说话时即将开始进行 Ｖるところだった表示某情况险些发生，多用于庆幸、懊恼、遗憾等的情绪表现，相当于：差一点儿······；险些······ 車道を歩いたので、もう少しでひき殺されるところだった。 やすい/にくいa.V-R＋やすい表示该动作很容易做，该事情很容易发生。 １. その町は物価も安く、人も親切で住みやすいところです。２. 彼は太りやすい体質なので、食べ過ぎないようにしているそうだ。 b. V-R＋にくい表示该动作很困难，轻易做不到的意思。 １. これはちょっと言いにくい話なんですが。２. 砂利道はハイヒールでは歩きにくい。 ～ば～ほど：越…越…接续: Nなら/であれば，(名词で)ある＋ほど Na ならば/であれば， Naな/である＋ほど A-ければ， A-い＋ほど V-ば＋，V‐る＋ほど 表示随着前句所述的动作、行为或性质状态的发展变化，主句所述的性质状态就越典型或随之发生相应的变化。 1. 厳しい時代であればあるほど、自分を磨くのができるんだ。2. 子供は元気であれば元気なほどいいです。3. 給料は高ければ高いほどいいです。4. 会話は練習すれば(練習)するほど上手になります。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo系统重装恢复]]></title>
    <url>%2F2019%2F03%2F12%2Fhexo%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A3%85%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[安装node.js和npmsudo apt install nodejssudo apt install npm 新版本安装(hexo不支持)curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - &amp;&amp;\sudo apt-get install -y nodejs nvm指定版本安装proxychains4 wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | proxychains4 bashsource ~/.zshrcexport NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node/export NVM_IOJS_ORG_MIRROR=http://npm.taobao.org/mirrors/iojsnvm install 12.16.2nvm use 12.16.2 换源sudo npm install -g nrmnrm lsnrm use taobao 安装Hexo`sudo npm install -g hexo-cli` 安装gitsudo apt install git 配置github-gitgit config --global user.name &quot;your github name&quot;git config --global user.email &quot;example@email.com&quot; 填写github账户名和注册邮箱 创建公钥ssh-keygen -t rsa -C &quot;example@email.com&quot; 将在~/.ssh/文件夹下生成github_name 和 github_name.pub两个文件， gedit github_name.pub 打开github登录，点击头像setting -&gt; SSH and GPG keys，将.pub 文件内容复制到 SSH keys中 测试是否设置成功ssh git@github.com 验证npm install hexo-deployer-git --savehexo clean &amp;&amp; hexo g &amp;&amp; hexo d 测试是否成功]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23单元]]></title>
    <url>%2F2019%2F02%2F27%2F23%E5%8D%95%E5%85%83%2F</url>
    <content type="text"><![CDATA[自动词、他动词自动词：表示状态，能力，现象的动词集合，不涉及人为的影响。 他动词：表示具有意志性的、指向某对象物体的行为动词集合。 1）以す结尾的动词，都是五段他动词，与它对应的动词是自动词； 鳴らすー鳴る 倒すー倒れる2）大多数下一段动词（不含れる）是他动词，与它对应的五段动词是自动词；如： 始めるー始まる かけるーかかる つけるーつく 3）可能动词及表示能力的动词，都是自动词； 如：書ける、見える、聞こえる できる 4）大多「れる」结尾的下一段动词是自动词，与它相对的是他动词，「れる」结尾的下一段动词，其对应的动词70%以上是以「す」结尾的他动词 崩れる—崩す 離れるー離す 、倒れる—倒す只有自动词没有他动词的动词 居る、ある、咲く、行く、来る、寝る、眠る、泣く只有他动词没有自动词的动词買う、売る、書く 打つ、殺す、聞く､話す、読む、見る、思う、考える Vておく&lt;动作结果的存续&gt; 口语形式：～とく 表示采取某种行为， A、为后面要做的事情，事先做好某种准备。Ｂ、将其结果状态保持下去。Ｃ、有时表示一种临时的措施。汉语：预先~；先~ 1.後で捨てるから、ゴミを集めておいてください。(2006年真题)2.先生が来るからテーブルの上にお皿を並べておく(2004年真题)3.教室のドア、開けておきましょう。 V（他动词）てある&lt;客体存续的状态&gt;表示主体有意图的动作行为完成之后的结果存在的状态。★因为是表示存续的状态，句中主语为动作的客体，动词多使用自主的他动词，他动词的“を格” 要换成“が格”形式。 1.教室に試験の時間割が貼ってある。(2010年真题)2.起きてみると、朝ご飯がもう作ってあった。3.部屋に花が飾ってある。 窓が開けてある（窗户打开着） 动作者不出现在句子中，但是能让人感受到动作者的存在 窓が開いている（窗户开着） 使人感受不到动作者的存在。 a 会議の資料はコピーしておいた。b 会議の資料はコピーしてあった。 1二者着重点不同。「ておく」叙述者多为动作执行者，着重于动作本身；「てある」着重动作完成后的结果状态。 2「ておく」和前面的动词结合，表示某项行为，而不是某种结果， 所以可以表示意志「～ておこう」，命令「～ておきなさい」， 「てある」则没有这样的用法。 電気を消さないで、朝までつけておこう。 3「ておく」作为一种“事先准备”， 用“非过去时”，表示动作将要着手；用“过去时”，表示准备动作已经完成，其动作的结果保存了下来。； 「てある」则表示动作完成后达到的结果，即其动作对象所处的一种状态。因此其“现在时”和“过去时”的差别并不太大。 「てある」表示这种准备已经做好的状态 「ておく」表示作为准备采取了某种行为 Ｖてよかった&lt;积极评价&gt;说明：表示对已经发生的事情的积极评价，含有两种意思:一是“独自庆幸”，二是“感激+庆幸”。都是说现在的心情。汉语：幸好…、…真好 １.とてもいい映画で、見てよかったと思う。２.王さんがいてくれてよかった。 Vばよかった&lt;后悔、遗憾&gt;表示对实际未能发生的事情或期待落空时的遗憾心情，既可以是说话人自身的后悔，也可以是对对方的遗憾或责难。汉语：如果~~就好了★：常和「のに」搭配使用。 1.私も行けばよかったと後悔している。2.旅行は楽しかったよ。高橋さんも来ればよかったのに。3.あなたに会わなければよかったのに。 Ｎをはじめ&lt;代表性事物&gt;提出具有代表性或典型的人或物，表明该人或物是同类事物中最为重要，具有代表性。汉语：以~为首★：常用形式：Ｎをはじめとして Ｎをはじめとする 1.日本滞在中は北川先生をはじめ多くの方々にお世話になり、 本当にありがとうございました。(2013年真题)2.私たちの町にはこのお寺をはじめ、いろいろな古い建物がある。(2005年真题) V-ることになる&lt;事态发展的结果&gt;表客观存在的规定（由于某种外在的原因导致形成了某种决定）或事态自然发展、变化所产生的结果。 接续：V-る/Ｖ－ない 决定~~ 1.明日は停電なので、会社は休むことになった。2.来年帰国することになると思う。3.わたしたち、結婚することになりました。 V-ることにする&lt;决定&gt;表示动作主体决定或下决心做（或不做）某事。 接续：V-る/Ｖ－ない 1.王さんはダイエットすることにした。2.私は今日からタバコをやめることにした。 Ｎをもとに(して)&lt;题材，话题&gt;表示以某一事物为题材或话题进行言语行为或创作活动。 汉语：以…为基础、根据 1.昨日見たドラマは、実際にあった話をもとに作られたそうだ。(2008年真题)2.漢字をもとにして仮名が作り出された。3.日本語のクラスは、テストの点数と今までの学習期間をもとに決定される。(2003年真题)]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数基础和函数参数]]></title>
    <url>%2F2019%2F01%2F29%2F%E5%87%BD%E6%95%B0%E5%9F%BA%E7%A1%80%E5%92%8C%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数基础和函数参数函数是组织好的，可重复使用的，用来实现单一，或相关联功能的代码段。 函数能提高应用的模块性，和代码的重复利用率。你已经知道Python提供了许多内建函数，比如print()。但你也可以自己创建函数，这被叫做用户自定义函数。 函数基础定义一个函数 你可以定义一个由自己想要功能的函数，以下是简单的规则： 函数代码块以 def 关键词开头，后接函数标识符名称和圆括号 ()。 任何传入参数和自变量必须放在圆括号中间，圆括号之间可以用于定义参数。 函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。 函数内容以冒号起始，并且缩进。 return [表达式] 结束函数，选择性地返回一个值给调用方。不带表达式的return相当于返回 None。 演示： 我们打印几个列表 li = [1, 0, 5, 7, 9]for i in li: print(i)print('---------')li = [1, 'A', 5, 7, 9]for i in li: print(i)print('---------')li = [1, 3, 's', 7, 9]for i in li: print(i) 输出结果： 10579---------1A579---------13s79 有没有更简单的呢？ 演示： l1 = [1, 0, 5, 7, 9]l2 = [1, &apos;A&apos;, 5, 7, 9]l3 = [1, 0, &apos;S&apos;, 7, 9]def demo(li): for i in li: print(i)demo(l1)print(&apos;---------&apos;)demo(l2)print(&apos;---------&apos;)demo(l3) 输出结果 10579---------1A579---------10S79 上述就是使用函数的形式来实现多个列表的打印，是不是比前面的更简单。 函数的定义 def 函数名(参数)： pass return 表达式 函数名命名规则： 字母、数字和下划线组成，和变量命名规则一致 return 后面可以返回任意表达式，但不能是赋值语句 注意：函数名定义和变量名的定义是一样的，只能使用字母、数字和下划线定义，不能以数字开头。 关键字 关键字是不能拿来做变量定义的。 演示： In [3]: a---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-3-3f786850e387&gt; in &lt;module&gt;()----&gt; 1 aNameError: name 'a' is not definedIn [4]: def File "&lt;ipython-input-4-7b18d017f89f&gt;", line 1 def ^SyntaxError: invalid syntax 如果把关键字拿来定义，是会报语法错误的。 In [1]: import keywordIn [2]: print(keyword.kwlist)[&apos;False&apos;, &apos;None&apos;, &apos;True&apos;, &apos;and&apos;, &apos;as&apos;, &apos;assert&apos;, &apos;break&apos;, &apos;class&apos;, &apos;continue&apos;, &apos;def&apos;, &apos;del&apos;, &apos;elif&apos;, &apos;else&apos;, &apos;except&apos;, &apos;finally&apos;, &apos;for&apos;, &apos;from&apos;, &apos;global&apos;, &apos;if&apos;, &apos;import&apos;, &apos;in&apos;, &apos;is&apos;, &apos;lambda&apos;, &apos;nonlocal&apos;, &apos;not&apos;, &apos;or&apos;, &apos;pass&apos;, &apos;raise&apos;, &apos;return&apos;, &apos;try&apos;, &apos;while&apos;, &apos;with&apos;, &apos;yield&apos;] 上述就是整个Python编程语言的全部关键字，在基础阶段都会提到的。 函数调用l1 = [1, 0, &apos;S&apos;, 7, 9]def demo(li): for i in li: print(i)demo(l1) 调用方式：函数名（参数） 函数返回l1 = [1, 0, &apos;S&apos;, 7, 9]def demo(li): for i in li: print(i) return &apos;ok&apos;print(demo(l1)) 输出： 10S79ok return： 注意 return 和 print 的区别，return是函数的返回值，返回值可以赋值给变量，而print只是打印出来 函数参数 那函数里面可以传入哪些对象呢？ def demo(x): print(x)demo(&apos;demo&apos;) 输出 demo 如果我们不传值呢？ def demo(x): print(x)demo() 输出 TypeError: demo() missing 1 required positional argument: &apos;x&apos; TypeError：demo()缺少一个必需的位置参数：’x’。 传入几个参数呢？ 必备参数 def func(x): pass def demo(x): print(x)demo(1, 2) 输出 TypeError: demo() takes 1 positional argument but 2 were given 一个参数对应一个数值 默认参数 def func(x, y=None): pass def demo(x, y=1): print(x, y)demo(1, 2)demo(3) 输出 1 23 1 y=1.就是默认参数，没有传入新参数的时候，就使用默认参数。 关键字参数def demo(x, y=1): print(x, y)demo(1, 2)demo(y="q", x='s') 输出 1 2s q 关键字参数，调用的时候带上参数名。 不定长参数 def func(args, *kwargs): pass 注意：*+参数名 def demo(*args): print(args)demo(1, 2, 3, 4)demo(1) 输出 (1, 2, 3, 4)(1,) 参数名前面加*号是不定长参数，输出是一个元组。 def demo(*a): print(*a) # 加*：去除括号 print(a)demo(1, 2, 3, 4)print('-------')demo((1, 2, 3, 4))print('-------')demo(*(1, 2, 3, 4)) 输出 1 2 3 4(1, 2, 3, 4)-------(1, 2, 3, 4)((1, 2, 3, 4),)-------1 2 3 4(1, 2, 3, 4) 加*：去除括号 def demo(**a): print(a)demo(x=1, y=2, s=2) 输出 &#123;&apos;x&apos;: 1, &apos;y&apos;: 2, &apos;s&apos;: 2&#125; 参数名前面加**号是不定长参数，输出是一个字典。 注意：传入的参数是键值对。 演示：def demo(*args, **kwargs): print(args) print(kwargs)demo(1, 2, 3, x=1, y=2, s=2) 输出 (1, 2, 3)&#123;&apos;x&apos;: 1, &apos;y&apos;: 2, &apos;s&apos;: 2&#125; 传入的键值对，只能放在最后。 总结： 必备参数：在函数调用的时候，必备参数必须要传入 默认参数： 在函数调用的时候，默认参数可以不传入值，不传入值时，会使用默认参数 不定长参数：在函数调用的时候，不定长参数可以不传入，也可以传入任意长度。其中定义时，元组形式可以放到参数最前面，字典形式只能放到最后面 常见的内置函数常见内置函数提供了一些处理的数据的方法，可以帮助我们提高开发速度 常见函数len 求长度 li = [2,8,5]In [6]: len(li)Out[6]: 3 min 求最小值 li = [2,8,5]In [6]: min(li)Out[6]: 2 max 求最大值 li = [2,8,5]In [8]: max(li)Out[8]: 8 sorted 排序 li = [2,8,5]In [9]: sorted(li)Out[9]: [2, 5, 8] reversed 反向 li = [2,8,5]In [10]: reversed(li)Out[10]: &lt;list_reverseiterator at 0x7f68aa81af98&gt;In [11]: list(reversed(li))Out[11]: [5, 8, 2] sum 求和 li = [2,8,5]In [12]: sum(li)Out[12]: 15 进制转换函数bin 二进制 In [13]: bin(12)Out[13]: &apos;0b1100&apos; oct 八进制 In [16]: oct(18)Out[16]: &apos;0o22 hex 十六进制 In [17]: hex(12)Out[17]: &apos;0xc&apos; ord 字符转ASCII码 In [19]: ord(&apos;a&apos;)Out[19]: 97 chr ASCII码转字符 In [20]: chr(97)Out[20]: &apos;a&apos; 扩展enumerate 返回一个可以枚举的对象 In [21]: li = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;]In [22]: enumerate(li)Out[22]: &lt;enumerate at 0x7f68aa877d80&gt;In [23]: list(enumerate(li))Out[23]: [(0, &apos;a&apos;), (1, &apos;b&apos;), (2, &apos;c&apos;), (3, &apos;d&apos;)]In [24]: dict(enumerate(li))Out[24]: &#123;0: &apos;a&apos;, 1: &apos;b&apos;, 2: &apos;c&apos;, 3: &apos;d&apos;&#125; eval 取出字符串中内容 将字符串str当成有效的表达式来求值并返回计算结果 In [25]: a = &quot;&#123;&apos;a&apos;:1&#125;&quot;In [26]: eval(a)Out[26]: &#123;&apos;a&apos;: 1&#125;In [27]: b = &apos;1 + 2 + 3&apos;In [28]: eval(b)Out[28]: 6 exec 执行字符串或complie方法编译过的字符串，没有返回值 In [29]: s = ''' ...: z = 10 ...: su = x + y + z ...: print(su) ...: print('OK') ...: '''In [30]: x = 1In [31]: y = 2In [32]: exec(s)13OKIn [33]: exec(s,&#123;'x':0,'y':0&#125;)10OKIn [34]: exec(s,&#123;'x':0,'y':0&#125;,&#123;'y':10,'z':0&#125;) #以字符串为主,以最后的为主20OK 注意：eval 和 exec 是炸弹 能不能就不用，就好像你从不知道这东西一样，除非你足够的熟悉 filter 过滤器 In [38]: def test1(x): ...: return x&gt;10 ...: l1 = [10,2,20,13,5]In [39]: filter(test1, l1)Out[39]: &lt;filter at 0x7f68aa7ecb70&gt;In [40]: list(filter(test1, l1))Out[40]: [20, 13] map 对于参数iterable中的每个元素都应用fuction函数，并将结果作为列表返回 In [41]: l2 = [1,2,3]In [42]: map(str,l2)Out[42]: &lt;map at 0x7f68aa7ecba8&gt;In [43]: list(map(str,l2))Out[43]: [&apos;1&apos;, &apos;2&apos;, &apos;3&apos;] zip 将对象逐一配对 In [44]: l3 = [1,2,3]In [45]: t1 = (&apos;a&apos;,&apos;b&apos;,&apos;c&apos;)In [46]: zip(t1,l3)Out[46]: &lt;zip at 0x7f68abb3ec48&gt;In [47]: list(zip(t1,l3))Out[47]: [(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)]In [48]: dict(zip(t1,l3))Out[48]: &#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3&#125;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类定义、属性和继承]]></title>
    <url>%2F2019%2F01%2F29%2F%E7%B1%BB%E5%AE%9A%E4%B9%89%E3%80%81%E5%B1%9E%E6%80%A7%E5%92%8C%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[类定义、属性和继承类定义之前我们在数据类型里面学习到了列表的方法，那是怎么做的可以让列表里面放下这么多方法呢？ class Abc: def fun1(self): print('this is fun1') def fun2(self): print('this is fun2')a=Abc()print(a)print(a.fun1())print(a.fun2()) 输出 &lt;__main__.Abc object at 0x0000024ED872A908&gt;this is fun1Nonethis is fun2None cla = ClassName() cla.fun1() cla.fun2() 实例化之后，可以实现类似于列表中方法的定义形式 总结 定义：类的定义使用关键字 class 封装：类可以把各种对象组织在一起，通过.(点)运算符来调用类中封装好的对象。 概念：类就像是我们平时说的名词，一个称呼，但是却不是一个具体的实例，比如说：我们都是人，但是人这个名词，不能具体指代你我，我们会用一个人的名字去指代一个具体的人，这个过程就类似于实例化。 属性1.类数据属性。类属性是可以直接通过“类名.属性名”来访问和修改。类属性是这个类的所有实例对象所共有的属性，任意一个实例对象都可以访问并修改这个属性（私有隐藏除外）。 2.实例数据属性。在属性前面加了self标识的属性为实例的属性，在定义的时候用的self加属性名字的形式，在查看实例的属性时就是通过实例的名称+‘.’+属性名来访问实例属性。 3.方法属性。定义属性方法的内容是函数，函数的第一个参数是self，代表实例本身。 举个栗子class Animal: eye = 2 # 类属性 def __init__(self, name, food): self.name = name # 实例属性 self.food = food def play(self): print('hahaha') 实例化cat = Animal(&apos;cat&apos;,&apos;fish&apos;) #先不传值cat.play() 输出 hahaha 类的实例化，实例化后会自动执行init这个初始化函数。 实例属性访问print(cat.name)print(cat.food) 输出 hahahacatfish 实例的属性，实例自己可以访问，定义时要加self，不可以 ClassName. attribute（类名.属性） 类属性print(Animal.eye)print(cat.eye) 输出 22 直接定义在类中，类和实例都可以访问，没有加self 可以 ClassName. attribute（类名.属性） 扩展print(Animal.name) 输出 AttributeError: type object &apos;Animal&apos; has no attribute &apos;name&apos; 类只能访问类属性，不能访问实例属性。 总结 类属性：类的属性，类名和实例都可以调用，相当于类和实例公用的变量 实例属性：实例自己的属性，类不能访问，其他的实例也不能访问 属性调用： 通过属性调用可以直接得到属性的属性值 方法类中的方法，就是函数，但是被称之为方法，在类中的方法，在被实例调用的时候会自动传入实例本身，因此，在一般情况下，需要在参数中加入self。 class Animal: eye = 2 # 类属性 def __init__(self, name, food): self.name = name # 实例属性 self.food = food def play(self): print('hahaha') 方法调用cat = Animal(&apos;cat&apos;,&apos;fish&apos;) cat.play() 输出 hahaha 类中的self指代的就是实例本身 扩展cat = Animal(&apos;cat&apos;,&apos;fish&apos;) Animal.play(cat) 输出 hahaha 继承如果在B类中定义一个方法，但是这个方法已经在A类中被定义过了，那怎样在B类中使用A类中的方法呢？ class Animal: eye = 2 def __init__(self, name, food): self.name = name self.food = food def play(self): print('hahaha')class Dog(Animal): def wangwang(self): print('汪汪汪！！%s' %self.name)demo = Dog('旺财', '骨头')print(demo.name)print(demo.food)print(demo.wangwang()) 输出 旺财骨头汪汪汪！！旺财 语法规则 class A: def play(slef): print(‘hahaha ‘) class B(A): pass 总结 类的继承可以让子类将父类的全部方法和属性继承过来. 在python3中，默认继承object类]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多继承和魔方方法]]></title>
    <url>%2F2019%2F01%2F29%2F%E5%A4%9A%E7%BB%A7%E6%89%BF%E5%92%8C%E9%AD%94%E6%96%B9%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[多继承和魔法方法多继承一个类可以继承一个类，继承之后可以把父类所有的方法和属性都直接继承过来，那一个类可以继承多个类吗？ 如果可以继承多个类的话，那如果两个父类中有一样的方法的情况下，子类继承哪一个呢？ 演示 class Base: def play(self): return 'this is Base'class A(Base): def play(self): return 'this is A'class B(Base): def play(self): return 'this is B' class C(A,B): passc = C()print(c.play()) 输出 this is A 首先类是可以多继承的 优先使用第一个类里面的方法。 总结 通过C类实例的方法调用来看 当继承多个父类时，如果父类中有相同的方法，那么子类会优先使用最先被继承的方法. 重构在上面的例子中，如果不想继承父类的方法怎么办呢？ class Base: def play(self): return 'this is Base'class A(Base): def play(self): return 'this is A'class B(Base): def play(self): return 'this is B'class C(A, B): def play(self): return 'this is C'c = C()print(c.play()) 输出 this is C 当子类继承父类之后，如果子类不想使用父类的方法，可以通过重写来覆盖父类的方法. 扩展重写父类方法之后，如果又需要使用父类的方法呢？ 方法一class Base: def play(self): print('this is Base')class A(Base): def play(self): print('this is A')class B(Base): def play(self): print('this is B')class C(A, B): def play(self): A.play(self) print('这是C')demo = C()demo.play() 输出 this is A这是C 方法二class Base: def play(self): print('this is Base')class A(Base): def play(self): print('this is A')class B(Base): def play(self): print('this is B')class C(A, B): def play(self): super().play() print('这是C')demo = C()demo.play() 输出 this is A这是C super super函数可以调用父类的方法 class Base: def play(self): print('this is Base')class A(Base): def play(self): super().play() print('this is A')class B(Base): def play(self): super().play() print('this is B')class C(A, B): def play(self): super().play() print('这是C')demo = C()demo.play() 输出 this is Basethis is Bthis is A这是C 那为什么是这个顺序输出呢？ print(C.mro()) 输出 [&lt;class &apos;__main__.C&apos;&gt;, &lt;class &apos;__main__.A&apos;&gt;, &lt;class &apos;__main__.B&apos;&gt;, &lt;class &apos;__main__.Base&apos;&gt;, &lt;class &apos;object&apos;&gt;] 继承顺序： 在python3中，类被创建时会自动创建方法解析顺序mro object是所有类的父类 Mixin开发模式 Mixin是一种开发模式，一般规范上，Mixin类是继承的终点，即不再被继承 Mixin的优点就是不需要过多考虑继承关系，不会出现各父类之间有相同方法的情况 总结 mro: 类在生成时会自动生成方法解析顺序，可以通过 类名.mro()来查看 super: super函数可以来调用父类的方法，使用super的好处在于即使父类改变了，那么也不需要更改类中的代码 Mixin: Mixin是一种开发模式，给大家在今后的开发中提供一种思路. 魔法方法在字符串拼接的时候，字符串可以直接相加，那我们自定义的类可以实现吗？ class Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width def area(self): area = self.width * self.length return area def __add__(self, other): add_length = self.length + other.length add_width = self.width + other.width return add_length,add_widtha = Rectangle(3,4)b = Rectangle(5,6)print(a+b) 输出 (8, 10) 运算方法 add和radd原理class A: passclass B: def __add__(self, other): print(&apos;__add__&apos;) def __radd__(self, other): print(&apos;__radd__&apos;)a = A()b = B()a+b 输出 __radd__ 优先在两类里找add方法，没有就自动调用radd方法。 演示 class A: def __init__(self,name,age): self.name = name self.age = ageclass B: def __init__(self,age): self.age = age def __add__(self, other): print('__add__') def __radd__(self, other): return other.age + self.agea = A('age',123)b = B(123)print(a+b) 输出 246 str和repr原理class Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width def area(self): area = self.width * self.length return area def __add__(self, other): add_length = self.length + other.length add_width = self.width + other.width return add_length, add_width def __radd__(self, other): return "Rectangle radd" def __str__(self): return 'length is %s, width is %s ' % (self.length, self.width) def __repr__(self): return 'area is %s' % self.area()a = Rectangle(3,4)b = Rectangle(5,6)print(a+b)print(a.__add__(b))print(a) 输出： # 有str(8, 10)(8, 10)length is 3, width is 4 # 无str(8, 10)(8, 10)area is 12 优先在两类里找str方法，没有就自动调用repr方法。 在python中，str和repr方法在处理对象的时候，分别调用的是对象的str和repr方法 print也是如此，调用str函数来处理输出的对象，如果对象没有定义str方法，则调用repr处理 call方法class Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width def area(self): area = self.width * self.length return area def __add__(self, other): add_length = self.length + other.length add_width = self.width + other.width return add_length, add_width def __radd__(self, other): return "Rectangle radd" def __str__(self): return 'length is %s, width is %s ' % (self.length, self.width) def __repr__(self): return 'area is %s' % self.area() def __call__(self): return 'Rectangle called'a = Rectangle(3,4)b = Rectangle(5,6)print(a()) 输出 Rectangle called 正常情况下，实例是不能像函数一样被调用的，要想实例能够被调用，就需要定义 call 方法 其他魔法方法演示： class Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width def area(self): area = self.width * self.length return area def __add__(self, other): add_length = self.length + other.length add_width = self.width + other.width return add_length, add_width def __radd__(self, other): return "Rectangle radd" def __str__(self): return 'length is %s, width is %s ' % (self.length, self.width) def __repr__(self): return 'area is %s' % self.area() def __call__(self): return 'Rectangle called'a = Rectangle(3,4)print(a.__class__)print(a.__class__.__base__)print(a.__class__.__bases__)print(a.__dict__) # 所有属性，键值对返回print(a.__doc__)print(a.__dir__()) 输出 &lt;class &apos;__main__.Rectangle&apos;&gt;&lt;class &apos;object&apos;&gt;(&lt;class &apos;object&apos;&gt;,)&#123;&apos;length&apos;: 3, &apos;width&apos;: 4&#125;None[&apos;length&apos;, &apos;width&apos;, &apos;__module__&apos;, &apos;__init__&apos;, &apos;area&apos;, &apos;__add__&apos;, &apos;__radd__&apos;, &apos;__str__&apos;, &apos;__repr__&apos;, &apos;__call__&apos;, &apos;__dict__&apos;, &apos;__weakref__&apos;, &apos;__doc__&apos;, &apos;__hash__&apos;, &apos;__getattribute__&apos;, &apos;__setattr__&apos;, &apos;__delattr__&apos;, &apos;__lt__&apos;, &apos;__le__&apos;, &apos;__eq__&apos;, &apos;__ne__&apos;, &apos;__gt__&apos;, &apos;__ge__&apos;, &apos;__new__&apos;, &apos;__reduce_ex__&apos;, &apos;__reduce__&apos;, &apos;__subclasshook__&apos;, &apos;__init_subclass__&apos;, &apos;__format__&apos;, &apos;__sizeof__&apos;, &apos;__dir__&apos;, &apos;__class__&apos;] 魔法方法应用场景 str和repr: str和repr都是分别调用这两个魔术方法来实现的 原理：在类中，很多事情其实调用的魔术方法来实现的 作用：通过合理的利用魔术方法，可以让我们更加方便的展示我们的数据]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>多继承</tag>
        <tag>魔方方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[描述器和装饰器]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%8F%8F%E8%BF%B0%E5%99%A8%E5%92%8C%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[单例模式类每次实例化的时候都会创建一个新的对象，如果要求类只能被实例化一次该怎么做呢？ class Earth: def __init__(self): self.name = 'earth'e = Earth()print(e, id(e))a = Earth()print(a, id(a)) 类可以多个实例化 &lt;__main__.Earth object at 0x000001D54B28A978&gt; 2015600617848&lt;__main__.Earth object at 0x000001D54B293EF0&gt; 2015600656112 我们可以看出，多个实例化，每个实例化的地址都不相同。 class Earth: def __new__(cls, *args, **kwargs): if not hasattr(cls, 'instance'): cls.instance = super().__new__(cls) return cls.instance def __init__(self): self.name = 'earth'e = Earth()print(e, id(e))a = Earth()print(a, id(a)) 类的实例化的时候，会在init前调用new方法。 &lt;__main__.Earth object at 0x0000024EF2DBA940&gt; 2538105186624&lt;__main__.Earth object at 0x0000024EF2DBA940&gt; 2538105186624 可以看出两次创建对象，结果返回的是同一个对象实例 变量共享class Earth: def __new__(cls, *args, **kwargs): if not hasattr(cls, 'instance'): cls.instance = super().__new__(cls) return cls.instance def __init__(self, name): self.name = namee = Earth('china')print(e, id(e))a = Earth('others')print(a, id(a))print(e.name)print(a.name) 输出 &lt;__main__.Earth object at 0x000002077AA33E80&gt; 2231145545344&lt;__main__.Earth object at 0x000002077AA33E80&gt; 2231145545344othersothers 应用 Python的logger就是一个单例模式，用以日志记录 Windows的资源管理器是一个单例模式 线程池，数据库连接池等资源池一般也用单例模式 网站计数器 使用情况 当每个实例都会占用资源，而且实例初始化会影响性能，这个时候就可以考虑使用单例模式，它给我们带来的好处是只有一个实例占用资源，并且只需初始化一次； 当有同步需要的时候，可以通过一个实例来进行同步控制，比如对某个共享文件（如日志文件）的控制，对计数器的同步控制等，这种情况下由于只有一个实例，所以不用担心同步问题。 总结 初始化函数之前：new方法会在初始化函数init方法之前执行。 单例模式：利用这个new方法可以很方便的实现类的单例模式。 合理利用：new 方法合理利用可以带来方便，常应用在类的单例模式。 定制属性访问 如何判断一个实例里面有某个属性呢？ 怎样删除实例属性呢？ 同样的怎样删除变量呢？ class Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width def area(self): area = self.width * self.length return areab = Rectangle(3,4) 接下来我们来对类的属性进行定制化 增加属性setattrsetattr(b, 's', 12)b.sOut[4]: 12setattr(b, 'h', 6)b.hOut[6]: 6 往类的属性里面添加方法并赋值。 b.__setattr__('s', 5)b.__setattr__('h', 15)b.sOut[12]: 5b.hOut[13]: 15 等价于类的对应魔术方法 删除属性delattrdelattr(b, &apos;s&apos;)delattr(b, &apos;h&apos;) 删除属性 b.__delattr__(&apos;s&apos;)b.__delattr__(&apos;h&apos;) 等价于类的对应魔术方法 修改属性setattrb.sOut[5]: 5b.hOut[6]: 15setattr(b, 's', 20)setattr(b, 'h', 20)b.sOut[9]: 20b.hOut[10]: 20 同样是使用setattr来修改属性 b.__setattr__('s', 20)b.__setattr__('h', 20)b.sOut[12]: 20b.hOut[13]: 20 等价于类的对应魔术方法 查找属性hasattrhasattr(b, &apos;s&apos;)Out[11]: Truehasattr(b, &apos;h&apos;)Out[12]: Truehasattr(b, &apos;x&apos;)Out[13]: False 有对应属性就返回True，否则就返回Flase getattrgetattr(b, &apos;s&apos;)Out[14]: 20getattr(b, &apos;h&apos;)Out[15]: 20getattr(b, &apos;x&apos;)Traceback (most recent call last): File &quot;C:\Program Files\Python36\lib\site-packages\IPython\core\interactiveshell.py&quot;, line 3265, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File &quot;&lt;ipython-input-16-ae1b4378a11a&gt;&quot;, line 1, in &lt;module&gt; getattr(b, &apos;x&apos;)AttributeError: &apos;Rectangle&apos; object has no attribute &apos;x&apos; 有就返回属性值，没有就报错。 b.__getattribute__('s')Out[17]: 20b.__getattribute__('x')Traceback (most recent call last): File "C:\Program Files\Python36\lib\site-packages\IPython\core\interactiveshell.py", line 3265, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File "&lt;ipython-input-18-f65163239ef2&gt;", line 1, in &lt;module&gt; b.__getattribute__('x')AttributeError: 'Rectangle' object has no attribute 'x' 扩展我们在查询属性的时候，使用getattr，如果没有属性值，又不想报错怎么办呢？ class Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width def area(self): area = self.width * self.length return area def __getattribute__(self, item): print(&quot;没有这个属性！&quot;)b = Rectangle(3,4) getattr(b, &apos;s&apos;)没有这个属性！ 当属性不存在时，如果定义了此方法，则调用方法等价于类的对应魔术方法 总结 hasattr: 判断是否存在属性，如果属性存在则进行下一步操作。 getattr: 得到属性值。 setattr：设置属性。 描述符如果在一个类中实例化另一个类，对这个属性进行访问的时候怎么做的？ class MyAtrribute: passclass MyClass: m = MyAtrribute()c = MyClass() c.m &lt;__main__.MyAtrribute object at 0x000001F4922CF2E8&gt; 返回的是对象 class MyAtrribute: def __get__(self, instance, owner): print('get') print(instance) print(owner)class MyClass: m = MyAtrribute()c = MyClass()print(c.m) get&lt;__main__.MyClass object at 0x00000258C5703E80&gt;&lt;class &apos;__main__.MyClass&apos;&gt;None 直接访问时，调用get方法 class MyAtrribute: def __get__(self, instance, owner): print('get') print(instance) print(owner) def __set__(self, instance, value): print(instance) print(value) print('set') def __delete__(self, instance): print(instance) print('delete')class MyClass: m = MyAtrribute() def __del__(self): print('__del__')c = MyClass()# 调用 __set__c.m = 1# 调用 __deletel__del c.mdelattr(c, 'm') &lt;__main__.MyClass object at 0x000002312DAEBF28&gt;1set&lt;__main__.MyClass object at 0x000002312DAEBF28&gt;delete&lt;__main__.MyClass object at 0x000002312DAEBF28&gt;delete__del__ 根据访问时带使用不同的方式，调用不用的属性。 总结 描述符大家了解即可 魔术方法的作用其实是让开发人员能够更加灵活的控制类的表现形式 装饰器之前我们讲了闭包，闭包中可以传入一个函数吗？ def fx(x): x += 1 def fy(y): return x + y return fya = fx(1)print(a(12)) 12 这是我们前面所见过的闭包 def f1(func): def f2(y): print('f2 running') return func(y) + 1 return f2def f3(m): print('f3 running') return m * ma = f1(f3)print(a)print(a(3)) &lt;function f1.&lt;locals&gt;.f2 at 0x0000026D2F4BA488&gt;f2 runningf3 running10 闭包传入函数 语法糖def f1(func): def f2(y): print('f2 running') return func(y) + 1 return f2@f1 # 语法糖def f3(m): print('f3 running') return m * mprint(f3(3)) # f3 = f1(f3)(3) f2 runningf3 running10 在Python中直接用语法糖，f3(3) = f1(f3)(3) 内置装饰器@propertyclass Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width @property def area(self): area = self.width * self.length return area def area1(self): area = self.width * self.length return area def __getattr__(self, item): print('no attribute')b = Rectangle(3,4)print(b.area1())print(b.area) 1212 访问函数时，就像访问属性一样 @staticmethodclass Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width @property def area(self): area = self.width * self.length return area @staticmethod def func(): print('func') def __getattr__(self, item): print('no attribute')b = Rectangle(3,4)Rectangle.func()b.func() funcfunc 静态方法 @classmethodclass Rectangle: # 传入长和宽 def __init__(self, length, width): self.length = length self.width = width @property def area(self): area = self.width * self.length return area @staticmethod def func(): print('func') @classmethod def show(cls): print(cls) print('show') def fun2(self): print(self) print('fun2') def __getattr__(self, item): print('no attribute')b = Rectangle(3,4)b.show()b.fun2()Rectangle.show()Rectangle.fun2(b) &lt;class &apos;__main__.Rectangle&apos;&gt;show&lt;__main__.Rectangle object at 0x000001897E3519B0&gt;fun2&lt;class &apos;__main__.Rectangle&apos;&gt;show&lt;__main__.Rectangle object at 0x000001897E3519B0&gt;fun2 类方法：cls代表类本身，如果加上self，在调用时就要把实例传入。 类装饰器class Test_Class: def __init__(self, func): self.func = func def __call__(self): print('类') print(self.func()) return self.func@Test_Classdef fun_test(): print('这是个测试函数') 类这是个测试函数None&lt;function fun_test at 0x000001E024B28730&gt; 类也可以做装饰器，但是需要定义call 方法 扩展查看函数运行时间的装饰器 import timedef run_time(func): def new_fun(*args,**kwargs): t0 = time.time() print('star time: %s'%(time.strftime('%x',time.localtime())) ) back = func(*args,**kwargs) print('end time: %s'%(time.strftime('%x',time.localtime())) ) print('run time: %s'%(time.time() - t0)) return back return new_fun@run_timedef demo(): print('1213')demo() star time: 12/19/181213end time: 12/19/18run time: 0.0 总结 装饰器本质是闭包，在不影响原函数使用的情况下，增加原函数功能。内置装饰器：三个内置装饰器是需要掌握的，在项目中会经常使用。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>描述器</tag>
        <tag>装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[私有属性和私有方法python3中有没有私有属性这种说法？如果有的话有是怎么使用的？ ”私有“变量、方法 1、封装类的实例上面的“私有”数据，但是Python语言并没有访问控制。 2、Python程序员不去依赖语言特性去封装数据，而是通过遵循一定的属性和方法命名规约来达到这个效果。 单下滑线(_) 第一个约定是任何以单下划线_开头的名字都应该是内部实现。 class A: def __init__(self): self._internal = 0 # An internal attribute self.public = 1 # A public attribute def public_method(self): ''' A public method ''' pass def _internal_method(self): print('_internal_method') Python并不会真的阻止别人访问内部名称。但是如果你这么做肯定是不好的，可能会导致脆弱的代码。 同时还要注意到，使用下划线开头的约定同样适用于模块名和模块级别函数。 a = A()a._internal_method()a._internal _internal_method0 双下滑线（__）你还可能会遇到在类定义中使用两个下划线(__)开头的命名。 class B: def __init__(self): self.__private = 0 def __private_method(self): print('_B__private_method') def public_method(self): pass self.__private_method() 使用双下划线开始会导致访问名称变成其他形式。 比如，在前面的类B中，私有属性会被分别重命名为 _B__private 和 _B__private_method 。 这时候你可能会问这样重命名的目的是什么，答案就是继承——这种属性通过继承是无法被覆盖的。 b = B()b._B__privateb._B__private_method()b.public_method() _B__private_method_B__private_method 私有名称 __private 和 __private_method 被重命名为 _C__private 和 _C__private_method ，这个跟父类B中的名称是完全不同的。 class C(B): def __init__(self): super().__init__() self.__private = 1 # Does not override B.__private # Does not override B.__private_method() def __private_method(self): print('_C__private_method') _B__private_method_B__private_method_C__private_method 文件基本操作我们的程序都是运行在内存中的，内存是不可持久化存储的，那怎样才能持久存储呢？ 打开文件path = &apos;text.txt&apos; # 相对路径path = &apos;home/seven/text.txt&apos; # 绝对路径file = open(path, mode=&apos;w+&apos;) 以w+模式打开文件，是为写入和读取的模式，没有文件会新建文件，有文件会清空文件。 文件打开模式 不同的文件打开模式，对文件的操作有不同 写入文件file.write('python')Out[4]: 6file.write('python2')Out[5]: 7 写单个字符串 file.writelines(['1', '2', '3']) 写一行数据 file.flush() 本来写入的数据是存在内存里的，使用flush方法，把数据保存到硬盘中。 读取与关闭file.seek(0) # 把光标移到首位file.read()Out[18]: 'python\n\npython3\n\nc++\n\nc\n\njava\n\nmachine learning\n\ndeep learning\n' 读取全部数据 file.readline()Out[21]: 'python\n'file.readline()Out[22]: '\n'file.readline()Out[23]: 'python3\n'file.readline()Out[24]: '\n'file.readline()Out[25]: 'c++\n' 一行一行的读取数据 file.readlines()Out[26]: ['\n', 'c\n', '\n', 'java\n', '\n', 'machine learning\n', '\n', 'deep learning\n'] 读取所有行并以列表形式返回 file.flush() # 把内存中的数据保存到硬盘中file.close() # 关闭并保存文件file.closed # 判断文件是否关闭 file.close()file.closedOut[28]: True 查看与移动指针file.tell()Out[9]: 50file.seek(0, 0) #0代表从文件开头开始算起，1代表从当前位置开始算起，2代表从文件末尾算起。Out[10]: 0file.tell()Out[11]: 0 tell 查看光标位置，seek移动光标的位置。 总结 持久存储：保存内存中数据都是易丢失的，只有保存在硬盘中才能持久的存储，保存在硬盘中的基本方法就是把数据写入文件中。 打开与关闭：在python中文件的打开与关闭变得十分简单快捷，文件在关闭的时候就会自动保存 写入与读取：文件的写入和读取是必须要十分熟练的内容 上下文管理文件能够自动关闭吗？ with open(&apos;test.txt&apos;,&apos;r&apos;) as file: st = file.read() print(st) cjavamachine learningdeep learningfile.closedOut[3]: True with能够自动关闭文件，不需要执行close方法 import timeclass RunTime: def __enter__(self): self.start_time = time.time() return self.start_time def __exit__(self, exc_type, exc_val, exc_tb): self.end_time = time.time() self.run_time = self.end_time - self.start_time print('Time consuming %s ' % self.run_time)with RunTime(): for i in range(100000): pass Time consuming 0.005983591079711914 通过这两个方法可以方便的实现上下文管理 with会把 enter 的返回值赋值给 as 后的变量 总结 with: 使用with打开文件，则文件不需要自己关闭，会自动的关闭 enter: 进入时需要执行的代码，相当于准备工作 exit : 退出时需要执行的代码，相当于收尾工作 IO流文件可以持久存储，但是现在类似于临时的一些文件，不需要持久存储，如一些临时的二维码等，这个不需要持久存储，但是却需要短时间内大量读取，这是时候还是只能保存在文件里面吗？ StringIOIn [4]: import ioIn [5]: sio = io.StringIO() # 创建ioIn [6]: sio.write('abc') # 写入数据Out[6]: 3In [7]: sioOut[7]: &lt;_io.StringIO at 0x7f0b775ddaf8&gt;In [8]: sio.read()Out[8]: ''In [9]: sio.seek(0)Out[9]: 0In [10]: sio.read()Out[10]: 'abc'In [11]: sio.getvalue() # 读取数据，全部的，不管光标位置Out[11]: 'abc'In [12]: sio.close()In [13]: sioOut[13]: &lt;_io.StringIO at 0x7f0b775ddaf8&gt;In [14]: sio.getvalue()---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-14-2c8cd5e6194b&gt; in &lt;module&gt;()----&gt; 1 sio.getvalue()ValueError: I/O operation on closed file StringIO在内存中如同打开文件一样操作字符串，因此也有文件的很多方法 当创建的StringIO调用 close() 方法时，在内存中的数据会被丢失 BytesIOIn [17]: bio = io.BytesIO() # 创建IOIn [18]: bioOut[18]: &lt;_io.BytesIO at 0x7f0b775b9150&gt;In [19]: bio.write(b&apos;abc&apos;) # 写入数据Out[19]: 3In [20]: bio.read()Out[20]: b&apos;&apos;In [21]: bio.seek(0)Out[21]: 0In [22]: bio.read()Out[22]: b&apos;abc&apos;In [23]: bio.getvalue() # 读取数据 Out[23]: b&apos;abc&apos;In [24]: bio.close()In [25]: bio.read()---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-25-dca3ff2736f4&gt; in &lt;module&gt;()----&gt; 1 bio.read()ValueError: I/O operation on closed file. BytesIO和 StringIO 类似，但是BytesIO操作的是 Bytes数据 使用工具文件可以直接新建，但是现在如果需要创建文件夹和移动文件夹怎么办呢？ os 操作系统交互 os模块提供python和操作系统交互的接口 直接调用吸引命令In [1]: import osIn [2]: os.system('ls')Data PythonClassEnv ReadMe.mdOut[2]: 0 通用路径操作In [5]: os.pathOut[5]: &lt;module 'posixpath' from '/usr/lib/python3.5/posixpath.py'&gt;In [6]: os.path.join(r'Data', r'a')Out[6]: 'Data/a' 文件目录操作In [7]: os.mkdir('text')In [8]: os.system('ls')Data PythonClassEnv ReadMe.md textOut[8]: 0 In [9]: os.rename('text', 'text1')In [10]: os.system('ls')Data PythonClassEnv ReadMe.md text1Out[10]: 0 os 提供了Python和操作系统交互方式，只要是和操作系统相关，就可以尝试在os模块中找方法 shutil 高级文件操作 shutil 模块提供了许多关于文件和文件集合的高级操作 引入： import shutil copy()功能：复制文件格式：shutil.copy(&apos;来源文件&apos;,&apos;目标地址&apos;)返回值：复制之后的路径 copy2()功能：复制文件，保留元数据格式：shutil.copy2(&apos;来源文件&apos;,&apos;目标地址&apos;)返回值：复制之后的路径 copyfileobj()将一个文件的内容拷贝的另外一个文件当中格式：shutil.copyfileobj(open(来源文件,&apos;r&apos;),open（&apos;目标文件&apos;,&apos;w&apos;）)返回值：无 copyfile()功能：将一个文件的内容拷贝的另外一个文件当中格式:shutil.copyfile(来源文件,目标文件)返回值：目标文件的路径 copytree()功能：复制整个文件目录格式:shutil.copytree(来源目录,目标目录)返回值：目标目录的路径注意：无论文件夹是否为空，均可以复制，而且会复制文件夹中的所有内容 copymode()功能：拷贝权限 copystat()功能：拷贝元数据（状态） rmtree()功能：移除整个目录，无论是否空格式：shutil.rmtree(目录路径)返回值：无 move()功能：移动文件或者文件夹格式：shutil.move(来源地址,目标地址)返回值：目标地址 which()功能：检测命令对应的文件路径格式：shutil.which(‘命令字符串’)返回值：命令文件所在位置注意：window和linux不太一样。 window的命令都是.exe结尾，linux则不是 disk_usage()功能：检测磁盘使用信息格式：disk_usage(‘盘符’)返回值：元组]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[异常 异常是什么？ 程序运行过程中出现异常，程序还能正常运行吗？ 如果出现异常该如何让程序正常运行下去呢？ 异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。 一般情况下，在Python无法正常处理程序时就会发生一个异常。 异常是Python对象，表示一个错误。 当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。 语法规则 try-except异常是我们敲代码的过程中遇到最多的，那么我们有什么办法来捕获异常呢？ a = 1bprint(&apos;ok&apos;) #ok能够打印出来吗？ NameError: name &apos;b&apos; is not defined 捕获异常 ，让代码正常执行 try: a = 1 bexcept NameError as e: print(e)print('ok') #ok能够打印出来吗？ name 'b' is not definedok 通过捕获异常，代码不仅把错误打印了，后面的代码也正常执行了。 那么其他异常怎么办呢？是一样的吗？ try: a = 1 file = open('test.txt', 'r')except NameError as e: print(e)print('ok') #ok能够打印出来吗？ FileNotFoundError: [Errno 2] No such file or directory: 'test.txt' 不同类型的异常，就要用不同的状态去捕获 try: a = 1 file = open('test.txt', 'r')except NameError as e: print(e)except FileNotFoundError as e: print(e)print('ok') #ok能够打印出来吗？ [Errno 2] No such file or directory: &apos;test.txt&apos;ok 异常那么多，我们需要每一个都写吗？ try: a = 1 c = 1 + &apos;a&apos; file = open(&apos;test.txt&apos;, &apos;r&apos;)except NameError as e: print(e)except FileNotFoundError as e: print(e)except Exception as e: print(e)print(&apos;ok&apos;) #ok能够打印出来吗？ unsupported operand type(s) for +: &apos;int&apos; and &apos;str&apos;ok 同时出现两个异常，会都捕获吗？ try: a = 1 c file = open('test.txt', 'r')except NameError as e: print(e)except FileNotFoundError as e: print(e)print('ok') #ok能够打印出来吗？ name &apos;c&apos; is not definedok 出现异常后，报异常后的代码就不会执行了，就会跳到except去执行。 try-except-elsetry: a = 1 c = 1 file = open('tests.txt', 'r')except NameError as e: print(e)except FileNotFoundError as e: print(e)except Exception as e: print(e)else: file.close()print('ok') #ok能够打印出来吗？ [Errno 2] No such file or directory: 'tests.txt'okfileTraceback (most recent call last): File "C:\Program Files\Python36\lib\site-packages\IPython\core\interactiveshell.py", line 3265, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File "&lt;ipython-input-3-046c168df224&gt;", line 1, in &lt;module&gt; fileNameError: name 'file' is not defined 这是有抛出异常的情况。 try: a = 1 c = 1 file = open('test.txt', 'x')except NameError as e: print(e)except FileNotFoundError as e: print(e)except Exception as e: print(e)else: file.close() print('ok') #ok能够打印出来吗？ okfileOut[3]: &lt;_io.TextIOWrapper name=&apos;test.txt&apos; mode=&apos;w&apos; encoding=&apos;cp936&apos;&gt;file.closedOut[4]: True 这是没有异常的情况 else是在不抛出异常的情况下执行。 try-except-finallytry: a = 1 c = 1 file = open('tests.txt', 'r')except NameError as e: print(e)except FileNotFoundError as e: print(e)except Exception as e: print(e)else: file.close()finally: print('end')print('ok') #ok能够打印出来吗？ [Errno 2] No such file or directory: 'tests.txt'endok 这是抛出异常的情况 try: a = 1 c = 1 file = open('test.txt', 'r')except NameError as e: print(e)except FileNotFoundError as e: print(e)except Exception as e: print(e)else: file.close()finally: print('end')print('ok') #ok能够打印出来吗？ endok 这是不抛出异常的情况 不管会不会抛出异常，finally都会在最后执行。 返回错误def func(): try: c = 1 file = open('tx.txt', 'r') print('aaaaaa') except FileNotFoundError as e: return e except NameError as e: print(e)x = func()print(x) [Errno 2] No such file or directory: &apos;tx.txt&apos; 直接抛出异常def func(): try: c = 1 file = open('tx.txt', 'r') print('aaaaaa') except FileNotFoundError as e: raise e except NameError as e: print(e)x = func()print(x) FileNotFoundError: [Errno 2] No such file or directory: &apos;tx.txt&apos; raise是直接抛出异常–和不使用try是一样的。 自定义类class MyError(Exception): def __init__(self, value): self.value = value def __str__(self): return repr(self.value)try: raise MyError(2 * 2)except MyError as e: print('My exception occurred, value:', e.value) print(e) My exception occurred, value: 44 自定义异常错误class MyError(ValueError): ERROR = ("-1", "没有该用户！")# 抛出异常测试函数def raiseTest(): # 抛出异常 raise MyError(MyError.ERROR[0], # 异常错误参数1 MyError.ERROR[1]) # 异常错误参数2# 主函数if __name__ == '__main__': try: raiseTest() except MyError as msg: print("errCode:", msg.args[0]) # 获取异常错误参数1 print("errMsg:", msg.args[1]) # 获取异常错误参数2 errCode: -1errMsg: 没有该用户！ 注意 注意事项： try 后面必须跟上 except except 只有在函数中才能使用 return finally 不管是否发生异常，始终都会执行 总结 try: 将可能会发生异常的代码放在try中，就可以得到异常，并做相应处理 except: except用来接受异常，并且可以抛出或者返回异常 else和finally: else在没有异常的时候会执行；finally不管是否有异常，都会执行 异常处理 python中有哪些异常？ 怎样查看所有的异常？ 如何通过程序的报错来找到有问题的代码 异常层次结构 在 Python 中所有的异常都是继承 BaseException 代码中会出现的异常都是 Exception 的子类， 因此在 except 中只需要在最后加上 Exception 即可 在抛出异常的过程中，会从上倒下依次对比异常，找到之后就不会再往后查找 断言在调试代码过程中，对于不知道的值可以使用print输出查看一下，但是有些时候，我们清楚某个值应该是怎样的，比如应该是int类型的数据，这个时候需要在类型不对的情况下终止代码，再来调试代码，该怎么做呢？ assert 1==1 assert 1==2 #报错assert len(in_s) == 4, 'input size rank 4 required!'assert len(f_s) == 4, 'filter size rank 4 required!'assert f_s[2] == in_s[3], 'intput channels not match filter channels.'assert f_s[0] &gt;= stride and f_s[1] &gt;= stride, 'filter should not be less than stride!'assert padding in ['SAME', 'VALID'], 'padding value[&#123;0&#125;] not allowded!!'.format(padding) 断言语句是将调试断言插入程序的一种便捷方式 assert 的语法规则是： 表达式返回 True 不报错 表达式返回 False 报错 报 AssertionError]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[列表推导式、迭代器、生成器、模块和包]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%88%97%E8%A1%A8%E6%8E%A8%E5%AF%BC%E5%BC%8F%E3%80%81%E8%BF%AD%E4%BB%A3%E5%99%A8%E7%94%9F%E6%88%90%E5%99%A8%EF%BC%8C%E6%A8%A1%E5%9D%97%E5%92%8C%E5%8C%85%2F</url>
    <content type="text"><![CDATA[推导表达式得到一个元素为1到10的列表，可以怎么做？ 列表循环添加方法一： x = list(range(1,11))xOut[3]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 方法二： li = []for i in range(1,11): li.append(i) liOut[3]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 这是我们前面所总结过的生成一个列表的方法。 列表推导li = [i for i in range(1,11)]liOut[3]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 通过列表推导，精简了代码。 运行时间对比import times = time.time()for i in range(1000000): x = list(range(1,11))e = time.time()print('list: ', e-s)f = time.time()for i in range(1000000): li = [] for i in range(1,11): li.append(i)end = time.time()print('append: ', end-f)ff = time.time()for i in range(1000000): li = [i for i in range(1,11)]end1 = time.time()print('[]: ', end1-ff) list: 0.7910020351409912append: 2.110013246536255[]: 1.0232622623443604 可以看出列表推导的方式是比append方法更高效的，而list强制转换的是可能出现问题，所以总的来说就是推荐使用列表推导的方法。 列表推导+条件判断l2 = [i for i in range(1,11) if i % 2 == 0]l2Out[4]: [2, 4, 6, 8, 10] 单独的if条件判断只能放在后面 列表推导+三目运算l2 = [i if i % 2 == 0 else 0 for i in range(1,11)]l2Out[3]: [0, 2, 0, 4, 0, 6, 0, 8, 0, 10] 如果是if+else的判断条件，就需要放前面。 集合se = &#123;i for i in range(1,11)&#125;seOut[4]: &#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10&#125; 字典li = list(range(1,11))di = &#123;i:j for i,j in enumerate(li)&#125;diOut[3]: &#123;0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10&#125; 总结 推导表达式相对于for循环来处理数据，要更加的方便。 列表推导表达式使用更加的广泛。 迭代器和生成器迭代器列表推导是往列表中一个一个地放入数据，那如果一个一个地取出数据呢？ li = list(range(1, 11))it = iter(li)it2 = li.__iter__()itOut[3]: &lt;list_iterator at 0x14c69f4b208&gt;it2Out[4]: &lt;list_iterator at 0x14c69f4b6a0&gt; 生成迭代器 迭代器对象dir(list)sir(str)dir(tuple) 迭代器对象本身需要支持以下两种方法，它们一起构成迭代器协议： iterator.__iter__()iterator.__next__() 取值next(it)Out[12]: 1next(it)Out[13]: 2next(it)Out[14]: 3it.__next__()Out[15]: 4it.__next__()Out[16]: 5it.__next__()Out[17]: 6next(it)Traceback (most recent call last): File "C:\Program Files\Python36\lib\site-packages\IPython\core\interactiveshell.py", line 3265, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File "&lt;ipython-input-13-bc1ab118995a&gt;", line 1, in &lt;module&gt; next(it)StopIteration 通过 next(iterator) iterator.next() 来进行取值 注意：如果迭代器值取完之后，会返回 StopIteration 错误 自定义迭代器class TupleIter: def __init__(self, li): self.li = li self._index = 0 def __iter__(self): return self def __next__(self): if self._index &lt; len(self.li): index = self.li[self._index] self._index += 1 return index else: raise StopIterationt1 = (1, 2, 3, 4, 5)a = TupleIter(t1)aOut[3]: &lt;__main__.TupleIter at 0x1376ba4b358&gt;next(a)Out[4]: 1a.__next__()Out[5]: 2 可以自己定义iter和next方法来自定义迭代器。 生成器def func(n): i = 0 while i &lt; n: yield i i += 1s = func(10)sOut[3]: &lt;generator object func at 0x000001442E4FE990&gt;[i for i in s]Out[4]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 迭代器提供了一个实现迭代器协议的简便方法 yield 表达式只能在函数中使用,在函数体中使用 yield 表达式可以使函数成为一个生成器 def func(end): n, a, b = 0, 0, 1 while n &lt; end: yield b a, b = b, a + b n += 1g = func(10)gOut[3]: &lt;generator object func at 0x00000238904BD990&gt;[i for i in g]Out[4]: [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 通过生成器就生成了一个迭代器，通过dir(g)就能查出iter和next的方法。就比我们自定义迭代器更简单。 def func(end): n, a, b = 0, 0, 1 while n &lt; end: print('*'*5, a, b) yield b print('-' * 5, a, b) a, b = b, a + b n += 1 g = func(10)next(g)***** 0 1Out[3]: 1next(g)----- 0 1***** 1 1Out[4]: 1next(g)----- 1 1***** 1 2Out[5]: 2 yield 可以返回表达式结果，并且暂定函数执行 通过迭代器去生成斐波拉契数列要比直接得到更加节省内存。 总结：yield只能在函数里面使用。 模块在另一个py文件中的对象如何导入到当前的py文件中呢？ 模块在python中，模块就是一个py文件，可以使用下面两种方法导入 import XXfrom XX import XX from XX import XX as XX import datetimefrom datetime import datetime (as this_datetime) 在同一目录下，可直接使用上面两种方法去导入；在不同目录下，需要使用 sys.path 添加路径 sys.path.append(‘path’) from pages import aa.demo() 不同的文件夹导入模块可以用这个两种方式。 在python3中导入后，会在当前路径下生成一个pycache 文件夹 sys模块sys 模块提供了与python解释器交互的函数，在python中它是始终可以导入使用的. sys.argvimport sysprint(sys.argv) $ python b.py 123 456['b.py', '123', '456'] 获取终端命令行输入 sys.pathimport sysprint(sys.path) 解释器模块导入查找路径 if name == ‘ main’:namepython会自动的给模块加上这个属性 如果模块是被直接调用的，则 name 的值是 main否则就是该模块的模块名 pages.a a__main__ b 注意if name == ‘ main’: 该语句可以控制代码在被其他模块导入时不被执行 __main__ b 包和包管理如果模块太多了，怎么方便的去管理呢？ 包概念 把很多模块放到一个文件夹里面，就可以形成一个包. 包管理 当把很多模块放在文件中时，为了方便引用包中的模块，引入了包管理 init.py 在包管理中，加入此模块，则包名可以直接通过属性访问的方式，访问此模块内的对象，此模块不加上可能不会报错，但是规范是要加上，文件内容可以为空 相对路径导入 在包管理中，可以通过. (一个点) 和 .. (两个点)分别来导入同层和上一层的模块 引入作用 在包中，如果包中模块要导入同一包中的其他模块，就必须使用此方法导入. 使用方法from .module(..module) import obj (as new_name) 引入之后的影响 当一个模块中出现此导入方式，则该模块不能被直接运行，只能被导入]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>列表推导式</tag>
        <tag>迭代器</tag>
        <tag>生成器</tag>
        <tag>模块</tag>
        <tag>包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%AD%A3%E5%88%99%2F</url>
    <content type="text"><![CDATA[正则在实际的应用中，我们会经常得到用户的输入，在得到用户的输入之后，需要我们对输入进行判断是否合法，比如判断输入的手机号码，从形式上来看是怎样的呢？ mu = input('请输入电话号码：')def phone_number(st): st = str(st) if len(st) == 11 and st.startswith('1') and st.isdigit() : return True else: print('Phone Number Error') return Falseprint(phone_number(mu)) 那有什么简单的方法呢？ 正则搜索matchimport rea = '12345678900'rm = re.match(r'1\d&#123;10&#125;',a)print(rm) searchimport rea = '12345678900'rs = re.search(r'1\d&#123;10&#125;',a)print(rs) 通过对比，可以很明显的发现，下面这种方式能够简单快捷的匹配出电话号码 总结 正则表达式：正则表达式是一种通用的用来简洁表达一组字符串的表达式，因此，正则表达式是和python无关的，在其他的语言或者不同的系统中，是通用的。 匹配：通过正则表达式就可以去匹配现有的字符串。 应用：通过正则匹配，可以迅速的过滤出我们需要的全部或者一部分字符串，查找文本中的特质值(如：病毒)等等。 元字符正则表达式该如何书写呢？ 观察如下两个例子： In [3]: re.search('a', 'abc')Out[3]: &lt;_sre.SRE_Match object; span=(0, 1), match='a'&gt;In [5]: re.search('.', 'ab.cd.de')Out[5]: &lt;_sre.SRE_Match object; span=(0, 1), match='a'&gt; 在第一个例子中，可以匹配出a 但是下面这个没有匹配出点，而是匹配到 a 这个 . 不是不能匹配到点，而是匹配任意字符，这个点已经被赋予了特殊的含义， .(点)就是一个元字符 正因为有这些元字符的存在，正则表达式才变得强大. \bIn [23]: re.search('\bs\b', 'abcdsd s we')In [24]: re.search(r'\bs\b', 'abcdsd s we')Out[24]: &lt;_sre.SRE_Match object; span=(7, 8), match='s'&gt; 在正则中，加上r 去掉字符串的转义，以免影响正则的使用 \b匹配一个单词边界，也就是指单词和空格间的位置。 .In [26]: re.search(r'.', 'abcdsd s we')Out[26]: &lt;_sre.SRE_Match object; span=(0, 1), match='a'&gt;In [27]: re.search(r'.', '\nabcdsd s we')Out[27]: &lt;_sre.SRE_Match object; span=(1, 2), match='a'&gt; 匹配除换行符之外的所有的字符 \dIn [28]: re.search(r'\d',r'abc141342d')Out[28]: &lt;_sre.SRE_Match object; span=(3, 4), match='1'&gt; 匹配0~9的数字 \sIn [30]: re.search(r'\s',r'abc 141342d')Out[30]: &lt;_sre.SRE_Match object; span=(3, 4), match=' '&gt; 匹配任意的空白符，包括空格，制表符(Tab)，换行符等 \wIn [31]: re.search(r'\w',r'abc 141342d')Out[31]: &lt;_sre.SRE_Match object; span=(0, 1), match='a'&gt; 匹配字母或数字或下划线或汉字等 \bIn [32]: re.search(r&apos;\bc\b&apos;,r&apos;abc c 342d&apos;)Out[32]: &lt;_sre.SRE_Match object; span=(4, 5), match=&apos;c&apos;&gt;In [33]: re.search(r&apos;\bbcb\b&apos;,r&apos;abc bcb 342d&apos;)Out[33]: &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;bcb&apos;&gt; \b 表示单词的边界 \ .In [34]: re.search(r'\.',r'ab.c .bcb 342d')Out[34]: &lt;_sre.SRE_Match object; span=(2, 3), match='.'&gt; 表示匹配点号本身 \D、\S、\W、\BIn [35]: re.search(r'\D','abc.1213')Out[35]: &lt;_sre.SRE_Match object; span=(0, 1), match='a'&gt;In [36]: re.search(r'\S','abc.1213')Out[36]: &lt;_sre.SRE_Match object; span=(0, 1), match='a'&gt;In [37]: re.search(r'\W','abc.1213')Out[37]: &lt;_sre.SRE_Match object; span=(3, 4), match='.'&gt;In [38]: re.search(r'\B','abc.1213')Out[38]: &lt;_sre.SRE_Match object; span=(1, 1), match=''&gt; 是与小写的相反的作用 \DIn [39]: re.search(r'\D','abc.1213')Out[39]: &lt;_sre.SRE_Match object; span=(0, 1), match='a'&gt; 除了数字以外的字符 ^In [41]: re.search(r'^ab',r'abc 141342d')Out[41]: &lt;_sre.SRE_Match object; span=(0, 2), match='ab'&gt; 脱字符，匹配输入字符串的开始的位置 $In [42]: re.search(r'd$',r'abc 141342d')Out[42]: &lt;_sre.SRE_Match object; span=(10, 11), match='d'&gt; 匹配输入字符串的结束位置 {}In [43]: re.search(r'\d&#123;1,3&#125;',r'abc 141 qw 342d') # 对象，找到一个就不找了Out[43]: &lt;_sre.SRE_Match object; span=(4, 7), match='141'&gt;In [44]: re.findall(r'\d&#123;1,3&#125;',r'abc 141 qw 342d') #列表，全部找出来Out[44]: ['141', '342']In [45]: re.findall(r'\d&#123;1,&#125;',r'abc 141 qw 34325252d')Out[45]: ['141', '34325252']In [46]: re.findall(r'\d&#123;,5&#125;',r'abc 141 qw 34325252d')Out[46]: ['', '', '', '', '141', '', '', '', '', '34325', '252', '', '']In [47]: re.findall(r'\d&#123;0,3&#125;',r'abc 141 qw 34325252d')Out[47]: ['', '', '', '', '141', '', '', '', '', '343', '252', '52', '', ''] {M,N} :M和N 为非负整数，其中M&lt;=N 表示前面的匹配M~N次 {M，}: 表示需要匹配M次 {，N}: 等价于{0~N} {N}: 表示需要匹配N次 *In [49]: re.findall(r'\d*',r'abc 141 qw 34325252d')Out[49]: ['', '', '', '', '141', '', '', '', '', '34325252', '', '']In [50]: re.findall(r'\d&#123;0,&#125;',r'abc 141 qw 34325252d')Out[50]: ['', '', '', '', '141', '', '', '', '', '34325252', '', ''] 匹配前面的子表达式零次或多次，等价于{0，} +In [51]: re.findall(r'\d+',r'abc 141 qw 34325252d')Out[51]: ['141', '34325252']In [52]: re.findall(r'\d&#123;1,&#125;',r'abc 141 qw 34325252d')Out[52]: ['141', '34325252'] 匹配前面的子表达式一次或多次，等价于{1，} ?In [57]: re.findall(r'\d&#123;0,1&#125;',r'ab5252d')Out[57]: ['', '', '5', '2', '5', '2', '', '']In [58]: re.findall(r'\d?',r'ab5252d')Out[58]: ['', '', '5', '2', '5', '2', '', ''] 匹配前面的子表达式零次或一次，等价于{0,1} 贪婪与非贪婪*?、+？In [61]: re.findall(r'\d*?',r'ab5252d')Out[61]: ['', '', '', '', '', '', '', '']In [62]: re.findall(r'\d+?',r'ab5252d')Out[62]: ['5', '2', '5', '2']In [65]: st ="&lt;html&gt;aaaa&lt;/html&gt;&lt;td&gt;bbbb&lt;/td&gt;"In [66]: re.findall(r'&lt;.*&gt;',st)Out[66]: ['&lt;html&gt;aaaa&lt;/html&gt;&lt;td&gt;bbbb&lt;/td&gt;']In [67]: re.findall(r'&lt;.*?&gt;',st)Out[67]: ['&lt;html&gt;', '&lt;/html&gt;', '&lt;td&gt;', '&lt;/td&gt;'] 在非贪婪模式下，始终找最短匹配 []字符集合[] 字符类，将要匹配的一类字符集放在[]里面 In [68]: re.findall(r'[\d]',r'abc 141 qw 34325252d')Out[68]: ['1', '4', '1', '3', '4', '3', '2', '5', '2', '5', '2']In [69]: re.findall(r'[0-9]',r'abc 141 qw 34325252d')Out[69]: ['1', '4', '1', '3', '4', '3', '2', '5', '2', '5', '2']In [70]: re.findall(r'[a-z]',r'abc 141 qw 34325252d')Out[70]: ['a', 'b', 'c', 'q', 'w', 'd'] [ . ? * ( ) {} ] : 匹配里面的这些符号 [0-9]: 匹配0到9的数字相当于\d \d: 匹配除数字以外的字符，相当于\D取反的意思 [a-z]: 匹配所有的小写字母 a-z : 匹配非小写字母 | : 相当于或（or）分支条件 ()分组匹配() 分组，将要匹配的一类字符集放在()组成一个小组 In [75]: re.findall(r'(32)',r'abc 141 qw 34325252d')Out[75]: ['32']In [76]: re.findall(r'a(3|2)',r'a3 a2 a23 ')Out[76]: ['3', '2', '2']In [77]: re.findall(r'a([32])',r'a3 a2 a23 ')Out[77]: ['3', '2', '2'] 分组匹配匹配() 内的字符串组合 re模块compile编译正则表达式为模式对象 当正则表达式多次使用，可以采用这种方式 In [78]: r = re.compile(r'\das')In [79]: r.findall('1as234')Out[79]: ['1as'] sub字符串替换 In [80]: re.sub('i','o','pythin***pythin',1)Out[80]: 'python***pythin'In [81]: re.sub('i','o','pythin***pythin',2)Out[81]: 'python***python'In [82]: re.sub('i','o','pythin***pythin')Out[82]: 'python***python' match从字符串开始位置匹配 In [83]: re.match(r'\d','123ad')Out[83]: &lt;_sre.SRE_Match object; span=(0, 1), match='1'&gt;In [84]: re.match(r'\d','a123ad') group得到匹配到的元素 In [94]: re.search(r'\d&#123;1,3&#125;',r'abc 141 qw 342d')Out[94]: &lt;_sre.SRE_Match object; span=(4, 7), match='141'&gt;In [95]: li = re.search(r'\d&#123;1,3&#125;',r'abc 141 qw 342d')In [96]: li.group()Out[96]: '141' start得到开始位置 In [97]: li.start()Out[97]: 4 end得到结束位置 In [98]: li.end()Out[98]: 7 span得到位置范围 In [99]: li.span()Out[99]: (4, 7) 注意：这几个方法在search中也存在 扩展在re中也有和字符串一样的split方法 In [85]: re.split(r'\s',' cee')Out[85]: ['', 'cee']In [86]: re.split(r'\s','aa bb cc dd')Out[86]: ['aa', 'bb', 'cc', 'dd']In [87]: re.split(r'[\s|c]','aa bb c dd ee')Out[87]: ['aa', 'bb', '', '', 'dd', 'ee']]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[requests库及爬虫案例]]></title>
    <url>%2F2019%2F01%2F28%2Frequests%E5%BA%93%E5%8F%8A%E7%88%AC%E8%99%AB%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[Request库使用 Requests 发送网络请求非常简单。 requests.get()requests.get(url, params=None, **kwargs) 获取HTML网页的主要方法，对应于HTTP的GET. 构造一个向服务器请求资源的Request对象 返回一个包含服务器资源的Response对象. help(requests.get) Sends a GET request. :param url: URL for the new :class:Request object. :param params: (optional) Dictionary or bytes to be sent in the query string for the :class:Request. :param **kwargs: Optional arguments that request takes. :return: :class:Response &lt;Response&gt; object :rtype: requests.Response 发送GET请求。 url：拟获取页面的url链接 params：url中的额外参数，字典或字节流格式，可选 **kwargs：12个控制访问的参数 普通getIn [22]: import requestsIn [23]: urlOut[23]: 'https://www.baidu.com'In [24]: r = requests.get(url)Out[24]: &lt;Response [200]&gt;In [27]: r.urlOut[27]: 'https://www.baidu.com/' 带参getIn [41]: r = requests.get(url+'/s', params=&#123;'wd':'dog'&#125;)In [42]: r.urlOut[42]: 'https://www.baidu.com/s?wd=dog' requests.head()获取HTML网页头信息的方法，对应于HTTP的HEAD requests.head(url, **kwargs) url：拟获取页面的url链接 **kwargs：13个控制访问的参数 requests.post()向HTML网页提交POST请求的方法，对应于HTTP的POST requests.post(url, data=None, json=None, **kwargs) url：拟获取页面的url链接 data：字典、字节序列或文件，Request的内容 json：JSON格式的数据，Request的内容 **kwargs：11个控制访问参数 requests.put()向HTML网页提交PUT请求的方法，对应于HTTP的PUT requests.put(url, data=None, **kwargs) url：拟更新页面的url链接 data：字典、字节序列或文件，Request的内容 **kwargs：12个控制访问参数 requests.patch()向HTML网页提交局部修改请求，对应于HTTP的PATCH requests.patch(url, data=None, **kwargs) url：拟更新页面的url链接 data：字典、字节序列或文件，Request的内容 **kwargs：12个控制访问参数 requests.delete()向HTML页面提交删除请求，对应于HTTP的DELETE requests.delete(url, **kwargs) url：拟删除页面的url链接 **kwargs：13个控制访问参数 response对象的属性r.status_codeHTTP请求的返回状态，200表示连接成功，404表示失败 r.textHTTP响应内容的字符串形式，即，url对应的页面内容 r.emcoding从HTTPheader中猜测的响应内容编码方式 r.apparent_encoding从内容分析出的响应内容编码方式（备选编码方式）. r.contentHTTP响应内容的二进制形式. 理解Response的编码r.encoding 从HTTP header中猜测的响应内容编码方式 注意：如果header中不存在charset，则认为编码为ISO-8859-1。 r.apparent_encoding 从内容中分析出的响应内容编码方式（备选编码方式） 注意：根据网页内容分析出的编码方式 理解Requests库的异常requests.ConnectionError网络连接错误异常，如DNS查询失败、拒绝连接等 requests.HTTPErrorHTTP错误异常 requests.URLRequiredURL缺失异常 requests.TooMangRedirects超过最大重定向次数，产生重定向异常 requests.ConnectTimeout连接远程服务器超时异常 requests.Timeout请求URL超时，产生超时异常 r.raise_for_status()如果不是200，产生异常requests.HTTPError 爬取网页的通用代码框架import requestsdef getHTMLText(url): try: r = requests.get(url, timeout=30) r.raise_for_status() #如果状态不是200，引发HTTPError异常# r.encoding = r.apparent_encoding return r.text except: return "产生异常"if __name__ == "__main__": url = "http://www.baidu.com" print(getHTMLText(url)) HTTP协议对资源的操作 request.request() requests.request(method, url, **kwargs) method：请求方式 url：拟获取页面的url链接 r = requests.request('GET', url, **kwargs)r = requests.request('HEAD', url, **kwargs)r = requests.request('POST', url, **kwargs)r = requests.request('PUT', url, **kwargs)r = requests.request('PATCH', url, **kwargs)r = requests.request('DELETE', url, **kwargs)r = requests.request('OPTIONS', url, **kwargs)**kwargs：控制访问的参数，均为可选项，共13个 超参数params字典或字节序列，作为参数增加到url中 kv = &#123;'key1': 'value1', 'key2': 'value2'&#125;r = requests.request('GET', 'http://python123.io/ws', params=kv)print(r.url) out: https://python123.io/ws?key1=value1&amp;key2=value2 data字典、字节序列或文件对象，作为Request的对象 body = '主体内容'.encode('utf-8')r = requests.request('POST', 'http://python123.io/ws', data=body)print(r.url) out: http://python123.io/ws jsonJSON格式的数据，作为Request的内容 kv = &#123;'key1': 'value1'&#125;r = requests.request('POST', 'http://python123.io/ws', json=kv)print(r.url) out: http://python123.io/ws headers字典，HTTP定制头 hd = &#123;'user-agent': 'Chrome/10'&#125;r = requests.request('POST', 'http://python123.io/ws', headers=hd)print(r.url) out: http://python123.io/ws cookies字典或CookieJar，Request中的cookie auth元组，支持HTTP认证功能 files字典类型，传输文件 fs = &#123;&apos;file&apos;: open(&apos;data.xls&apos;,&apos;rb&apos;)&#125;r = requests.request(&apos;POST&apos;, &apos;http://python123.io/ws&apos;, files=fs)print(r.url) timeout设定超时时间，秒为单位 r = requests.request(&apos;GET&apos;, &apos;http://www.baidu.com&apos;, timeout=10) proxies字典类型，设置访问代理服务器，可以增加登录认证 pxs = &#123;'http': 'http://user:pass@10.10.10.1:1234' 'https': 'https://10.10.10.1:4321'&#125;r = requests.request('GET', 'http://www.baidu.com', proxies=pxs) allow_redirectsTrue/False，默认为Ture，重定向开关 streamTrue/False，默认为True，获取内容立即下载开关 verifyTrue/False，默认为True，认证SSL证书开关 cert本地SSL证书路径 爬虫案例网站实例网站：百度图片搜索 分析网页搜索关键字：猫 https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;fm=index&amp;pos=history&amp;word=%E7%8C%AB 搜索关键字：狗 https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;fm=index&amp;pos=history&amp;word=%E7%8B%97 对比get的网址，发现只有搜索关键字不一样。 获得网页数据我们就才有前面提到的通用的代码框架 import requestsdef getHTMLText(url): try: r = requests.get(url, timeout=30) r.raise_for_status() # 如果状态不是200，引发HTTPError异常# r.encoding = r.apparent_encoding return r.text except: return "产生异常"if __name__ == "__main__": key_word = '小狗' url = 'https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0' \ '&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;fm=index&amp;pos=history&amp;word=' html = getHTMLText(url+key_word) print(html) 通用代码框架加上我们刚刚分析网址get的请求网址，就可以获取到网页的数据。 处理数据接下来就是处理数据，把我们所需要的图片网址匹配出来 通过F12找到图片的网址–这个不是原图地址 右键 查看网页源代码，分析JSON数据可知，其中的字段objURL，即表示了原图的下载地址。 通过正则在代码里匹配出图片的网址 pic_urls = re.findall('"objURL":"(.*?)",', html, re.S)print(pic_urls) 展示结果def down(urls): for i, url in enumerate(urls): try: pic = requests.get(url, timeout=15) string = str(i + 1) + '.jpg' with open(string, 'wb') as f: f.write(pic.content) print('成功下载第%s张图片: %s' % (str(i + 1), str(url))) except Exception as e: print('下载第%s张图片时失败: %s' % (str(i + 1), str(url))) print(e) continue 通过访问我们获取到的图片网址，对图片进行保存。 完整代码import requestsimport redef getHTMLText(url): """ 获取网页数据 :param url: 访问网址 :return: """ try: r = requests.get(url, timeout=30) r.raise_for_status() # 如果状态不是200，引发HTTPError异常# r.encoding = r.apparent_encoding return r.text except: return "产生异常"def down(urls): """ 下载图片 :param urls: 图片网址列表 :return: """ for i, url in enumerate(urls): try: pic = requests.get(url, timeout=15) string = str(i + 1) + '.jpg' with open(string, 'wb') as f: f.write(pic.content) print('成功下载第%s张图片: %s' % (str(i + 1), str(url))) except Exception as e: print('下载第%s张图片时失败: %s' % (str(i + 1), str(url))) print(e) continueif __name__ == "__main__": key_word = '小狗' url = 'https://image.baidu.com/search/index?tn=baiduimage&amp;ipn=r&amp;ct=201326592&amp;cl=2&amp;lm=-1&amp;st=-1&amp;sf=1&amp;fmq=&amp;pv=&amp;ic=0' \ '&amp;nc=1&amp;z=&amp;se=1&amp;showtab=0&amp;fb=0&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;ie=utf-8&amp;fm=index&amp;pos=history&amp;word=' html = getHTMLText(url+key_word) urls = re.findall('"objURL":"(.*?)",', html, re.S) # 匹配原图地址 print(len(urls)) down(urls)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>requests库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVM案例]]></title>
    <url>%2F2019%2F01%2F27%2FSVM%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[支持向量机（SVM）import numpy as npimport matplotlib.pyplot as pltfrom scipy import stats# use seaborn plotting defaultsimport seaborn as sns; sns.set()%matplotlib inline 支持向量基本原理 如何解决这个线性不可分问题呢？咱们给它映射到高维来试试 $z=x^2+y^2$ 例子#随机来点数据from sklearn.datasets.samples_generator import make_blobs #制造数据集X, y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60) #cluster_std 离散程度print(X.shape)print(y.shape)plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') #https://matplotlib.org/tutorials/colors/colormaps.html s 大小 随便的画几条分割线，哪个好来着？ xfit = np.linspace(-1, 3.5)plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')plt.plot([0.6], [2.1], 'x', color='red', markeredgewidth=2, markersize=10)for m, b in [(1, 0.65), (0.5, 1.6), (-0.2, 2.9)]: plt.plot(xfit, m * xfit + b, '-k')plt.xlim(-1, 3.5); Support Vector Machines: 最小化 雷区xfit = np.linspace(-1, 3.5)plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]: yfit = m * xfit + b plt.plot(xfit, yfit, '-k') plt.fill_between(xfit, yfit - d, yfit + d, edgecolor='none', color='#AAAAAA', alpha=0.4)plt.xlim(-1, 3.5); 训练一个基本的SVMfrom sklearn.svm import SVC # &quot;Support vector classifier&quot;model = SVC(kernel=&apos;linear&apos;)model.fit(X, y) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&apos;ovr&apos;, degree=3, gamma=&apos;auto&apos;, kernel=&apos;linear&apos;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) #绘图函数def plot_svc_decision_function(model, ax=None, plot_support=True): """Plot the decision function for a 2D SVC""" if ax is None: ax = plt.gca() #创建一个实例 xlim = ax.get_xlim() #获取x轴范围 ylim = ax.get_ylim() #获取y轴范围 # create grid to evaluate model x = np.linspace(xlim[0], xlim[1], 30) y = np.linspace(ylim[0], ylim[1], 30) Y, X = np.meshgrid(y, x) #从坐标向量返回坐标矩阵 xy = np.vstack([X.ravel(), Y.ravel()]).T #连续的扁平数组 #垂直堆叠数组（行方式） 2列 P = model.decision_function(xy).reshape(X.shape) #xy到分离超平面的距离 # plot decision boundary and margins ax.contour(X, Y, P, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--']) #等高线绘图和标注的类。 # plot support vectors if plot_support: ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=300, linewidth=1, facecolors='none'); ax.set_xlim(xlim) ax.set_ylim(ylim) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap=&apos;autumn&apos;)plot_svc_decision_function(model); 这条线就是我们希望得到的决策边界啦 观察发现有3个点做了特殊的标记，它们恰好都是边界上的点 它们就是我们的support vectors（支持向量） 在Scikit-Learn中, 它们存储在这个位置 support_vectors_（一个属性） model.support_vectors_ array([[0.44359863, 3.11530945], [2.33812285, 3.43116792], [2.06156753, 1.96918596]]) 观察可以发现，只需要支持向量我们就可以把模型构建出来 接下来我们尝试一下，用不同多的数据点，看看效果会不会发生变化 分别使用60个和120个数据点 def plot_svm(N=10, ax=None): X, y = make_blobs(n_samples=200, centers=2, random_state=0, cluster_std=0.60) X = X[:N] y = y[:N] model = SVC(kernel='linear', C=1E10) model.fit(X, y) ax = ax or plt.gca() ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') ax.set_xlim(-1, 4) ax.set_ylim(-1, 6) plot_svc_decision_function(model, ax)fig, ax = plt.subplots(1, 2, figsize=(16, 6))fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)for axi, N in zip(ax, [60, 120]): plot_svm(N, axi) axi.set_title('N = &#123;0&#125;'.format(N)) 左边是60个点的结果，右边的是120个点的结果 观察发现，只要支持向量没变，其他的数据怎么加无所谓！ 引入核函数的SVM 首先我们先用线性的核来看一下在下面这样比较难的数据集上还能分了吗？ from sklearn.datasets.samples_generator import make_circlesX, y = make_circles(100, factor=.1, noise=.1)clf = SVC(kernel='linear').fit(X, y)plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')plot_svc_decision_function(clf, plot_support=False); 坏菜喽，分不了了，那咋办呢？试试高维核变换吧！ We can visualize this extra data dimension using a three-dimensional plot: #加入了新的维度rfrom mpl_toolkits import mplot3dr = np.exp(-(X ** 2).sum(1))def plot_3D(elev=30, azim=30, X=X, y=y): ax = plt.subplot(projection='3d') ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap='autumn') ax.view_init(elev=elev, azim=azim) ax.set_xlabel('x') ax.set_ylabel('y') ax.set_zlabel('r')plot_3D(elev=45, azim=45, X=X, y=y) #加入基函数clf = SVC(kernel=&apos;rbf&apos;, C=1E6)clf.fit(X, y) SVC(C=1000000.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=’ovr’, degree=3, gamma=’auto’, kernel=’rbf’, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')plot_svc_decision_function(clf)plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=300, lw=1, facecolors='none'); 使用这种核支持向量机，我们学习一个合适的非线性决策边界。这种核变换策略在机器学习中经常被使用！ 调节SVM参数: Soft Margin问题调节C参数 当C趋近于无穷大时：意味着分类严格不能有错误 当C趋近于很小的时：意味着可以有更大的错误容忍 X, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.8)plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap=&apos;autumn&apos;); X, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.8)fig, ax = plt.subplots(1, 2, figsize=(16, 6))fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)for axi, C in zip(ax, [10.0, 0.1]): model = SVC(kernel='linear', C=C).fit(X, y) axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plot_svc_decision_function(model, axi) axi.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=300, lw=1, facecolors='none'); axi.set_title('C = &#123;0:.1f&#125;'.format(C), size=14) X, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=1.1)fig, ax = plt.subplots(1, 2, figsize=(16, 6))fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)for axi, gamma in zip(ax, [10.0, 0.1]): model = SVC(kernel='rbf', gamma=gamma).fit(X, y) #gamma越大越复杂，gamma越小越简单 axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plot_svc_decision_function(model, axi) axi.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=300, lw=1, facecolors='none'); axi.set_title('gamma = &#123;0:.1f&#125;'.format(gamma), size=14) Example: Face Recognition面部识别from sklearn.datasets import fetch_lfw_peoplefaces = fetch_lfw_people(min_faces_per_person=60)print(faces.target_names)print(faces.images.shape) [‘Ariel Sharon’ ‘Colin Powell’ ‘Donald Rumsfeld’ ‘George W Bush’ ‘Gerhard Schroeder’ ‘Hugo Chavez’ ‘Junichiro Koizumi’ ‘Tony Blair’](1348, 62, 47) Let’s plot a few of these faces to see what we’re working with: fig, ax = plt.subplots(3, 5)fig.tight_layout()for i, axi in enumerate(ax.flat): axi.imshow(faces.images[i],cmap='bone' ) #黑白 axi.set(xticks=[], yticks=[], xlabel=faces.target_names[faces.target[i]]) 每个图的大小是 [62×47] 在这里我们就把每一个像素点当成了一个特征，但是这样特征太多了，用PCA降维一下吧！ from sklearn.svm import SVC#from sklearn.decomposition import RandomizedPCAfrom sklearn.decomposition import PCAfrom sklearn.pipeline import Pipeline from sklearn.model_selection import train_test_splitXtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=40) 使用grid search cross-validation来选择我们的参数 from sklearn.model_selection import GridSearchCVparam_grid = &#123;'svc__C': [1, 5, 10], 'svc__gamma': [0.0001, 0.0005, 0.001]&#125;pipe = Pipeline([ ('pca',PCA(n_components = 150 ,whiten=True, random_state=64)), ('svc', SVC(kernel='rbf', class_weight='balanced')) ])grid = GridSearchCV(pipe, param_grid)grid.fit(Xtrain,ytrain)print(grid.best_params_) {‘svcC’: 5, ‘svcgamma’: 0.001} model = grid.best_estimator_yfit = model.predict(Xtest)yfit.shape (337,) 看看咋样吧！ fig, ax = plt.subplots(4, 6)for i, axi in enumerate(ax.flat): axi.imshow(Xtest[i].reshape(62, 47), cmap='bone') axi.set(xticks=[], yticks=[]) axi.set_ylabel(faces.target_names[yfit[i]].split()[-1], color='black' if yfit[i] == ytest[i] else 'red')fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14); from sklearn.metrics import classification_reportprint(classification_report(ytest, yfit, target_names=faces.target_names)) 精度(precision) = 正确预测的个数(TP)/被预测正确的个数(TP+FP) 召回率(recall)=正确预测的个数(TP)/预测个数(TP+FN) F1 = 2精度召回率/(精度+召回率) from sklearn.metrics import confusion_matrixmat = confusion_matrix(ytest, yfit)sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=faces.target_names, yticklabels=faces.target_names)plt.xlabel('true label')plt.ylabel('predicted label');]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22单元语法]]></title>
    <url>%2F2019%2F01%2F27%2F22%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[たら&lt;假定条件&gt;条件从句～たら表示动作或者事物存在的假定条件。主句所陈述的是在该条件下进行的动作行为或发生的情况。 接续： Ｖたら A詞干+かったら Na/N+だったら ✿汉语：如果～就～、如果～的话～ 1.もし分からないことがあったら、調べてください。(2010年题)2.近所の人に会ったら、挨拶しましょう。(2009年真题)3.元気だったら、またいつか会えるね。 Ｖてみる＜尝试性动作＞ 表示尝试着进行某动作或做某事。 ✿汉语：～一下，试着~，~一看 1.友達が怪我で入院したと聞き、慌てて病院に行ってみると思っていたよりも元気で安心した。(2013年真题)2.私が最も行ってみたい寺は京都にある。 (2012年真题)3.旅行のことはもう一度皆さんと相談してみる。 ~そうだ&lt;间接引语&gt;表示间接引语，主要用于说话人转述从其他地方获得的信息。有时用Nによると来明确指示信息的来源。接续：简体句子+そうだ ✿汉语：听说~，据说~★：否定形式：「～ないそうだ」。 1.来週、うちの近くでお祭りがあるそうだ。2.友達によると、去年の試験は簡単だったそうだ。3.天気予報によると、明日は雨だそうだ。 って＜引用＞1、表示引用 ，口语 同～と（言う/思う） 接续：句子って 1.彼はすぐ来るって言ってるよ 。2.めんどくさいって思うときどうする? 2、ＮってＮ 叫…的… 同という これ、夏目漱石って作家の書いた本です。 3、Ｎ/A/Vって 主题 （提出话题，下定义） 1.ワールドカップ って何のことですか。2.若いっていいですね。3.反対するって、勇気のいることです。 ~なんて&lt;主题&gt;表示意外或惊讶，有时还带有轻蔑的口气。接续：句子简体/名词 1.初めて買った人が一等に当たったなんて、すごいですね。2.あんな人が社長なんて信じられない。 人物名词を対象に（して） &lt;动作对象&gt;表示以该人物为对象实施某一行为。 ✿汉语：以…为对象 1.大学生を対象に英語を教える。2.中国にいる日本人を対象にして生活調査を実施した。 Nを中心に（して）＜核心内容＞ ✿以…为中心，以…为主（进行某动作）★：还有其他形式：～を中心とする ～を中心とした 1.この作者の作品は、若い女性を中心に読まれている。(2003年真题)2.日本語を中心にして、様々な授業を受けている。 ～と考えられる/思われる れる、られる自动态。自动态表示这些心理活动是自然而然产生的人类感情。并非所有动词都有相对的自动态，一般仅限于表示思想思考、感觉等心理活动的词。★： 思う－思われる (一类动词：う ＝＞ あ+れる) 案じる－案じられる （二类动词：る ＝＞ られる） ～するー～される (三类动词： する ＝＞ される ; くる ＝＞ こられる) 1.来年は国の経済が回復すると思われます。2.この問題は子供には難しいと思われる。 使用的动词：案じる（担心） 思う（想） 思い出す（想起） 感じる(感觉) 偲ぶ（怀念） 考える（思考） ～ために/～ための(N) ＜目的＞说明：表示目的。从句谓语动词多为意志动词。接续：Vる・Ｎ＋の ために ✿汉语：为了★注意：前后两个句子的主语必须要一致 1.日本で働くために日本語を勉強している。(2008年真题)2.応援してくれているファンのためにも勝ちたい。 (2012年真题)3.弟が日本に留学するために、父はお金を貯めています。（ｘ） ~ために&lt;原因&gt;一般指客观原因，主句谓语动词多为非自主动词。多用于书面语或比较郑重的场合。ために后项多为消极结果。接续：简体句，其中「Naな＋, Ｎの＋」 ✿汉语：因为~，由于~ 1.携帯電話を忘れたために、連絡ができなかった。(2009年真题)2.台風のために学校が休みになった。 Vるように&lt;目的&gt;用于表达要达到的目标或目的。主句一般为达到该目标或目的所采取的手段。从句谓语动词多为非意志动词。 Eg.できる・見える・わかる・なる 接续：Ｖる・Ｖない＋ように ✿汉语：为了~避免~ 1.思いついたアイディアを忘れてしまわないように必ずノートを持ち歩くようにしている。(2013年真题)2.よく見えるように、大きく書きました。 ために VS ように(目的)1.「ために」前后从句为同一主语；「ように」前后主语可不一样。2.「ために」前面动词一般为意志性动词； 「ように」前面则多为无意志性动词（分かる、可能态、ｖない）。3.「ために」侧重人的主观意志，实现某种动作 「ように」表示实现某种状态，情形。 (どんなに・いくら)～ても＜转折性条件＞前接转折性条件。主句从句之间关系一般不符合常理。★：どんなに：强调程度深 いくら：强调动作重复，数量，程度接续：Ｖても Ｎ・Naでも Aくても ✿汉语：即使也要；不管再也 どんなに～でしょう＜感叹＞该句式用于构成感叹句，表喜悦，悲伤，期盼等心情。 ✿汉语：多么~~ 1.N1に受かったら、どんなにうれしいでしょう。2.子供が重い病気になったら、親はどんなに悲しいでしょう。 ～こと&lt;名词化&gt;こと作为形式名词使用时一般表示名词化，就是说将整个句子成分变成名词性的成分。这样使它们可以接格助词或判断词。接续：连体形+こと 1.銀行の名前が変わったことを知らなかった。(2006年真题)2.毎日努力することが一番大事だ。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语义分割]]></title>
    <url>%2F2019%2F01%2F25%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[语义分割 semantic segmentationPascal VOC CityScapes DatasetPascal VOC 2012： http://host.robots.ox.ac.uk/pascal/VOC/voc2012/ https://www.dropbox.com/s/oeu149j8qtbs1x0/SegmentationClassAug.zip?dl=0 Paper： https://arxiv.org/pdf/1706.05587.pdfSource Code： https://github.com/NanqingD/DeepLabV3-Tensorflow 基础Convolution CNN Image Source: https://skymind.ai/wiki/convolutional-network TensorFlowGraph and Session： Tensorflow separates definition of computations from their execution DeepLabAtrous Convolution Residual Unit Network ​ Softmax Loss Function H(y,p)=-\sum_iy_ilog(p_i)​ Data Preprocessing​ Train/Evaluation​ Finetuning]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas]]></title>
    <url>%2F2019%2F01%2F25%2Fpandas%2F</url>
    <content type="text"><![CDATA[Series对象pandas库的Series对象用来表示一维数据结构，跟数组类似，但多了一些额外的功能，它的内部结构很简单(如下表)，由两个相互关联的数组组成，其中主数组用于存放数据（Numpy任意类型数据）。主数组的每个元素都有一个与之相关联的标签，这些标签存储的另一个叫做Index的数组中。 |Series| -|- index|value 0|12 1|-4 2|7 3|9 In: s = pd.Series([12,-4,7,9])s out: 0 121 -42 73 9dtype: int64 可以看出左侧Index是一列标签，右侧是标签对应的元素 声明Series时，若不指定标签，pandas默认使用从0开始一次递增的数值作为标签。这种情况下，标签与Series对象中的元素索引一致。但是最好使用有意义的标签，用以区分和识别每个元素 in: s = pd.Series([12,-4,7,9],index=['a','b','c','d'])s out: a 12b -4c 7d 9dtype: int64 获取元素s.values array([12, -4, 7, 9], dtype=int64) s.index Index([‘a’, ‘b’, ‘c’, ‘d’], dtype=’object’) s[2] 7 s[&apos;c&apos;] 7 in: s[:2] out: a 12b -4dtype: int64 in: s[[&apos;b&apos;,&apos;c&apos;]] out: b -4c 7dtype: int64 为元素赋值in: s[1]=0s out: a 12b 0c 7d 9dtype: int64 in: s[&apos;b&apos;] = 1s out: a 12b 1c 7d 9dtype: int64 用Numpy数组或其他Series对象定义新Series对象in: a = np.array([1,2,3,4])b= pd.Series(a)b out: 0 11 22 33 4dtype: int32 in: c= pd.Series(b)c out: 0 11 22 33 4dtype: int32 这样做时不要忘记新Series对象中的元素不是原Num数组或Series对象的副本，而是对他们的引用，也就是说，这些对象是动态插入到新Series对象中。如改变原有对象元素的值，新Series对象中这些元素也会发生改变。 in: b[2]=11b out: 0 11 22 113 4dtype: int32 in: c out: 0 11 22 113 4dtype: int32 筛选元素pandas库的开发是以NumPy库为基础的，因此就数据结构而言，NumPy数组的多种操作方法得以扩展到Series对象中，其中就是根据条件筛选数据结构中的元素之一方法。 in: s[s&gt;8] out: a 12d 9dtype: int64 运算和数学函数适用于NumPy数组的运算符（+，-，* ，/ ）或其他数学函数，也适用于Series对象。 in: s / 2 out: a 6.0b 0.5c 3.5d 4.5dtype: float64 in: s out: a 12b 1c 7d 9dtype: int64 NumPy库的数学函数，必须制定他们出处np,并把Series实例作为参数传入。 in: np.log(s) out: a 2.484907b 0.000000c 1.945910d 2.197225dtype: float64 Series对象的组成元素in: color = pd.Series([1,0,2,1,2,3],index=['white','white','blue','green','green','yellow'])color out: white 1white 0blue 2green 1green 2yellow 3dtype: int64 color.unique() array([1, 0, 2, 3], dtype=int64) 返回一个数组，包含去重后的元素，但乱序 in: color.value_counts() out: 2 21 23 10 1dtype: int64 返回各个不同的元素，还计算每个元素在Series中出现次数 in: color.isin([0,3]) out: white Falsewhite Trueblue Falsegreen Falsegreen Falseyellow Truedtype: bool 判断给定的一列元素是否包含在数据结构中,返回布尔值 in: color[color.isin([0,3])] out: white 0yellow 3dtype: int64 NaNin: s = pd.Series([1,2,np.NaN,14])s out: 0 1.01 2.02 NaN3 14.0dtype: float64 in: s.isnull() out: 0 False1 False2 True3 Falsedtype: bool in: s.notnull() out: 0 True1 True2 False3 Truedtype: bool in: s[s.notnull()] out: 0 1.01 2.03 14.0dtype: float64 in: s[s.isnull()] out: 2 NaNdtype: float64 Series用作字典in: mydict = &#123;&apos;red&apos;:2000,&apos;blue&apos;:1000,&apos;yellow&apos;:500,&apos;orange&apos;:1000&#125;myseries = pd.Series(mydict)myseries out: blue 1000orange 1000red 2000yellow 500dtype: int64 索引数组用字典的键来填充，每个索引所对应的元素为用作索引的键在字典中对应的值。你还可以单独制定索引，pandas会控制字典的键和数组索引标签之间的相关性。如遇缺失值处，pandas就会为其添加NaN。 in: colors = [&apos;red&apos;,&apos;yellow&apos;,&apos;orange&apos;,&apos;blue&apos;,&apos;green&apos;]myseries = pd.Series(mydict,index =colors)myseries out: red 2000.0yellow 500.0orange 1000.0blue 1000.0green NaNdtype: float64 Series 对象之间的运算in: mydict = &#123;&apos;red&apos;:200,&apos;blue&apos;:100,&apos;yellow&apos;:50,&apos;orange&apos;:100,&apos;black&apos;:700&#125;myseries2 = pd.Series(mydict)myseries2 out: black 700blue 100orange 100red 200yellow 50dtype: int64 in: myseries + myseries2 out: black NaNblue 1100.0green NaNorange 1100.0red 2200.0yellow 550.0dtype: float64 DataFrame对象DataFrame这种列表式数据结构跟工作表（最常见的是Excel工作表）极为相似，其设计初衷是将Series的使用场景由一维扩展到多维。DataFrame由按一定顺序排列的多列数据组成，各列数据类型可以有不同。 定义DataFrame对象data = &#123;&apos;color&apos;:[&apos;blue&apos;,&apos;green&apos;,&apos;yellow&apos;,&apos;red&apos;,&apos;white&apos;],&apos;object&apos;:[&apos;ball&apos;,&apos;pen&apos;,&apos;pecil&apos;,&apos;paper&apos;,&apos;mug&apos;],&apos;price&apos;:[1.2,1.0,0.6,0.9,1.7]&#125;frame = pd.DataFrame(data)frame 如果用来创建DataFrame对象的dict对象包含一些用不到的数据，你可以只选择自己感兴趣的。在DataFrame构造函数中，用columns选项制定需要的列即可。新建的DataFrame各列顺序与你制定的列顺序一致，而与他们在字典中的顺序无关。 frame2 = pd.DataFrame(data,columns=[&apos;object&apos;,&apos;price&apos;])frame2 DataFrame对象和Series一样，如果Index数组没有明确制定标签，pandas也会自动为其添加一列从0开始的数值作为索引。如果想用标签作为DataFrame的索引，则要把标签放在数组中，赋给index选项 frame3 = pd.DataFrame(data,index=[&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;,&apos;five&apos;])frame3 选取元素frame.columns #列名 Index([‘color’, ‘object’, ‘price’], dtype=’object’) frame.index #索引 RangeIndex(start=0, stop=5, step=1) frame.values #所有元素 out: array([[&apos;blue&apos;, &apos;ball&apos;, 1.2], [&apos;green&apos;, &apos;pen&apos;, 1.0], [&apos;yellow&apos;, &apos;pecil&apos;, 0.6], [&apos;red&apos;, &apos;paper&apos;, 0.9], [&apos;white&apos;, &apos;mug&apos;, 1.7]], dtype=object) in: frame[&apos;price&apos;] out: 0 1.21 1.02 0.63 0.94 1.7Name: price, dtype: float64 in: frame.price out: 0 1.21 1.02 0.63 0.94 1.7Name: price, dtype: float64 in: frame.ix[2] out: color yellowobject pecilprice 0.6Name: 2, dtype: object frame in: frame.loc[2] out: color yellowobject pecilprice 0.6Name: 2, dtype: object in: frame.iloc[2] out: color yellowobject pecilprice 0.6Name: 2, dtype: object frame.loc[[2,4]] frame.iloc[[2,4]] #i表示整数 frame3.loc[&apos;one&apos;] out: color blueobject ballprice 1.2Name: one, dtype: object frame[1:3] frame[&apos;object&apos;][3] ‘paper’ 赋值frame.index.name = &apos;id&apos;frame.columns.name = &apos;item&apos;frame frame[&apos;new&apos;] = 12frame frame[&apos;new&apos;] = [3.0,1.3,2.2,0.8,1.1]frame in: ser = pd.Series(np.arange(5))ser out: 0 01 12 23 34 4dtype: int32 frame[&apos;new&apos;] = serframe frame[&apos;price&apos;][2] = 3.3frame frame.set_value(2,&apos;price&apos;,2) frame.at[2,&apos;price&apos;]=22frame frame.isin([1.0,&apos;pen&apos;]) frame[frame.isin([1.0,&apos;pen&apos;])] del frame['new']frame 删除一列 d1 = &#123;&apos;red&apos;:&#123;2012:22,2013:33&#125;,&apos;white&apos;:&#123;2011:13,2012:22,2013:16&#125;,&apos;blue&apos;:&#123;2011:17,2012:27,2013:18&#125;&#125;frame2 = pd.DataFrame(d1)frame2 frame2.T Index对象in: ins = pd.Series([5,0,3,8,4],index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;,&apos;green&apos;])ins out: red 5blue 0yellow 3white 8green 4dtype: int64 ins.index Index([‘red’, ‘blue’, ‘yellow’, ‘white’, ‘green’], dtype=’object’) ins.idxmin() #返回索引值最小的元素 ‘blue’ ins.idxmax() #返回索引值最大的元素 ‘white’ 重复标签的Indexserd = pd.Series(range(6),index=[&apos;white&apos;,&apos;white&apos;,&apos;blue&apos;,&apos;green&apos;,&apos;green&apos;,&apos;yellow&apos;])serd out: white 0white 1blue 2green 3green 4yellow 5dtype: int64 in: serd[&apos;white&apos;] out: white 0white 1dtype: int64 serd.index.is_unique False 判断是否存在重复项 frame.index.is_unique True frame 索引对象的其他功能更换索引ser = pd.Series([2,3,4,5],index=[&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;])ser out: one 2two 3three 4four 5dtype: int64 in: ser.reindex([&apos;three&apos;,&apos;four&apos;,&apos;five&apos;,&apos;one&apos;]) out: three 4.0four 5.0five NaNone 2.0dtype: float64 自动编制索引ser2 = pd.Series([1,5,6,3],index =[0,3,5,6])ser2 out: 0 13 55 66 3dtype: int64 in: ser2.reindex(range(6),method=&apos;ffill&apos;) #插值，以得到一个完整的序列（前插） out: 0 11 12 13 54 55 6dtype: int64 in: ser2.reindex(range(6),method=&apos;bfill&apos;) #插值，以得到一个完整的序列（后插） out: 0 11 52 53 54 65 6dtype: int64 删除pandas提供专门的删除操作函数：drop() ser3 = pd.Series(np.arange(4.),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;])ser3 out: red 0.0blue 1.0yellow 2.0white 3.0dtype: float64 in: ser3.drop('yellow') out: red 0.0blue 1.0white 3.0dtype: float64 in: ser3.drop([&apos;blue&apos;,&apos;white&apos;]) out: red 0.0yellow 2.0dtype: float64 frame = pd.DataFrame(np.arange(16).reshape((4,4)),index=[&apos;blue&apos;,&apos;yellow&apos;,&apos;red&apos;,&apos;white&apos;],columns=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])frame frame.drop([&apos;blue&apos;,&apos;yellow&apos;]) #默认删除行 frame.drop([&apos;pen&apos;,&apos;pencil&apos;],axis=1) #删除列 add() sub() div() mul()in: ser4 = pd.Series(np.arange(4.),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;])ser4 out: red 0.0blue 1.0yellow 2.0white 3.0dtype: float64 in: ser5 = pd.Series(np.arange(5.),index=[&apos;red&apos;,&apos;blue&apos;,&apos;black&apos;,&apos;brown&apos;,&apos;yellow&apos;])ser5 out: red 0.0blue 1.0black 2.0brown 3.0yellow 4.0dtype: float64 in: ser4 + ser5 out: black NaNblue 2.0brown NaNred 0.0white NaNyellow 6.0dtype: float64 frame1 = pd.DataFrame(np.arange(16).reshape((4,4)),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;],columns=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])frame1 frame2 = pd.DataFrame(np.arange(12).reshape((4,3)),index=[&apos;blue&apos;,&apos;green&apos;,&apos;white&apos;,&apos;yellow&apos;],columns=[&apos;mug&apos;,&apos;pen&apos;,&apos;ball&apos;])frame2 frame1 + frame2 frame1.add(frame2) frame2 = pd.DataFrame(np.arange(16).reshape((4,4)),index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;],columns=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])frame2 ser1 = pd.Series(np.arange(4),index=[&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])ser1 out: ball 0pen 1pencil 2paper 3dtype: int32 frame2 - ser1 ser1[&apos;mug&apos;] = 9ser1 out: ball 0pen 1pencil 2paper 3mug 9dtype: int64 frame2 - ser1 通用函数np.sqrt(frame2) #平方根 按行或列执行操作的函数f = lambda x:x.max() - x.min()frame2.apply(f) out: ball 12pen 12pencil 12paper 12dtype: int64 in: frame2.apply(f,axis = 1) # 行 out: red 3blue 3yellow 3white 3dtype: int64 in: def f(x): return pd.Series([x.min(),x.max()],index=['min','max']) frame2.apply(f) 统计函数frame2.sum() out: ball 24pen 28pencil 32paper 36dtype: int64 in: frame.describe() 排序根据索引排序ser = pd.Series([5,0,3,8,4],index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;,&apos;green&apos;])ser out: red 5blue 0yellow 3white 8green 4dtype: int64 in: ser.sort_index() #a-zp升序 out: blue 0green 4red 5white 8yellow 3dtype: int64 in: ser.sort_index(ascending=False) #降序 out: yellow 3white 8red 5green 4blue 0dtype: int64 in: frame2 frame2.sort_index() frame2.sort_index(axis=1) 根据对象排序frame2.sort_values(by = &apos;pen&apos;) frame2.at[&apos;red&apos;,&apos;pen&apos;]=18frame2 frame2.sort_values(by = &apos;pen&apos;) 排位in: ser.rank() #排位 out: red 4.0blue 1.0yellow 2.0white 5.0green 3.0dtype: float64 in: ser.rank(method = &apos;first&apos;) out: red 4.0blue 1.0yellow 2.0white 5.0green 3.0dtype: float64 in: ser.rank(ascending=False) #降序 out: red 2.0blue 5.0yellow 4.0white 1.0green 3.0dtype: float64 in: frame2.rank() frame3 = frame2.sort_values(by = &apos;pen&apos;)frame3.rank() 相关性和协方差seq2 = pd.Series([3,4,3,4,5,4,3,2],[&apos;2006&apos;,&apos;2007&apos;,&apos;2008&apos;,&apos;2009&apos;,&apos;2010&apos;,&apos;2011&apos;,&apos;2012&apos;,&apos;2013&apos;])seq2 out: 2006 32007 42008 32009 42010 52011 42012 32013 2dtype: int64 seq = pd.Series([1,2,3,4,4,3,2,1],[&apos;2006&apos;,&apos;2007&apos;,&apos;2008&apos;,&apos;2009&apos;,&apos;2010&apos;,&apos;2011&apos;,&apos;2012&apos;,&apos;2013&apos;])seq out: 2006 12007 22008 32009 42010 42011 32012 22013 1dtype: int64 in: seq.corr(seq2) 0.7745966692414835 seq.cov(seq2) 0.8571428571428571 frame2 = pd.DataFrame([[1,4,3,6],[4,5,6,1],[3,3,1,5],[4,1,6,4]],index=[&apos;red&apos;,&apos;blue&apos;,&apos;yellow&apos;,&apos;white&apos;],columns = [&apos;ball&apos;,&apos;pen&apos;,&apos;pencil&apos;,&apos;paper&apos;])frame2 frame2.corr() frame2.cov() corrwith()方法可以计算DataFrame对象的列或行与Series对象或其他DataFrame对象元素两两之间的相关性 frame2.corrwith(ser) out: ball -0.140028pen -0.869657pencil 0.080845paper 0.595854dtype: float64 in: f1 = frame2.corrwith(frame)f1 out: ball -0.182574pen -0.831522pencil 0.105409paper 0.597614dtype: float64 in: f1.dropna() #删除NaN out: ball -0.182574pen -0.831522pencil 0.105409paper 0.597614dtype: float64 in: f1[f1.notnull()] out: ball -0.182574pen -0.831522pencil 0.105409paper 0.597614dtype: float64 in: frame3 = pd.DataFrame([[6,np.nan,6],[np.nan,np.nan,np.nan],[2,np.nan,5]],index = [&apos;blue&apos;,&apos;green&apos;,&apos;red&apos;],columns = [&apos;ball&apos;,&apos;mug&apos;,&apos;pen&apos;])frame3 frame3.dropna() frame3.dropna(how =&apos;all&apos;) frame3.fillna(0) #指定缺失值填充 frame3.fillna(&#123;&apos;ball&apos;:1,&apos;mug&apos;:0,&apos;pen&apos;:99&#125;) mser = pd.Series(np.random.rand(8),index=[[&apos;white&apos;,&apos;white&apos;,&apos;white&apos;,&apos;blue&apos;,&apos;blue&apos;,&apos;red&apos;,&apos;red&apos;,&apos;red&apos;],[&apos;up&apos;,&apos;down&apos;,&apos;right&apos;,&apos;up&apos;,&apos;down&apos;,&apos;up&apos;,&apos;down&apos;,&apos;left&apos;]])mser #等级索引 out: white up 0.096961 down 0.633575 right 0.652724blue up 0.269485 down 0.518140red up 0.143647 down 0.335544 left 0.574777dtype: float64 in: mser.index out: MultiIndex(levels=[[&apos;blue&apos;, &apos;red&apos;, &apos;white&apos;], [&apos;down&apos;, &apos;left&apos;, &apos;right&apos;, &apos;up&apos;]], labels=[[2, 2, 2, 0, 0, 1, 1, 1], [3, 0, 2, 3, 0, 3, 0, 1]]) in: mser[&apos;white&apos;] out: up 0.096961down 0.633575right 0.652724dtype: float64 in: mser[:,&apos;up&apos;] out: white 0.096961blue 0.269485red 0.143647dtype: float64 mser[&apos;white&apos;,&apos;up&apos;] 0.09696136257353527 frame = mser.unstack() #把等级索引Series转换成简单的DataFrame对象frame frame.stack() out: blue down 0.518140 up 0.269485red down 0.335544 left 0.574777 up 0.143647white down 0.633575 right 0.652724 up 0.096961dtype: float64 mframe = pd.DataFrame(np.random.randn(16).reshape(4,4), index =[[&apos;white&apos;,&apos;white&apos;,&apos;red&apos;,&apos;red&apos;],[&apos;up&apos;,&apos;down&apos;,&apos;up&apos;,&apos;down&apos;]], columns=[[&apos;pen&apos;,&apos;pen&apos;,&apos;paper&apos;,&apos;paper&apos;],[1,2,1,2]])mframe mframe.columns.names =[&apos;objects&apos;,&apos;id&apos;]mframe.index.names = [&apos;colors&apos;,&apos;status&apos;]mframe mframe.swaplevel(&apos;colors&apos;,&apos;status&apos;) #互换位置 mframe.sort_index(level=&apos;colors&apos;) #根据层级排序 mframe.sum(level=&apos;colors&apos;) #按照层级统计 mframe.sum(level=&apos;id&apos;,axis=1) #按照层级统计 pandas：数据读写 csv和文本文件多年以来，人们已习惯于文本文件的读写，特别是列表形式的数据。如果文件每一行的多 个元素是用逗号隔开的，则这种格式叫作CSV，这可能是最广为人知和最受欢迎的格式。 其他由空格或制表符分隔的列表数据通常存储在各种类型的文本文件中（扩展名一般 为.txt )。 因此这种文件类型是最常见的数据源，它易于转录和解释。pandas的下列函数专门用来处理 这种文件类型： read_csv read_table to_csv csvframe = pd.read_csv(&apos;myCSV_01.csv&apos;)csvframe csvframe = pd.read_table(&apos;myCSV_01.csv&apos;,sep=&apos;,&apos;)csvframe 第一行作为列名称，但是往往很多数据第一行不是列名 csvframe = pd.read_csv(&apos;myCSV_02.csv&apos;)csvframe csvframe = pd.read_csv(&apos;myCSV_02.csv&apos;,header=None) #添加默认表头csvframe csvframe = pd.read_csv(&apos;myCSV_02.csv&apos;,names=[&apos;white&apos;,&apos;red&apos;,&apos;blue&apos;,&apos;green&apos;,&apos;animal&apos;]) #指定表头csvframe csvframe = pd.read_csv(&apos;myCSV_03.csv&apos;)csvframe csvframe = pd.read_csv(&apos;myCSV_03.csv&apos;,index_col=[&apos;color&apos;,&apos;status&apos;]) #等级索引csvframe pd.read_table(&apos;ch05_04.txt&apos;,sep=&apos;\s+&apos;) #根据正则解析 pd.read_table(&apos;ch05_05.txt&apos;,sep=r&apos;\D+&apos;,header=None,engine=&apos;python&apos;) 另一种很常见的情况是，解析数据时把空行排除在外。文件中的表头或没有必要的注释，有时用不到。使用skiprows选项，可以排除多余的行。把要排除的行的行号放到数组中，赋给该选项即可。 pd.read_table(&apos;ch05_06.txt&apos;,sep=&apos;,&apos;,skiprows=[0,1,3,6]) 从TXT文件读取部分数据处理大文件或是只对文件部分数据感兴趣时，往往需要按照部分（块）读取文件，因为只需 要部分数据s这两种情况都得使用迭代。 举例来说，假如只想读取文件的一部分，可明确指定要解析的行号，这时要用到nrows和skiprows选项。你可以指定起始行n (n = SkipRows)和从起始行往后读多少行（nrows = i). pd.read_csv(&apos;myCSV_02.csv&apos;,skiprows=[2],nrows=3,header=None) 另外一项既有趣又很常用的操作是切分想要解析的文本，然后遍历各个部分，逐一对其执行 某一特定操作。 例如，对于一列数字，每隔两行取一个累加起来，最后把和插人到Series对象中„这个小例 子理解起来很简单，也没有实际应用价值，但是一旦领会了其原理，你就能将其用到更加复杂的情况。 out = pd.Series()pieces = pd.read_csv(&apos;myCSV_01.csv&apos;,chunksize=3)pieces In: i = 0for piece in pieces: print(piece['white']) out.at[i] = piece['white'].sum() i += 1 out: 0 11 22 3Name: white, dtype: int643 24 45 4Name: white, dtype: int64 in: out out: 0 61 10dtype: int64 往CSV文件写入数据frame1 frame1.to_csv(&apos;ch05_07.csv&apos;) 把DataFrame写人文件时，索引和列名称连同数据一起写入。使用index和 header选项，把它们的值设置为False,可取消这一默认行为 frame1.to_csv(&apos;ch05_07b.csv&apos;,index =False,header=False)frame3 需要注意的是，数据结构中的NaN写入文件后，显示为空字段 frame3.to_csv(&apos;ch05_08.csv&apos;) 可以用to_csv()函数的na_rep选项把空字段替换为你需要的值。常用值有NULL、0和NaN frame3.to_csv(&apos;ch05_09.csv&apos;,na_rep=&apos;NaN&apos;) 读写HTML文件frame = pd.DataFrame(np.arange(4).reshape(2,2))frame print(frame.to_html()) out: &lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt; &lt;thead&gt; &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;0&lt;/th&gt; &lt;th&gt;1&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;0&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; frame = pd.DataFrame( np.random.random((4,4)),index = [&apos;white&apos;,&apos;black&apos;,&apos;red&apos;,&apos;blue1&apos;],columns = [&apos;up&apos;,&apos;down&apos;,&apos;right&apos;,&apos;left&apos;])frame in: s = [&apos;&lt;HTML&gt;&apos;]s.append(&apos;&lt;HEAD&gt;&lt;TITLE&gt;My DataFrame&lt;/TITLE&gt;&lt;/HEAD&gt;&apos;)s.append(&apos; &lt;B0DY&gt;&apos;)s.append(frame.to_html())s.append(&apos;&lt;/BODY&gt;&lt;/HTML&gt;&apos;)html = &apos;&apos;.join(s)html_file = open(&apos;myFrame.html&apos;,&apos;w&apos;)html_file.write(html)html_file.close() 读取web_frames = pd.read_html(&apos;myFrame.html&apos;)web_frames[0] ranking = pd.read_html(&apos;http://www.meccanismocomplesso.org/en/ meccanismo-complesso-sito-2/classifica-punteggio/&apos;)ranking[0] 此处省略。。。 ranking[1] 从XML读取数据pandas的所有I/O API函数中，没有专门用来处理XML(可扩展标记语言）格式的。虽然没有， 但这种格式其实很重要，因为很多结构化数据都是以XML格式存储的。pandas没有专门的处理函 数也没关系，因为Python有很多读写XML格式数据的库（除了pandas)。 其中一个库叫作lxml,它在大文件处理方面性能优异，因而从众多同类库之中脱颖而出。这 一节将介绍如何用它处理XML文件，以及如何把它和pandas整合起来，以最终从XML文件中获 取到所需数据并将其转换为DataFrame对象。 from lxml import objectifyxml = objectify.parse('books.xml')xml root = xml.getroot()root root.Book.Author ‘ 272103_l_EnRoss, Mark’ root.Book.PublishDate ‘2014-22-0l’ mes = root.Book.getchildren()mes [‘ 272103_l_EnRoss, Mark’, ‘XML Cookbook’, ‘Computer’, 23.56, ‘2014-22-0l’] [child.tag for child in mes] [‘Author’, ‘Title’, ‘Genre’, ‘Price’, ‘PublishDate’] [child.text for child in mes] [‘ 272103_l_EnRoss, Mark’, ‘XML Cookbook’, ‘Computer’, ‘23.56’, ‘2014-22-0l’] 读写 Microsoft Excel文件 to_excel() read_excel() 能够读取.xls和.xlsx两种类型的文件 读写JSON数据 read_json() to_json() HDF5格式至此，已学习了文本格式的读写。若要分析大量数据，最好使用二进制格式。Python有多 种二进制数据处理工具。HDF5库在这个方面取得了一定的成功。 HDF代表等级数据格式（hierarchical data format )。HDF5库关注的是HDF5文件的读写，这种文件的数据结构由节点组成，能够存储大量数据集。 该库全部用c语言开发，提供了python/matlab和Java语言接口。它的迅速扩展得益于开发人 员的广泛使用，还得益于它的效率，尤其是使用这种格式存储大量数据，其效率很高。比起其他处理起二进制数据更为简单的格式，HDF5支持实时压缩，因而能够利用数据结构中的重复模式压缩文件。 目前，Python提供两种操纵HDF5格式数据的方法：PyTables和h5py。这两种方法有几点不同，选用哪一种很大程度上取决于具体需求。 h5py为HDF5的高级API提供接口。PyTables封装了很多HDF5细节，提供更加灵活的数据容器、索引表、搜索功能和其他计算相关的介质。 pandas还有一个叫作HDFStore、类似于diet的类，它用PyTables存储pandas对象。使用HDF5格式之前，必须导人HDFStore类。 from pandas.io.pytables import HDFStoreframe = pd.DataFrame(np.arange(16).reshape(4,4),index=['white','black1','red','blue'],columns=['up','down','right','left'])frame1 store = HDFStore(&apos;mydata.h5&apos;)store[&apos;obj1&apos;] = frameframe2 store[&apos;obj2&apos;] = frame2store File path: mydata.h5 store[&apos;obj2&apos;] store[&apos;obj1&apos;] pickle ——python对象序列化pickle模块实现了一个强大的算法，能够对用Python实现的数据结构进行序列化（pickling) 和反序列化操作。序列化是指把对象的层级结构转换为字节流的过程。序列化便于对象的传输、存储和重建，仅用接收器就能重建对象，还能保留它的所有原始特征。 import pickledata = &#123; 'color': ['white','red'], 'value': [5, 7]&#125;pickled_data = pickle.dumps(data)pickled_data b’\x80\x03}q\x00(X\x05\x00\x00\x00colorq\x01]q\x02(X\x05\x00\x00\x00whiteq\x03X\x03\x00\x00\x00redq\x04eX\x05\x00\x00\x00valueq\x05]q\x06(K\x05K\x07eu.’ nframe = pickle.loads(pickled_data)nframe {‘color’: [‘white’, ‘red’], ‘value’: [5, 7]} 用pandas实现对象序列化用pandas库实现对象序列化（反序列化）很方便，所有工具都是现成的，无需在Python会话中导入cPickle模块，所有的操作都是隐式进行的。 pandas的序列化格式并不是完全使用ASCII编码 frame = pd.DataFrame(np.arange(16).reshape(4,4), index = [&apos;up&apos;,&apos;down&apos;,&apos;left&apos;,&apos;right&apos;])frame.to_pickle(&apos;frame.pkl&apos;)pd.read_pickle(&apos;frame.pkl&apos;) pandas的所有序列化和反序列化操作都在后台运行，用户根本看不到。这使得这两项操作对数据分析人员而言尽可能简单和易于理解。 注意 :使用这种格式时，要确保打开的文件的安全性。pickle格式无法规避错误和恶意数据。 对接数据库在很多应用中，所使用的数据来自于文本文件的很少，因为文本文件不是存储数据最有效的方式 数据往往存储于SQL类关系型数据库，作为补充，NoSQL数据库近来也已流行开来。 从SQL数据库加载数据，将其转换为DataFrame对象很简单pandas提供的几个函数简化了该过程。 pandas.io.sql模块提供独立于数据库、叫作sqlalchemy的统一接口。该接口简化了连接模式， 不管对于什么类型的数据库，操作命令都只有一套。连接数据库使用create_engine()函数，你可以用它配置驱动器所需的用户名、密码、端口和数据库实例等所有属性。 数据库URL的典型形式是： dialect+driver://username:password@host:port/database 名称的标识名称，例如sqlite，mysql，postgresql，oracle，或mssql。drivername是用于使用全小写字母连接到数据库的DBAPI的名称。如果未指定，则将导入“默认”DBAPI（如果可用） - 此默认值通常是该后端可用的最广泛的驱动程序。 from sqlalchemy import create_engine PostgreSQLdefaultengine = create_engine(‘postgresql://scott:tiger@localhost/mydatabase’) psycopg2engine = create_engine(‘postgresql+psycopg2://scott:tiger@localhost/mydatabase’) pg8000engine = create_engine(‘postgresql+pg8000://scott:tiger@localhost/mydatabase’) MySqldefaultengine = create_engine(‘mysql://scott:tiger@localhost/foo’) mysql-pythonengine = create_engine(‘mysql+mysqldb://scott:tiger@localhost/foo’) MySQL-connector-pythonengine = create_engine(‘mysql+mysqlconnector://scott:tiger@localhost/foo’) OurSQLengine = create_engine(‘mysql+oursql://scott:tiger@localhost/foo’) Oracleengine = create_engine(‘oracle://scott:tiger@127.0.0.1:1521/sidname’) engine = create_engine(‘oracle+cx_oracle://scott:tiger@tnsname’) Microsoft SQLpyodbcengine = create_engine(‘mssql+pyodbc://scott:tiger@mydsn’) pymssqlengine = create_engine(‘mssql+pymssql://scott:tiger@hostname:port/dbname’) SQLite由于SQLite连接到本地文件，因此URL格式略有不同。URL的“文件”部分是数据库的文件名。 对于相对文件路径，这需要三个斜杠： sqlite:/// where is relative: engine = create_engine(‘sqlite:///foo.db’) 对于绝对文件路径，三个斜杠后面是绝对路径： Unix/Mac - 4 initial slashes in total engine = create_engine(‘sqlite:////absolute/path/to/foo.db’) Windows engine = create_engine(‘sqlite:///C:\path\to\foo.db’) Windows alternative using raw string engine = create_engine(r’sqlite:///C:\path\to\foo.db’) SQLite3数据读写学习使用Python内置的SQLite数据库sqlite3。SQLite3工具实现了简单、 轻量级的DBMS SQL,因此可以内置于用Python语言实现的任何应用。它很实用，你可以在单个文件中创建一个嵌入式数据库。 若想使用数据库的所有功能而又不想安装真正的数据库，这个工具就是最佳选择。若想在使用真正的数据库之前练习数据库操作，或在单一程序中使用数据库存储数据而无需考虑接口， SQLite3都是不错的选择。 frame = pd.DataFrame( np.arange(20).reshape(4,5), columns=['white','red','blue','black','green'])frame #连接SQLite3数据库engine = create_engine(&apos;sqlite:///foo.db&apos;)#把DataFrame转换为数据库表。frame.to_sql(&apos;colors&apos;,engine)#读取。pd.read_sql(&apos;colors&apos;,engine) 数据处理数据准备 加载 组装 合并（merging） 拼接（concatenation） 组合（combine） 变形（轴向旋转） 删除 合并对于合并操作，熟悉SQL的读者可以将其理解为JOIN操作，它使用一个或多个键把多行数据 结合在一起. 事实上，跟关系型数据库打交道的开发人员通常使用SQL的JOIN查询，用几个表共有的引用 值（键）从不同的表获取数据。以这些键为基础，我们能够获取到列表形式的新数据，这些数据是对几个表中的数据进行组合得到的。pandas库中这类操作叫作合并，执行合并操作的函数为 merge(). import pandas as pdimport numpy as npframe1 = pd.DataFrame( &#123;'id':['ball','pencil','pen','mug','ashtray'], 'price': [12.33,11.44,33.21,13.23,33.62]&#125;)frame1 frame2 = pd.DataFrame( &#123;'id':['pencil','pencil','ball','pen'], 'color': ['white','red','red','black']&#125;)frame2 pd.merge(frame1,frame2) frame1 = pd.DataFrame( &#123;'id':['ball','pencil','pen','mug','ashtray'], 'color': [' white','red','red','black','green'], 'brand': ['OMG','ABC','ABC','POD','POD']&#125;)frame1 frame2 = pd.DataFrame( &#123;&apos;id&apos;:[&apos;pencil&apos;,&apos;pencil&apos;,&apos;ball&apos;,&apos;pen&apos;], &apos;brand&apos;: [&apos;OMG&apos;,&apos;POD&apos;,&apos;ABC&apos;,&apos;POD&apos;]&#125;)frame2 pd.merge(frame1,frame2) pd.merge(frame1,frame2,on=&apos;id&apos;) pd.merge(frame1,frame2,on=&apos;brand&apos;) 假如两个DataFrame基准列的名称不一致，该怎样进行合并呢？为 了解决这个问题，你可以用left_on和right_on选项指定第一个和第二个DataFrame的基准列。 frame2.columns = [&apos;brand&apos;,&apos;sid&apos;]frame2 pd.merge(frame1,frame2,left_on=&apos;id&apos;,right_on=&apos;sid&apos;) merge()函数默认执行的是内连接操作；上述结果中的键是由交叉操作（intersection)得到的。 其他选项有左连接、右连接和外连接。外连接把所有的键整合到一起，其效果相当于左连接 和右连接的效果之和。连接类型用how选项指定。 frame2.columns = [&apos;brand&apos;,&apos;id&apos;] frame4 = pd.DataFrame( &#123;&apos;id&apos;:[&apos;ball&apos;,&apos;pencil&apos;,&apos;pen&apos;,&apos;mug&apos;,&apos;ashtray&apos;], &apos;color&apos;: [&apos; white&apos;,&apos;red&apos;,&apos;red&apos;,&apos;black&apos;,&apos;green&apos;], &apos;brand&apos;: [&apos;OMG&apos;,&apos;ABC&apos;,&apos;ABC&apos;,&apos;POD&apos;,&apos;POD&apos;]&#125;)frame4 pd.merge(frame4,frame2,on=&apos;id&apos;) pd.merge(frame4,frame2,on=&apos;id&apos;,how=&apos;outer&apos;) pd.merge(frame4,frame2,on=&apos;id&apos;,how=&apos;left&apos;) pd.merge(frame4,frame2,on=&apos;id&apos;,how=&apos;right&apos;) pd.merge(frame4,frame2,on=[&apos;id&apos;,&apos;brand&apos;],how=&apos;outer&apos;) 根据索引合并pd.merge(frame4,frame2,right_index=True, left_index=True) #frame4.join(frame2) #会报错，因为列名有重合 frame2.columns = [&apos;brand2&apos;,&apos;id2&apos;] frame4.join(frame2) 拼接另外一种数据整合操作叫作拼接（concatenation)。NumPy的concatenate()函数就是用于数 组的拼接操作。 array1 = np.arange(9).reshape((3,3))array1 array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) array2 = np.arange(9).reshape((3,3))+6array2 array([[ 6, 7, 8], [ 9, 10, 11], [12, 13, 14]]) np.concatenate([array1,array2],axis = 1) array([[ 0, 1, 2, 6, 7, 8], [ 3, 4, 5, 9, 10, 11], [ 6, 7, 8, 12, 13, 14]]) np.concatenate([array1,array2],axis = 0) array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 6, 7, 8], [ 9, 10, 11], [12, 13, 14]]) pandas库以及它的Series和DataFrame等数据结构实现了带编号的轴，它可以进一步扩展数组 拼接功能。pandas的concat()函数实现了按轴拼接的功能。 ser1 = pd.Series(np.random.rand(4),index=[1,2,3,4])ser1 1 0.6766142 0.6074903 0.4913704 0.687731dtype: float64 ser2 = pd.Series(np.random.rand(4),index=[5,6,7,8])ser2 5 0.1299626 0.6506537 0.7016358 0.820312dtype: float64 pd.concat([ser1,ser2]) 1 0.6766142 0.6074903 0.4913704 0.6877315 0.1299626 0.6506537 0.7016358 0.820312dtype: float64 concat()函数默认按照axis=0这条轴拼接数据，返回Series对象。如果指定axis=l，返回结果将是DataFrame对象。 pd.concat([ser1,ser2],axis=1) pd.concat([ser1,ser2],keys=[1,2]) #等级索引 1 1 0.676614 2 0.607490 3 0.491370 4 0.6877312 5 0.129962 6 0.650653 7 0.701635 8 0.820312dtype: float64 frame5 = pd.DataFrame(np.random.rand(9).reshape(3,3), index=[1,2,3],columns=['A','B','C'])frame5 frame2 = pd.DataFrame(np.random.rand(9).reshape(3,3), index=[4,5,6],columns=['A','B','C'])frame2 pd.concat([frame5,frame2]) pd.concat([frame5,frame2],axis = 1) 组合还有另外一种情况，我们无法通过合并或拼接方法组合数据。例如，两个数据集的索引完全或部分重合。 ser1 = pd.Series(np.random.rand(5),index=[1,2,3,4,5])ser1 1 0.4797042 0.9568983 0.7859664 0.8685565 0.134064dtype: float64 ser2 = pd.Series(np.random.rand(4),index=[2,4,5,6])ser2 2 0.3372204 0.5708065 0.4197856 0.140270dtype: float64 ser1.combine_first(ser2) 1 0.4797042 0.9568983 0.7859664 0.8685565 0.1340646 0.140270dtype: float64 ser2.combine_first(ser1) 1 0.4797042 0.3372203 0.7859664 0.5708065 0.4197856 0.140270dtype: float64 ser1[:3].combine_first(ser2[:3]) 1 0.4797042 0.9568983 0.7859664 0.5708065 0.419785dtype: float64 轴向旋转frame5 = pd.DataFrame(np.arange(9).reshape(3,3), index=['white','black','red'], columns=['ball','pen','pencil'])print(frame5) out: ball pen pencilwhite 0 1 2black 3 4 5red 6 7 8 in: frame6 = frame5.stack() #列变行frame6 out: white ball 0 pen 1 pencil 2black ball 3 pen 4 pencil 5red ball 6 pen 7 pencil 8dtype: int32 in: frame6.unstack() frame6.unstack(0) in: frame5.unstack() out: ball white 0 black 3 red 6pen white 1 black 4 red 7pencil white 2 black 5 red 8dtype: int32 in: longframe = pd.DataFrame(&#123; 'color':['white','white','white','red','red','red','black','black','black'], 'item':['ball','pen','mug','ball','pen','mug','ball','pen','mug'], 'value': np.random.rand(9)&#125;)longframe 这种记录数据的模式有几个缺点。例如其中一个缺点是，因为一些字段具有多样性和 重复性特点，所以选取列作为键时，这种格式的数据可读性较差，尤其是无法完全理解基准列和 其他列之间的关系a 除了长格式，还有一种把数据调整为表格形式的宽格式。这种模式可读性强，也易于连接其他表，且占用空间较少。因此一般而言，用它存储数据效率更高，虽然它的可操作性差，这一点 尤其体现在填充数据时。 如要选择一列或几列作为主键，所要遵循的规则是其中的元素必须是唯一的。 讲到格式转换，pandas提供了能够把长格式DataFrame转换为宽格式的pivot()函数，它以用 作键的一列或多列作为参数。 接着上面的例子，选择color列作为主键，item列作为第二主键，而它们所对应的元素则作 为DataFrame的新列。 wideframe = longframe.pivot('color','item')wideframe 这种格式的DataFrame对象更加紧凑，它里面的数据可读性也更强。 删除数据处理的最后一步是删除多余的行和列。 frame7 = pd.DataFrame(np.arange(9).reshape(3,3), index=['white','black','red'], columns=['ball','pen','pencil'])frame7 del frame7['ball'] #删除列frame7 frame7.drop(&apos;white&apos;) #删除行 frame7.drop(&apos;pen&apos;,axis=1) 数据转换删除重复元素dframe = pd.DataFrame(&#123; 'color': ['white','white','red','red','white'],'value': [2,1,3,3,2]&#125;)dframe DataFrame对象的duplicated()函数可用来检测重复的行，返回元素为布尔型的Series对象。 每个元素对应一行，如果该行与其他行重复（也就是说该行不是第一次出现），则元素为True; 如果跟前面不重复，则元素就为False。 dframe.duplicated() 0 False1 False2 False3 True4 Truedtype: bool 返回元素为布尔值的Series对象用处很大，特别适用于过滤操作。 dframe[dframe.duplicated()] 通常，所有重复的行都需要从DataFrame对象中删除。pandas库的drop_duplicates()函数实 现了删除功能，该函数返回的是删除重复行后的DataFmme对象。 dframe.drop_duplicates() 映射用映射替换元素frame8 = pd.DataFrame(&#123; 'item':['ball','mug','pen','pencil','ashtray'], 'color': ['white','rosso','verde','black','yellow'], 'price':[5.56,4.20,1.30,0.56,2.75]&#125;)frame8 要用新元素替换不正确的元素，需要定义一组映射关系。在映射关系中，旧元素作为键，新元素作为值。 newcolors =&#123; 'rosso':'red', 'verde':'green'&#125;frame8.replace(newcolors) DataFrame对象中两种旧颜色被替换为正确的元素。还有一种常见情况，是把NaN替换为其他值，比如0。这种情况下，仍然可以用replace()函数，它能优雅地完成该项操作。 ser = pd.Series([13,np.nan,4,6,np.nan,3])ser 0 13.01 NaN2 4.03 6.04 NaN5 3.0dtype: float64 ser.replace(np.nan,0) 0 13.01 0.02 4.03 6.04 0.05 3.0dtype: float64 用映射添加元素frame9 = pd.DataFrame(&#123; 'item':['ball','mug','pen','pencil','ashtray'], 'color':['white','red','green','black','yellow']&#125;)frame9 price = &#123; 'ball' : 5.56, 'mug' : 4.20, 'bottle1' : 1.30, 'scissors' : 3.41, 'pen' : 1.30, 'pencil' : 0.56, 'ashtray' : 2.75&#125; frame9['price'] = frame9['item'].map(price)frame9 重命名轴索引reindex = &#123; 0:'first', 1:'second', 2:'third', 3:'fourth', 4:'fifth'&#125;frame9.rename(reindex) recolumn =&#123; 'item':'object', 'price':'value'&#125; 索引被重命名。若要重命名各列，必须使用columns选项 frame9.rename(index = reindex,columns=recolumn) 对于只有单个元素要替换的最简单情况，可以对传入的参数做进一步限定，而无需把多个变 量都写出来，也避免产生多次赋值操作。 frame9.rename(index=&#123;1:&apos;first&apos;&#125;,columns = &#123;&apos;item&apos;:&apos;object&apos;&#125;) frame9 frame9.rename(index=&#123;1:'first'&#125;,columns = &#123;'item':'object'&#125;,inplace=True) frame9 离散化和面元划分ages=[20,22,25,27,21,23,37,31,61,45,41,32]bins=[18,25,35,60,100] cat = pd.cut(ages,bins)cat out: [(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]Length: 12Categories (4, interval[int64]): [(18, 25] &lt; (25, 35] &lt; (35, 60] &lt; (60, 100]] in: cat.codes array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8) 每个面元的出现次数，即每个类别有多少个元素，可使用value_counts()函数。 pd.value_counts(cat) ##查看每个种类的数量 (18, 25] 5(35, 60] 3(25, 35] 3(60, 100] 1dtype: int64 cuts = pd.cut(ages,bins,right=False) ## 使用right=False可以修改开端和闭端 out: [[18, 25), [18, 25), [25, 35), [25, 35), [18, 25), ..., [25, 35), [60, 100), [35, 60), [35, 60), [25, 35)]Length: 12Categories (4, interval[int64]): [[18, 25) &lt; [25, 35) &lt; [35, 60) &lt; [60, 100)] in: cut1 = pd.cut(ages,bins,right=False,labels=list(&apos;abcd&apos;))cut1 out: [a, a, b, b, a, ..., b, d, c, c, b]Length: 12Categories (4, object): [a &lt; b &lt; c &lt; d] in: pd.cut(ages,5) # 如果cut传入的是数字n，那么就会均分成n份。 out: [(19.959, 28.2], (19.959, 28.2], (19.959, 28.2], (19.959, 28.2], (19.959, 28.2], ..., (28.2, 36.4], (52.8, 61.0], (44.6, 52.8], (36.4, 44.6], (28.2, 36.4]]Length: 12Categories (5, interval[float64]): [(19.959, 28.2] &lt; (28.2, 36.4] &lt; (36.4, 44.6] &lt; (44.6, 52.8] &lt; (52.8, 61.0]] pd.value_counts(pd.cut(ages,4)) (19.959, 30.25] 6(30.25, 40.5] 3(40.5, 50.75] 2(50.75, 61.0] 1dtype: int64 pd.qcut(ages,5) out: [(19.999, 22.2], (19.999, 22.2], (22.2, 25.8], (25.8, 31.6], (19.999, 22.2], ..., (25.8, 31.6], (40.2, 61.0], (40.2, 61.0], (40.2, 61.0], (31.6, 40.2]]Length: 12Categories (5, interval[float64]): [(19.999, 22.2] &lt; (22.2, 25.8] &lt; (25.8, 31.6] &lt; (31.6, 40.2] &lt; (40.2, 61.0]] in: pd.value_counts(pd.qcut(ages,4)) out: (38.0, 61.0] 3(29.0, 38.0] 3(22.75, 29.0] 3(19.999, 22.75] 3dtype: int64 异常值检测和过滤data = pd.DataFrame(np.random.randn(1000,3))data.describe() 可能会将比标准差大3倍的元素视作异常值。用std()函数就可以求得DataFrame对象每一列的标准差。 3σ原则(|x-\mu|>3σ) data.std() 0 1.0495921 1.0252272 1.001221dtype: float64 data[(np.abs(data-data.mean())&gt;(3*data.std())).any(1)] #过滤条件 排序nframe = pd.DataFrame(np.arange(25).reshape(5,5))nframe new_order = np.random.permutation(5) #乱序整数[0-4] 如果是100 [0-99]new_order array([4, 0, 3, 1, 2]) nframe.take(new_order) #排序 np.random.permutation(100) out: array([94, 5, 24, 55, 99, 80, 76, 25, 82, 66, 52, 37, 87, 16, 15, 78, 69, 41, 72, 71, 89, 3, 58, 10, 17, 35, 30, 77, 22, 14, 13, 98, 88, 32, 36, 4, 33, 11, 59, 40, 79, 46, 50, 8, 54, 1, 23, 93, 95, 38, 90, 9, 62, 26, 73, 91, 75, 21, 7, 56, 83, 18, 6, 67, 42, 74, 43, 84, 47, 86, 65, 49, 60, 29, 34, 96, 19, 81, 2, 20, 31, 51, 70, 39, 63, 48, 53, 45, 28, 12, 68, 57, 27, 0, 97, 92, 61, 64, 85, 44]) nframe.take([3,4,2]) #只对一部分排序 sample = np.random.randint(len(nframe),size =3) #随机整数sample array([2, 2, 4]) nframe.take(sample) 数据聚合GroupByframe10 = pd.DataFrame(&#123; 'color': ['white','red','green','red','green'],'object': ['pen','pencil','pencil','ashtray','pen'], 'price1' : [5.56,4.20,1.30,0.56,2.75],'price2' : [4.75,4.12,1.60,0.75,3.15]&#125;)frame10 group = frame10[&apos;price1&apos;].groupby(frame10[&apos;color&apos;])group group.groups {‘green’: Int64Index([2, 4], dtype=’int64’), ‘red’: Int64Index([1, 3], dtype=’int64’), ‘white’: Int64Index([0], dtype=’int64’)} group.sum() colorgreen 4.05red 4.76white 5.56Name: price1, dtype: float64 group.mean() colorgreen 2.025red 2.380white 5.560Name: price1, dtype: float64 等级分组ggroup = frame10[&apos;price1&apos;].groupby([frame10[&apos;color&apos;],frame10[&apos;object&apos;]]) ggroup.groups {(‘green’, ‘pen’): Int64Index([4], dtype=’int64’), (‘green’, ‘pencil’): Int64Index([2], dtype=’int64’), (‘red’, ‘ashtray’): Int64Index([3], dtype=’int64’), (‘red’, ‘pencil’): Int64Index([1], dtype=’int64’), (‘white’, ‘pen’): Int64Index([0], dtype=’int64’)} ggroup.sum() out: color object green pen 2.75 pencil 1.30red ashtray 0.56 pencil 4.20white pen 5.56Name: price1, dtype: float64 in: frame10[[&apos;price1&apos;,&apos;price2&apos;]].groupby(frame10[&apos;color&apos;]).mean() 组迭代for name,group in frame10.groupby('color'): print(name) print(group) out: green color object price1 price22 green pencil 1.30 1.604 green pen 2.75 3.15red color object price1 price21 red pencil 4.20 4.123 red ashtray 0.56 0.75white color object price1 price20 white pen 5.56 4.75 链式转换result1 = frame10[&apos;price1&apos;].groupby(frame10[&apos;color&apos;]).mean()result1 colorgreen 2.025red 2.380white 5.560Name: price1, dtype: float64 result2 = frame10.groupby(frame10[&apos;color&apos;]).mean()result2 frame10.groupby(frame10[&apos;color&apos;])[&apos;price1&apos;].mean() colorgreen 2.025red 2.380white 5.560Name: price1, dtype: float64 (frame10.groupby(frame10[&apos;color&apos;]).mean())[&apos;price1&apos;] colorgreen 2.025red 2.380white 5.560Name: price1, dtype: float64 frame10.groupby(&apos;color&apos;).mean().add_prefix(&apos;mean_&apos;) 替换maps = &#123;&apos;x&apos;:xx&#125;data[&apos;name&apos;] = data[&apos;name&apos;].apply(lamda x: maps[x]) 取值sub_data = data.loc[data[&apos;name&apos;]==1]]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matplotlib]]></title>
    <url>%2F2019%2F01%2F24%2Fmatplotlib%2F</url>
    <content type="text"><![CDATA[matplotlib测试用数据： unrate.csv：https://pan.baidu.com/s/1uVCVvYKfcphjqcbMpLBdkg fandango_scores.csv：https://pan.baidu.com/s/1jareiLJC0YzNKgTOUxdbqQ percent-bachelors-degrees-women-usa.csv：https://pan.baidu.com/s/1oPtYASsjEoZbD8PEwNWFrw train.csv：https://pan.baidu.com/s/1Y2NaPDYtRxFWJABd1YxxJg import pandas as pd unrate = pd.read_csv('unrate.csv') #unrate['DATE'] = pd.to_datetime(unrate['DATE']) print(unrate.head(12)) DATE VALUE0 1948-01-01 3.41 1948-02-01 3.82 1948-03-01 4.03 1948-04-01 3.94 1948-05-01 3.55 1948-06-01 3.66 1948-07-01 3.67 1948-08-01 3.98 1948-09-01 3.89 1948-10-01 3.710 1948-11-01 3.811 1948-12-01 4.0 import matplotlib.pyplot as pltplt.plot()plt.show() first_twelve = unrate[0:12]plt.plot(first_twelve[&apos;DATE&apos;], first_twelve[&apos;VALUE&apos;])plt.show() plt.plot(first_twelve[&apos;DATE&apos;], first_twelve[&apos;VALUE&apos;])plt.xticks(rotation=45)# print help(plt.xticks)plt.show() plt.figure(figsize=(10, 10))plt.plot(first_twelve[&apos;DATE&apos;], first_twelve[&apos;VALUE&apos;])plt.xticks(rotation=90)plt.xlabel(&apos;Month&apos;)plt.ylabel(&apos;Unemployment Rate&apos;)plt.title(&apos;Monthly Unemployment Trends, 1948&apos;)plt.show() import matplotlib.pyplot as pltfig = plt.figure()ax1 = fig.add_subplot(3,2,1)ax2 = fig.add_subplot(3,2,2)ax6 = fig.add_subplot(3,2,6)plt.show() import numpy as npfig = plt.figure()#fig = plt.figure(figsize=(3, 3))ax1 = fig.add_subplot(2,1,1)ax2 = fig.add_subplot(2,1,2)ax1.plot(np.random.randint(1,5,5), np.arange(5))ax2.plot(np.arange(10)*3, np.arange(10))plt.show() print(unrate[&apos;DATE&apos;])unrate[&apos;DATE&apos;] = pd.to_datetime(unrate[&apos;DATE&apos;]) print(unrate[&apos;DATE&apos;])#unrate[&apos;MONTH&apos;] = unrate[&apos;DATE&apos;].dt.monthunrate[&apos;MONTH&apos;] = unrate[&apos;DATE&apos;].dt.monthfig = plt.figure(figsize=(6,3))plt.plot(unrate[0:12][&apos;MONTH&apos;], unrate[0:12][&apos;VALUE&apos;], c=&apos;red&apos;)plt.plot(unrate[12:24][&apos;MONTH&apos;], unrate[12:24][&apos;VALUE&apos;], c=&apos;blue&apos;)plt.show() fig = plt.figure(figsize=(10,6))colors = [&apos;red&apos;, &apos;blue&apos;, &apos;green&apos;, &apos;orange&apos;, &apos;black&apos;]for i in range(5): start_index = i*12 end_index = (i+1)*12 subset = unrate[start_index:end_index] plt.plot(subset[&apos;MONTH&apos;], subset[&apos;VALUE&apos;], c=colors[i]) plt.show() fig = plt.figure(figsize=(10,6))colors = [&apos;red&apos;, &apos;blue&apos;, &apos;green&apos;, &apos;orange&apos;, &apos;black&apos;]for i in range(5): start_index = i*12 end_index = (i+1)*12 subset = unrate[start_index:end_index] label = str(1948 + i) plt.plot(subset[&apos;MONTH&apos;], subset[&apos;VALUE&apos;], c=colors[i], label=label)plt.legend(loc=&apos;best&apos;)#print (help(plt.legend))plt.show() fig = plt.figure(figsize=(10,6))colors = [&apos;red&apos;, &apos;blue&apos;, &apos;green&apos;, &apos;orange&apos;, &apos;black&apos;]for i in range(5): start_index = i*12 end_index = (i+1)*12 subset = unrate[start_index:end_index] label = str(1948 + i) plt.plot(subset[&apos;MONTH&apos;], subset[&apos;VALUE&apos;], c=colors[i], label=label)plt.legend(loc=&apos;upper left&apos;)plt.xlabel(&apos;Month, Integer&apos;)plt.ylabel(&apos;Unemployment Rate, Percent&apos;)plt.title(&apos;Monthly Unemployment Trends, 1948-1952&apos;)plt.show() import pandas as pdreviews = pd.read_csv(&apos;fandango_scores.csv&apos;)cols = [&apos;FILM&apos;, &apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]norm_reviews = reviews[cols]print(norm_reviews[:1]) FILM RT_user_norm Metacritic_user_nom \0 Avengers: Age of Ultron (2015) 4.3 3.55 IMDB_norm Fandango_Ratingvalue Fandango_Stars 0 3.9 4.5 5.0 import matplotlib.pyplot as pltfrom numpy import arange#The Axes.bar() method has 2 required parameters, left and height. #We use the left parameter to specify the x coordinates of the left sides of the bar. #We use the height parameter to specify the height of each barnum_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]bar_heights = norm_reviews.loc[0, num_cols].values#print (bar_heights)bar_positions = arange(5) + 0.75#print (bar_positions)fig, ax = plt.subplots()ax.bar(bar_positions, bar_heights, 0.5)plt.show() num_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]bar_heights = norm_reviews.loc[0, num_cols].valuesbar_positions = arange(5) + 0.75tick_positions = range(1,6)fig, ax = plt.subplots()# print(fig)# print(ax)# print(help(plt.subplots))ax.bar(bar_positions, bar_heights, 0.5)ax.set_xticks(tick_positions)ax.set_xticklabels(num_cols, rotation=90)ax.set_xlabel(&apos;Rating Source&apos;)ax.set_ylabel(&apos;Average Rating&apos;)ax.set_title(&apos;Average User Rating For Avengers: Age of Ultron (2015)&apos;)plt.show() import matplotlib.pyplot as pltfrom numpy import arangenum_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;, &apos;Fandango_Stars&apos;]bar_widths = norm_reviews.loc[0, num_cols].valuesbar_positions = arange(5) + 0.75tick_positions = range(1,6)fig, ax = plt.subplots()ax.barh(bar_positions, bar_widths, 0.5)ax.set_yticks(tick_positions)ax.set_yticklabels(num_cols)ax.set_ylabel(&apos;Rating Source&apos;)ax.set_xlabel(&apos;Average Rating&apos;)ax.set_title(&apos;Average User Rating For Avengers: Age of Ultron (2015)&apos;)plt.show() fig, ax = plt.subplots()ax.scatter(norm_reviews[&apos;Fandango_Ratingvalue&apos;], norm_reviews[&apos;RT_user_norm&apos;])ax.set_xlabel(&apos;Fandango&apos;)ax.set_ylabel(&apos;Rotten Tomatoes&apos;)plt.show() #Switching Axesfig = plt.figure(figsize=(5,10))ax1 = fig.add_subplot(2,1,1)ax2 = fig.add_subplot(2,1,2)ax1.scatter(norm_reviews[&apos;Fandango_Ratingvalue&apos;], norm_reviews[&apos;RT_user_norm&apos;])ax1.set_xlabel(&apos;Fandango&apos;)ax1.set_ylabel(&apos;Rotten Tomatoes&apos;)ax2.scatter(norm_reviews[&apos;RT_user_norm&apos;], norm_reviews[&apos;Fandango_Ratingvalue&apos;])ax2.set_xlabel(&apos;Rotten Tomatoes&apos;)ax2.set_ylabel(&apos;Fandango&apos;)plt.show() fig, ax = plt.subplots()#ax.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;])#ax.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;],bins=20)ax.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;], range=(4, 5),bins=20) #4-5 其实结束plt.show() fig = plt.figure(figsize=(5,20))ax1 = fig.add_subplot(4,1,1)ax2 = fig.add_subplot(4,1,2)ax3 = fig.add_subplot(4,1,3)ax4 = fig.add_subplot(4,1,4)ax1.hist(norm_reviews[&apos;Fandango_Ratingvalue&apos;], bins=20, range=(0, 5))ax1.set_title(&apos;Distribution of Fandango Ratings&apos;)ax1.set_ylim(0, 50)ax2.hist(norm_reviews[&apos;RT_user_norm&apos;], 20, range=(0, 5))ax2.set_title(&apos;Distribution of Rotten Tomatoes Ratings&apos;)ax2.set_ylim(0, 50)ax3.hist(norm_reviews[&apos;Metacritic_user_nom&apos;], 20, range=(0, 5))ax3.set_title(&apos;Distribution of Metacritic Ratings&apos;)ax3.set_ylim(0, 50)ax4.hist(norm_reviews[&apos;IMDB_norm&apos;], 20, range=(0, 5))ax4.set_title(&apos;Distribution of IMDB Ratings&apos;)ax4.set_ylim(0, 50)plt.show() fig, ax = plt.subplots()ax.boxplot(norm_reviews[&apos;RT_user_norm&apos;])ax.set_xticklabels([&apos;Rotten Tomatoes&apos;])ax.set_ylim(0, 5)plt.show() num_cols = [&apos;RT_user_norm&apos;, &apos;Metacritic_user_nom&apos;, &apos;IMDB_norm&apos;, &apos;Fandango_Ratingvalue&apos;]fig, ax = plt.subplots()ax.boxplot(norm_reviews[num_cols].values) #箱线图ax.set_xticklabels(num_cols, rotation=90)ax.set_ylim(0,5)plt.show() women_degrees = pd.read_csv(&apos;percent-bachelors-degrees-women-usa.csv&apos;)plt.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;])plt.show() plt.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;], c=&apos;blue&apos;, label=&apos;Women&apos;)plt.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[&apos;Biology&apos;], c=&apos;green&apos;, label=&apos;Men&apos;)plt.legend(loc=&apos;upper right&apos;)plt.title(&apos;Percentage of Biology Degrees Awarded By Gender&apos;)plt.show() fig, ax = plt.subplots()ax.tick_params(bottom=&quot;off&quot;, top=&apos;on&apos;, left=&quot;off&quot;, right=&quot;on&quot;)fig, ax = plt.subplots()ax.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;], label=&apos;Women&apos;)ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[&apos;Biology&apos;], label=&apos;Men&apos;)ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)ax.set_title(&apos;Percentage of Biology Degrees Awarded By Gender&apos;)ax.legend(loc=&quot;upper right&quot;)plt.show() fig, ax = plt.subplots()ax.plot(women_degrees[&apos;Year&apos;], women_degrees[&apos;Biology&apos;], c=&apos;blue&apos;, label=&apos;Women&apos;)ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[&apos;Biology&apos;], c=&apos;green&apos;, label=&apos;Men&apos;)ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)print(type(ax.spines))for key,spine in ax.spines.items(): spine.set_visible(False)ax.legend(loc=&apos;upper right&apos;)plt.show() major_cats = [&apos;Biology&apos;, &apos;Computer Science&apos;, &apos;Engineering&apos;, &apos;Math and Statistics&apos;]fig = plt.figure(figsize=(12, 12))for sp in range(0,4): ax = fig.add_subplot(2,2,sp+1) ax.plot(women_degrees[&apos;Year&apos;], women_degrees[major_cats[sp]], c=&apos;blue&apos;, label=&apos;Women&apos;) ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[major_cats[sp]], c=&apos;green&apos;, label=&apos;Men&apos;)plt.legend(loc=&apos;upper right&apos;)plt.show() #Colorimport pandas as pdimport matplotlib.pyplot as pltwomen_degrees = pd.read_csv(&apos;percent-bachelors-degrees-women-usa.csv&apos;)major_cats = [&apos;Biology&apos;, &apos;Computer Science&apos;, &apos;Engineering&apos;, &apos;Math and Statistics&apos;]cb_dark_blue = (0/255, 107/255, 164/255)cb_orange = (255/255, 128/255, 14/255)fig = plt.figure(figsize=(12, 12))for sp in range(0,4): ax = fig.add_subplot(2,2,sp+1) # The color for each line is assigned here. ax.plot(women_degrees[&apos;Year&apos;], women_degrees[major_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;) ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[major_cats[sp]], c=cb_orange, label=&apos;Men&apos;) for key,spine in ax.spines.items(): spine.set_visible(False) ax.set_xlim(1968, 2011) ax.set_ylim(0,100) ax.set_title(major_cats[sp]) ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)plt.legend(loc=&apos;upper right&apos;)plt.show() #Setting Line Widthcb_dark_blue = (0/255, 107/255, 164/255)cb_orange = (255/255, 128/255, 14/255)fig = plt.figure(figsize=(12, 12))for sp in range(0,4): ax = fig.add_subplot(2,2,sp+1) # Set the line width when specifying how each line should look. ax.plot(women_degrees[&apos;Year&apos;], women_degrees[major_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=10) ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[major_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=10) for key,spine in ax.spines.items(): spine.set_visible(False) ax.set_xlim(1968, 2011) ax.set_ylim(0,100) ax.set_title(major_cats[sp]) ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)plt.legend(loc=&apos;upper right&apos;)plt.show() stem_cats = [&apos;Engineering&apos;, &apos;Computer Science&apos;, &apos;Psychology&apos;, &apos;Biology&apos;, &apos;Physical Sciences&apos;, &apos;Math and Statistics&apos;]fig = plt.figure(figsize=(18, 3))for sp in range(0,6): ax = fig.add_subplot(1,6,sp+1) ax.plot(women_degrees[&apos;Year&apos;], women_degrees[stem_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=3) ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[stem_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=3) for key,spine in ax.spines.items(): spine.set_visible(False) ax.set_xlim(1968,2011) ax.set_ylim(0,100) ax.set_title(stem_cats[sp]) ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)plt.legend(loc=&apos;upper right&apos;)plt.show() fig = plt.figure(figsize=(18, 3))for sp in range(0,6): ax = fig.add_subplot(1,6,sp+1) ax.plot(women_degrees[&apos;Year&apos;], women_degrees[stem_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=3) ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[stem_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=3) for key,spine in ax.spines.items(): spine.set_visible(False) ax.set_xlim(1968, 2011) ax.set_ylim(0,100) ax.set_title(stem_cats[sp]) ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;)plt.legend(loc=&apos;upper right&apos;)plt.show()fig = plt.figure(figsize=(18, 3))for sp in range(0,6): ax = fig.add_subplot(1,6,sp+1) ax.plot(women_degrees[&apos;Year&apos;], women_degrees[stem_cats[sp]], c=cb_dark_blue, label=&apos;Women&apos;, linewidth=3) ax.plot(women_degrees[&apos;Year&apos;], 100-women_degrees[stem_cats[sp]], c=cb_orange, label=&apos;Men&apos;, linewidth=3) for key,spine in ax.spines.items(): spine.set_visible(False) ax.set_xlim(1968, 2011) ax.set_ylim(0,100) ax.set_title(stem_cats[sp]) ax.tick_params(bottom=&quot;off&quot;, top=&quot;off&quot;, left=&quot;off&quot;, right=&quot;off&quot;) if sp == 0: ax.text(2005, 87, &apos;Men&apos;) ax.text(2002, 8, &apos;Women&apos;) elif sp == 5: ax.text(2005, 62, &apos;Men&apos;) ax.text(2001, 35, &apos;Women&apos;)plt.show() seabornimport pandas as pdtitanic = pd.read_csv(&apos;train.csv&apos;)cols = [&apos;Survived&apos;, &apos;Pclass&apos;, &apos;Sex&apos;, &apos;Age&apos;, &apos;SibSp&apos;, &apos;Parch&apos;, &apos;Fare&apos;, &apos;Embarked&apos;]titanic = titanic[cols].dropna() import seaborn as snsimport matplotlib.pyplot as pltsns.distplot(titanic[&apos;Age&apos;])plt.show() import seaborn as snsimport numpy as npimport matplotlib as mplimport matplotlib.pyplot as plt%matplotlib inline def sinplot(flip=1): x = np.linspace(0, 14, 100) for i in range(1, 7): plt.plot(x, np.sin(x + i * .5) * (7 - i) * flip) sinplot() sns.set()sinplot() 5种主题风格 darkgrid whitegrid dark white ticks sns.set_style(&quot;whitegrid&quot;)data = np.random.normal(size=(20, 6)) + np.arange(6) / 2sns.boxplot(data=data) sns.set_style(&quot;dark&quot;)sinplot() sns.set_style(&quot;white&quot;)sinplot() sns.set_style(&quot;ticks&quot;)sinplot() sinplot()sns.despine() sns.violinplot(data)sns.despine(offset=10,trim=True) #轴线的距离# sns.violinplot(data=data)# sns.despine(offset=10, trim=True); sns.set_style(&quot;whitegrid&quot;)sns.boxplot(data=data,palette=&quot;deep&quot;)sns.despine(left=True) with sns.axes_style(&quot;darkgrid&quot;): plt.subplot(211) sinplot()plt.subplot(212)sinplot(-1) sns.set()sns.set_context(&quot;paper&quot;)plt.figure(figsize=(8, 6))sinplot() sns.set_context(&quot;talk&quot;)plt.figure(figsize=(8, 6))sinplot() sns.set_context(&quot;poster&quot;)plt.figure(figsize=(8, 6))sinplot() sns.set_context(&quot;notebook&quot;, font_scale=1.5, rc=&#123;&quot;lines.linewidth&quot;: 2.5&#125;)sinplot() 调色板 颜色很重要 color_palette()能传入任何Matplotlib所支持的颜色 color_palette()不写参数则默认颜色 set_palette()设置所有图的颜色 分类色板current_palette = sns.color_palette()sns.palplot(current_palette) 圆形画板当你有六个以上的分类要区分时，最简单的方法就是在一个圆形的颜色空间中画出均匀间隔的颜色(这样的色调会保持亮度和饱和度不变)。这是大多数的当他们需要使用比当前默认颜色循环中设置的颜色更多时的默认方案。 最常用的方法是使用hls的颜色空间，这是RGB值的一个简单转换。 sns.palplot(sns.color_palette(&quot;hls&quot;, 8)) data = np.random.normal(size=(20, 8)) + np.arange(8) / 2sns.boxplot(data=data,palette=sns.color_palette(&quot;hls&quot;, 8)) hls_palette()函数来控制颜色的亮度和饱和 l-亮度 lightness s-饱和 saturation sns.palplot(sns.hls_palette(8, l=.7, s=.9)) sns.palplot(sns.color_palette(&quot;Paired&quot;,8)) 使用xkcd颜色来命名颜色xkcd包含了一套众包努力的针对随机RGB色的命名。产生了954个可以随时通过xdcd_rgb字典中调用的命名颜色。 https://xkcd.com/color/rgb/ plt.plot([0, 1], [0, 1], sns.xkcd_rgb[&quot;pale red&quot;], lw=3) #https://xkcd.com/color/rgb/plt.plot([0, 1], [0, 2], sns.xkcd_rgb[&quot;medium green&quot;], lw=3)plt.plot([0, 1], [0, 3], sns.xkcd_rgb[&quot;denim blue&quot;], lw=3)plt.plot([0, 1], [0, 4], sns.xkcd_rgb[&quot;olive&quot;],lw = 5) colors = [&quot;windows blue&quot;, &quot;amber&quot;, &quot;greyish&quot;, &quot;faded green&quot;, &quot;dusty purple&quot;]sns.palplot(sns.xkcd_palette(colors)) 连续色板色彩随数据变换，比如数据越来越重要则颜色越来越深 Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Vega10, Vega10_r, Vega20, Vega20_r, Vega20b, Vega20b_r, Vega20c, Vega20c_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spectral, spectral_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, vlag, vlag_r, winter, winter_r sns.palplot(sns.color_palette(&quot;Blues&quot;))sns.palplot(sns.color_palette(&quot;Accent&quot;)) 如果想要翻转渐变，可以在面板名称中添加一个_r后缀 cubehelix_palette()调色板色调线性变换 sns.palplot(sns.color_palette(&quot;cubehelix&quot;, 8)) sns.palplot(sns.cubehelix_palette(8, start=.5, rot=-.75)) sns.palplot(sns.cubehelix_palette(8, start=.75, rot=-.150)) light_palette() 和dark_palette()调用定制连续调色板sns.palplot(sns.light_palette(&quot;green&quot;)) sns.palplot(sns.dark_palette(&quot;purple&quot;)) sns.palplot(sns.light_palette(&quot;navy&quot;, reverse=True)) sns.palplot(sns.light_palette((210, 90, 60), input=&quot;husl&quot;)) x = np.random.normal(size=100)sns.distplot(x,kde=False) #kde 核密度估计 sns.distplot(x, bins=20, kde=False) from scipy import stats, integratex = np.random.gamma(6, size=200)sns.distplot(x, kde=False, fit=stats.gamma) mean, cov = [0, 1], [(1, .5), (.5, 1)]data = np.random.multivariate_normal(mean, cov, 200)df = pd.DataFrame(data, columns=[&quot;x&quot;, &quot;y&quot;])df 散点图sns.jointplot(x=&quot;x&quot;, y=&quot;y&quot;, data=df) sns.jointplot(x=&quot;x&quot;, y=&quot;y&quot;, data=df,kind = &quot;reg&quot;) x, y = np.random.multivariate_normal(mean, cov, 1000).Twith sns.axes_style(&quot;white&quot;): sns.jointplot(x=x, y=y, kind=&quot;hex&quot;, color=&quot;k&quot;) iris = sns.load_dataset(&quot;iris&quot;)sns.pairplot(iris) tips = sns.load_dataset(&quot;tips&quot;)tips.head() regplot()和lmplot()都可以绘制回归关系,推荐regplot() sns.lmplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips); anscombe = sns.load_dataset(&quot;anscombe&quot;)print(anscombe.head())print(type(anscombe))sns.regplot(x=&quot;x&quot;, y=&quot;y&quot;, data=anscombe.query(&quot;dataset == &apos;I&apos;&quot;), ci=None, scatter_kws=&#123;&quot;s&quot;: 80&#125;) # ci 置信区间 query 查询布尔表达式所在的数据 sns.lmplot(x=&quot;x&quot;, y=&quot;y&quot;, data=anscombe.query(&quot;dataset == &apos;II&apos;&quot;), ci=None, scatter_kws=&#123;&quot;s&quot;: 80&#125;) sns.lmplot(x="x", y="y", data=anscombe.query("dataset == 'II'"), order=2, ci=None, scatter_kws=&#123;"s": 80&#125;) #order : int, optional#If order is greater than 1, use numpy.polyfit to estimate a polynomial regression. sns.lmplot(x="total_bill", y="tip", hue="smoker", data=tips); sns.lmplot(x="total_bill", y="tip", hue="smoker", data=tips, markers=["o","*"], palette="Set1"); #hue 列名分割#matplotlib.markers sns.lmplot(x="total_bill", y="tip", hue="smoker", col="time", data=tips); sns.lmplot(x="total_bill", y="tip", hue="smoker", col="time", row="sex", data=tips); f, ax = plt.subplots(figsize=(5, 5))sns.regplot(x="total_bill", y="tip", data=tips, ax=ax); sns.lmplot(x="total_bill", y="tip", col="day", data=tips, col_wrap=2, size=4) #size 图size sns.lmplot(x="total_bill", y="tip", col="day", data=tips,) sns.lmplot(x="total_bill", y="tip", col="day", data=tips,aspect=.5) # aspect 长宽比 多变量sns.set(style="whitegrid", color_codes=True)sns.stripplot(x="day", y="total_bill", data=tips) 重叠是很常见的现象，但是重叠影响我观察数据的量了 sns.stripplot(x="day", y="total_bill", data=tips, jitter=True) #抖动量 sns.swarmplot(x="day", y="total_bill", data=tips) sns.swarmplot(x="day", y="total_bill", hue="sex",data=tips) sns.swarmplot(x="total_bill", y="day", hue="time", data=tips) 盒图 IQR即统计学概念四分位距，第1/4分位与第3/4分位之间的距离 $N = 1.5IQR$ 如果一个值$&gt;Q3+N$或$&lt;Ｑ1-N$,则为离群点 sns.boxplot(x="day", y="total_bill", hue="time", data=tips) sns.violinplot(x="total_bill", y="day", hue="time", data=tips) sns.violinplot(x="day", y="total_bill", hue="sex", data=tips, split=True) sns.violinplot(x="day", y="total_bill", hue="sex", data=tips) sns.violinplot(x="day", y="total_bill", data=tips, inner=None) #inner 小提琴内部图形sns.swarmplot(x="day", y="total_bill", data=tips, color="w", alpha=.5) # alpha 透明度 sns.violinplot(x=&quot;day&quot;, y=&quot;total_bill&quot;, data=tips, inner=None)sns.swarmplot(x=&quot;day&quot;, y=&quot;total_bill&quot;, data=tips, color=&quot;w&quot;,) 条形图显示值的集中趋势可以用条形图 titanic = sns.load_dataset("titanic")print(titanic.describe())print(titanic.info())sns.barplot(x="sex", y="survived", hue="class", data=titanic) 点图点图可以更好的描述变化差异 sns.pointplot(x="sex", y="survived", hue="class", data=titanic); sns.pointplot(x="class", y="survived", hue="sex", data=titanic, palette=&#123;"male": "g", "female": "m"&#125;, markers=["^", "o"], linestyles=["-", "--"]); 宽形数据sns.boxplot(data=iris,orient="h") #orient 垂直和水平 多层面板分类图sns.factorplot(x="day", y="total_bill", hue="smoker", data=tips) sns.factorplot(x="day", y="total_bill", hue="smoker", data=tips, kind="bar") sns.factorplot(x="day", y="total_bill", hue="smoker", col="time", data=tips, kind="swarm") sns.factorplot(x="time", y="total_bill", hue="smoker", col="day", data=tips, kind="box", size=4, aspect=.5) seaborn.factorplot(x=None, y=None, hue=None, data=None, row=None, col=None, col_wrap=None, estimator=, ci=95, n_boot=1000, units=None, order=None, hue_order=None, row_order=None, col_order=None, kind=’point’, size=4, aspect=1, orient=None, color=None, palette=None, legend=True, legend_out=True, sharex=True, sharey=True, margin_titles=False, facet_kws=None, **kwargs) Parameters： x,y,hue 数据集变量 变量名 date 数据集 数据集名 row,col 更多分类变量进行平铺显示 变量名 col_wrap 每行的最高平铺数 整数 estimator 在每个分类中进行矢量到标量的映射 矢量 ci 置信区间 浮点数或None n_boot 计算置信区间时使用的引导迭代次数 整数 units 采样单元的标识符，用于执行多级引导和重复测量设计 数据变量或向量数据 order, hue_order 对应排序列表 字符串列表 row_order, col_order 对应排序列表 字符串列表 kind : 可选：point 默认, bar 柱形图, count 频次, box 箱体, violin 提琴, strip 散点，swarm 分散点 size 每个面的高度（英寸） 标量 aspect 纵横比 标量 orient 方向 “v”/“h” color 颜色 matplotlib颜色 palette 调色板 seaborn颜色色板或字典 legend hue的信息面板 True/False legend_out 是否扩展图形，并将信息框绘制在中心右边 True/False share{x,y} 共享轴线 True/False g = sns.FacetGrid(tips, col="time") sns.set(style="ticks")g = sns.FacetGrid(tips, col="time") #把数据中很多子集画出来 g = sns.FacetGrid(tips, col="time") #占位print(help(g.map))g.map(plt.hist, "tip") #画图 g = sns.FacetGrid(tips, col="sex", hue="smoker")g.map(plt.scatter, "total_bill", "tip", alpha=.7)g.add_legend() g = sns.FacetGrid(tips, row="smoker", col="time", margin_titles=True) #变量标题右侧，实验性并不总是有效g.map(sns.regplot, "size", "total_bill", color=".1", fit_reg=False, x_jitter=.1) #color 颜色深浅 fit_reg 回归的线 x_jitter 浮动 g = sns.FacetGrid(tips, col="day", size=4, aspect=.5)g.map(sns.barplot, "sex", "total_bill",order=["Male","Female"]) from pandas import Categoricalordered_days = tips.day.value_counts().indexprint (ordered_days)ordered_days = Categorical([&apos;Thur&apos;, &apos;Fri&apos;, &apos;Sat&apos;, &apos;Sun&apos;])g = sns.FacetGrid(tips, row=&quot;day&quot;, row_order=ordered_days, size=1.7, aspect=4)g.map(sns.boxplot, &quot;total_bill&quot;,order=[&quot;Male&quot;,&quot;Female&quot;]) pal = dict(Lunch="seagreen", Dinner="gray")g = sns.FacetGrid(tips, hue="time", palette=pal, size=5)g.map(plt.scatter, "total_bill", "tip", s=50, alpha=.7, linewidth=.5, edgecolors="red") #edgecolors 元素边界颜色 g.add_legend() g = sns.FacetGrid(tips, hue="sex", palette="Set1", size=5, hue_kws=&#123;"marker": ["^", "v"]&#125;)g.map(plt.scatter, "total_bill", "tip", s=100, linewidth=.5, edgecolor="white")g.add_legend() with sns.axes_style("white"): g = sns.FacetGrid(tips, row="sex", col="smoker", margin_titles=True, size=2.5)g.map(plt.scatter, "total_bill", "tip", color="#334488", edgecolor="white", lw=.5);g.set_axis_labels("Total bill (US Dollars)", "Tip");g.set(xticks=[10, 30, 50], yticks=[2, 6, 10]);g.fig.subplots_adjust(wspace=.02, hspace=.02); #子图与子图#g.fig.subplots_adjust(left = 0.125,right = 0.5,bottom = 0.1,top = 0.9, wspace=.02, hspace=.02) iris = sns.load_dataset("iris")g = sns.PairGrid(iris)g.map(plt.scatter) g = sns.PairGrid(iris)g.map_diag(plt.hist) #对角线g.map_offdiag(plt.scatter) #非对角线 g = sns.PairGrid(iris, hue="species")g.map_diag(plt.hist)g.map_offdiag(plt.scatter)g.add_legend(); g = sns.PairGrid(iris, vars=["sepal_length", "sepal_width"], hue="species") #vars 取一部分# print(iris.species.value_counts().index)# print(iris.describe())# print(iris.info())# print(iris.head(10))g.map(plt.scatter) g = sns.PairGrid(tips, hue="size", palette="GnBu_d")g.map(plt.scatter, s=50, edgecolor="white")g.add_legend(); 热力图uniform_data = np.random.rand(3, 3)print (uniform_data)heatmap = sns.heatmap(uniform_data) ax = sns.heatmap(uniform_data, vmin=0.2, vmax=0.5) #最大最小取值 normal_data = np.random.randn(3, 3)print (normal_data)ax = sns.heatmap(normal_data, center=0) #中心值 flights = sns.load_dataset("flights")flights.head()flights = flights.pivot("month", "year", "passengers") #根据列值重塑数据print (flights)ax = sns.heatmap(flights) ax = sns.heatmap(flights, annot=True,fmt="d") ax = sns.heatmap(flights, linewidths=.5) ax = sns.heatmap(flights, cmap="YlGnBu") ax = sns.heatmap(flights, cbar=False) #隐藏bar]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy]]></title>
    <url>%2F2019%2F01%2F23%2Fnumpy%2F</url>
    <content type="text"><![CDATA[Numpy是用Python进行科学计算，尤其是数据分析时，所用到的一个基础库。它是大量python数学和科学计算包的基础，比如后面要讲到的pandas库就用到了Numpy。pandas库专门用于数据分析，充分借鉴了Python标准库Numpy的相关概念。而Python标准库所提供的内置工具对数据分析方面的大多数计算来说都过于简单或不够用。 为了更好地理解和是用Python所有的科学计算包，尤其是pandas,需要先行掌握Numpy库的用法，这样才能把pandas的用法发挥到极致。 NumPy - 数据类型 NumPy 支持比 Python 更多种类的数值类型。 下表显示了 NumPy 中定义的不同标量数据类型。 数据类型 类型代码 描述 bool_ 存储为一个字节的布尔值（真或假） int_ 默认整数，相当于 C 的long，通常为int32或int64 intc 相当于 C 的int，通常为int32或int64 intp 用于索引的整数，相当于 C 的size_t，通常为int32或int64 int8 i1 字节（-128 ~ 127） int16 i2 16 位整数（-32768 ~ 32767） int32 i4 32 位整数（-2147483648 ~ 2147483647） int64 i8 64 位整数（-9223372036854775808 ~ 9223372036854775807） uint8 u1 8 位无符号整数（0 ~ 255） uint16 u2 16 位无符号整数（0 ~ 65535） uint32 u4 32 位无符号整数（0 ~ 4294967295） uint64 u8 64 位无符号整数（0 ~ 18446744073709551615） float_ float64的简写 float16 f2 半精度浮点：符号位，5 位指数，10 位尾数 float32 f4或者f 单精度浮点：符号位，8 位指数，23 位尾数 float64 f8或者d 双精度浮点：符号位，11 位指数，52 位尾数 complex_ c16 complex128的简写 complex64 c8 复数，由两个 32 位浮点表示（实部和虚部） omplex128 c16 复数，由两个 64 位浮点表示（实部和虚部） bool ? 存储True和False值的布尔类型 object O python对象类型 String S 固定场读字符串类型（每一个字符一个字节）。创建一个长度为8的字符串，应该使用S8 Unicode_ U 固定长度的unicode类型（字节数由平台决定），和字符串定义方式一样 np.array([1,2],dtype=&apos;f8&apos;) 结果：array([1., 2.]) 建立ndarray多维数组n3 = np.array( [ [ [1,2,3,4], [2,3,4,5] ], [ [3,4,5,6], [4,5,6,7] ] ])n3 array([[[1, 2, 3, 4], [2, 3, 4, 5]], [[3, 4, 5, 6], [4, 5, 6, 7]]]) n3.ndim #维度 3 n3.shape #形状 (2, 2, 4) n3.itemsize #每个元素的长度为几个字节 4 n3.size #数组长度 16 n3.data #指向数组数据开始的Python缓冲区对象 n4 = np.array( [ [ [1,2,3,4], [2,3,4,5] ], [ [3,4,5,6], [4,5,6,7] ], [ [3,4,5,6], [4,5,6,7] ] ])n4 array([[[1, 2, 3, 4], [2, 3, 4, 5]], [[3, 4, 5, 6], [4, 5, 6, 7]], [[3, 4, 5, 6], [4, 5, 6, 7]]]) n4.shape (3, 2, 4) n5 = np.array([[&apos;1&apos;,&apos;2&apos;]]) #&lt;表示字节顺序，小端（最小有效字节存储在最小地址中）| ：忽视字节顺序#&lt; ：低位字节在前，即小端模式(little endian)# &gt; ：高位字节在前，即大端模式(big endian)#U表示Unicode，数据类型#1表示元素位长，数据大小n5.dtype dtype(‘&lt;U1’) n5.dtype.name ‘str32’ n6 = np.array([[&apos;12&apos;,&apos;22&apos;]])n6.dtype dtype(‘&lt;U2’) np.array([&apos;Python&apos;,&apos;tanzhou &apos;,&apos;hello&apos;,&apos;sa&apos;],dtype=&apos;&lt;U4&apos;) array([‘Pyth’, ‘tanz’, ‘hell’, ‘sa’], dtype=’&lt;U4’) np.array([&apos;1&apos;,&apos;2 &apos;,&apos;2&apos;],dtype=&apos;int&apos;) array([1, 2, 2]) np.array([&apos;1.1&apos;,&apos;2 &apos;,&apos;2&apos;],dtype=&apos;float&apos;) array([1.1, 2. , 2. ]) n6.size 2 n6.dtype.type numpy.str_ n4[0][0][2] 3 x = np.zeros((3,3)) #生成指定维度的全0矩阵x array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) y = np.zeros([3,3]) y array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) np.ones((3,4,5),dtype=np.int) #生成指定维度的全1矩阵 array([[[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]]) np.empty((3,4)) #生成指定维度的垃圾值矩阵，只分配，不对其进行初始化 输出：array([[4.6e-322, 0.0e+000, 0.0e+000, 0.0e+000], [0.0e+000, 0.0e+000, 0.0e+000, 0.0e+000], [0.0e+000, 0.0e+000, 0.0e+000, 0.0e+000]]) a = np.zeros((3,4,5))a array([[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]]) b = np.zeros_like(a)b out: array([[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]]) In: c = np.ones_like(a)c out: array([[[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]], [[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]], [[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]]) in: np.arange(0,10) #生成数值序列的数组 类似python range array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) np.arange(0,10,0.6) array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. , 6.6, 7.2,7.8, 8.4, 9. , 9.6]) np.arange(0,12).reshape(3,4) array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) np.linspace(0,10,5) array([ 0. , 2.5, 5. , 7.5, 10. ]) np.logspace(0,2,5) #0 表示 10^0 2 表示10^2 5个元素等比数列 array([ 1. , 3.16227766, 10. , 31.6227766 , 100. ]) np.logspace(0,2,5,endpoint=False) #10**(0.4)=2.51188643150958 array([ 1. , 2.51188643, 6.30957344, 15.84893192, 39.81071706]) np.logspace(0,1,12,base=2,endpoint=False) array([1. , 1.05946309, 1.12246205, 1.18920712, 1.25992105, 1.33483985, 1.41421356, 1.49830708, 1.58740105, 1.68179283, 1.78179744, 1.88774863]) np.logspace(0,1,12,base=np.e) array([1. , 1.09516944, 1.1993961 , 1.31354196, 1.43855101, 1.5754571 , 1.72539247, 1.88959711, 2.06942901, 2.26637541, 2.48206508, 2.71828183]) np.random.random(3) array([0.42129851, 0.82031203, 0.2013445 ]) a = np.arange(0, 40, 10)b = np.tile(a, (3, 5)) print(a)b [ 0 10 20 30] array([[ 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30], [ 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30], [ 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30, 0, 10, 20, 30]]) s = b&apos;Hello World&apos; a = np.frombuffer(s, dtype = np.int8) a array([ 72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100], dtype=int8) np.fromfile(&apos;save_date.npy&apos;) array([1.87585069e-309, 1.17119999e+171, 5.22741680e-037, 8.44740097e+252, 2.65141232e+180, 9.92152605e+247, 2.16209968e+233, 1.05176541e-153, 6.01399921e-154, 6.01347002e-154, 6.01347002e-154, 6.01347002e-154, 6.01347002e-154, 6.01347002e-154, 6.01347002e-154, 6.55490914e-260, 6.54218855e-001, 3.99443697e-001, 4.50091561e-001, 6.60862373e-001, 8.77753297e-001, 3.89115607e-001, 9.45576953e-001, 4.07118309e-001, 3.05937465e-001, 7.01606366e-001, 9.23868345e-001, 3.49139962e-001, 2.71655829e-001, 6.88059971e-001, 1.25104393e-001, 5.42319627e-001]) def func(i,x): #return i%4 + 1 return inp.fromfunction(func,(10,2)) array([[0., 0.], [1., 1.], [2., 2.], [3., 3.], [4., 4.], [5., 5.], [6., 6.], [7., 7.], [8., 8.], [9., 9.]]) def func2(i,j): return (i+1)*(j+1)np.fromfunction(func2,(9,9)) array([[ 1., 2., 3., 4., 5., 6., 7., 8., 9.], [ 2., 4., 6., 8., 10., 12., 14., 16., 18.], [ 3., 6., 9., 12., 15., 18., 21., 24., 27.], [ 4., 8., 12., 16., 20., 24., 28., 32., 36.], [ 5., 10., 15., 20., 25., 30., 35., 40., 45.], [ 6., 12., 18., 24., 30., 36., 42., 48., 54.], [ 7., 14., 21., 28., 35., 42., 49., 56., 63.], [ 8., 16., 24., 32., 40., 48., 56., 64., 72.], [ 9., 18., 27., 36., 45., 54., 63., 72., 81.]]) 基本操作算术运算符 算术 函数 y = x1 + x2 add(x1, x2 [, y]) y = x1 - x2 subtract(x1, x2 [, y]) y = x1 * x2 multiply (x1, x2 [, y]) y = x1 / x2 divide (x1, x2 [, y]), 如果两个数组的元素为整数，那么用整数除法 y = x1 / x2 true_divide (x1, x2 [, y]), 总是返回精确的商 y = x1 // x2 floor_divide (x1, x2 [, y]), 总是对返回值取整 y = - x negative(x [,y]) y = x1 ** x 2 power(x1, x2 [, y]) y = x1 % x2 remainder(x1, x2 [, y]),或mod(x1, x2, [, y]) a = np.arange(4)a array([0, 1, 2, 3]) b = a+4b array([4, 5, 6, 7]) a*2 array([0, 2, 4, 6]) c = a + b #元素级操作，对应位置元素运算组成新数组c array([ 4, 6, 8, 10]) c-a array([4, 5, 6, 7]) a * np.sin(b) #正弦曲线 array([-0. , -0.95892427, -0.558831 , 1.9709598 ]) a * np.sqrt(b) #平方根 array([0. , 2.23606798, 4.89897949, 7.93725393]) A = np.arange(0,9).reshape(3,3)A array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) B = np.ones((3,3))B array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) A*B array([[0., 1., 2.], [3., 4., 5.], [6., 7., 8.]]) 矩阵积np.dot(A,B) array([[ 3., 3., 3.], [12., 12., 12.], [21., 21., 21.]]) A.dot(B) array([[ 3., 3., 3.], [12., 12., 12.], [21., 21., 21.]]) B.dot(A) array([[ 9., 12., 15.], [ 9., 12., 15.], [ 9., 12., 15.]]) 自增自减a = np.arange(4)a array([0, 1, 2, 3]) a += 1a array([1, 2, 3, 4]) a -= 1a array([0, 1, 2, 3]) a *= 2a array([0, 2, 4, 6]) a+=1a array([1, 3, 5, 7]) 通用函数通用函数（ufunc）是一种对ndarray中的数据执行元素级运算的函数。 一元ufunc 函数 说明 abs、fabs 计算整数、浮点数或复数的绝对值 sqrt 计算各元素平方根 square 计算各元素平方 exp 计算各元素的指数 log、log10、log2、log1p 分别为自然对数(底数为e)、底数为10的log、底数为2的log、log(1+x) sign 计算各元素的正负号 ceil 计算各元素的ceiling值，即大于等于该值的最小整数 floor 计算各元素的floor值，即小于等于该值的最大整数 rint 将各元素值四舍五入到最接近的 modf 将数组的小数和整数部分以两个独立的数组形式返回 isnan “哪些值是NaN” 返回布尔值 isfinite、isinf “哪些元素是有穷的” “哪些元素是无穷的” cos、cosh、sin、sinh、tan、tanh 普通型和双曲型三角函数 arccos、arccosh、arcsin、arcsinh、arctan、arctanh 反三角函数 logical_not 计算各元素not x的真值，相当于 二元ufunc 函数 说明 add 元素相加 subtract 从第一个数组中减去第二个数组的元算 multiply 元素相乘 divide、floor_divide 除法或向下圆整除法（丢弃余数） power A的b次方 maximum、fmax 元素级的最大值计算。fmax将忽略nan minimum、fmin 元素级的最小值计算。fmin将忽略nan mod 元素级的求模计算（除法） copysign 将第二个数组中的值的符号复制给第一个数组中的 greater、greater_equal、less、less_equal、equal、not_equal 执行元素级的比较运算，产生布尔型数组 logical_and、logical_or、logical_xor 执行元素级的真值逻辑运算。相当于&amp; \ a = np.arange(1,5)a array([1, 2, 3, 4]) b = np.arange(1,5)b array([1, 2, 3, 4]) np.add(a,b) array([2, 4, 6, 8]) np.sqrt(a) array([1. , 1.41421356, 1.73205081, 2. ]) np.log(a) array([0. , 0.69314718, 1.09861229, 1.38629436]) np.sin(a) array([ 0.84147098, 0.90929743, 0.14112001, -0.7568025 ]) x = np.random.rand(12).reshape(3,4)x array([[0.07660223, 0.88255407, 0.24269254, 0.18597141], [0.25274604, 0.80124666, 0.9287589 , 0.91310848], [0.28050844, 0.17827769, 0.98518043, 0.05057346]]) np.sort(x) #每行 array([[0.07660223, 0.18597141, 0.24269254, 0.88255407], [0.25274604, 0.80124666, 0.91310848, 0.9287589 ], [0.05057346, 0.17827769, 0.28050844, 0.98518043]]) np.sort(x,axis = 0) array([[0.07660223, 0.17827769, 0.24269254, 0.05057346], [0.25274604, 0.80124666, 0.9287589 , 0.18597141], [0.28050844, 0.88255407, 0.98518043, 0.91310848]]) j = np.argsort(x) #每行，索引j array([[0, 3, 2, 1], [0, 1, 3, 2], [3, 1, 0, 2]], dtype=int64) 聚合函数a = np.array([3.3,4.4,5.5,6.6,7.7],dtype=&apos;f8&apos;)a array([3.3, 4.4, 5.5, 6.6, 7.7]) a.sum() 27.499999999999996 a.min() 3.3 a.max() 7.7 a.mean() 5.499999999999999 a.std() 1.5556349186104046 索引机制、切片和迭代方法a = np.arange(10,16)a array([10, 11, 12, 13, 14, 15]) a[4] 14 a[-1] 15 a[:] array([10, 11, 12, 13, 14, 15]) a[1:3] array([11, 12]) a[1:5:2] array([11, 13]) A = np.arange(10,19).reshape(3,3)A array([[10, 11, 12], [13, 14, 15], [16, 17, 18]]) A[1,2] 15 A[0:] array([[10, 11, 12], [13, 14, 15], [16, 17, 18]]) A[:,0] array([10, 13, 16]) A[0:2,0:2] array([[10, 11], [13, 14]]) A[[0,2],0:2] #抽取行或列的索引不连续，可以吧这几个索引放在数组中 array([[10, 11], [16, 17]]) 数组迭代for row in A: print(row) [10 11 12][13 14 15][16 17 18] for item in A.flat: #遍历每一个元素，A.flat print(item) 101112131415161718 除了for循环，Numpy提供了更为优雅的遍历方法通常用函数处理行、列或单个元素时，需要用到遍历。如果想用聚合函数处理每一列或行，返回一个数值作为结果，做好用纯NumPy方法处理循环：apply_along_axis()函数 np.apply_along_axis(np.mean,axis = 0,arr = A ) #axis 为0 按列 array([13., 14., 15.]) np.apply_along_axis(np.mean,axis = 1,arr = A ) #axis 为1 按行 array([11., 14., 17.]) def foo(x): return x/2np.apply_along_axis(foo,axis = 0,arr = A ) array([[5. , 5.5, 6. ], [6.5, 7. , 7.5], [8. , 8.5, 9. ]]) 条件和布尔数组A = np.random.random((4,4))A array([[0.06191449, 0.69862293, 0.60835369, 0.46886347], [0.06462235, 0.76134531, 0.22378327, 0.13396092], [0.81113357, 0.84190968, 0.97530762, 0.55843035], [0.89516065, 0.42526586, 0.54832821, 0.63796767]]) A&lt;0.5 array([[ True, False, False, True], [ True, False, True, True], [False, False, False, False], [False, True, False, False]]) A[A&lt;0.5] array([0.06191449, 0.46886347, 0.06462235, 0.22378327, 0.13396092, 0.42526586]) 形状变换a = np.random.random(12)a array([0.20564606, 0.13384151, 0.14979041, 0.52310893, 0.29431663,0.21416307, 0.97855221, 0.96023057, 0.88113124, 0.70537608,0.2383707 , 0.80332851]) A = a.reshape(3,4) #返回新数组，创建新对象A array([[0.20564606, 0.13384151, 0.14979041, 0.52310893], [0.29431663, 0.21416307, 0.97855221, 0.96023057], [0.88113124, 0.70537608, 0.2383707 , 0.80332851]]) a.shape = 3,4 #a.shape = （3,4）a array([[0.20564606, 0.13384151, 0.14979041, 0.52310893], [0.29431663, 0.21416307, 0.97855221, 0.96023057], [0.88113124, 0.70537608, 0.2383707 , 0.80332851]]) a = a.ravel()a array([0.20564606, 0.13384151, 0.14979041, 0.52310893, 0.29431663, 0.21416307, 0.97855221, 0.96023057, 0.88113124, 0.70537608, 0.2383707 , 0.80332851]) a.shape = (3,4)a array([[0.20564606, 0.13384151, 0.14979041, 0.52310893], [0.29431663, 0.21416307, 0.97855221, 0.96023057], [0.88113124, 0.70537608, 0.2383707 , 0.80332851]]) a.shape = 12a array([0.20564606, 0.13384151, 0.14979041, 0.52310893, 0.29431663, 0.21416307, 0.97855221, 0.96023057, 0.88113124, 0.70537608, 0.2383707 , 0.80332851]) A.transpose() array([[0.20564606, 0.29431663, 0.88113124], [0.13384151, 0.21416307, 0.70537608], [0.14979041, 0.97855221, 0.2383707 ], [0.52310893, 0.96023057, 0.80332851]]) A.T array([[0.20564606, 0.29431663, 0.88113124], [0.13384151, 0.21416307, 0.70537608], [0.14979041, 0.97855221, 0.2383707 ], [0.52310893, 0.96023057, 0.80332851]]) 数组操作连接数组A = np.ones((3,3))B = np.zeros((3,3))A array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) B array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) np.vstack((A,B)) array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) np.hstack((A,B)) array([[1., 1., 1., 0., 0., 0.], [1., 1., 1., 0., 0., 0.], [1., 1., 1., 0., 0., 0.]]) c = np.arange(16).reshape(4,4)c array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]]) a = np.array([0,1,2])b = np.array([3,4,5])c = np.array([6,7,8]) np.column_stack((a,b,c)) array([[0, 3, 6], [1, 4, 7], [2, 5, 8]]) np.row_stack((a,b,c)) array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) 数组切分A = np.arange(16).reshape((4,4))A array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]]) [B,C] = np.hsplit(A,2)B array([[ 0, 1], [ 4, 5], [ 8, 9], [12, 13]]) C array([[ 2, 3], [ 6, 7], [10, 11], [14, 15]]) [B,C] = np.vsplit(A,2)B array([[0, 1, 2, 3], [4, 5, 6, 7]]) C array([[ 8, 9, 10, 11], [12, 13, 14, 15]]) [A1,A2,A3] = np.split(A,[1,3],axis=1) #axis = 0 按行切分，axis = 1 按列切分 A1 array([[ 0], [ 4], [ 8], [12]]) A2 array([[ 1, 2], [ 5, 6], [ 9, 10], [13, 14]]) A3 array([[ 3], [ 7], [11], [15]]) [A1,A2,A3] = np.split(A,[1,3],axis=0) A1 array([[0, 1, 2, 3]]) A2 array([[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) A3 array([[12, 13, 14, 15]]) 广播机制 广播机制这一操作实现了对两个或以上数组进行运算或用函数处理，即使这些数组形状并不完全相同。并不是所有的维度都要彼此兼容才符合广播机制的要求，但它们必须满足一定的条件。 若两个数组的各维度兼容，也就是两个数组的每一维等长，或其中一个数组为一维，那么广播机制就适用。如果这两个条件都不能满足，Numpy就会抛出异常，说两个数组不兼容。 广播机制两条规则。第一条是为缺失的维度补上个1.如果这时满足兼容性条件，就可以应用光比机制。再来看第二条规则。 第二条规则鉴定缺失元素（一维）都用已有值进行了补充。 A = np.arange(16).reshape(4,4)b = np.arange(4)A array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]]) b array([0, 1, 2, 3]) A + b array([[ 0, 2, 4, 6], [ 4, 6, 8, 10], [ 8, 10, 12, 14], [12, 14, 16, 18]]) m = np.arange(6).reshape(3,1,2)n = np.arange(6).reshape(3,2,1)m array([[[0, 1]], [[2, 3]], [[4, 5]]]) n array([[[0], [1]], [[2], [3]], [[4], [5]]]) m + n array([[[ 0, 1], [ 1, 2]], [[ 4, 5], [ 5, 6]], [[ 8, 9], [ 9, 10]]]) 结构化数组structarray = np.array([(1,&apos;First&apos;,0.5,1+2j),(2,&apos;Second&apos;,1.3,2-2j),(3,&apos;Third&apos;,0.8,1+3j)],dtype=(&apos;i2,a6,f4,c8&apos;))structarray array([(1, b&apos;First&apos;, 0.5, 1.+2.j), (2, b&apos;Second&apos;, 1.3, 2.-2.j), (3, b&apos;Third&apos;, 0.8, 1.+3.j)], dtype=[(&apos;f0&apos;, &apos;&lt;i2&apos;), (&apos;f1&apos;, &apos;S6&apos;), (&apos;f2&apos;, &apos;&lt;f4&apos;), (&apos;f3&apos;, &apos;&lt;c8&apos;)]) structarray = np.array([(1,&apos;First&apos;,0.5,1+2j),(2,&apos;Second&apos;,1.3,2-2j),(3,&apos;Third&apos;,0.8,1+3j)])structarray array([[&apos;1&apos;, &apos;First&apos;, &apos;0.5&apos;, &apos;(1+2j)&apos;], [&apos;2&apos;, &apos;Second&apos;, &apos;1.3&apos;, &apos;(2-2j)&apos;], [&apos;3&apos;, &apos;Third&apos;, &apos;0.8&apos;, &apos;(1+3j)&apos;]], dtype=&apos;&lt;U11&apos;) structarray = np.array([(1,&apos;First&apos;,0.5,1+2j),(2,&apos;Second&apos;,1.3,2-2j),(3,&apos;Third&apos;,0.8,1+3j)],dtype=[(&apos;id&apos;,&apos;&lt;i2&apos;),(&apos;position&apos;,&apos;S6&apos;),(&apos;value&apos;,&apos;f4&apos;),(&apos;complex&apos;,&apos;c8&apos;)])structarray array([(1, b&apos;First&apos;, 0.5, 1.+2.j), (2, b&apos;Second&apos;, 1.3, 2.-2.j), (3, b&apos;Third&apos;, 0.8, 1.+3.j)], dtype=[(&apos;id&apos;, &apos;&lt;i2&apos;), (&apos;position&apos;, &apos;S6&apos;), (&apos;value&apos;, &apos;&lt;f4&apos;), (&apos;complex&apos;, &apos;&lt;c8&apos;)]) 数组数据文件的读写data = np.random.random(16).reshape(4,4)data array([[0.51264409, 0.4027414 , 0.49030108, 0.60320778], [0.09145262, 0.15780606, 0.43957007, 0.46891392], [0.60041983, 0.93856545, 0.22183402, 0.51324425], [0.76605488, 0.74672403, 0.02454652, 0.85436632]]) np.save(&apos;save_date&apos;,data) loaded_data = np.load(&apos;save_date.npy&apos;) loaded_data array([[0.51264409, 0.4027414 , 0.49030108, 0.60320778], [0.09145262, 0.15780606, 0.43957007, 0.46891392], [0.60041983, 0.93856545, 0.22183402, 0.51324425], [0.76605488, 0.74672403, 0.02454652, 0.85436632]]) data = np.array([(1., 123., 1.4, 23.), (2., 110., 0.5, 18.), (3., 164., 2.1, 19.)], dtype=[(&apos;id&apos;, &apos;&lt;f8&apos;), (&apos;value1&apos;, &apos;&lt;f8&apos;), (&apos;value2&apos;, &apos;&lt;f8&apos;), (&apos;value3&apos;, &apos;&lt;f8&apos;)]) np.savetxt(&apos;datas.csv&apos;,data,delimiter=&apos;,&apos;) np.loadtxt(&apos;datas.csv&apos;,delimiter=&apos;,&apos;) array([[ 1. , 123. , 1.4, 23. ], [ 2. , 110. , 0.5, 18. ], [ 3. , 164. , 2.1, 19. ]]) 读写文本格式的数据（如TXT或CSV） data = np.genfromtxt(&apos;data.csv&apos;,delimiter=&apos;,&apos;,names = True) #文件名，分割值的字符，是否含有标题 data array([(1., 123., 1.4, 23.), (2., 110., 0.5, 18.), (3., 164., 2.1, 19.)], dtype=[(&apos;id&apos;, &apos;&lt;f8&apos;), (&apos;value1&apos;, &apos;&lt;f8&apos;), (&apos;value2&apos;, &apos;&lt;f8&apos;), (&apos;value3&apos;, &apos;&lt;f8&apos;)]) data[&apos;id&apos;] array([1., 2., 3.]) np.where函数np.where函数是三元表达式 x if condition else y 的矢量化版本 x = np.array([2,3,4,5,6,])y = np.array([10,11,12,13,14])condition =np.array([True,False,True,True,False])z = np.where(condition,x,y)z array([ 2, 11, 4, 5, 14]) 处理缺失值data =np.array([[1,2,np.NaN,4],[np.NaN,2,3,4]])data array([[ 1., 2., nan, 4.], [nan, 2., 3., 4.]]) np.isnan(data) array([[False, False, True, False], [ True, False, False, False]]) np.where(np.isnan(data),0,data) array([[1., 2., 0., 4.], [0., 2., 3., 4.]]) 数组去重np.unique([1, 1, 2, 2, 3, 3]) array([1, 2, 3]) a = np.array([[1, 1], [2, 3]])np.unique(a) array([1, 2, 3])]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聚类]]></title>
    <url>%2F2019%2F01%2F23%2F%E8%81%9A%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[聚类的概念聚类是一种无监督机器学习方法，它基于数据的内部结构寻找观察样本的自然族群（即集群），常用于新闻分类、推荐系统等。聚类的特点是训练数据没有标注，通常使用数据可视化评价结果。 聚类分析仅根据在数据中发现的描述对象及其关系的信息，将数据对象分组。其目标是，组内的对象相互之间是相似的（相关的），而不同组中的对象是不同的（不相关的）。组内的相似性（同质性）越大，组间差别越大，聚类就越好。 聚类的方法聚类的常用方法包括： 划分聚类法，K均值:是基于原型的、划分的聚类技术。它试图发现用户指定个数K的簇（由质心代表）。 层次聚类。凝聚的层次聚类：开始，每个点作为一个单点簇；然后，重复地合并两个最靠近的簇，直到产生单个的、包含所有点的簇。 基于密度的聚类， DBSCAN是一种产生划分聚类的基于密度的聚类算法，簇的个数由算法自动地确定。低密度区域中的点被视为噪声而忽略，因此DBSCAN不产生完全聚类。 常用的聚类数据集常用的聚类数据集包括 scikit-learn blob: 简单聚类 scikit-learn circle: 非线性可分数据集 scikit-learn moon: 更复杂的数据集 聚类的性能度量我们希望聚类结果的“簇内相似度”高且“簇间相似度”低。 其性能度量大致有两类： 将聚类结果与某个“参考模型”进行比较。称为“外部指标”。 直接考查聚类结果而不利于任何参考模型。称为“内部指标”。 外部指标对数据集D={x_1,x_2,…,x_m},假定通过聚类给出的簇划分为C=C_1,C_2,…,C_k,参考模型给出的簇划分为C’=C_1^T,C_2^T,…,C_s^T。相应的，令λ与λ^T分别表示与C和C^T对应的簇标记向量。注意的是，参考模型给出的划分类别数量不一定等于通过聚类得到的数量。 样本两两配对： 1.a=\mid SS \mid ,SS={(x_i,x_j)\mid \lambda_i = \lambda_j,\lambda_i^T=\lambda_j^T,i]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>聚类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树与随机森林]]></title>
    <url>%2F2019%2F01%2F23%2F%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%2F</url>
    <content type="text"><![CDATA[决策树决策树（decision tree）是一种分类与回归方法，本文主要讨论用于分类的决策树，决策树的结构呈树形结构，在分类问题中，其代表基于特征对数据进行分类的过程，通常可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。其主要优点是模型可读性好并且分类速度快。训练的时候，利用训练数据根据损失函数最小化的原则建立决策树模型。 决策树的学习通常包括三个步骤：特征选择，生成决策树，对决策树进行剪枝。这些决策树的思想主要来自Quinlan在1986年提出的ID3算法和1993年提出的C4.5算法，以及Breiman等人在1984年提出的CART算法。 用于分类的决策树是一种对数据进行分类的树形结构。决策树主要由节点（node）和有向边（directed edge）组成。节点有两种类型：内部节点（internal node）以及叶节点（leaf node）。内部节点表示一个特征或者属性，叶节点表示一个类。其结构如图所示： 决策树学习采用的是自顶向下的递归方法, 其基本思想是以信息熵为度量构造一棵熵值 下降最快的树,到叶子节点处的熵值为零, 此时每个叶节点中的实例都属于同一类。 最大优点: 可以自学习。在学习的过程中,不需要使用者了解过多背景知识,只需要对训练实例进行较好的标注,就能够进行学习。 显然,属于有监督学习。 决策树三种生成算法１、 ID3 — 信息增益 最大的准则 ​ ID3算法的核心是在决策树各个节点上使用信息增益作为特征选择的依据，递归的构建决策树。 从根节点开始，对节点计算所有可能的特征的信息增益，选择信息增益最大的特征作为节点的特征，由该特征的不同取值建立子节点；再对子节点递归的调用以上方法，构建决策树；知道所有特征的信息增益均很小或没有特征可以选择为止，得到最后一个决策树。ID3相当于用最大似然法进行概率模型的选择。 ２、C4.5 — 信息增益比 最大的准则 ​ C4.5算法使用信息增益率作为特征选择的依据，算法的流程与ID3相似。 ３、CART 回归树: 平方误差 最小 的准则 分类树: 基尼系数 最小的准则 CART树的名字其实非常有意思，Classification And Regression Tree（分类回归树），它使用基尼系数(Gini Index)作为特征的划分依据。顾名思义，CART既可以用来做分类也可以用来做回归。它是在给定输入随机变量X条件下输出随机变量Y的条件概率分布的学习方法。 CART树假设我们的决策树是二叉树，内部节点特征的取值为是或否。 CART算法为： １．决策树的生成：基于训练数据集生成决策树，生成的决策树要尽量大； ２．决策树剪枝：用验证数据集对已经生成的巨额子树进行剪枝并选择最优子树。 信息熵信息熵（information entropy） 是度量样本集合纯度的最常用的一种指标。 熵：$H(X)=-\sum_{x \in X} p(x,y)logp(x)$ 联合熵：$H(X，Y)=-\sum_{x \in X,y \in Y} p(x,y)logp(x,y)$ 条件熵：$H(X|Y)=-\sum_{x \in X,y \in Y} p(x,y)logp(x|y)$ 相对熵：$D(p||q)=\sum_x p(x)log\frac{p(x)}{q(x)}$ 互信息：$I(x,y)=\sum_{x\in X, y \in Y} p(x,y )log\frac{p(x,y)}{p(x)p(y)}$ 决策树学习基本算法 信息增益-$g(D,A)$信息增益(Information Gain)：表示得知特征A的信息而使得类X的信息的不确定性减少的程度。 定义：特征A对训练数据集D的信息增益g(D, A)，定义为集合D的经验熵H(D)与经验条件熵H(D|A)的差值。 g(D,A)=H(D)−H(D|A)而这又是互信息的定义。所以决策树中的信息增益等价于训练集中类与特征的互信息。 总结：一般而言，信息增益g(D, A)越大，就意味着使用特征A来进行划分所获得的“纯度提升”就越大。著名的ID3决策树学习算法就是以信息增益为准则来学习划分属性的。 增益率信息率(Information Gain Ratio)： 用信息增益作为划分特征的依据时，会存在一些问题。例如，如果使用数据的ID作为特征，这样，每个数据点相当于均匀分布，所以得到的信息增益一定是最大的，但是我们都知道ID是不能作为特征的。这样如果单纯的使用信息增益作为划分特征的依据的话，会导致我们生成的树比较矮胖，容易过拟合。 定义：特征A对训练数据集D的信息增益率$gR(D,A)$定义为其信息增益$g(D,A)$与训练数据集D关于特征A的值的信息熵$IV(D)$之比： gR(D,A)=\frac {g(D,A)}{IV(D)}总结：信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，著名的C4.5决策树算法就不直接使用信息增益而是使用“增益率” 。 Gini系数数据集P的纯度可以用Gini值来度量。 Gini(P)=\sum_{k=1}^K p_k(1-p_k)=1-\sum_{k=1}^Kp_k^2总结：CART决策树使用Gini指数来选择划分属性。$Gini(P)$反映了从数据集D中随机抽取了两个样本，其类别标记不一致的概率，因此，$Gini（D）$越小，则数据集P的纯度就越高。 决策树的评价 —— loss function 假定样本的总类别数为K个；树T的叶节点个数为$∣T∣$，t是树T的叶节点，叶节点有N_t个样本点，其中k类的样本点有N_{ik}个，H_t(T)为叶节点t上的经验熵，则决策树的loss function可以定义为： C_a(T)=\sum_{t\in Leaf}N_tH_t(T)+a|T|决策树种避免过拟合的方法——剪枝 预剪枝：在决策树生成过程中，对每个结点在划分前先进行估计，如果当前的结点划分不能带来决策树泛化性能提升，则停止划分并将当前的结点标记为叶节点。 后剪枝：先从训练集生成一个完整的决策树，然后自底向上的对非叶节点进行考察，若将该结点对应的子树替换为叶节点能带来决策树泛化能力性能提升，则就把该子树替换为叶结点。 在上面决策树的评价指标loss function ：C_a(T)=\sum_{t\in Leaf}N_tH_t(T)+a|T|中： C(T)表示模型对训练数据集的预测误差，即模型与训练数据的拟合程度， $∣T∣$表示模型复杂度，由参数α控制两者之间的影响。 当α确定时： 子树越大，与训练集的拟合越好，但模型的复杂度就越高； 子树越小，模型简单，但与训练集的拟合度不好。 决策树生成学习局部的模型，而剪枝学习整体的模型! 剪枝的过程为： 计算每个节点的经验熵； 递归的从树的叶节点向上回缩，设一组叶节点回缩到其父节点之前和之后的整体树分别为T_B和T_A，对应的损失函数值分别为C_α(T_B)和C_α(T_A),如果C_α(T_A)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>随机森林</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑回归]]></title>
    <url>%2F2019%2F01%2F22%2F%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[概念Logistic Regression 在《机器学习》-周志华一书中又叫对数几率回归。逻辑回归和多重线性回归实际上有很多的相同之处，除了它们的因变量（函数）不同外，其他的基本差不多，所以逻辑回归和线性回归又统属于广义线性模型（generalizedlinear model）。 广义线性模型的形式其实都差不多，不同的就是因变量（函数）的不同。 如果是连续的，就是多重线性回归 如果是二项分布，就是Logistic回归 如果是Poisson分布，就是Poisson分布 如果是负二项分布，就是负二项回归 Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。 主要用途 寻找危险因素：寻找某一疾病的危险因素等； 预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大； 判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。 一般步骤 寻找h函数（即hypothesis）； 构造J函数（损失函数）； 想办法使得J函数最小并求得回归参数（θ） 构造预测函数（hypothesis）Logistic回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别），所以利用了Logistic函数（或称为Sigmoid函数），函数形式为： $g(z)=\frac{1}{1+e^{-z}}$ 为了方便后面使用我们求出g(z)g(z)的导数： $g’(z)=\frac1{1+e^{-z} } \cdot (1- \frac1{1+e^{-z} })=g(z)(1-g(z))$ Sigmoid 函数在有个很漂亮的“S”形，如下图所示: 构建预测函数对于线性边界的情况，边界形式如下： \theta_0+\theta_1x_1+\cdot \cdot \cdot + \theta_nx_n=\sum_{i=1}^n \theta_ix_i = \theta^Tx构建的预测函数为： h_\theta(x)=g(\theta^Tx)=\frac1{1+e^{-\theta^Tx}}构建损失函数由于是二项分布，函数$h_ \theta(x)$的值就有特殊的含义，它所表示的是结果取1的概率，因此对于输入x的分类结果就判别为类别1和类别0的概率分别为： $P(y=1|x;\theta)=h_\theta(x) $ $P(y=0|x;\theta)=1-h_\theta(x)$ 所以： P(y|x;\theta) = {h_\theta(x) }^y{(1-h_\theta(x)) }^{1-y}构建似然函数L(\theta)=\prod_{i=1}^n P(y_i|x_i;\theta) =\prod_{i=1}^n {h_\theta(x_i) }^{y_i}{(1-h_\theta(x_i)) }^{1-y_i}对数似然函数l(\theta)=logL(\theta)=\sum_{i=1}^n(y_ilogh_\theta(x_i)+(1-y_i)log(1-h_\theta(x_i)))最大似然估计就是求使$l(\theta)$取最大值时的θ，其实这里可以使用梯度上升法求解，求得的θ就是要求的最佳参数。 梯度下降法求的最小值θ更新过程： $\theta_j :=\theta_j-a(\frac{\partial l(\theta)}{\partial \theta_j})$ 对θ求偏导: $\frac{\partial l(\theta)}{\partial \theta_j}=\frac{\partial g(\theta^Tx)}{\partial \theta_j}(\frac{y}{g(\theta^Tx)}-\frac{1-y}{g(\theta^Tx)})$ $=g(\theta^Tx)(1-g(\theta^Tx)) \frac{\partial\theta^Tx}{\partial \theta_j}(\frac{y}{g(\theta^Tx)}-\frac{1-y}{g(\theta^Tx)})$ $=(y(1-g(\theta^Tx))-(1-y)g(\theta^Tx))x_j$ $=(y-h_\theta(x))x_j$ θ更新过程就可以写为： \theta_j :=\theta_j-a \sum_{i=1}^n (y_i-h_{\theta} (x_i))x_i^j但是在在Andrew Ng的课程中将$J(\theta)$取为下式，即： J(\theta)=-\frac{1}{m}l(\theta)因为乘了一个负的系数-1/m，所以取$J(\theta)$最小值时的θ为要求的最佳参数。 \frac{\partial l(\theta)}{\partial \theta_j}=\frac 1 m \sum_{i=1}^n(h_\theta(x_i)-y_i)x_i^j相应的θ: \theta_j :=\theta_j-a \frac 1 m \sum_{i=1}^n (h_\theta(x_i)-y_i)x_i^j向量化（Vectorization ）Vectorization是使用矩阵计算来代替for循环，以简化计算过程，提高效率。 如上式，Σ(…)是一个求和的过程，显然需要一个for语句循环m次，所以根本没有完全的实现vectorization。 下面介绍向量化的过程： 约定训练数据的矩阵形式如下，x的每一行为一条训练样本，而每一列为不同的特称取值： g(A)的参数A为一列向量，所以实现g函数时要支持列向量作为参数，并返回列向量。由上式可知$h_\theta(x)-y$可以由$g(A)-y$一次求得 θ更新过程可以改为: \theta_j :=\theta_j-a \frac 1 m \sum_{i=1}^n (h_\theta(x_i)-y_i)x_i^j=\theta_j-a \frac 1 m \sum_{i=1}^n e_ix_i^j=\theta_j-a \frac1 m x^TE综上所述，Vectorization后θ更新的步骤如下： $A=x \cdot \theta$ $E=g(A)-y$ $\theta:=\theta-ax^TE$ 正则化Regularization同样逻辑回归也有欠拟合、适合拟合、过拟合问题 对于线性回归或逻辑回归的损失函数构成的模型，可能会有些权重很大，有些权重很小，导致过拟合（就是过分拟合了训练数据），使得模型的复杂度提高，泛化能力较差（对未知数据的预测能力）。 解决方法1）减少特征数量（减少特征会失去一些信息，即使特征选的很好） 可用人工选择要保留的特征； 模型选择算法； 2）正则化（特征较多时比较有效） 保留所有特征，但减少θ的大小 正则化方法正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或惩罚项。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化项就越大。 正则项可以取不同的形式，在回归问题中取平方损失，就是参数的L2范数，也可以取L1范数。取平方损失时，模型的损失函数变为： J(\theta)=\frac1{2m}\sum_{i=1}^{n}(h_\theta(x_i)-y_i)^2+\lambda\sum_{j=1}^n \theta_j^2lambda是正则项系数： 如果它的值很大，说明对模型的复杂度惩罚大，对拟合数据的损失惩罚小，这样它就不会过分拟合数据，在训练数据上的偏差较大，在未知数据上的方差较小，但是可能出现欠拟合的现象； 如果它的值很小，说明比较注重对训练数据的拟合，在训练数据上的偏差会小，但是可能会导致过拟合。 正则化后的梯度下降算法θ的更新变为： \theta_j :=\theta_j-a \frac 1 m \sum_{i=1}^n (h_\theta(x_i)-y_i)x_i^j - \frac \lambda m \theta_j其他优化算法 Conjugate gradient method(共轭梯度法) Quasi-Newton method(拟牛顿法) BFGS method(局部优化法) L-BFGS(Limited-memory BFGS)（有限内存局部优化法） 后二者由拟牛顿法引申出来，与梯度下降算法相比，这些算法的优点是： 第一，不需要手动的选择步长； 第二，通常比梯度下降算法快； 但是缺点是更复杂。 多类分类问题多类分类问题中,我们的训练集中有多个类(&gt;2),我们无法仅仅用一个二元变量(0或1)来做判断依据。例如我们要预测天气情况分四种类型:晴天、多云、下雨或下雪。 一种解决这类问题的途径是采用一对多(One-vs-All)方法（可以将其看做成二类分类问题：保留其中的一类，剩下的作为另一类 ）。在一对多方法中,我们将多类分类问题转化成二元分类问题。为了能实现这样的转变,我们将多个类中的一个类标记为正向类(y=1),然后将其他所有类都标记为负向类,这个模型记作： $h_\theta^{(1)}(x)$ 接着,类似地第我们选择另一个类标记为正向类(y=2),再将其它类都标记为负向类,将这个模型记作: $h_\theta^{(2)}(x)$ 依此类推。最后我们得到一系列的模型简记为: $h_\theta^{(i)}(x)=p(y=i|x;\theta)$ 最后,在我们需要做预测时,我们将所有的分类机都运行一遍,然后对每一个输入变量,都选择最高可能性的输出变量。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习简介]]></title>
    <url>%2F2019%2F01%2F22%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[机器学习任务的一般步骤１．确定特征 – 可能是最重要的步骤! （收集训练数据）２．确定模型 – 目标函数/决策边界形状３．模型训练：根据训练数据估计模型参数 – 优化计算４．模型评估：在校验集上评估模型预测性能５．模型应用/预测 模型 非线性模型 目标函数 损失函数—回归 损失函数—分类 正则项 常用正则函数 常见线性模型的损失和正则项组合 L2损失 L1损失 Huber Logistic损失 合叶损失 ε-insentive损失 L2正则 岭回归 L2正则 Logistic回归 SVM SVR L1正则 LASSO L1正则 Logistic回归 L2+L1正则 Elastic net]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性回归]]></title>
    <url>%2F2019%2F01%2F22%2F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[线性回归（Linear Regression）数理统计中回归分析，用来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，其表达形式为$y=wx+e$，e为误差服从均值为0的正态分布，其中只有一个自变量的情况称为简单回归，多个自变量的情况叫多元回归。 注意，统计学中的回归并非如线性回归非与严格直线函数完全能拟合，所以我们统计中称之为回归用以与其直线函数区别。 下面看个例子： 数据：工资和年龄（2个特征）目标：预测银行会贷款给我多少钱（标签）考虑：工资和年龄都会影响最终银行贷款的结果那么它们各自有多大的影响呢？（参数） 工资 年龄 额度 4000 25 20000 8000 30 70000 5000 28 35000 7500 33 50000 这个表格表示的是可贷款的金额 与 工资 和 年龄之间的关系，其中 工资 和 年龄 为 特征，可贷款金额为目标函数值。 那么根据线性函数可得到以下公式： h_\theta(x)=\theta_{1}x_{1}+\theta_{2}x_{2}上面的这个式子是当一个模型只有两个特征(x1,x2)的时候的线性回归式子。 正常情况下，现金贷中可贷款的额度和用户的很多特征相关联，并不只是简单的这两个特征。所以我们需要把这个式子进行通用化。 假如有n个特征的话，那么式子就会变成下面的样子： h_\theta(x)=\theta_{1}x_{1}+\theta_{2}x_{2} + \cdot \cdot \cdot \cdot \cdot+\theta_{n}x_{n} = \sum_{i=1}^{n}\theta_{i}x_{i}利用矩阵的知识对线性公式进行整合因为机器学习中基本上都是用矩阵的方式来表示参数的，也就是说我们需要把这个多项求和的式子用矩阵的方式表达出来，这样才方便后续的计算。 \theta_{i \times 1} = [\theta_1,\theta_2,\cdot\cdot\cdot\theta_i,]X_{i\times1}=[x_1,x_2,\cdot \cdot \cdot x_i]\theta^TX=\begin{bmatrix} \theta_1 \\ \theta_2 \\ \cdot \\ \cdot \\ \cdot \\ \theta_i \end{bmatrix} \cdot [x_1,x_2,\cdot \cdot \cdot x_i] = \sum_{i=1}^{n}\theta_{i}x_{i}我们把权重参数和特征参数，都看成是1行n列的矩阵(或者是行向量)。那么就可以根据矩阵乘法的相关知识，把上述多项求和的式子，转换成矩阵的乘法的表达式。 由此我们就把多项求和化简称了 。 h_\theta(x)=\theta^TX误差真实值和预测值之间肯定是存在误差的，我们用\varepsilon来表示该误差 所以回归函数变为： h_\theta(x)=\theta^Tx+\varepsilon我们根据实际情况，假设认为这个误差项是满足以下几个条件的: 误差\varepsilon_{(i)}是独立的。 具有相同的分布。 服从均值为0方差为θ_2的高斯分布。 然后我们回到刚开始的现金贷产品的贷款额度问题上面: 独立：张三和李四一起使用这款产品，可贷款额互不影响 同分布：张三和李四是使用的是同一款产品 高斯分布：绝大多数的情况下，在一个的空间内浮动不大 似然函数由前面两步，我们已经把线性回归模型，推导成下面的这个式子: $y_{(i)}=\theta^Tx_i+\varepsilon_i$ (1) 因为误差项是符合高斯分布的，所以误差项的概率值： $P(\varepsilon_i)=\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(\varepsilon_i)^2}{2\sigma^2})}$ (2) 将 (1) 式代入 (2) 式： $P(y_i|x_i,\theta)=\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}$ 由于是误差值，所以是越小越好，所以我们接下来就是讨论什么样的特征值和特征组合能够让误差值最小，似然函数的作用就是要根据样本求什么样的参数和特征的组成能够接近真实值，越接近真实值则误差就越小。 引入似然函数(似然函数就是求能让真实值和预测值相等的那个参数 )： L(\theta) = \prod_{i=1}^{N} P(y_i|x_i,\theta)=\prod_{i=1}^{N}\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}$\prod$表示各元素相乘 上面的式子是多个参数的乘积的形式，很难进行计算，所以我们又采用了对数的一个小技巧，把多个数相乘，转化成多个数相加的形式。 因为对数的性质: $logA\cdot B = logA+logB$ 根据上面的这种换算关系，我们就把似然函数的式子换算成下面的这个。 (因为似然函数是越大越好，似然函数的值和对数似然函数的值是成正比的，对值求对数，并不会影响到最后求极限的值。所以才敢进行对数处理。) $l(\theta) = logL(\theta) = log\prod_{i=1}^{N}\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}$ 对上式进行整理： $l(\theta) = logL(\theta) = \sum_{i=1}^{N}log\frac{1}{\sqrt{2\pi}\sigma}e^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})}$ $= \sum_{i=1}^{N}(log\frac{1}{\sqrt{2\pi}\sigma}+loge^{-(\frac{(y_i-\theta^Tx_i)^2}{2\sigma^2})})$ $= Nlog\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$ 因为： $Nlog\frac{1}{\sqrt{2\pi}\sigma}$和$-\frac{1}{2\sigma^2}$是一个定值 似然函数是要越大越好 所以： $l(\theta) = \sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$ $\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$越小越好——最小二乘法（损失函数） 最小二乘法上述代价函数中使用的均方误差，其实对应了我们常用的欧几里得的距离（欧式距离，Euclidean Distance）, 基于均方误差最小化进行模型求解的方法称为“最小二乘法”（least square method），即通过最小化误差的平方和寻找数据的最佳函数匹配； 当函数子变量为一维时，最小二乘法就蜕变成寻找一条直线； 然后我们把得到的损失函数推广到n维，转换成矩阵形式（参考前面利用矩阵的知识对线性公式进行整合）： $J(\theta)=\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2$(损失函数) 其对应的均方误差表示为如下矩阵： $J(\theta) = {(y-X\theta)^T(y-X\theta)}$ 其中Ｘ: X=\begin{bmatrix} 1 && x_1^T \\ 1 && x_2^T \\ \cdot \\ \cdot \\ \cdot \\ 1 && x_N^T \end{bmatrix} =\begin{bmatrix} 1 && x_{11} && x_{12} && \cdot \cdot \cdot x_{1n} \\ 1 && x_{21} && x_{22} && \cdot \cdot \cdot x_{2n} \\ \cdot \\ \cdot \\ \cdot \\ 1&& x_{m1} && x_{m2} && \cdot \cdot \cdot x_{mn} \end{bmatrix}对$θ$求导: $J(\theta) = {(y-X\theta)^T(y-X\theta)}=y^Ty-y^Tx\theta-\theta^Tx^Ty+\theta^Tx^Tx\theta$ $\frac{\partial J(\theta)}{\partial(\theta)} = \frac{\partial y^Ty}{\partial(\theta)} - \frac{\partial y^Tx\theta}{\partial(\theta)} - \frac{\partial \theta^Tx^Ty}{\partial(\theta)} + \frac{\partial \theta^Tx^Tx\theta}{\partial(\theta)}$ $\frac{\partial J(\theta)}{\partial(\theta)} = 0-x^Ty-x^Ty+2x^Tx\theta$ $\frac{\partial J(\theta)}{\partial(\theta)} =2x^T(x\theta-y)$ 根据导数的性质，该值在导数为0时为最小 所以： 根据微积分定理，令上式等于零，可以得到 θ 最优的闭式解。当$2(x^Ty-x^Tx\theta)=0$时取得最小 最终： $\theta = (x^Tx)^{-1}x^Ty$ X和Y都是已知的，那么得到了最终的参数值。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVM]]></title>
    <url>%2F2019%2F01%2F22%2FSVM%2F</url>
    <content type="text"><![CDATA[背景 最大间隔分类器 距离的计算在样本空间中，划分超平面可通过如下线性方程描述： w^Tx+b=0样本空间中任意点x到超平面的距离可写为: r=\frac{\lvert w^Tx+b\rvert}{\lVert w\rVert}数据标签定义 优化的目标 目标函数 拉格朗日乘子法 SVM求解 SVM求解实例 支持向量：真正发挥作用的数据点，ɑ值不为0的点 带松弛因子的SVM：C-SVM soft-margin 核方法 低维不可分问题 常用核函数 支持向量回归（SVR） Scikit learn 中的SVM实现 Scikit learn 中的SVC实现 核函数kernel RBF核的参数 RBF核—核参数正好 RBF核—欠拟合 RBF核—过拟合 总结SVM的优点： – 在高维空间中行之有效 – 当维数大于样本数时仍然可用（但性能不好） – 在决策函数中只使用训练点的一个子集（支持向量），大大节省了内存开 销 – 用途广泛：决策函数中可使用不同的核函数• 劣势： ​ – SVM不直接提供概率估计​ – 可通过交叉验证计算，代价比较高• Scikit-learn中的支持向量机同时支持密集样本向量（numpy.ndarray和可通过numpy.asarray转化的数据类型）和稀疏样本向量（任何scipy.sparse对象）。但如果想用SVM对稀疏数据进行预测，则必须先在这些数据上拟合。为了优化性能，应该使用C阶（C-Ordered）numpy.ndarray（密集的）或scipy.sparse.csr_matrix（稀疏的），并指定dtype=float64]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVD分解]]></title>
    <url>%2F2019%2F01%2F22%2FSVD%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[奇异值分解(SVD)原理奇异值分解(Singular Value Decomposition，以下简称SVD)是在机器学习领域广泛应用的算法，它不光可以用于降维算法中的特征分解，还可以用于推荐系统，以及自然语言处理等领域。是很多机器学习算法的基石。 特征值和特征向量 注意到要进行特征分解，矩阵A必须为方阵。那么如果A不是方阵，即行和列不相同时，我们还可以对矩阵进行分解吗？ 答案是可以，此时我们的SVD登场了。 SVD的定义 SVD计算举例 SVD性质 由于这个重要的性质，SVD可以用于PCA降维，来做数据压缩和去噪。也可以用于推荐算法，将用户和喜好对应的矩阵做特征分解，进而得到隐含的用户需求来做推荐。同时也可以用于NLP中的算法，比如潜在语义索引（LSI）。下面我们就对SVD用于PCA降维做一个介绍。 SVD用于PCA在主成分分析（PCA）中，我们讲到要用PCA降维，需要找到样本协方差矩阵 $XX^T$ 的最大的d个特征向量，然后用这最大的d个特征向量张成的矩阵来做低维投影降维。可以看出，在这个过程中需要先求出协方差矩阵 $XX^T$ ，当样本数多样本特征数也多的时候，这个计算量是很大的。 注意到我们的SVD也可以得到协方差矩阵 $XX^T$ 最大的d个特征向量张成的矩阵，但是SVD有个好处，有一些SVD的实现算法可以不先求出协方差矩阵 $XX^T$ ，也能求出我们的右奇异矩阵V。也就是说，我们的PCA算法可以不用做特征分解，而是做SVD来完成。这个方法在样本量很大的时候很有效。实际上，scikit-learn的PCA算法的背后真正的实现就是用的SVD，而不是我们我们认为的暴力特征分解。 另一方面，注意到PCA仅仅使用了我们SVD的右奇异矩阵，没有使用左奇异矩阵，那么左奇异矩阵有什么用呢？ 假设我们的样本是m×n的矩阵X，如果我们通过SVD找到了矩阵 $XX^T$ 最大的d个特征向量张成的m×d维矩阵U，则我们如果进行如下处理： X'_{d\times n}=U_{d\times m}^TX_{m\times n}可以得到一个d×n的矩阵X‘,这个矩阵和我们原来的m×n维样本矩阵X相比，行数从m减到了d，可见对行数进行了压缩。也就是说，左奇异矩阵可以用于行数的压缩。相对的，右奇异矩阵可以用于列数即特征维度的压缩，也就是我们的PCA降维。 Numpy求解SVDimport numpy as npdata = np.array( [[1, 1, 1, 0, 0], [2, 2, 2, 0, 0], [3, 3, 3, 0, 0], [5, 5, 3, 2, 2], [0, 0, 0, 3, 3], [0, 0, 0, 6, 6]])u, sigma, vt = np.linalg.svd(data) #SVD分解print(u.shape, sigma.shape, vt.shape) SVD小结SVD作为一个很基本的算法，在很多机器学习算法中都有它的身影，特别是在现在的大数据时代，由于SVD可以实现并行化，因此更是大展身手。SVD的原理不难，只要有基本的线性代数知识就可以理解，实现也很简单因此值得仔细的研究。当然，SVD的缺点是分解出的矩阵解释性往往不强，有点黑盒子的味道，不过这不影响它的使用。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[点击预估]]></title>
    <url>%2F2019%2F01%2F21%2F%E7%82%B9%E5%87%BB%E9%A2%84%E4%BC%B0%2F</url>
    <content type="text"><![CDATA[目标广告显示：只显示相关的广告 背景： ​ – 用户喜欢相关的广告​ – 只有用户点击时，广告平台才能收到广告费 所以预测一个广告是否会被点击很关键 方式： – 预估点击率 (predict Click Through Rate, pCTR) 推荐系统 vs. 点击率预估 CTR的挑战• 用最少的资源在大量的数据上训练大量的模型 上亿的特征数目（模型系数的数目） 每天有上亿的流量（提供上亿次预测服务） 上亿的训练样本数目 • 其他 正负样本数目不均衡 面向稀有事件的 Logistic Regression 模型校准 特征稀疏（OneHot编码） https://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/15/model-calibration-for-logistic-regression-in-rare-events-data CTR预估• 预测模型：预估广告是否被点击，是一个两类分类问题 • 特征：用户、广告、场景、媒体 • 性能评估：准确率/召回率、AUC 基础特征展示广告：在某场景下，通过某媒体向用户展示广告– 场景：当时场景，如何时何地，使用何种设备，使用什么浏览器等– 广告 - 广告主特征、广告自身的特征如campaign、创意、类型，是否重定向等– 媒体 - 媒体（网页、app等）的特征、广告位的特征等– 用户 - 用户画像、用户浏览历史、检索关键词等 特征工程• 特征离散化• 特征交叉 FM/FFM： 类别型 特征 OneHot编码后再组合 GBDT：用树的叶子节点索引作为样本特征 特征组合并特征离散化• 特征选择：嵌入到模型 预测模型• Logistic回归（LR）： – 特征工程很重要 – LR-FTRL： Google在2010年提出了一些理论基础，2013年给出了Paper，并且带有FTRL的实现伪代码。在此之后，FTRL才大规模应用在工业界。• FM(Factorization Machines) – Steffen Rendle于2010年提出Factorization Machines（FM），并发布开源工具libFM。凭借这单个模型，他在KDD Cup 2012上，取得Track1的第2名和Track2的第3名。本质上可看作是：高效特征交叉 + LR。• 深度学习DNN – 特征工程工作量少，但10^11 级别的原始广告特征、以及特征的稀疏性对DNN还是巨大挑战 CTR模型评估• 原则上分类性能评价指标均可用于CTR模型评估 – Logloss、PR、…• 最常用的评估指标：ROC曲线下的面积（Area Under Curve， AUC ） – 随机分类模型AUC为0.5 – 越接近1模型的效果越好当随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。 AUC• 当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变 ,AUC不变• CTR场景下，测试数据中的正负样本的分布可能随着时间变化而变化 CTR预估-Logistic回归（LR） Logistic回归 + L1正则由于CTR预估中特征维数非常高，我们希望得到稀疏解，利用L1正则，目标函数为 Google: Large scale LR model• Ad Click Prediction A view from the trenches– Google FTRL模型在点击率预估任务上的应用• FTRL是L1正则的LR，但对模型训练进行了优化：– 在线学习（Online Learning）– 模型稀疏• 很重要，因为CTR问题中通常特征维数很高（上亿）• 很稀疏（离散特征＋OneHot 编码） FTRL (Follow The Regulized Leader)• 在批处理模式下，L1正则化通常产生稀疏模型• 但Online中，每次权重向量的更新并不是沿着全局梯度进行下降，而是沿着某个样本的产生的梯度方向进行下降，整个寻优过程变得像是一个随机查找的过程，这样Online最优化求解即使采用L1正则化的方式，也很难产生稀疏解。• 在线稀疏模：FTRL – FTRL 综合了RDA和FOBOS，在L1范数或者其他非光滑的正则项下，能高效地得到稀疏解 FTRL• FTRL和SGD是等价的。 • FTRL工程实现技巧（如节省内存等）请见原始论文。 • Tensorflow支持FRTL：FtrlOptimizer 性能： L1-FOBOS、L1-RDA和L1-FTRL在一个小规模数据集（10^6 ）上的性能 参考文献[1] Convex function. http://en.wikipedia.org/wiki/Convex_function[2] Lagrange multiplier. http://en.wikipedia.org/wiki/Lagrange_multiplier[3] Karush–Kuhn–Tucker conditions. http://en.wikipedia.org/wiki/Karush-Kuhn-Tucker_conditions[4] 冯扬. 并行逻辑回归 . http://blog.sina.com.cn/s/blog_6cb8e53d0101oetv.html[5] Gradient. http://sv.wikipedia.org/wiki/Gradient[6] Subgradient. http://sv.wikipedia.org/wiki/Subgradient[7] Andrew Ng. CS229 Lecture notes. http://cs229.stanford.edu/notes/cs229-notes1.pdf[8] Stochastic Gradient Descent. http://en.wikipedia.org/wiki/Stochastic_gradient_descent[9] T. Hastie, R. Tibshirani &amp; J. Friedman. The Elements of Statistical Learning, Second Edition: Data Mining,Inference, and Prediction. Springer Series in Statistics. Springer, 2009 [10] John Langford, Lihong Li &amp; Tong Zhang. Sparse Online Learning via Truncated Gradient. Journal of Machine Learning Research, 2009[11] John Duchi &amp; Yoram Singer. Efficient Online and Batch Learning using Forward Backward Splitting. Journal ofMachine Learning Research, 2009[12] Lin Xiao. Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization. Journal of Machine Learning Research, 2010[13] Convex Set. http://en.wikipedia.org/wiki/Convex_set[14] H. Brendan McMahan &amp; M Streter. Adaptive Bound Optimization for Online Convex Optimization. In COLT,2010[15] H. Brendan McMahan. Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and L1 Regularization. In AISTATS, 2011 [16] H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Ad Click Prediction: a View from the Trenches. In ACM SIGKDD, 2013[17] Martin A. Zinkevich, Markus Weimer, Alex Smola &amp; Lihong Li. Parallelized Stochastic Gradient Descent. In NIPS 2010 Facebook : GBDT+LR• Practical Lessons from Predicting Clicks on Ads at Facebook [1]• 用GBDT编码特征，然后再用LR做分类– GBDT可替代FM做特征编码– LR可用FTRL代替 [1] Xinran He et al. Practical Lessons from Predicting Clicks on Ads at Facebook, 2014. https://cloud.tencent.com/developer/article/1005052 动机• 用LR做CTR预估时，需做大量的特征工程 （非线性特征）– 连续特征离散化（+ One-Hot编码）– 特征进行二阶或者三阶的特征组合• 问题：– 连续变量切分点如何选取？– 离散化为多少份合理？– 选择哪些特征交叉？– 多少阶交叉，二阶，三阶或更多？• GBDT：一举解决了上面的问题– 确定切分点和切分数目不在是凭主观经验，而是根据信息增益/Gini指标– 每棵决策树从根节点到叶节点的路径，会经过不同的特征，此路径就是特征组合，而且包含了二阶，三阶甚至更多（所以GBDT提取特征时层数不用太深） 如上图所示： GBDT训练得到：第一棵树有3个叶子结点第二棵树有2个叶子节点 GBDT编码：对于一个输入样本点x，如果它在第一棵树最后落在其中的第3个叶子结点，在第二棵树里最后落在第1个叶子结点，则通过GBDT获得的新特征向量为[0, 0, 1, 1,0]，向量中的前三位对应第一棵树的3个叶子结点，后两位对应第二棵树的２个叶子结点 实现• xgboost：predict函数– predict(data, output_margin=False, ntree_limit=0, pred_leaf=False, pred_contribs=False, approx_contribs=False)• lightGBM: predict函数– predict(data, output_margin=False, ntree_limit=0, pred_leaf=False, pred_contribs=False, approx_contribs=False) xgb_feature = xgb.predict(dtv, pred_leaf = True) GBDT+FM• Kaggle 2014年竞赛：Criteo Display Advertising Challenge– https://www.kaggle.com/c/criteo-display-ad-challenge• Rank1解决方案：3 idiot’s FM （FFM的发明者） • Kaggle 2015年竞赛： Click-Through Rate Prediction – https://www.kaggle.com/c/avazu-ctr-prediction• Rank2解决方案： 为什么不直接用GBDT？ • 因为GBDT在线预测比较困难，而且训练时间复杂度高于LR。 • 所以实际中，可以离线训练GBDT，然后将该模型作为在线ETL的一部分。 Factorization Machines（FM）• Steffen Rendle于2010年提出Factorization Machines[1]，并发布开源工具libFM （http://www.libfm.org/ ）。– 凭借这单个模型，他在KDD Cup 2012上，取得Track1的第2名和Track2的第3名。• FM旨在解决稀疏数据的特征组合问题– Recall：LR为线性模型，需要输入足够强的特征（特征组合） [1] Steffen Rendle, Factorization Machines, Proceedings of the 10th IEEE International Conference on Data Mining (ICDM 2010), Sydney, Australia 数据稀疏• CTR预估中很多类别型特征：例国家、节日– 国家和节日为类别型特征 ，需要One Hot 编码 原始特征： OneHot编码： 特征组合某些特征经过关联之后，与label之间的相关性就会提高例：将国家于假日组合： “ USA”与“Thanksgiving” “China”与“Chinese New Year” 这样的关联特征，对用户的点击有着正向的影响来自“China”的用户很可能会在“Chinese New Year”有大量的浏览、购买行为，在“Thanksgiving”却不会有特别的消费行为。更多示例：• “化妆品”类商品与“女”性• “球类运动配件”的商品与“男”性 二阶多项式模型 FM 模型训练 Field-aware Factorization Machines（ＦＦＭ） FFM的二次交叉项 FFM实现• 作者提供C++版本实现： libffm– https://github.com/guestwalk/libffm 实验结果 DNN for CTR• Google: Deep wide DNN – Wide &amp; Deep Learning for Recommender Systems• FNN:– Deep Learning over Multi - field Categorical Data – A Case Study on User ResponsePrediction• PNN:– Product - based Neural Networks for User Response Prediction• NFM– Neural Factorization Machines for Sparse Predictive Analytics• Alibaba display ads: Deep interest network– Deep Interest Network for Click - Through Rate Prediction– Use attention - like network structure to model local activation of user interest to candidatead. 参考文献1、http://blog.csdn.net/lilyth_lilyth/article/details/480321192、http://www.cnblogs.com/Matrix_Yao/p/4773221.html3、http://www.herbrich.me/papers/adclicksfacebook.pdf4、https://www.kaggle.com/c/criteo-display-ad-challenge5、https://www.kaggle.com/c/avazu-ctr-prediction6、https://en.wikipedia.org/wiki/Demand-side_platform7、http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf8、http://www.cs.cmu.edu/~wcohen/10-605/2015-guest-lecture/FM.pdf9、http://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf10、https://github.com/guestwalk/libffm11、https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad12、http://openmp.org/wp/openmp-specifications/13、http://blog.csdn.net/gengshenghong/article/details/700870414、https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>点击预估</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LSTM]]></title>
    <url>%2F2019%2F01%2F21%2FLSTM%2F</url>
    <content type="text"><![CDATA[ＬＳＴＭ模型LSTM（Long Short-Term Memory）是长短期记忆网络，是一种时间递归神经网络，适合于处理和预测时间序列中间隔和延迟相对较长的重要事件。就是所谓的该记得会一直传递，不该记得就被“忘记”。 “记忆细胞”变得稍微复杂了一点 细胞状态细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传会很容易保持不变。 LSTM控制“细胞状态”的方式： 通过“门”让信息选择性通过，来去除或者增加信息到细胞状态。 包含一个SIGMOD神经元层和一个pointwise乘法操作。 SIGMOD层输出0到1之间的概率值，描述每个部分有多少量可以通过。0代表“不许任何量通过”，1就表示“允许任意量通过”。 遗忘门遗忘门（forget gate）顾名思义，是控制是否遗忘的，在LSTM中即以一定的概率控制是否遗忘上一层的隐藏细胞状态。遗忘门子结构如下图所示： 图中输入的有上一序列的隐藏状态h_{t−1}和本序列数据x_t，通过一个激活函数，一般情况下是SIGMOD，得到遗忘门的输出$f_t$。由于SIGMOD的输出$f_t$在[0,1]之间，因此这里的输出$f_t$代表了遗忘上一层隐藏细胞的概率。 数学表达式： f(t)=\sigma(W_f h_{t-1}+U_f x_t+b_f)其中：$W_f、U_f、b_f$为线性关系的权重项和偏置项，σ为SIGMOD激活函数。 输入门输入门（input gate）负责处理当前序列位置的输入，它的子结构如下图： 从图中可以看到输入门由两部分组成，第一部分使用了sigmoid激活函数，输出为i_{(t)},第二部分使用了tanh激活函数，输出为c_{(t)}, 两者的结果后面会相乘再去更新细胞状态。 SIGMOD层决定什么值需要更新。 Tanh层创建一个新的候选值向量$c_{(t)}$ 第二步还是为状态更新做准备。 数学表达式： i{(t)} = \sigma(W_ih_{t-1} + U_ix_t + b_i)\tilde c{(t)} =tanh(W_ah_{t-1} + U_ax_t + b_a)其中$W_i,U_i,b_i,W_a,U_a,b_a$，为线性关系的权重项和偏置项，σ为SIGMOD激活函数。 更新细胞在研究LSTM输出门之前，我们要先看看LSTM之细胞状态。前面的遗忘门和输入门的结果都会作用于细胞状态 C(t)，我们来看看细胞如何从C(t−1)到C(t): 由图可知：细胞状态C_t由两部分组成；第一部分是C_{t−1}和遗忘门输出f_t的乘积，第二部分是输入门的i_t和\tilde c_{(t)}的乘积，总结为如下三点： 更新C_{(t−1)}为C_{(t)}。 把C_{(t−1)}和$f_{(t)}$相乘，丢弃掉我们确定需要丢弃的信息。 加上$i(t) * \tilde c_{(t)}$。最后得到新的候选值，根据我们决定更新每个状态的程度进行变化。 数学表达式： C_{(t)} = C_{(t-1)} \odot f{(t)} + i_{(t)} \odot \tilde c_{(t)}其中，⨀为Hadamard积. 输出门有了新的隐藏细胞状态C(t)，我们就可以来看输出门了，子结构如下： 从图中可以看出：隐藏状态h_t的更新由两个部分组成：第一部分是o_t，它是由上一序列的隐藏状态h_{t−1}和本序列的x_t，以及激活函数SIGMOD得到的，第二部分是由隐藏状态C_t和Tanh激活函数组成，即： 最开始先运行一个SIGMOD层来确定细胞状态的哪个部分将输出。 接着用tanh处理细胞状态（得到一个-1到1之间的值），再将它和SIGMOD门的输出相乘。输出我们确定输出的那部分值。 数学表达式： o_t=\sigma(W_o[h_{t-1},x_t]+b_o)h_t=o_t*tanh(C_t)总结 LSTM变体 增加peephole connection 让门层也会接受细胞状态的输入。 数学表达式： f_t=\sigma(W_f \cdot[C_{t-1}, h_{t-1},x_t]+b_f)i_t=\sigma(W_i \cdot[C_{t-1}, h_{t-1},x_t]+b_i)o_t=\sigma(W_o \cdot[C_{t-1}, h_{t-1},x_t]+b_o) 通过使用coupled忘记和输入门 之前是分开确定需要忘记和添加的信息，然后一同做出决定。 数学表达式： C_t=f_t * C_{t-1}+(1-f_t) * \tilde C_tGRUGatad Reacurrent Unit (GRU)，2014年提出。 将忘记门和输入门合成了一个单一的更新门 混合了细胞状态和隐藏状态 比标准的LSTM简单 数学表达式： z_t=\sigma(W_z \cdot [h_{t-1},x_t])r_t=\sigma(W_r \cdot [h_{t-1},x_t])\tilde h_t= tanh(W \cdot [r_t*h_{t-1},x_t])h_t=(1-z_t) * h_{t-1} + z_t * \tilde h_tLSTM总结 实现ＬＳＴＭimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# 导入数据mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)# 超参数设置lr = 0.001 # 学习率epochs = 100000 # 最大训练次数batch_size = 128 # 小批量样本数n_inputs = 28 # Mnist数据输入维度 (img shape: 28*28)n_steps = 28 # time stepsn_hidden_units = 128 # 隐层神经元n_classes = 10 # MNIST 分类 (0-9 digits)# x y placeholderx = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) # [None, 28, 28]y = tf.placeholder(tf.float32, [None, n_classes]) # [None,10]# 对 weights biases 初始值的定义weights = &#123; # shape (28, 128) &apos;in&apos;: tf.Variable(tf.random_normal([n_inputs, n_hidden_units])), # shape (128, 10) &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden_units, n_classes]))&#125;biases = &#123; # shape (128, ) &apos;in&apos;: tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])), # shape (10, ) &apos;out&apos;: tf.Variable(tf.constant(0.1, shape=[n_classes, ]))&#125;def RNN(X, weights, biases): # input layer # 原始的 X 是 3 维数据, 我们需要把它变成 2 维数据才能使用 weights 的矩阵乘法 # X ==&gt; (128 batches * 28 steps, 28 inputs) X = tf.reshape(X, [-1, n_inputs]) # X_in = W*X + b X_in = tf.matmul(X, weights[&apos;in&apos;]) + biases[&apos;in&apos;] # X_in ==&gt; (128 batches, 28 steps, 128 hidden) 换回3维 X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units]) # cell计算 # 使用 basic LSTM Cell. cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True) init_state = cell.zero_state(batch_size, dtype=tf.float32) # 初始化全零 state # 使用tf.nn.dynamic_rnn(cell, inputs)，我们要确定inputs的格式。 # tf.nn.dynamic_rnn中的time_major参数会针对不同inputs格式有不同的值。 # 如果inputs为（批次，步骤，输入）==&gt; time_major=False; # 如果inputs为（步骤，批次，输入）==&gt; time_major=True; outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False) # 输出层 results = tf.matmul(final_state[1], weights[&apos;out&apos;]) + biases[&apos;out&apos;] return resultspred = RNN(x, weights, biases)cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))train_optimizer = tf.train.AdamOptimizer(lr).minimize(cost)correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) step = 0 while step * batch_size &lt; epochs: batch_xs, batch_ys = mnist.train.next_batch(batch_size) batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs]) _ = sess.run([train_optimizer], feed_dict=&#123;x: batch_xs, y: batch_ys&#125;) if step % 20 == 0: # 计算批次数据的准确率 acc = sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;) # Calculate batch loss loss = sess.run(cost, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;) print(&quot;Iter &quot; + str(step * batch_size) + &quot;, Minibatch Loss= &quot; + \ &quot;&#123;:.6f&#125;&quot;.format(loss) + &quot;, Training Accuracy= &quot; + \ &quot;&#123;:.5f&#125;&quot;.format(acc)) step += 1 print(&quot; Finished!&quot;) # 计算准确率 for 128 mnist test images test_len = 128 test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_inputs)) test_label = mnist.test.labels[:test_len] print(&quot;Testing Accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label&#125;)) GRUimport tensorflow as tf# 导入 MINST 数据集from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(&quot;MNIST_data&quot;, one_hot=True)n_input = 28 # MNIST data 输入 (img shape: 28*28)n_steps = 28 # timestepsn_hidden = 128 # hidden layer num of featuresn_classes = 10 # MNIST 列别 (0-9 ，一共10类)tf.reset_default_graph()# tf Graph inputx = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])y = tf.placeholder(&quot;float&quot;, [None, n_classes])x1 = tf.unstack(x, n_steps, 1)# grugru = tf.contrib.rnn.GRUCell(n_hidden)outputs = tf.contrib.rnn.static_rnn(gru, x1, dtype=tf.float32)pred = tf.contrib.layers.fully_connected(outputs[-1], n_classes, activation_fn=None)learning_rate = 0.001training_iters = 100000batch_size = 128display_step = 10# Define loss and optimizercost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)# Evaluate modelcorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))# 启动sessionwith tf.Session() as sess: sess.run(tf.global_variables_initializer()) step = 1 # Keep training until reach max iterations while step * batch_size &lt; training_iters: batch_x, batch_y = mnist.train.next_batch(batch_size) # Reshape data to get 28 seq of 28 elements batch_x = batch_x.reshape((batch_size, n_steps, n_input)) # Run optimization op (backprop) sess.run(optimizer, feed_dict=&#123;x: batch_x, y: batch_y&#125;) if step % display_step == 0: # 计算批次数据的准确率 acc = sess.run(accuracy, feed_dict=&#123;x: batch_x, y: batch_y&#125;) # Calculate batch loss loss = sess.run(cost, feed_dict=&#123;x: batch_x, y: batch_y&#125;) print(&quot;Iter &quot; + str(step * batch_size) + &quot;, Minibatch Loss= &quot; + \ &quot;&#123;:.6f&#125;&quot;.format(loss) + &quot;, Training Accuracy= &quot; + \ &quot;&#123;:.5f&#125;&quot;.format(acc)) step += 1 print(&quot; Finished!&quot;) # 计算准确率 for 128 mnist test images test_len = 128 test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input)) test_label = mnist.test.labels[:test_len] print(&quot;Testing Accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: test_data, y: test_label&#125;))]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>LSTM</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DCGAN]]></title>
    <url>%2F2019%2F01%2F21%2FDCGAN%2F</url>
    <content type="text"><![CDATA[简介DCGAN即使用卷积网络的对抗网络，其原理和GAN一样，只是把CNN的卷积技术用于GAN模式的网络里，G（生成器）网在生成数据时，使用反卷积的重构技术来重构原始图片。D（判别器）网用卷积技术来识别图片特征，进而作出判别。 https://arxiv.org/abs/1511.06434 架构 判别器 生成器在DCGAN中，生成式模型G(z)使用一个比较特殊的深度卷积网络来实现，如下图所示： 反卷积从前面两幅图中可以看出，DCGAN的生成式模型G(z)中出现了上采样（upsampling）。 卷积神经网络的下采样很好理解，加入pooling层即可，然而这里的上采样要如何实现呢？ 这里，DCGAN通过“微步幅卷积”（fractionally-strided convolution）进行上采样。 假设有一个3×3的输入，希望输出的尺寸比这要大，那么可以把这个3×3的输入通过在像素之间插入0的方式来进行扩展，如下图所示。当扩展到7×7的尺寸后，再进行卷积，就可以得到尺寸比原来大的输出。 特点 调优 https://github.com/hindupuravinash/the-gan- 实现深度卷积神经网络生成Mnist手写数据集—-DCGAN 导入环境 import numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltfrom tensorflow.examples.tutorials.mnist import input_data 数据准备与超参数设置 mnist = input_data.read_data_sets(&apos;data&apos;)# 定义参数batch_size = 64noise_size = 100epochs = 5n_samples = 25learning_rate = 0.001 数据处理 def get_inputs(noise_dim, image_height, image_width, image_depth): # 真实数据 inputs_real = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth], name=&apos;inputs_real&apos;) # 噪声数据 inputs_noise = tf.placeholder(tf.float32, [None, noise_dim], name=&apos;inputs_noise&apos;) return inputs_real, inputs_noise 构建DCGAN网络结构 生成器 def get_generator(noise_img, output_dim, is_train=True, alpha=0.01): with tf.variable_scope(&quot;generator&quot;, reuse=(not is_train)): # 100 x 1 to 4 x 4 x 512 # 全连接层 layer1 = tf.layers.dense(noise_img, 4 * 4 * 512) layer1 = tf.reshape(layer1, [-1, 4, 4, 512]) # batch normalization layer1 = tf.layers.batch_normalization(layer1, training=is_train) # Leaky ReLU layer1 = tf.maximum(alpha * layer1, layer1) # dropout layer1 = tf.nn.dropout(layer1, keep_prob=0.8) # 4 x 4 x 512 to 7 x 7 x 256 layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding=&apos;valid&apos;) layer2 = tf.layers.batch_normalization(layer2, training=is_train) layer2 = tf.maximum(alpha * layer2, layer2) layer2 = tf.nn.dropout(layer2, keep_prob=0.8) # 7 x 7 256 to 14 x 14 x 128 layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding=&apos;same&apos;) layer3 = tf.layers.batch_normalization(layer3, training=is_train) layer3 = tf.maximum(alpha * layer3, layer3) layer3 = tf.nn.dropout(layer3, keep_prob=0.8) # 14 x 14 x 128 to 28 x 28 x 1 logits = tf.layers.conv2d_transpose(layer3, output_dim, 3, strides=2, padding=&apos;same&apos;) # MNIST原始数据集的像素范围在0-1，这里的生成图片范围为(-1,1) # 因此在训练时，记住要把MNIST像素范围进行resize outputs = tf.tanh(logits) return outputs 判别器 def get_discriminator(inputs_img, reuse=False, alpha=0.01): with tf.variable_scope(&quot;discriminator&quot;, reuse=reuse): # 28 x 28 x 1 to 14 x 14 x 128 # 第一层不加入BN layer1 = tf.layers.conv2d(inputs_img, 128, 3, strides=2, padding=&apos;same&apos;) layer1 = tf.maximum(alpha * layer1, layer1) layer1 = tf.nn.dropout(layer1, keep_prob=0.8) # 14 x 14 x 128 to 7 x 7 x 256 layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding=&apos;same&apos;) layer2 = tf.layers.batch_normalization(layer2, training=True) layer2 = tf.maximum(alpha * layer2, layer2) layer2 = tf.nn.dropout(layer2, keep_prob=0.8) # 7 x 7 x 256 to 4 x 4 x 512 layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding=&apos;same&apos;) layer3 = tf.layers.batch_normalization(layer3, training=True) layer3 = tf.maximum(alpha * layer3, layer3) layer3 = tf.nn.dropout(layer3, keep_prob=0.8) # 4 x 4 x 512 to 4*4*512 x 1 flatten = tf.reshape(layer3, (-1, 4 * 4 * 512)) logits = tf.layers.dense(flatten, 1) outputs = tf.sigmoid(logits) return logits, outputs 计算损失值 def get_loss(inputs_real, inputs_noise, image_depth, smooth=0.1): g_outputs = get_generator(inputs_noise, image_depth, is_train=True) d_logits_real, d_outputs_real = get_discriminator(inputs_real) d_logits_fake, d_outputs_fake = get_discriminator(g_outputs, reuse=True) # 计算Loss g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_outputs_fake) * (1 - smooth))) d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_outputs_real) * ( 1 - smooth))) d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_outputs_fake))) d_loss = tf.add(d_loss_real, d_loss_fake) return g_loss, d_loss 初始化优化器 def get_optimizer(g_loss, d_loss, learning_rate=0.001): train_vars = tf.trainable_variables() g_vars = [var for var in train_vars if var.name.startswith(&quot;generator&quot;)] d_vars = [var for var in train_vars if var.name.startswith(&quot;discriminator&quot;)] # Optimizer with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars) d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars) return g_opt, d_opt 显示图片 def plot_images(samples): fig, axes = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True, figsize=(7, 7)) for img, ax in zip(samples, axes.flatten()): ax.imshow(img.reshape((28, 28)), cmap=&apos;Greys_r&apos;) ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) fig.tight_layout(pad=0) plt.show()def show_generator_output(sess, n_images, inputs_noise, output_dim): noise_shape = inputs_noise.get_shape().as_list()[-1] # 生成噪声图片 examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape]) samples = sess.run(get_generator(inputs_noise, output_dim, False), feed_dict=&#123;inputs_noise: examples_noise&#125;) result = np.squeeze(samples, -1) return result 开始训练 def train(noise_size, data_shape, batch_size, n_samples): # 存储loss losses = [] steps = 0 inputs_real, inputs_noise = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3]) g_loss, d_loss = get_loss(inputs_real, inputs_noise, data_shape[-1]) print(&quot;FUNCTION READY!!&quot;) g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, learning_rate) print(&quot;TRAINING....&quot;) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # 迭代epoch for e in range(epochs): for batch_i in range(mnist.train.num_examples // batch_size): steps += 1 batch = mnist.train.next_batch(batch_size) batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3])) # scale to -1, 1 batch_images = batch_images * 2 - 1 # noise batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size)) # run optimizer sess.run(g_train_opt, feed_dict=&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) sess.run(d_train_opt, feed_dict=&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) if steps % 101 == 0: train_loss_d = d_loss.eval(&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) train_loss_g = g_loss.eval(&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) losses.append((train_loss_d, train_loss_g)) print(&quot;Epoch &#123;&#125;/&#123;&#125;....&quot;.format(e + 1, epochs), &quot;Discriminator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_d), &quot;Generator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_g)) if e % 1 == 0: # 显示图片 samples = show_generator_output(sess, n_samples, inputs_noise, data_shape[-1]) plot_images(samples)with tf.Graph().as_default(): train(noise_size, [-1, 28, 28, 1], batch_size, n_samples) print(&quot;OPTIMIZER END!!&quot;)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>DCGAN</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PG3 & IRL]]></title>
    <url>%2F2019%2F01%2F20%2FPG3%E5%92%8CIRL%2F</url>
    <content type="text"><![CDATA[参考资料Reinforcement Learning: An Introductionhttp://incompleteideas.net/book/the-book-2nd.htmlDave Silver强化学习课程http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html ＰＧ AC ＰＰＯ近端策略优化（Proximal Policy Optimization，PPO) https://spinningup.openai.com/en/latest/algorithms/ppo.html PPO的优点： VGP:在线采样，在线更新，采样完成的数据用来更新一次，因为更新过一次之后，策略就发生了改变（策略评估只能使用当下的策略生成数据），样本利用率低，效率低。PPO:在线采样，离线更新，采样完后的数据可以用来多次更新网络，样本利用率高，效率高。如何用之前的策略生成的数据评估当下的策略，重要性采样！ 重要性采样因为： 所以期望： 方差： 可见： 重要性采样（提高数据利用率）+约束策略变化幅度（减少方差）： PPO: TRPO: PPO-Clip 当优势值为正： 当优势值为负： ＩＴ正向强化学习中，所有的agent都是从头学习，其劣势有：1：需要由专家给出合理的奖励函数，很难对复杂的动作给出一个合适的奖励动作，例如飞机特技表演。2：比较耗时，需要训练成百上千个回合，并且有很多情况下，真实环境不具备这样的训练条件（不安全，价格昂贵），例如手术机器人学习动手术。怎么办？由专家进行演示，让学习者进行模仿模仿学习（Imitation Learning）： 1：直接法：直接学习策略监督式学习：行为克隆 Behavior Cloning2：间接法：学习奖励机制逆向强化学习（Inverse reinforcement learning） 直接法监督式学习：行为克隆+Data Augmentation 间接法学习奖励机制。 逆向强化学习IRL,从专家轨迹中推测专家这样做的动机。 Max-margin 分类器（SVM） http://www.andrew.cmu.edu/course/10-703/slides/Lecture_Imitation_supervised-Nov-5-2018.pdf Apprenticeship Learning学徒学习]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>PG3</tag>
        <tag>IRL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GAN理论]]></title>
    <url>%2F2019%2F01%2F20%2FGAN%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[简介对抗神经网络其实是两个网络的组合，可以理解为一个网络生成模拟数据，另一个网络判断生成的数据是真实的还是模拟的。生成模拟数据的网络要不断优化自己让判别的网络判断不出来，判别的网络也要优化自己让自己判断得更准确。二者关系形成对抗，因此叫对抗生成神经网络。 GAN由generator（生成式模型）和discriminator（判别式模型）两部分构成。 $\bullet$ generator：主要是从训练数据中产生相同分布的samples，对于输入x，类别标签y，在生成式模型中估计其联合概率分布（两个及以上随机变量组成的随机向量的概率分布）。 $\bullet$ discriminator：判断输入是真实数据还是generator生成的数据，即估计样本属于某类的条件概率分布。它采用传统的监督学习的方法。 基本结构生成器生成式模型又叫生成器。它先用一个随机编码向量来输出一个模拟样本。 一般的生成模型, 必须先初始化一个“假设分布”，即后验分布， 通过各种抽样方法抽样这个后验分布，就能知道这个分布与真实分布之间究竟有多大差异。这里的差异就要通过构造损失函数(loss function)来估算。 判别器判别式模型又叫判别器。它的输入是一个样本（可以是真实样本也可以是模拟样本），输出一个判断该样本是真样本还是模拟样本（假样本）的结果 总结：判别器的目标是区分真假样本，生成器的目标是让判别器区分不出真假样本，两者目标相反，存在对抗。 我们可以把生成模型看作一个伪装者，而把判别模型看成一个警察。生成模型通过不断地学习来提高自己的伪装能力，从而使得生成出来的数据能够更好地“欺骗”判别模型。而判别模型则通过不断的训练来提高自己的判别能力，能够更准确地判断出数据的来源。GAN就是这样一个不断对抗的网络。 $\bullet$ 生成模型以随机变量作为输入，其输出是对真实数据分布的一个估计。$\bullet$ 生成数据和真实数据的采样都由判别模型进行判别，并给出真假性的判断和当前的损失。$\bullet$ 利用反向传播，GAN对生成模型和判别模型进行交替优化。 例子假设数据的概率分布为M，但是我们不知道具体的分布和构造是什么样的，就好像是一个黑盒子。为了了解这个黑盒子，我们就可以构建一个对抗生成网络： $\bullet$ 生成模型G：使用一种我们完全知道的概率分布N来不断学习成为我们不知道的概率分布M.$\bullet$ 判别模型D：用来判别这个不断学习的概率是我们知道的概率分布N还是我们不知道的概率分布M。 https://arxiv.org/abs/1406.2661 模型训练训练两个模型的方法：单独交替迭代训练判别模型： 希望真样本集尽可能输出1，假样本集输出0。对于判别网络，此时问题转换成一个有监督的二分类问题，直接送到神经网络模型中训练。生成网络：目的是生成尽可能逼真的样本。在训练生成网络的时候，需要联合判别网络才能达到训练的目的。 总结：首先固定G，单独训练D，为了让D得到充分训练，有的时候要迭代多次。D训练完毕后，固定D，训练G，如此循环。训练的方式是反向传播算法。 数学推导符号定义 $P_{data}(x)$：真实数据的分布 $P_z(Z)$：噪声数据 $P_g(x)$：生成模型生成的数据分布 D(X)：判别器 G(x)：生成器 定义生成器和判别器`E_{x \sim P_{data}}(x) \cdot logD(x) 由上式可知：当x \sim P_{data}(x) ,D(x)=1的时，E_{x \sim P_{data}}(x)取得最大值。 `E_{x \sim P_{z}}(z) \cdot log(1-D(G(z))) 由上式可知：当x \sim P_{z}(z) , D(G(z))=0时，E_{x \sim P_{z}}(z)取得最大值。 所以为了我们的判别模型越来越好，能力越来越强大，定义目标函数为： $V(G,D)= logD(x) + log(1-D(G(z)))$ 要使判别模型取得最好，所以需要使V(G,D)V(G,D)取得最大，即： $D = agrmax_DV(G,D)$ 当判别模型最好的时候，最好的生成模型就是目标函数取得最小的时候： $G=argmin_G(aggmax_D(V(G, D)))$ 所以经过这一系列的讨论，这个问题就变成了最大最小的问题，即： `min_Gmax_DV(G, D)=E_{x \sim P_{data}}(x) \cdot logD(x)+ E_{x \sim P_{z}}(z) \cdot log(1-D(G(z))) 最优判别模型最终的目标函数： `V(G,D)= \int_x P_{data}(x) \cdot logD(x) + P_g(x)log(1-D(G(z))) d(x) 令：$V(G,D)=f(y), P_{data}(x)=a, P_g(x)=b$ 所以：$f(y)=alogy+blog(1-y)$ 因为: $a+b \ne 0$ 所以最大值：$\frac{a}{a+b}$ 最后，我们得到的最优判别模型就是： `D(x)=\frac{P_{data}(X)}{P_{data}(X)+P_g(x)} 由于生成对抗网络的目的是：得到生成模型可以生成非常逼真的数据，也就是说是和真实数据的分布是一样的。因此最优的判别模型的输出为： `D(x)=\frac{P_{data}}{P_{data}+P_g}=\frac12 其中：P_g和P_{data}的数据分布是一样的。 也就是说当D输出为0.5时，说明鉴别模型已经完全分不清真实数据和GAN生成的数据了，此时就是得到了最优生成模型了。 特点优点： $\bullet$ 模型优化只用到了反向传播，而不需要马尔科夫链。$\bullet$ 训练时不需要对隐变量做推断。$\bullet$ 理论上，只要是可微分函数都能用于构建生成模型G和判别模型D，因而能够与深度神经网络结合–&gt;深度产生式模型。$\bullet$ 生成模型G的参数更新不是直接来自于数据样本，而是使用来自判别模型D的反向传播梯度。 缺点： $\bullet$ 可解释性差，生成模型的分布没有显示的表达。它只是一个黑盒子一样的映射函数：输入是一个随机变量，输出是我们想要的一个数据分布。$\bullet$ 比较难训练，生成模型D和判别模型G之间需要很好的同步。例如，在实际中我们常常需要 D 更新 K次， G 才能更新 1 次，如果没有很好地平衡这两个部件的优化，那么G最后就极大可能会坍缩到一个鞍点。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据集]]></title>
    <url>%2F2019%2F01%2F20%2F%E6%95%B0%E6%8D%AE%E9%9B%86%2F</url>
    <content type="text"><![CDATA[一般数据集1、Kaggle：一个包含各种外部贡献数据集的数据科学网站。你可以在其主列表中找到各种合适的数据集，从拉面评级到篮球数据，甚至是西雅图宠物许可证，应有尽有。 https://www.kaggle.com/ 2、UCI 机器学习库：网络上最古老的数据集源之一，是寻找有趣的数据集的第一站。虽然这里的数据集是用户贡献的，因此清洁度不一，但绝大多数都是干净的。你可以直接从 UCI 机器学习库下载数据，无需注册。 http://mlr.cs.umass.edu/ml/ 政府公开数据集3、Data.gov：该网站可以从多个美国政府机构下载数据。数据范围从政府预算到学校绩效分数。但请注意：大部分数据有待进一步研究。 https://www.data.gov/ 4、食物环境地图集：包含当地食物选择如何影响美国饮食的数据。 https://catalog.data.gov/dataset/food-environment-atlas-f4a22 5、学校系统财务：对美国学校系统财务状况的调查。 https://catalog.data.gov/dataset/annual-survey-of-school-system-finances 6、慢性病数据：美国各地区慢性病指标数据。 https://catalog.data.gov/dataset/u-s-chronic-disease-indicators-cdi-e50c9 7、美国国家教育统计中心：来自美国和世界各地的教育机构和教育人口统计数据。 https://nces.ed.gov/ 8、英国数据服务：英国最大的社会、经济和人口数据集。 https://www.ukdataservice.ac.uk/ 9、Data USA：美国公共数据的全面可视化。 http://datausa.io/ 金融与经济10、Quandl：经济和金融数据很好的数据源，有助于建立预测经济指标或股票价格模型。 https://www.quandl.com/ 11、世界银行开放数据：涵盖全球人口统计数据和大量经济和发展指标的数据集。 https://data.worldbank.org/ 12、国际货币基金组织数据：国际货币基金组织公布的有关国际金融、债务利率、外汇储备、商品价格和投资的数据。 https://www.imf.org/en/Data 13、金融时报市场数据：来自世界各地的金融市场最新信息，包括股票价格指数、商品和外汇。 https://markets.ft.com/data/ 14、谷歌趋势：检查和分析世界各地的互联网搜索活动和热门新闻报道的数据。 https://trends.google.com/trends/?q=google&amp;ctab=0&amp;geo=all&amp;date=all&amp;sort=0 15、美国经济协会（AEA）：寻找美国宏观经济数据的良好来源。 https://www.aeaweb.org/resources/data/us-macro-regional 机器学习数据集16、Labelme：带图像标注的大型数据集。 http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php 17、ImageNet：业界最新算法图像数据集。根据 WordNet 层次结构进行组织，其中层次结构的每个节点由数百和数千个图像描述。 http://image-net.org/ 18、LSUN：有众多辅助任务的场景理解（房间布局估计、特点预测等） http://lsun.cs.princeton.edu/2016/ 19、MS COCO：通用图像理解和字幕。 http://mscoco.org/ 20、COIL100：100 个不同的物体，在 360 度旋转的每个角度成像。 http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php 21、视觉基因组：非常详细的视觉知识库，带有~100K 图像的字幕。 http://visualgenome.org/ 22、谷歌的开放图像：在知识共享版权下的 900 万个图像网址集合，“超过 6000 个类别标签注释”。 https://ai.googleblog.com/2016/09/introducing-open-images-dataset.html 23、Labelled Faces in the Wild：13,000 张人脸标记图像，用于开发人脸识别应用程序。 http://vis-www.cs.umass.edu/lfw/ 24、斯坦福狗数据集：包含 20,580 张图片和 120 种不同的狗品种。 http://vision.stanford.edu/aditya86/ImageNetDogs/ 25、室内场景识别：一种非常特殊的数据集，因为大多数场景识别模型都最好建立在“室外”，这个数据集非常实用。包含 67 个室内类别，总共 15620 张图像。 http://web.mit.edu/torralba/www/indoor.html 情绪分析26、多域情绪分析数据集：一个有点老旧的数据集，其中包含来自亚马逊的产品评论。 http://www.cs.jhu.edu/~mdredze/datasets/sentiment/ 27、IMDB 评论：一个较旧的，相对较小的二元情绪分类数据集，包含 25,000 个电影评论。 http://ai.stanford.edu/~amaas/data/sentiment/ 28、斯坦福情绪树库：带有情感注释的标准情绪数据集。 http://nlp.stanford.edu/sentiment/code.html 29、Sentiment140：一个流行的数据集，使用 160,000 条预先删除表情符号的推文。 http://help.sentiment140.com/for-students/ 30、Twitter 美国航空公司情绪：2015 年 2 月美国航空公司的 Twitter 数据，分类为正面、负面和中性推文。 https://www.kaggle.com/crowdflower/twitter-airline-sentiment 自然语言处理31、安然数据集：来自安然高级管理层的电子邮件数据，以文件夹形式分类存放。 https://www.cs.cmu.edu/~./enron/ 32、亚马逊评论：包含亚马逊 18 年来约 3500 万条评论。数据包括产品和用户信息、评级和明文审核。 https://snap.stanford.edu/data/web-Amazon.html 33、Google Books Ngrams：Google 图书中的一系列文字。 https://aws.amazon.com/datasets/google-books-ngrams/ 34、Blogger Corpus：收集了来自 blogger.com 的 681288 篇博文。每个博客至少包含 200 个常用英语单词。 http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm 35、维基百科链接数据：维基百科全文。该数据集包含来自 400 多万篇文章的近 19 亿个单词。你可以按段落、短语或段落本身的一部分进行搜索。 https://code.google.com/archive/p/wiki-links/downloads 36、Gutenberg 电子书列表：Project Gutenberg 的电子书注释列表。 http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs 37、加拿大议会议事录：来自第 36 届加拿大议会记录的 130 万对文本。 http://www.isi.edu/natural-language/download/hansard/ 38、Jeopardy：来自有奖竞猜节目 Jeopardy 的超过 200,000 个问题归档。 https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/ 39、英语短信垃圾邮件集：由 5574 条英文短信垃圾邮件组成的数据集。 http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/ 40、Yelp 评论：Yelp 发布的一个开放数据集，包含超过 500 万条评论。 https://www.yelp.com/dataset 41、UCI 垃圾邮件集：一个大型垃圾邮件数据集，对垃圾邮件过滤非常有用。 https://archive.ics.uci.edu/ml/datasets/Spambase 更详细列表： https://gengo.ai/datasets/the-best-25-datasets-for-natural-language-processing/ 自动驾驶42、Berkeley DeepDrive BDD100k：目前是自动驾驶 AI 的最大数据集。包含超过 100000 个视频，包括一天中不同时段和天气条件下超过 1100 小时的驾驶体验。带注释的图像来自纽约和旧金山地区。 http://bdd-data.berkeley.edu/ 43、百度 Apolloscapes：大型数据集，定义了 26 种不同的语义项目，如汽车、自行车、行人、建筑物、路灯等。 http://apolloscape.auto/ 44、Comma.ai：超过 7 小时的高速公路驾驶数据。细节包括汽车的速度、加速度、转向角和 GPS 坐标。 https://archive.org/details/comma-dataset 45、牛津的机器人汽车：在英国牛津的同一条路线重复行驶 100 多次、耗时一年多收集的数据集。该数据集包含天气、交通和行人的不同组合，以及建筑和道路工程等长期变化。 http://robotcar-dataset.robots.ox.ac.uk/ 46、城市景观数据集：一个大型数据集，记录 50 个不同城市的城市街景。 https://www.cityscapes-dataset.com/ 47、CSSAD 数据集：此数据集对于自动驾驶车辆的感知和导航非常有用。但该数据集严重偏向发达国家的道路情况。 http://aplicaciones.cimat.mx/Personal/jbhayet/ccsad-dataset 48、KUL 比利时交通标志数据集：比利时法兰德斯地区数以千计的物理交通标志，有超过 10000 多个交通标志注释。 http://www.vision.ee.ethz.ch/~timofter/traffic_signs/ 49、麻省理工学院实验室：在 AgeLab 收集的 1000 多个小时多传感器驾驶数据集的样本。 http://lexfridman.com/automated-synchronization-of-driving-data-video-audio-telemetry-accelerometer/ 50、LISA：智能和安全汽车实验室，加州大学圣地亚哥分校数据集：该数据集包括交通标志、车辆检测、交通信号灯和轨迹模式。 http://cvrr.ucsd.edu/LISA/datasets.html]]></content>
      <categories>
        <category>数据集</category>
      </categories>
      <tags>
        <tag>数据集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21单元语法]]></title>
    <url>%2F2019%2F01%2F20%2F21%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[～そうだ＜征兆、推测＞1、征兆接续：V-R（第一连用型）+ そうだ 样态助动词，表示征兆，是说话人对即将发生的动作，变化的征兆进行的描述，一般是说话人通过自身的感官判断或觉察到的。(主観)常与｢今にも｣连用。变形之后按二类形容词活用。 ✿汉语：就要~了、快要~了 1.今にも雨が降りそうです。 2.寒くて死にそうだ。3.ポケットから財布が落ちそうだよ。(2002年真题) 2、推测接续： $\bullet$ A1-词干(去い) + そうだ $\bullet$ A2-词干 + そうだ $\bullet$ VーR + そうだ 表示推断、猜测、发生的可能性，是说话人根据事物的外表、经验等判断某事态很有可能发生或某事物具有某性质。变形之后按二类形容词活用。 ✿汉语：看上去~；看起来~；好像~★：いい・ない: よさそうだ・なさそうだ 1.山田さんはいつも難しそうな本を読んでいる。(2006年真题) 2.石田さんは忙しそうだから、手伝おう。(2003年真题)3.あの様子では二人はもうすぐ結婚しそうです。 ３、そうだ的否定形式Vそうだ的否定为：｢Vそうにもない｣ 口语中常用｢そうもない｣或｢そうにない｣。即省略「に」或「も」表示发生某动作的可能性极小。 1.この本は売れそうもない。2.一人の力だけでは、とうていできそうにもない。 Aそうだ的否定为： $\bullet$ 「そうではない」 $\bullet$ 「A1-くなさそうだ」 $\bullet$ 「A2- ではなさそうだ」 1.最近、授業は少ないから、忙しそうではない。 最近、授業は少ないから、忙しくなさそうだ。2.彼は一週間以上も病気だから、体はあまり元気そうではない。 彼は一週間以上も病気だから、体はあまり元気ではなさそうだ。 4、そうだ修饰名词或动词修饰名词时：A/V +そう+な+ N修饰动词时：Aそう+に+ V 1.彼は悲しそうな顔をしている。2.彼は楽しそうに笑った。3.李さんは元気そうな声で話してくれた。4.雨が降りそうな天気だ。 授受动词1、あげる（自谦）：さしあげる接续：（赠与者）N1は∕が＋（接受者）N2に＋（所赠物品）N3を＋あげる。 当接受者的身份、地位、年龄高于赠与者时：あげるーさしあげる 先生が大学をおやめになる日、みんなで先生にアルバムをさしあげました。 2、くれるーくださる接续：（赠与者）N1は∕が＋（我或我这一方的人）に＋（所赠物品）N2を＋くれる。 当赠与者的身份、地位、年龄高于接受者时：くれるーくださる 先輩が妹にコンサートのチケットをくださいました。 3、もらう－いただく接续：（接受者）N1は＋（赠与者）N2に∕から＋（所得物品）N3を＋もらう。 当赠与者的身份、地位、年龄高于接受者时：もらう－いただく わたしは社長に会社のぺんをいただきました。 補助動詞・行为的授受$\bullet$ ～てあげる $\Rightarrow$ ～てさしあげる（謙譲語） $\bullet$ ～てもらう $\Rightarrow$ ～ていただく （謙譲語） $\bullet$ ～てくれる $\Rightarrow$ ～てくださる （尊敬語） ①Aは Bに Vてあげる Vて やる Vてさしあげる 表示A为B做某事。A是授予者，用「は」提示；(授予者为第一人时常省略）B是接受者，用「に」提示。 1.これ、貸してあげるよ。(2007年真题)2.この写真は家族にもぜひ見せてやりたい。3.吉田先生を駅まで車で送って差し上げた。 「～てやる」用于AB之间关系亲近，随意，或B身份、地位低于A时。「～てあげる」是「～てやる」的客气说法，「～てさしあげる」则比「～てあげる」更客气，常常用来叙述B是A的尊长时的授受关系。 ★：另外「～てあげる」会使行为接受者觉得这是对方施恩于自己而感到不快，用时应注意。 特殊接续： $\bullet$ 彼女の手を取ってあげる $\bullet$ 彼女の荷物を持ってあげる $\bullet$ 彼女を手伝ってあげる ②AはBに(から)Vてもらう Vていただく 表示A接受B所做的事。A是接受者，用「は」提示。B是授予者，用「に」或「から」提示。B为A所做的事用「て」前面的动词表示。★：「~ていただく」是「~てもらう」的谦语， 一般用于B比A身份高，或B是A所尊敬的人。 1.本田先生に貸していただいた本を家に忘れた。(2012年真题)2.この書類を広田さんに渡しておいてもらえないか。(2012年真题) ③Aは (私に) Vてくれる Vてくださる 表示A为我（我们，我方人员）做某事。与①相反。Ｂ在句中往往省略。★：「 Vていただく」与「 Vてくださる」的区别在于：前者常带有“该动作是受益者要求对方进行的” 1.友達がたくさん来てくれた。2.そちらの方が私の荷物を持ってくださいました。(2008年真题)3.友達が掃除を手伝ってくれた。(2006年真题) 变形总结 原型 授受敬语 行为的授受 行为的授受敬语 あげる さしあげる てあげる てさしあげる もらう いただく てもらう ていただく くれる くださる てくれる てくださる ようだようだ&lt;比喻&gt;比况助动词「ようだ」一般接在体言后面，表示比喻。常和副词「まるで」 「ちょうど」 「あたかも」前后呼应使用。 接续：Nの～ ✿汉语：好像~、宛如~★：「ようだ」作为2类形容词型活用，可作为修饰语使用。 N +の+ ような + 体言 N+ の + ように + 用言 1.まるで夢のようだ。2.今日は寒くて、まるで冬のようだ。3.母は初めて飛行機に乗って、子供のように喜んだ。(2008年真题) ようだ&lt;举例&gt;表示某一事物与作为例子举出的另一事物具有某一相同特征。接续：Ｎの＋ ✿汉语：像~一样、例如~常用形式： Nの+ ような + 体言 Nの+ ように + 用言 1.みかんのようなビタミンＣが豊かな果物を食べたい。2.私は田中さんのような優しい人が好きだ。3.みんなが子供のように元気に歌い始めた。(2005年真题) みたいだみたいだ＜比喻＞为「ようだ」 的随意的口语表现形式。 接续： N+ みたいだ N+ みたいな + 体言 N+ みたいに + 用言 ✿汉语：好像~、宛如~ １.うれしい、まるで夢みたいだ。２.あの人は日本人みたいだ。 みたいだ＜举例＞为「ようだ」 的随意的口语表现形式。 接続： Ｎ+ みたいな + 体言 Ｎ+ みたいに + 用言 ✿汉语：像~一样、例如~ １.君みたいなあわて者、見たことがないよ。２.あなたみたいに日本語が話せたらうれしいけど。 疑問詞＋Ｖたらいいか ＜询问＞疑問詞＋Ｖたらいいか。アドバイスを求める。询问对方怎么做比较好（方式，地点，时间）✿“~怎么做才好呢？”“~如何是好呢？” １.どう説明したらいいか。２.誰に聞いたらいいか。３.風邪を引きそうなとき、何をたべたらいいか教えてください。４.図書館に行くとき、どの駅で降りたらいいかネットで調べましょう。 ～すぎる＜过度＞表示过度。行为、动作超过了一般的程度或范围。接续： V第一连用形 + すぎる A词干 + すぎる ✿汉语：过于、过度~ １.食べ過ぎて、お腹が痛いです。２.コピーの字が薄すぎて、読めない。（2004年真题）３.この花は、土が乾いたら水をやる必要があるが、やりすぎるのもよくない。(2013年真题) ～Ｖております＜自谦＞「ております」是「ています」的自谦； 也可以是正式场合的「ています」的表达。 １.今長沙に住んでおります。２.私のうちにもどうぞいらっしゃってください。お待ちしております。３.社長は今電話に出ておりますので、しばらくお待ちください。(2000年真题)]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PG和TD3]]></title>
    <url>%2F2019%2F01%2F18%2FPG%E5%92%8CTD3%2F</url>
    <content type="text"><![CDATA[TD3TD3 = Twin Delayed DDPG：三点改进： 改进１Twin:有两个Q值预测网络，使用输出Q值较小的那个用作计算TD error的目标值； Double DQN: Double q learning(Q值来自于神经网络): Clipped Double Q-learning algorithm: 改进２Delayed：更新策略的频率要小于更新Q值，即训练actor网络的次数要小于训练critic网络； 在值网络估计不准确的情况下（TD error很大），更新策略会引发 在更新critic网络d次之后再更新actor网络 改进３目标策略平滑：Idea:相似的动作在同一个状态下的Q值也相似 Trick: 过程 效果 TD3 vs DDPG 参数设计 PG一个特定的回合内，其生成的轨迹概率轨迹: 概率： 重要性采样比率: 梯度公式： *\nabla_{\theta}logP(\tau|\theta)=\nabla \sum_{t=0}^T log\pi_{\theta}(a_t|s_t) 带入求导： 又： 所以： 所以： \nabla_{\theta}J(\pi_\theta)=\nabla E_{\tau\sim\pi_\theta} [R(\tau)] =\nabla_\theta \int_{\tau\sim\pi_\theta} P(\tau|\theta)R(\tau) = \int_{\tau\sim\pi_\theta} \nabla_\theta P(\tau|\theta)R(\tau) = \int_{\tau\sim\pi_\theta} P(\tau|\theta)\nabla_\theta logP(\tau|\theta)R(\tau) = E_{\tau\sim\pi_\theta}[\nabla_\theta logP(\tau|\theta)R(\tau)] = E_{a_t\sim\pi_\theta}[\nabla_\theta \sum_{t=0}^T log\pi_\theta(a_t|s_t)R(\tau)] 过程 蒙特卡洛估计方差太大，见下图：使用神经网络来估计Q值 从上图看出负的噪声影响很大，怎么办呢？ 可以增加一个b值补偿 推导： 方差公式和梯度公式： 梯度公式带入方差公式： 求导： 所以：]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>PG</tag>
        <tag>TD3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNN理论]]></title>
    <url>%2F2019%2F01%2F17%2FRNN%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[循环神经网络（RNN）是一类神经网络，包括一层内的加权连接，与传统前馈神经网络相比，加权连接仅反馈到后续层。因为RNN包含循环，所以RNN就可以在处理输入信息的时候同时储存信息。这种记忆使得RNN非常适合处理必须考虑事先输入的任务（比如时序数据）。所以循环神经网络在自然语言处理领域非常适合。 传统神经网络（包含CNN），输入和输出都是互相独立的。RNN引入了“记忆”的概念 x：输入层的值U：输入层到隐层的权重参数s：隐层的值v：隐层到输出层的权重参数o：输出层的值W：递归神经网络的隐藏层的值s不仅仅取决于当前这次的输入x，还取决于上一次隐藏层的值s。权重参数W就是隐藏层上一次的值作为这一次的输入的权重。 关键点：$St$的值不仅仅取决于$X_t$，还取决于$S{t−1}$(就是上一状态的隐层的值) 循环神经网络的计算公式： O_t=f(V \cdot S_t) \quad (1)输出层的计算公式，由于输出层是一个全连接层，所以说它每个节点都和隐层的节点相连。V是输出层的权重参数，f是激活函数。 S_t=f(U \cdot X_t+W \cdot S_{t-1}) \quad (2)隐层的计算公式，它是一个循环层，U是输入x的权重参数，W是上一次的值$S_{t−1}$作为这一次输入的权重参数，f是激活函数。 总结：从上面的公式中，我们可以看出，循环层和全连接层的区别就是循环层多了一个权重参数w。 扩展：如果反复的把（1）式带入 （2）式： ${O}_t=f(V\cdot{S}_t)$ `= V \cdot f(U \cdot X_t + W \cdot S_{t-1}) `= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot S_{t-2})) `= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot f(U \cdot X_{t-2}+W \cdot S_{t-3}))) `= V \cdot f(U \cdot X_t+W \cdot f(U \cdot X_{t-1}+W \cdot f(U \cdot X_{t-2}+W \cdot f(U \cdot X_{t-3}+…)))) 总结：从上面可以看出，递归神经网络的输出值$ot$，是受前面几次输入值$X_t、X{t−1}、X{t−2}、X{t−3}…$影响的，这也就是为什么递归神经网络可以往前看任意多个输入值的原因。 双向递归神经网络 从上图可以看出，双向递归神经网络的隐层是需要保持两个值： A：参与正向计算 A′：参与反向计算 所以$y_2$的值就取决于$A_2$和$A′_2$。计算方法： y_2=f(V \cdot A_2+V’ \cdot A_2’)$A_2和A_2′$则分别计算： A_2 = f(W \cdot A_1+U \cdot X_2)A_2’=f(W’ \cdot A_3’+U’ \cdot X_2)总结： 正向计算时：隐层的值S_t和S_{t−1}有关。 反向计算时：隐层的值S′_t和S′_{t−1}有关。 最终的输出取决于正向和反向计算的和。 扩展：我们仿照（1）和（2）那种方式： O_t =f(V \cdot S_t+V’ \cdot S_t’)S_t =f(U \cdot X_t+W \cdot S_{t-1})S_t’=f(U’ \cdot X_t+W’ \cdot S_{t+1}’)注意：从上面三个公式我们可以看到，正向计算和反向计算不共享权重，也就是说U和U’、W和W’、V和V’都是不同的权重矩阵。 深度递归神经网络 我们把第ii个隐层的值表示为$S_t^{(i)}、S_t’^{(i)}$ ,则深度递归神经网络的计算方式就可以表示为： {O}_t=f \cdot (V^{(i)} \cdot S_t^{(i)}+V’^{(i)} \cdot S_t’^{(i)})S_t^{(i)}=f(U^{(i)}\cdot S_t^{(i-1)}+W^{(i)}\cdot S_{t-1})S_t’^{(i)}=f(U’^{(i)}\cdot S_t’^{(i-1)}+W’^{(i)}\cdot S_{t+1}’)···S_t^{(1)}=f(U^{(1)} \cdot X_t+W^{(1)}\cdot S_{t-1})S_t’^{(1)}=f(U’^{(1)}\cdot X_t+W’^{(1)}\cdot S_{t+1}’)总结 从上图我们可以总结出： one to one：一个输入（单一标签）对应一个输出（单一标签） one to many：一个输入对应多个输出，即这个架构多用于图片的对象识别，即输入一个图片，输出一个文本序列。 many to one： 多个输入对应一个输出，多用于文本分类或视频分类，即输入一段文本或视频片段，输出类别。 many to many：这种结构广泛的用于机器翻译，输入一个文本，输出另一种语言的文本。 many to many：这种广泛的用于序列标注。 在众多的深度学习网络中，RNN由于能够接收序列输入，也能得到序列输出，在自然语言处理中取得了巨大的成功，并得到广泛的应用。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度下降]]></title>
    <url>%2F2019%2F01%2F17%2F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%2F</url>
    <content type="text"><![CDATA[梯度下降方法用负梯度作搜索方向，即令$\bigtriangleup x=-\bigtriangledown f(x)$, 是一种自然的选择。相应的方法就称梯度方法或者梯度下降方法。 梯度下降算法的概念梯度下降算法是一个被广泛使用的优化算法, 它可以用于寻找最小化成本函数的参数值. 也就是说: 当函数$ J(\theta)$取得最小值时, 求所对应的自变量θ的过程， 此处θ就是机器要学习的参数，$J(\theta)$就是用于参数估计的成本函数, 是关于θ的函数. 梯度下降的基本步骤梯度下降法的计算过程就是沿梯度下降的方向求解极小值（也可以沿梯度上升方向求解极大值） 给定 初始点:$x \in dom f$ 重复进行： $\bigtriangleup x :=-\bigtriangledown f(x)$ 直线搜索。通过精确或回溯直线搜索方法确实步长t. 修改 :$x =x+t\bigtriangleup x$ 直到：满足停止准则。 换种方式： 对成本函数进行微分, 得到其在给定点的梯度. 梯度的正负指示了成本函数值的上升或下降:$Δ(\theta)=\frac{∂J(\theta)}{∂\theta}$ 选择使成本函数值减小的方向, 即梯度负方向, 乘以学习率为 α 计算得参数的更新量, 并更新参数:$\theta=\theta−αΔ(\theta)$ 重复以上步骤, 直到取得最小的成本 批量梯度下降法（Batch Gradient Descent） 批量梯度下降法，是梯度下降法最常用的形式，具体做法也就是在更新参数时使用所有的样本来进行更新，这个方法对应于线性回归的梯度下降算法，也就是说线性回归的梯度下降算法就是批量梯度下降法。 具体实现过程： 假设函数:h_\theta = \sum_{i=1}^n\theta_ix_i 成本函数:J(\theta)=\frac{1}{2m} \sum_{i=1}^n(h_\theta(x_i)-y_i)^2 对成本函数进行求偏导：对每一个参数\theta_j进行分别求偏导，得出各自的梯度。\frac{\partial J(\theta)}{\partial \theta}=-\frac1 m \sum_{i=1}^n(y_i-h_\theta(x_i))x_j^i 每个参数都按照梯度的负方向进行更新: \theta_j=\theta_j+\frac a m \sum_{i=1}^n(y_i-h_\theta(x_i))x_j^i BGD伪代码： repeat{ \theta_j=\theta_j+\frac a m \sum_{i=1}^n(y_i-h_\theta(x_i))x_j^i(for every j = 0, 1, .. n) } 总结： 优点：BGD 得到的是全局最优解, 因为它总是以整个训练集来计算梯度, 缺点：因此带来了巨大的计算量, 计算迭代速度很很慢. 随机梯度下降法（Stochastic Gradient Descent）随机梯度下降法，其实和批量梯度下降法原理类似，区别在于求梯度时没有用所有的m个样本的数据，而是仅仅选取一个样本j来求梯度。 具体实现过程： SGD 每次以一个样本, 而不是整个数据集来计算梯度. 因此, SGD 从成本函数开始, 就不必再求和了, 针对单个样例的成本函数可以写成: J(\theta)=\frac{1}{2} (h_\theta(x_i)-y_i)^2于是, SGD 的参数更新规则就可以写成 ： \theta_j=\theta_j+a (y_i-h_\theta(x_i))x_j^iSGD伪代码： repeat { for i = 1, .., m{ \theta_j=\theta_j+a (y_i-h_\theta(x_i))x_j^i (for every j = 0, 1, .. n) } } 总结： SGD 的关键点在于以随机顺序选取样本. 因为 SGD 存在局部最优困境, 若每次都以相同的顺序选取样本, 其有很大的可能会在相同的地方陷入局部最优解困境, 或者收敛减缓. 因此, 欲使 SGD 发挥更好的效果, 应充分利用随机化带来的优势: 可以在每次迭代之前 (伪代码中最外围循环), 对训练集进行随机排列. 缺点：因为每次只取一个样本来进行梯度下降, SGD 的训练速度很快, 但会引入噪声, 使准确度下降 优点：可以使用在线学习. 也就是说, 在模型训练好之后, 只要有新的数据到来, 模型都可以利用新的数据进行再学习, 更新参数,以适应新的变化. ＢＧＤ vs ＳＧＤ随机梯度下降法和批量梯度下降法是两个极端，一个采用所有数据来梯度下降，一个用一个样本来梯度下降。自然各自的优缺点都非常突出。对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，随机梯度下降法用于仅仅用一个样本决定梯度方向，导致解很有可能不是最优。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。 MBGD就综合了这两种方法的优点。 小批量梯度下降法（Mini-batch Gradient Descent）MBGD 是为解决 BGD 与 SGD 各自缺点而发明的折中算法, 或者说它利用了 BGD 和 SGD 各自优点. 其基本思想是: 每次更新参数时, 使用 n 个样本, 既不是全部, 也不是 1. (SGD 可以看成是 n=1 的 MBGD 的一个特例) MBGD 的成本函数或其求导公式或参数更新规则公式基本同 BGD 。 MBGD 的伪代码： say b=10, m=1000, repeat { for i = 1, 11, 21, .., 991 { \theta_j=\theta_j+\frac a {10} \sum_{i=1}^{i+9}(y_i-h_\theta(x_i))x_j^i (for every j = 0, 1, .. n) } } 梯度下降算法总结]]></content>
      <categories>
        <category>优化算法</category>
      </categories>
      <tags>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDQN & DDPG]]></title>
    <url>%2F2019%2F01%2F17%2FDouble-QDN%2F</url>
    <content type="text"><![CDATA[ε-贪婪（greedy）策略目的：探索与利用ε∈(0,1)，随着时间的推移逐渐减小直至0产生一个(0,1)的随机数m如果ε&gt;m 采取随机策略，例如一共4个动作，那么选每一个动作的概率都是 0.25如果ε&lt;m 采取贪婪策略，计算当前网络所有输出值Q(St,a)，选择使得 Q(St,a)最大的那个at值作为下一步的动作 玻尔兹曼softmax$q_t(a)$为t时刻，采取动作a的Q值大小 τ表示是一个衰减系数（类似于模拟退火算法的温度项），随着训练次数的增加而逐渐减少，与ε相对应。随着τ的减小，选择使Q值最大的那个动作a值的概率也越来越高。 ε-贪婪 VS 玻尔兹曼` DDQNDQN: Double Q learning: Double DQN: PRIORITIZED EXPERIENCE REPLAY(优先化记忆回放)每一个rollout的被采样概率: 其中: importance-sampling (IS) weights（重要性采样权重）: SumTree: DDQN+PER: Dueling DQNDueling Network Architectures for Deep Reinforcement Learningvalue和Q value： 优势值（Advantage function） 结合方式： DQN性能 DDPGＤＱＮ的问题： 动作空间必须是离散的能不能将DQN的思想应用到连续的动作空间？ DDPG 是一种离策略算法DDPG仅可以用于连续动作空间的问题]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>DDPG</tag>
        <tag>DDQN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DQN]]></title>
    <url>%2F2019%2F01%2F16%2FDQN%2F</url>
    <content type="text"><![CDATA[DQN的背景传统强化学习的局限性，无法很好的解决状态空间或者动作空间很大的实际问题举例：小车使用相机进行导航，动作为向左，向前，向右，3种 100 x 100的灰度图片，状态数： 256^{10000}如果使用q-learning，q(s,a)的个数为3\times256^{10000}以现在的存储与计算能力，不可能完成 首先解决状态空间很大的问题 能不能根据现在的状态来估计Q(s,a)的值？ 价值函数估计假设近似器参数为w,注意有些公式给的是θ，两者是一个意思 回归器的选择: 特征线性组合 神经网络 决策树 最近邻 傅里叶/小波基 DQN VS Q_learning深度Q网络(Deep Q-Network,DQN): Q-learning(离策略（Off-policy）TD控制): Q learning学习目标： Q函数近似的学习目标: θ可以是任何回归器的参数，如果特指深度神经网络，那么我们也称之为深度Q网络 深度Q网络(Deep Q-Network,dqn)1、如何通过神经网络进行近似端到端的形式输入：状态或者观测输出：Q值２、与监督学习的异同？ 不用人工标注,神经网络生成 目标值 １、数据怎么来？使用当下策略生成。2.、有没有问题？相邻两次的更新使用的样本是是相关的Q（s1,a1）=0.9, 估计成了1.0, s2与s1很相似Q(s2,a1) = 0.05+1*0.99=1.04，s3与s2很相似……3 、在训练时，打散训练样本的顺序 经验回放定义一个replay buffer，RB, 记录下前N次的rollouts在训练的时候，随机采样，进行训练 DQN with experience replay ：]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>DQN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP传输图片]]></title>
    <url>%2F2019%2F01%2F16%2FTCP%E4%BC%A0%E8%BE%93%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[import socketimport pickleimport numpy as npfrom PIL import Imageimport ioimport sysimport threadingdef main(img):# start_svc = datetime.datetime.now() try: img = img.convert(&apos;L&apos;) img = img.resize((256,256)) # print(img.mode) # print(img.size) arr = np.asarray(img, dtype=&quot;float32&quot;) # arr = arr.flatten() arr = arr.reshape(1,-1) #data.append(arr) # name = &quot;&quot; + job_name + &quot;.pkl&quot; # name = &quot;AAA.pkl&quot; #end_svc = datetime.datetime.now() pca_data = pca.transform(arr) y_test_pred = svc.predict(pca_data) #time = end_svc - start_svc #print(time) return y_test_pred except Exception as err: return str(err)len_rev=0def tcp_connected(s,addr): print(&apos;Accept new connection from %s:%s...&apos; % addr) while 1: data =s.recv(1600000) len_rev=len(data) # print(len_rev) if len_rev&gt;=1000000: image = Image.open(io.BytesIO(data)) result=main(image)[0] s.send(result.encode()) print(result) elif len_rev&lt;=100 and data.decode()== &apos;close&apos;: sock.close() sys.exit(0)arg1 = &quot;&quot; + sys.argv[1]s = socket.socket() # 创建 socket 对象all_port=[6001,42683]arg=int(arg1)port=all_port[arg]print(port)#path_to_watch=r&apos;image/Cam&#123;&#125;/&apos;.format(arg+1)s.bind((&apos;127.0.0.1&apos;, port)) # 绑定端口s.listen(2) # 监听连接,传入连接请求的最大数5 # 接受一个新连接sock,ad=s.accept() # 创建新线程来处理TCP连接name = &quot;SVC_PCA.pkl&quot;pca, svc = pickle.load(open(name, &apos;rb&apos;))t = threading.Thread(tcp=tcp_connected(sock, ad))]]></content>
      <categories>
        <category>图片分类</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时序差分学习]]></title>
    <url>%2F2019%2F01%2F16%2F%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[时序差分学习（Temporal-Difference Learning, TD learning）是强化学习中最核心与最著名的思想 ‘If one had to identify one idea as central and novel to reinforcement learning, it would undoubtedly be temporal-difference (TD) learning.’ —Richard S. Sutton&amp; Andrew G. BartoTD = DP + MCTD, DP都是使用下一时刻的状态函数来估计当前时刻的状态函数。TD,MC都是通过经历一次一次与环境互动，产生多个episode来估计状态函数。 ＴＤ： V(S_t)\leftarrow V(S_t)+\alpha(G_t-V(S_t))ＭＣ： V(S_t)\leftarrow V(S_t)+\alpha(R_{t+1}+V(S_{t+1})-V(S_t))Sarsa在策略（On policy）ＴＤ控制 Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\gamma(R_{t+1}+Q(S_{t+1},A_{t+1})-Q(S_t,A_t)) Expected Sarsa离策略（Off-policy）TD控制 Q-learning离策略（Off-policy）TD控制 Q-learning vs Sarsa例子：悬崖行走（固定的ε=0.1） Q-learning的问题过估计（overestimate），因此产生了Double Q learning Double Q learning Q learning vs. Double Q learning训练参数：ε=0.1，α=0.1, γ=1]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>TD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蒙特卡洛方法]]></title>
    <url>%2F2019%2F01%2F16%2F%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[MC如何在没有模型的情况下评估一个策略？ 如何计算Ｖ（ｓ）和Ｑ（ｓ）？ 通过采样的方式 如何得到数据？ On policy: 使用当下的策略生成的数据进行策略评估 Off policy: 使用其他策略生成的数据进行策略评估 首次访问蒙特卡洛预测（评估）： Every-Visit Monte-Carlo Policy Evaluation: Incremental Mean: Incremental Monte-Carlo Updates 随机策略在预测完成当前策略下的V和Q之后，我们需要对当下的策略进行改进可以采用完全贪婪的策略提升吗？ s4-&gt;s3; s3-&gt;s2;s2-&gt;s2;s2-&gt;s1;s4-&gt;s3; s3-&gt;s2;s2-&gt;s1; V(s)，Q(s,a)0,1,1,1,0,0,0Q(s2,a=左)= Q(s3,a=左)= Q(s4,a=左)=1，Q(s4,a=右)=0一直向左走？ ε-贪婪（greedy）策略目的： Exploration（探索）与Exploitation（利用） ε∈(0,1)，随着时间的推移逐渐减小直至0 产生一个(0,1)的随机数m 如果ε&gt;m 采取随机策略，例如一共4个动作，那么选每一个动作的概率都是 0.25如果ε&lt;m 采取贪婪策略，计算当前网络所有输出值Q(St,a)，选择使得Q(St,a)最大的那个at值作为下一步的动作 On-pokicy first-visit 蒙特卡洛方法： 重要性采样 一个特定的回合内，其生成的轨迹概率： 轨迹： 重要性采样比率： 使用重要性采样的蒙特卡洛方法：]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>MC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图片分类-pca_svc]]></title>
    <url>%2F2019%2F01%2F15%2F%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E4%B9%8Bpca-svc%2F</url>
    <content type="text"><![CDATA[PCA_SVC训练import osfrom PIL import Imageimport numpy as npfrom sklearn.decomposition import PCAfrom sklearn.svm import SVCimport timeimport datetimedef load_Img(imgDir): lable = os.listdir(imgDir) #print(lable) OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0]) NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1]) #print(NG_name) label=[] data=[] for i in range(len(OK_name)): start = datetime.datetime.now() OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1] OK_img = Image.open(OK_path) OK_img=OK_img.convert(&apos;L&apos;) # print(OK_img.size) end = datetime.datetime.now() print(end - start) OK_img = OK_img.resize((64,64)) OK_arr = np.asarray(OK_img, dtype=&quot;float32&quot;) OK_arr = OK_arr.flatten() data.append(OK_arr) label.append(lable[0]) # label.append(1) for j in range(len(NG_name)): NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1] NG_img = Image.open(NG_path) NG_img=NG_img.convert(&apos;L&apos;) # print(NG_img.size) NG_img = NG_img.resize((64,64)) NG_arr = np.asarray(NG_img, dtype=&quot;float32&quot;) NG_arr = NG_arr.flatten() data.append(NG_arr) # label.append(0) label.append(lable[1]) return label ,datacraterDir = &quot;E:\image\Result&quot;label,data = load_Img(craterDir)#print(label)#print(data)#将数据分割训练数据与测试数据from sklearn.model_selection import train_test_split# 随机采样20%的数据构建测试样本，其余作为训练样本X_train, X_test, y_train, y_test = train_test_split(data,label , random_state=33, test_size=0.2)# 一个参数点（PCA维数为n）的模型训练和测试，得到该参数下模型在校验集上的预测性能def n_component_analysis(n,C,gamma, X_train, y_train, X_val, y_val): #start = time.time() start = datetime.datetime.now() pca = PCA(n_components=n) print(&quot;PCA begin with n_components: &#123;&#125;&quot;.format(n)); pca.fit(X_train) # 在训练集和测试集降维 X_train_pca = pca.transform(X_train) X_val_pca = pca.transform(X_val) # 利用SVC训练 print(&apos;SVC begin&apos;) clf1 = SVC(C=C,gamma=gamma) # clf1 = SVC(C=C,kernel=&apos;rbf&apos;,gamma=gamma) clf1.fit(X_train_pca, y_train) # 返回accuracy accuracy = clf1.score(X_val_pca, y_val) end = datetime.datetime.now() # end = time.time() print(&quot;accuracy: &#123;&#125;,C:&#123;&#125;,gamma:&#123;&#125; time elaps:&#123;&#125;&quot;.format(accuracy,C,gamma ,end - start)) return accuracy# 设置超参数（PCA维数）搜索范围n_s = np.linspace(0.70, 0.85, num=3)#需要调优的参数C_s = np.logspace(4,6, 3)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份gamma_s = np.logspace(-8, -6, 3)accuracy = []if __name__==&apos;__main__&apos;: for n in n_s: for i, oneC in enumerate(C_s): for j, gamma in enumerate(gamma_s): tmp = n_component_analysis(n, oneC, gamma,X_train, y_train, X_test, y_test) accuracy.append(tmp) 保存模型# coding=utf-8import osimport sysfrom PIL import Imageimport numpy as npfrom sklearn.svm import SVCimport picklefrom sklearn.decomposition import PCA#将数据分割训练数据与测试数据from sklearn.model_selection import train_test_split# 随机采样20%的数据构建测试样本，其余作为训练样本def Gain_Img(imgDir): lable = os.listdir(imgDir) OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0]) NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1]) print(lable) for i in range(len(OK_name)): OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1] OK_img = Image.open(OK_path) OK_img=OK_img.convert(&apos;L&apos;) OK_img = OK_img.resize((256,256)) out1 = OK_img.rotate(90) # 逆时针旋转45度 if not os.path.exists(&apos;rotation/&#123;&#125;&apos;.format(lable[0])): os.makedirs(&apos;rotation/&#123;&#125;&apos;.format(lable[0])) if not os.path.exists(&apos;rotation/&#123;&#125;&apos;.format(lable[1])): os.makedirs(&apos;rotation/&#123;&#125;&apos;.format(lable[1])) out1.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i)) OK_img.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i)) for j in range(len(NG_name)): NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1] NG_img = Image.open(NG_path) NG_img = NG_img.convert(&apos;L&apos;) NG_img = NG_img.resize((256,256)) out2 = NG_img.rotate(90) # 逆时针旋转45度 out2.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j)) NG_img.save(&quot;rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j))def load_Img(imgDir): lable = os.listdir(imgDir) OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0]) NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1]) label=[] data=[] for i in range(len(OK_name)): OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1] OK_img = Image.open(OK_path) # OK_img = OK_img.convert(&apos;L&apos;) # OK_img = OK_img.resize((64, 64)) OK_arr = np.asarray(OK_img, dtype=&quot;float32&quot;) OK_arr = OK_arr.flatten() data.append(OK_arr) label.append(lable[0]) for j in range(len(NG_name)): NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1] NG_img = Image.open(NG_path) # NG_img = NG_img.convert(&apos;L&apos;) # NG_img = NG_img.resize((64, 64)) NG_arr = np.asarray(NG_img, dtype=&quot;float32&quot;) NG_arr = NG_arr.flatten() data.append(NG_arr) label.append(lable[1]) return label ,datadef main(path,job_name): try: label, data = load_Img(path) X_train, X_test, y_train, y_test = train_test_split(data,label , random_state=33, test_size=0.2) pca = PCA(n_components=0.7) pca.fit(X_train) # 在训练集和测试集降维 X_train_pca = pca.transform(X_train) X_test_pca = pca.transform(X_test) SVC4=SVC(C=10000,gamma=1e-06) SVC4 = SVC4.fit(X_train_pca, y_train) accuracy = SVC4.score(X_test_pca, y_test) #保存模型 name=&quot;&quot;+job_name+&quot;.pkl&quot; pickle.dump((pca,SVC4),open(name, &apos;wb&apos;)) return str(accuracy) except Exception as err: return str(err)if __name__ == &apos;__main__&apos;: # print(main(&quot;E:\image\SVM&quot;)) arg1=&quot;&quot;+sys.argv[1] arg2=&quot;&quot;+sys.argv[2] gain = Gain_Img(arg1) print(main(&quot;rotation&quot;,arg2)) 实时测试见ＴＣＰ传输图片]]></content>
      <categories>
        <category>图片分类</category>
      </categories>
      <tags>
        <tag>SVC</tag>
        <tag>PCA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PIL简单应用]]></title>
    <url>%2F2019%2F01%2F15%2FPIL%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[PIL简介PIL是python自带的图像处理库 安装： pip install pillow 扩充数据－旋转准备：新建Train文件夹，将ＮＧ和ＯＫ图片分别放在命名为ＮＧ和ＯＫ的文件夹，新建rotation文件夹，或者修改路径 import osfrom PIL import Imageimport numpy as npdef load_Img(imgDir): lable = os.listdir(imgDir) OK_name=os.listdir(imgDir+&apos;/&apos;+lable[0]) NG_name=os.listdir(imgDir+&apos;/&apos;+lable[1]) print(lable) for i in range(len(OK_name)): OK_path = imgDir + &quot;/&quot; + lable[0]+&apos;/&apos;+OK_name[i-1] OK_img = Image.open(OK_path) OK_img=OK_img.convert(&apos;L&apos;) OK_img = OK_img.resize((256,256)) out1 = OK_img.rotate(90) # 逆时针旋转90度 out1.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i)) OK_img.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[0],lable[0],i)) for j in range(len(NG_name)): NG_path = imgDir + &apos;/&apos; + lable[1] + &apos;/&apos; + NG_name[j - 1] NG_img = Image.open(NG_path) NG_img = NG_img.convert(&apos;L&apos;)#L为灰度 NG_img = NG_img.resize((256,256))#改变大小 out2 = NG_img.rotate(90) # 逆时针旋转90度 out2.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_90_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j)) NG_img.save(&quot;E:\\image\\rotation\\&#123;&#125;\\&#123;&#125;_&#123;&#125;.bmp&quot;.format(lable[1],lable[1],j))craterDir = &quot;E:\image\Train&quot;rotation=load_Img(craterDir)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>PIL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习基础]]></title>
    <url>%2F2019%2F01%2F15%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[强化学习的作用Reinforcement learning is learning what to do—how to map situations to actions—so as to maximize a numerical reward signal.强化学习是学习做什么（决策），即基于当前的场景，学习如何做出一个可以最大化回报的动作。 深度学习与强化学习的关系multiple layers of nonlinear processing units for feature extraction and transformation.深度学习（DL）:用多层非线性处理单元学习从输入到输出的特征提取和变换 深度强化学习（DRL）：在强化学习的框架下，用深度神经网络来近似策略 基本结构 状态集：s ∈ S 动作集：a ∈ A 策略π： s =&gt; a 转移函数：Ｔ(s,a,s’) 或者：转移概率： P(s’|s,a) 奖励函数： R(s,a,s’) MDP策略：在状态 s 下采取什么动作 a ，找到一个最优策略 π* π（a|s）:表示策略 π 下，在状态 s 下采取行动 a 的概率 方式：通过定义每一个状态的好坏，以及或者该状态下采取某一个动作后的好坏，来寻找最优策略 价值函数状态s，在策略π下的价值函数： v_\pi(s)=E_\pi[G_t|S_t=s]=E_\pi[\sum_{k=0}^\infty\gamma^kR_{t+k+1}|S_t=s]状态s,在执行动作a情况下，策略π的价值函数： q_\pi(s,a)=E_\pi[G_t|S_t=s,A_t=a]=E_\pi[\sum_{k=0}^\infty\gamma^kR_{t+k+1}|S_t=s,A_t=a]贝尔曼方程 描述了当前状态下的价值函数与其下一时刻状态下的价值函数的关系 DP“The term dynamic programming (DP) refers to a collection of algorithms that can be used to compute optimal policies given a perfect model of the environment as a Markov decision process (MDP).”动态规划是在给定模型情况下求解最优策略的马尔科夫决策过程的一系列算法的统称。 动态规划主要分为：策略迭代与值迭代（Policy iteration vs Value iteration） 前提条件：转移概率p(s’,r|s,a)已知 贝尔曼最优性方程： 值迭代 实例 运用公式： 结果： 策略迭代策略迭代＝策略评估＋策略提升 策略评估目标：通过执行策略π，计算每个状态对应的状态函数值 实例： 策略提升在策略评估之后，采用贪婪策略进行策略更新 v_\pi=E_{a\sim\pi}(q_\pi(s,a))将策略改成： \pi'=argmax_a(q_\pi(s,a))则： v_\pi'>v_\pi VI和PI的联系策略评估： 策略提升： 值迭代： ＰＭＤＰＭＤＰ假设中，状态是完全已知的。实际生活中，由于传感器的局限性。往往难以得到当前状态的准确状态值。 但我们可以估计当前的状态分布belief: b(s) 更新belief: 实例]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络理论]]></title>
    <url>%2F2019%2F01%2F15%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[卷积层任务：对输入的图像进行特征提取 用一个小的权重矩阵去覆盖输入数据，对应位置元素加权相乘，其和作为结果的一个像素点。 这个权重在输入数据上滑动，形成一张新的矩阵 这个权重矩阵就被称为卷积核（convolution kernel） 其覆盖的位置称为感受野（receptive fileld ） 生成的新矩阵叫做特征图（feature map） 如下图所示： 步长（stride）： 步长为1，表示跳过1个像素 步长为2，就表示跳过2个像素 补齐（padding）方式: valid方式 same方式（会在图像的边缘用0补齐） 输出维度计算公式： VALID: W-F+1/S SAME: W/S 注意：彩色图像的卷积核是三阶的，所有的通道的结果要做累加。 实例： padding=same；步长设置为2 池化层｀任务`：对特征进行采样，即用一个数值替代一块区域，主要是为了降低网络训练参数及模型的过拟合程度。以及降低计算量。 池化/采样的方式通常有以下两种： 最大池化（Max Pooling: 选择Pooling窗口中的最大值作为采样值； 均值池化（Mean Pooling）: 将Pooling窗口中的所有值相加取平均，以平均值作为采样值 高斯池化：借鉴高斯模糊的方法。不常用。 可训练池化：使用一个训练函数y=f(x)y=f(x)。不常用。 全链接层任务：全连接层的每一个结点都与上一层的所有结点相连，用来把前边提取到的特征综合起来。由于其全相连的特性，一般全连接层的参数也是最多的。 dropout层任务：在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了。主要是为了防止过拟合。 激活层任务：卷积后的结果压缩到某一个固定的范围做非线性映射，这样可以一直保持一层一层下去的数值范围是可控的。 激活函数： Sigmoid Tanh（双曲正切） ReLU Leaky ReLU ELU Maxout 卷积神经网络一般采用的激活函数是ReLU(The Rectified Linear Unit/修正线性单元)，它的特点是收敛快，求梯度简单，但较脆弱，图像如下： 激活层的实践经验： 不要用sigmoid！不要用sigmoid！不要用sigmoid！ 首先试RELU，因为快，但要小心点 、 如果2失效，请用Leaky ReLU或者Maxout 某些情况下tanh倒是有不错的结果，但是很少]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典卷积神经网络]]></title>
    <url>%2F2019%2F01%2F15%2F%E7%BB%8F%E5%85%B8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[LeNet这是最早用于数字识别的CNN LeNet5特征能够总结为如下几点： 1）卷积神经网络使用三个层作为一个系列： 卷积，池化，非线性 2） 使用卷积提取空间特征 3）使用映射到空间均值下采样（subsample） 4）双曲线（tanh）或S型（sigmoid）形式的非线性 5）多层神经网络（MLP）作为最后的分类器 6）层与层之间的稀疏连接矩阵避免大的计算成本 AlexNet2012 ILSVRC比赛远超第2名的CNN，比 LeNet更深，用多层小卷积层叠加替换单大卷积层。 AlexNet的结构模型如下： VGGNet2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好 VGG各版本结构如下： 经典卷积网络实现详见：卷积神经网络实现]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>VGG</tag>
        <tag>LeNet</tag>
        <tag>AlexNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反向传播]]></title>
    <url>%2F2019%2F01%2F14%2F%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%2F</url>
    <content type="text"><![CDATA[定义损失函数： E_{total}=\frac12 (y-outo)^2定义激活函数： \sigma(x)=sigmod(x)前向传播第一层(输入层)： x_1\ \ \ x_2\ \ \ b_1加权和： net h_1=x_1w_1+x_2w_2+b_1 第二层(隐层)： outh_1=sigmod(neth_1) 加权和： neto_1=outh_1w_3+outh_2w_4+b_2 第三层(输出层)： outo_1=sigmod(neto_1) 计算误差值： Eo_1 = \frac12 (y_1-outo_1)^2 Eo_2 = \frac12 (y_2-outo_2)^2 E_{total}=Eo_1+Eo_2 总结：要是使误差值最小，就需要误差反向传播算法，更新得到最小误差的权重参数w和b。 反向传播须知：我们需要反向传递回去更新每一层对应的权重参数w和b。 我们使用链式法则来反向模式求导。 更新第三层（输出层）的权重参数：更新参数w： \frac{\partial E_{total}}{\partial w_3}=\frac{\partial E_{total}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial w_3} = \frac{\partial \frac12(y_1-outo_1)^2}{\partial outo_1} \cdot \frac{\partial sigmod(neto_1)}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial w_3} =(outo_1-y_1)\cdot outo_1(1-outo_1)\cdot outh_1 w_{3new}=w_{3old}-\eta \frac{\partial E_{total}}{\partial w_3}，η是学习率更新参数b： \frac{\partial E_{total}}{\partial b_2}=\frac{\partial E_{total}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial b_2} = \frac{\partial \frac12(y_1-outo_1)^2}{\partial outo_1} \cdot \frac{\partial sigmod(neto_1)}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial b_2} =(outo_1-y_1)\cdot outo_1(1-outo_1) b_{2new}=b_{2old}-\eta \frac{\partial E_{total}}{\partial b_2}, η是学习率同理可得：w4：也就是同一层的w都可以用这种方式更新。 更新上一层(隐层)的权重参数：更新权重参数w和b： \frac{\partial E_{total}}{\partial w_1}=\frac{\partial E_{total}}{\partial outh_1} \cdot \frac{\partial outh_1}{\partial neth_1} \cdot \frac{\partial neth_1}{\partial w_1} \frac{\partial E_{total}}{\partial b_1}=\frac{\partial E_{total}}{\partial outh_1} \cdot \frac{\partial outh_1}{\partial neth_1} \cdot \frac{\partial neth_1}{\partial b_1}其中： \frac{\partial E_{total}}{\partial outh_1} = \frac{\partial Eo_1}{\partial outh_1}+ \frac{\partial Eo_2}{\partial outh_1} \frac{\partial Eo_1}{\partial outh_1} = \frac{\partial Eo_1}{\partial neto_1} \cdot \frac{\partial neto_1}{\partial outh_1} \frac{\partial Eo_1}{\partial neto_1} = \frac{\partial E_{o_1}}{\partial outo_1} \cdot \frac{\partial outo_1}{\partial neto_1} = (outo_1-y_1)\cdot outo_1(1-outo_1) \frac{\partial neto_1}{\partial outh_1} = \frac{\partial (outh_1w_3+outo_2w_4+b_2)}{\partial outh_1} = w_3同理可得： \frac{\partial Eo_2}{\partial outh_1} = \frac{\partial Eo_2}{\partial neto_2} \cdot \frac{\partial neto_2}{\partial outh_1} \frac{\partial Eo_2}{\partial neto_2} = \frac{\partial E_{o_2}}{\partial outo_2} \cdot \frac{\partial outo_2}{\partial neto_2} = (outo_2-y_2)\cdot outo_2(1-outo_2) \frac{\partial neto_2}{\partial outh_1} = w_5（outh1连接outo2的权重，暂定为w5）综合上式： \frac{\partial E_{total}}{\partial w_1}= [w_3 (outo_1-y_1)\cdot outo_1(1-outo_1) + w_5(outo_2-y_2)\cdot outo_2(1-outo_2)] \cdot outh_1(1-outh_1) \cdot x_1 \frac{\partial E_{total}}{\partial b_1}= [w_3 (outo_1-y_1)\cdot outo_1(1-outo_1) +w_5(outo_2-y_2)\cdot outo_2(1-outo_2)] \cdot outh_1(1-outh_1)更新： w_{1new}=w_{1old}-\eta \frac{\partial E_{total}}{\partial w_1} b_{1new}=b_{1old}-\eta \frac{\partial E_{total}}{\partial b_1}同理可得：w2：也就是同一层的w都可以用这种方式更新。 推广 我们定义第L层的第i个神经元更新权重参数时(上标表示层数，下标表示神经元)： \frac{\partial E_{total}}{\partial net_i^{(L)}} = \delta_i^{(L)} \frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)}，其中w_{ij}^{(l)}表示第l层的第i个神经元连接第l−1层的第j的神经元的相连的权重参数w。如下图所示： 推广总结根据前面所定义的： E_{total}=\frac12 (y-outo)^2 \sigma(x)=sigmod(x) \frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)} \delta_i^{(L)}=\frac{\partial E_{total}}{\partial net_i^{(L)}} = \frac{\partial E_{total}}{\partial outh_i} \cdot \frac{\partial outh_i}{\partial net_i^{(L)}} = \bigtriangledown_{out} E_{total} \times \sigma^{\prime}(net_i^{(L)})对于第ll层： \delta^{(l)}=\frac{\partial E_{total}}{\partial net^{(l)}} = \frac{\partial E_{total}}{\partial net^{(l+1)}} \cdot \frac{\partial net^{(l+1)}}{\partial net^{(l)}} = \delta^{(l+1)} \times \frac{\partial net^{(l+1)}}{\partial net^{(l)}} = \delta^{(l+1)} \times \frac{\partial (w^{(l+1)}\sigma (net^{(l)}))}{\partial net^{(l)}} = \delta^{(l+1)} w^{(l+1)} \sigma^{\prime}(net^{(L)})对于偏置项bias： \frac{\partial E_{total}}{\partial bias_i^{(l)}}=\delta_i^{(l)}四项基本原则基本形式 \delta_i^{(L)}= \bigtriangledown_{out} E_{total} \times \sigma^{\prime}(net_i^{(L)}) \delta^{(l)} = \sum_j \delta_j^{(l+1)} w_{ji}^{(l+1)} \sigma^{\prime}(net_i^{(l)}) \frac{\partial E_{total}}{\partial bias_i^{(l)}}=\delta_i^{(l)} \frac{\partial E_{total}}{\partial w_{ij}^{(l)}}=outh_j^{(l-1)}\delta_i^{(l)}矩阵形式 \delta_i^{(L)}= \bigtriangledown_{out} E_{total} \bigodot \sigma^{\prime}(net_i^{(L)})其中 ⨀是Hadamard乘积（对应位置相乘） \delta^{(l)} = (w^{(l+1)})^T \delta^{(l+1)} \bigodot \sigma^{\prime}(net^{(l)}) \frac{\partial E_{total}}{\partial bias^{(l)}}=\delta^{(l)} \frac{\partial E_{total}}{\partial w^{(l)}}=\delta^{(l)}(outh^{(l-1)})^T实例 因为： \delta_i^{(L)}= \bigtriangledown_{out} E_{total} \bigodot \sigma^{\prime}(net_i^{(L)})所以： \delta^{(1)} = (w^{(2)})^T \delta^{(2)} \bigodot \sigma^{\prime}(net^{(1)}) =(\begin{bmatrix} 0.6 & 0.8 \\ 0.7 & 0.9\end{bmatrix}^T \cdot \begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix}) \bigodot \begin{bmatrix} 0.20977282 \\ 0.19661193\end{bmatrix} =\begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix}因为： \frac{\partial E_{total}}{\partial w^{(l)}}=\delta^{(l)}(outh^{(l-1)})^T所以： \Delta w^{(2)} = \delta^{(2)}(outh^{(1)})^T =\begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix} \cdot \begin{bmatrix} 0.70056714\\ 0.73105858 \end{bmatrix}^T = \begin{bmatrix} -0.00869356 & -0.00907194 \\ 0.5870176 & 0.612567 \end{bmatrix} \Delta w^{(1)} = \delta^{(1)}x^T =\begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix} \cdot \begin{bmatrix} 0.5\\ 1\end{bmatrix}^T = \begin{bmatrix} 0.00537109& 0.01074218\\ 0.00643758 & 0.01287516 \end{bmatrix}权重更新： w_{new}^2 = w_{old}^2-\Delta w^{(2)} = {\begin{bmatrix} 0.6 & 0.8 \\ 0.7 & 0.9\end{bmatrix}}-\begin{bmatrix} -0.00869356 & 0.00907194 \\ 0.5870176 & 0.612567 \end{bmatrix} = \begin{bmatrix} 0.60869356 & 0.80907194 \\ 0.64129824& 0.8387433 \end{bmatrix} b_{new}^2=b_{old}^2-\Delta b^2 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}-\begin{bmatrix} -0.01240932\\ 0.08379177\end{bmatrix} =\begin{bmatrix} 1.01240932\\ 0.91620823\end{bmatrix} w_{new}^1= w_{old}^1-\Delta w^{(1)} =\begin{bmatrix} 0.1 & 0.3 \\ 0.2 & 0.4\end{bmatrix} - \begin{bmatrix} 0.00537109& 0.01074218\\ 0.00643758 & 0.01287516 \end{bmatrix} = \begin{bmatrix} 0.09462891& 0.28925782\\ 0.19356242& 0.38712484\end{bmatrix} b_{new}^1=b_{old}^1-\Delta b^1 =\begin{bmatrix} 0.5 \\ 0.5 \end{bmatrix} - \begin{bmatrix} 0.01074218\\ 0.01287516\end{bmatrix} =\begin{bmatrix} 0.48925782\\ 0.48712484\end{bmatrix}权重初始化]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>反向传播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图床]]></title>
    <url>%2F2019%2F01%2F14%2F%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[安装picgo下载地址: https://github.com/Molunerfinn/PicGo/releases linux下载AppImage文件 右键属性，将权限设为允许为启动程序 配置以阿里云为例： 点击右上角头像，找到accessKeyId和accessKeySecret 创建对象存储，类型设为公共，记住存储空间名和地域（比如华南为oss-cn-shenzhen） 右键点击picgo，选择主窗口；将以上对应信息配置到图床配置，保存并应用]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>图床</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[感知器与激活函数]]></title>
    <url>%2F2019%2F01%2F14%2F%E6%84%9F%E7%9F%A5%E5%99%A8%E4%B8%8E%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[定义感知器是激活函数为阶跃函数的神经元。感知器的模型如下：· 输入(inputs)：一个感知器可以接收多个输入(x1,x2,…,xn|xi∈R)· 权值(weights)：每一个输入上都有一个权值wi∈R，此外还有一个偏置项b∈R，也就是上图的w0。· 加权和(weighted sum)：就是输入权值 x x 权值 w + 偏置项 b的总和。· 激活函数(step function)：感知器的激活函数： f(x) = \begin{cases} 0, & \text{x>0} \\ 1, & \text{x≤0} \end{cases}· 输出(output)：感知器的输出由加权值用激活函数做非线性变换。也就是这个公式：y=f(w⋅x+b)我们使用unit激活函数结合上图就有： y=f(w⋅x+b)=f(w1x1+w2x2+w3x3+bias) 其中f(x)就是激活函数 f(x)={1x&gt;0 0x≤0 ，图像如下图所示: 实例 x_1=[-1.0, 3.0, 2.0] \\ x_2=[2.0, -1.0, 5.0] \\ x_3=[-2.0, 0.0, 3.0 ] \\ x_4=[4.0, 1.0, 6.0] \\ w=[4.0, -3.0, 5.0 ] \\ b=2.0则： X=\begin{bmatrix} -1.0 & 3.0 & 2.0 \\ 2.0 & -1.0& 5.0 \\ -2.0& 0.0& 3.0 \\ 4.0& 1.0 & 6.0 \end{bmatrix} w^T =\begin{bmatrix} 4.0 \\ -3.0 \\ 5.0 \end{bmatrix}所以： logits = X\cdot w^T + b = \begin{bmatrix} -1.0 & 3.0 & 2.0 \\ 2.0 & -1.0& 5.0 \\ -2.0& 0.0& 3.0 \\ 4.0& 1.0 & 6.0 \end{bmatrix} \cdot \begin{bmatrix} 4.0 \\ -3.0 \\ 5.0 \end{bmatrix} + 2.0 \\ =[-1.0 \ \ \ 38.0 \ \ \ 7.0 \ \ \ 43.0 ]带入激活函数： output = f(x)=[0\ \ \ 1 \ \ \ 1 \ \ \ 1 ]隐层 激活函数unit激活函数： f(x) = \begin{cases} 0, & \text{x>0} \\ 1, & \text{x≤0} \end{cases} sigmod激活函数： f(x)=sigmod(x)=\frac{1}{1+e^{-x}} tanh激活函数： f(x)=tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}} relu激活函数： f(x) = \begin{cases} x, & \text{x>0} \\ 0, & \text{x≤0} \end{cases} 激活函数的作用 引入非线性因素。 在我们面对线性可分的数据集的时候，简单的用线性分类器即可解决分类问题。但是现实生活中的数据往往不是线性可分的，面对这样的数据，一般有两个方法：引入非线性函数、线性变换。 线性变换就是把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类 激活函数的特点 unit：线性分界 – 几乎已经不用了 sigmoid：非线性分界 – 两端软饱和，输出为 (0,1)区间 – 两端有梯度消失问题 – 因为输出恒正，可能有 zig现象 tanh：非线性分界 ：非线性分界 – 两端软饱和，输出为 (-1, 1) 区间 – 仍然存在梯度消失问题 – 没有 zig，收敛更快 (LeCun 1989) ReLU：非线性分界 – 左侧硬饱和，右无输出为 [0,+∞)区间 – 左侧会出现梯度一直为 0的情况，导致神经元 不再更新（死亡） – 改善了梯度弥散 – 同样存在 zig]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>感知器</tag>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络实现]]></title>
    <url>%2F2019%2F01%2F13%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[net新建netWork.py,添加以下代码 准备import tensorflow as tfimport config# 卷积操作def conv2d(name, l_input, w, b): return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(l_input, w, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;), b), name=name)# 最大下采样操作def max_pool(name, l_input, k): return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=&apos;SAME&apos;, name=name)# 归一化操作def norm(name, l_input, lsize=4): return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name) LeNetdef LeNet(inputs): mu = 0 sigma = 0.1 print(inputs.shape) # TODO: 第一层卷积：输入=32x32x3, 输出=28x28x6 conv1_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 6], mean=mu, stddev=sigma)) conv1_b = tf.Variable(tf.zeros(6)) conv1 = tf.nn.conv2d(inputs, conv1_w, strides=[1, 1, 1, 1], padding=&apos;VALID&apos;) + conv1_b print(conv1.shape) # 激活函数 conv1_out = tf.nn.relu(conv1) # 池化层， 输入=28x28x6, 输出=14x14x6 pool_1 = tf.nn.max_pool(conv1_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;VALID&apos;) print(pool_1.shape) # TODO: 第二层卷积： 输入=14x14x6， 输出=10x10x16 conv2_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 6, 16], mean=mu, stddev=sigma)) conv2_b = tf.Variable(tf.zeros(16)) conv2 = tf.nn.conv2d(pool_1, conv2_w, strides=[1, 1, 1, 1], padding=&apos;VALID&apos;) + conv2_b print(conv2.shape) # 激活函数 conv2_out = tf.nn.relu(conv2) # 池化层， 输入=10x10x16, 输出=5x5x16 pool_2 = tf.nn.max_pool(conv2_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;VALID&apos;) print(pool_2.shape) # Flatten 输入=5x5x16， 输出=400 pool_2_flat = tf.reshape(pool_2, [-1, 400]) # TODO: 第三层全连接层， 输入=400， 输出=120 fc1_w = tf.Variable(tf.truncated_normal(shape=[400, 120], mean=mu, stddev=sigma)) fc1_b = tf.Variable(tf.zeros(120)) fc1 = tf.matmul(pool_2_flat, fc1_w) + fc1_b # 激活函数 fc1_out = tf.nn.relu(fc1) print(fc1_out.shape) # TODO: 第四层全连接层： 输入=120， 输出=84 fc2_w = tf.Variable(tf.truncated_normal(shape=[120, 84], mean=mu, stddev=sigma)) fc2_b = tf.Variable(tf.zeros(84)) fc2 = tf.matmul(fc1_out, fc2_w) + fc2_b # 激活函数 fc2_out = tf.nn.relu(fc2) print(fc2_out.shape) # TODO: 第五层全连接层： 输入=84， 输出=10 fc3_w = tf.Variable(tf.truncated_normal(shape=[84, 10], mean=mu, stddev=sigma)) fc3_b = tf.Variable(tf.zeros(10)) fc3_out = tf.matmul(fc2_out, fc3_w) + fc3_b print(fc3_out.shape) return fc3_out alex_netdef alex_net(_X, _weights, _biases, _dropout): # 向量转为矩阵 # _X = tf.reshape(_X, shape=[-1, 28, 28, 3]) print(_X.shape) # TODO: 第一层卷积： conv1 = conv2d(&apos;conv1&apos;, _X, _weights[&apos;wc1&apos;], _biases[&apos;bc1&apos;]) # 下采样层 pool1 = max_pool(&apos;pool1&apos;, conv1, k=2) # 归一化层 norm1 = norm(&apos;norm1&apos;, pool1, lsize=4) print(norm1.shape) # TODO: 第二层卷积： conv2 = conv2d(&apos;conv2&apos;, norm1, _weights[&apos;wc2&apos;], _biases[&apos;bc2&apos;]) # 下采样 pool2 = max_pool(&apos;pool2&apos;, conv2, k=2) # 归一化 norm2 = norm(&apos;norm2&apos;, pool2, lsize=4) print(norm2.shape) # TODO: 第三层卷积： conv3 = conv2d(&apos;conv3&apos;, norm2, _weights[&apos;wc3&apos;], _biases[&apos;bc3&apos;]) # 归一化 norm3 = norm(&apos;norm3&apos;, conv3, lsize=4) print(norm3.shape) # TODO: 第四层卷积 # 卷积 conv4 = conv2d(&apos;conv4&apos;, norm3, _weights[&apos;wc4&apos;], _biases[&apos;bc4&apos;]) # 归一化 norm4 = norm(&apos;norm4&apos;, conv4, lsize=4) print(norm4.shape) # TODO: 第五层卷积 # 卷积 conv5 = conv2d(&apos;conv5&apos;, norm4, _weights[&apos;wc5&apos;], _biases[&apos;bc5&apos;]) # 下采样 pool5 = max_pool(&apos;pool5&apos;, conv5, k=2) # 归一化 norm5 = norm(&apos;norm5&apos;, pool5, lsize=4) print(norm5.shape) # TODO: 第六层全连接层 # 先把特征图转为向量 dense1 = tf.reshape(norm5, [-1, _weights[&apos;wd1&apos;].get_shape().as_list()[0]]) dense1 = tf.nn.relu(tf.matmul(dense1, _weights[&apos;wd1&apos;]) + _biases[&apos;bd1&apos;], name=&apos;fc1&apos;) dense1 = tf.nn.dropout(dense1, _dropout) print(dense1.shape) # TODO: 第七层全连接层： dense2 = tf.nn.relu(tf.matmul(dense1, _weights[&apos;wd2&apos;]) + _biases[&apos;bd2&apos;], name=&apos;fc2&apos;) # Relu activation dense2 = tf.nn.dropout(dense2, _dropout) print(dense2.shape) # TODO: 第八层全连接层： # 网络输出层 out = tf.matmul(dense2, _weights[&apos;out&apos;]) + _biases[&apos;out&apos;] print(out.shape) return out cnn_1def CNN_1(inputs): # (32x32x3)--&gt;(32x32x64) with tf.name_scope(&apos;conv1&apos;): h_conv1 = tf.layers.conv2d(inputs, 64, [2, 2], padding=&apos;SAME&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(h_conv1.shape) # 构建池化层--采用最大池化 # (32X32X64)--&gt;(16X16X64) with tf.name_scope(&apos;pool1&apos;): h_pool1 = tf.layers.max_pooling2d(h_conv1, pool_size=[2, 2], strides=[2, 2], padding=&apos;SAME&apos;) print(h_pool1.shape) # 构建第二层卷积计算层--(16x16x64)--&gt;(16x16x128). with tf.name_scope(&apos;conv2&apos;): h_conv2 = tf.layers.conv2d(h_pool1, 128, [4, 4], padding=&apos;SAME&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(h_conv2.shape) # 构建第二个池化层(16x16x128)--&gt;(8x8x128) with tf.name_scope(&apos;pool2&apos;): h_pool2 = tf.layers.max_pooling2d(h_conv2, pool_size=[2, 2], strides=[2, 2], padding=&apos;SAME&apos;) print(h_pool2.shape) # 构建全连接层--(8x8x128)--&gt;(1024) with tf.name_scope(&apos;fc1&apos;): h_pool2_flat = tf.layers.flatten(h_pool2) h_fc1 = tf.layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu) print(h_fc1.shape) # Dropout--防止过拟合 with tf.name_scope(&apos;dropout&apos;): # keep_prob = tf.placeholder(tf.float32) h_fc_drop = tf.nn.dropout(h_fc1, keep_prob=config.keep_prob) # 构建全连接层--1024--&gt;512 with tf.name_scope(&apos;fc2&apos;): fc2 = tf.layers.dense(h_fc_drop, 512, activation=tf.nn.relu) print(fc2.shape) # 构建全连接层--512--&gt;10 with tf.name_scope(&apos;fc3&apos;): out = tf.layers.dense(fc2, 10, activation=None) print(out.shape) return out VGG16def VGG16(inputs): print(inputs.shape) # (32x32x3) --&gt; (32x32x64) with tf.name_scope(&apos;conv_1&apos;): conv_1_out = tf.layers.conv2d(inputs, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_1_out.shape) # (32x32x64) --&gt; (32x32x64) with tf.name_scope(&apos;conv_2&apos;): conv_2_out = tf.layers.conv2d(conv_1_out, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_2_out.shape) # (32x32x64) --&gt; (16x16x64) with tf.name_scope(&apos;pool_1&apos;): pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_1_out.shape) # (16x16x64) --&gt; (16x16x128) with tf.name_scope(&apos;conv_3&apos;): conv_3_out = tf.layers.conv2d(pool_1_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_3_out.shape) # (16x16x128) --&gt; (16x16x128) with tf.name_scope(&apos;conv_4&apos;): conv_4_out = tf.layers.conv2d(conv_3_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_4_out.shape) # (16x16x128) --&gt; (8x8x128) with tf.name_scope(&apos;pool_2&apos;): pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_2_out.shape) # (8x8x128) --&gt; (8x8x256) with tf.name_scope(&apos;conv_5&apos;): conv_5_out = tf.layers.conv2d(pool_2_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_5_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_6&apos;): conv_6_out = tf.layers.conv2d(conv_5_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_6_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_7&apos;): conv_7_out = tf.layers.conv2d(conv_6_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_7_out.shape) # (8x8x256) --&gt; (4x4x256) with tf.name_scope(&apos;pool_3&apos;): pool_3_out = tf.layers.max_pooling2d(conv_7_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_3_out.shape) # (4x4x256) --&gt; (4x4x512) with tf.name_scope(&apos;conv_8&apos;): conv_8_out = tf.layers.conv2d(pool_3_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_8_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_9&apos;): conv_9_out = tf.layers.conv2d(conv_8_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_9_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_10&apos;): conv_10_out = tf.layers.conv2d(conv_9_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_10_out.shape) # (4x4x512) --&gt; (2x2x512) with tf.name_scope(&apos;pool_4&apos;): pool_4_out = tf.layers.max_pooling2d(conv_10_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_4_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_11&apos;): conv_11_out = tf.layers.conv2d(pool_4_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_11_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_12&apos;): conv_12_out = tf.layers.conv2d(conv_11_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_12_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_13&apos;): conv_13_out = tf.layers.conv2d(conv_12_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_13_out.shape) # (2x2x512) --&gt; (1x1x512) with tf.name_scope(&apos;pool_5&apos;): pool_5_out = tf.layers.max_pooling2d(conv_13_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_5_out.shape) # (1x1x512) --&gt; 512 with tf.name_scope(&apos;fc_1&apos;): pool_5_outz_flat = tf.layers.flatten(pool_5_out) fc_1_out = tf.layers.dense(pool_5_outz_flat, 512, activation=tf.nn.relu) fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob) print(fc_1_drop.shape) # 512 --&gt; 512 with tf.name_scope(&apos;fc_2&apos;): fc_2_out = tf.layers.dense(fc_1_drop, 512, activation=tf.nn.relu) fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob) print(fc_2_drop.shape) # 512 --&gt; 10 with tf.name_scope(&apos;fc_3&apos;): fc_3_out = tf.layers.dense(fc_2_drop, 10, activation=None) print(fc_3_out.shape) return fc_3_out vgg19def VGG19(inputs): print(inputs.shape) # (32x32x3) --&gt; (32x32x64) with tf.name_scope(&apos;conv_1&apos;): conv_1_out = tf.layers.conv2d(inputs, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_1_out.shape) # (32x32x64) --&gt; (32x32x64) with tf.name_scope(&apos;conv_2&apos;): conv_2_out = tf.layers.conv2d(conv_1_out, 64, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_2_out.shape) # (32x32x64) --&gt; (16x16x64) with tf.name_scope(&apos;pool_1&apos;): pool_1_out = tf.layers.max_pooling2d(conv_2_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_1_out.shape) # (16x16x64) --&gt; (16x16x128) with tf.name_scope(&apos;conv_3&apos;): conv_3_out = tf.layers.conv2d(pool_1_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_3_out.shape) # (16x16x128) --&gt; (16x16x128) with tf.name_scope(&apos;conv_4&apos;): conv_4_out = tf.layers.conv2d(conv_3_out, 128, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_4_out.shape) # (16x16x128) --&gt; (8x8x128) with tf.name_scope(&apos;pool_2&apos;): pool_2_out = tf.layers.max_pooling2d(conv_4_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_2_out.shape) # (8x8x128) --&gt; (8x8x256) with tf.name_scope(&apos;conv_5&apos;): conv_5_out = tf.layers.conv2d(pool_2_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_5_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_6&apos;): conv_6_out = tf.layers.conv2d(conv_5_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_6_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_7&apos;): conv_7_out = tf.layers.conv2d(conv_6_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_7_out.shape) # (8x8x256) --&gt; (8x8x256) with tf.name_scope(&apos;conv_8&apos;): conv_8_out = tf.layers.conv2d(conv_7_out, 256, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_8_out.shape) # (8x8x256) --&gt; (4x4x256) with tf.name_scope(&apos;pool_3&apos;): pool_3_out = tf.layers.max_pooling2d(conv_8_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_3_out.shape) # (4x4x256) --&gt; (4x4x512) with tf.name_scope(&apos;conv_9&apos;): conv_9_out = tf.layers.conv2d(pool_3_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_9_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_10&apos;): conv_10_out = tf.layers.conv2d(conv_9_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_10_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_11&apos;): conv_11_out = tf.layers.conv2d(conv_10_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_11_out.shape) # (4x4x512) --&gt; (4x4x512) with tf.name_scope(&apos;conv_12&apos;): conv_12_out = tf.layers.conv2d(conv_11_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_12_out.shape) # (4x4x512) --&gt; (2x2x512) with tf.name_scope(&apos;pool_4&apos;): pool_4_out = tf.layers.max_pooling2d(conv_12_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_4_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_13&apos;): conv_13_out = tf.layers.conv2d(pool_4_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_13_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_14&apos;): conv_14_out = tf.layers.conv2d(conv_13_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_14_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_15&apos;): conv_15_out = tf.layers.conv2d(conv_14_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_15_out.shape) # (2x2x512) --&gt; (2x2x512) with tf.name_scope(&apos;conv_16&apos;): conv_16_out = tf.layers.conv2d(conv_15_out, 512, [3, 3], padding=&apos;same&apos;, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer(mean=0., stddev=0.1)) print(conv_16_out.shape) # (2x2x512) --&gt; (1x1x512) with tf.name_scope(&apos;pool_5&apos;): pool_5_out = tf.layers.max_pooling2d(conv_16_out, pool_size=[2, 2], strides=[2, 2], padding=&apos;same&apos;) print(pool_5_out.shape) # (1x1x512) --&gt; 512 with tf.name_scope(&apos;fc_1&apos;): pool_5_outz_flat = tf.layers.flatten(pool_5_out) fc_1_out = tf.layers.dense(pool_5_outz_flat, 512, activation=tf.nn.relu) fc_1_drop = tf.nn.dropout(fc_1_out, keep_prob=config.keep_prob) print(fc_1_drop.shape) # 512 --&gt; 512 with tf.name_scope(&apos;fc_2&apos;): fc_2_out = tf.layers.dense(fc_1_drop, 512, activation=tf.nn.relu) fc_2_drop = tf.nn.dropout(fc_2_out, keep_prob=config.keep_prob) print(fc_2_drop.shape) # 512 --&gt; 10 with tf.name_scope(&apos;fc_3&apos;): fc_3_out = tf.layers.dense(fc_2_drop, 10, activation=None) print(fc_3_out.shape) return fc_3_out 读取数据加载数据import pickleimport numpy as npfrom sklearn.preprocessing import MinMaxScaler, LabelBinarizerdef load_cifar10_batch(path, batch_id): &quot;&quot;&quot; 加载batch的数据 :param path: 数据存储的目录 :param batch_id:batch的编号 :return:features and labels &quot;&quot;&quot; with open(path + &apos;/data_batch_&apos; + str(batch_id), mode=&apos;rb&apos;) as file: batch = pickle.load(file, encoding=&apos;latin1&apos;) # features and labels features = batch[&apos;data&apos;].reshape((len(batch[&apos;data&apos;]), 3, 32, 32)).transpose(0, 2, 3, 1) labels = batch[&apos;labels&apos;] return features, labels 数据预处理def pre_processing_data(x_train, y_train, x_test, y_test): # features minmax = MinMaxScaler() # 重塑数据 # (50000, 32, 32, 3) --&gt; (50000, 32*32*3) x_train_rows = x_train.reshape(x_train.shape[0], 32*32*3) # (10000, 32, 32, 3) --&gt; (10000, 32*32*3) x_test_rows = x_test.reshape(x_test.shape[0], 32*32*3) # 归一化 x_train_norm = minmax.fit_transform(x_train_rows) x_test_norm = minmax.fit_transform(x_test_rows) # 重塑数据 x_train = x_train_norm.reshape(x_train_norm.shape[0], 32, 32, 3) x_test = x_test_norm.reshape(x_test_norm.shape[0], 32, 32, 3) # labels # 对标签进行one-hot n_class = 10 label_binarizer = LabelBinarizer().fit(np.array(range(n_class))) y_train = label_binarizer.transform(y_train) y_test = label_binarizer.transform(y_test) return x_train, y_train, x_test, y_test 数据准备新建Read_date.pydef cifar10_data(): # 加载训练数据 cifar10_path = &apos;data&apos; # 一共是有5个batch的训练数据 x_train, y_train = load_cifar10_batch(cifar10_path, 1) for n in range(2, 6): features, labels = load_cifar10_batch(cifar10_path, n) x_train = np.concatenate([x_train, features]) y_train = np.concatenate([y_train, labels]) # 加载测试数据 with open(cifar10_path + &apos;/test_batch&apos;, mode=&apos;rb&apos;) as file: batch = pickle.load(file, encoding=&apos;latin1&apos;) x_test = batch[&apos;data&apos;].reshape((len(batch[&apos;data&apos;]), 3, 32, 32)).transpose(0, 2, 3, 1) y_test = batch[&apos;labels&apos;] x_train, y_train, x_test, y_test = pre_processing_data(x_train, y_train, x_test, y_test) return x_train, y_train, x_test, y_test config新建config.py；复制以下代码 初始化卷积神经网络参数import tensorflow as tfimport matplotlib.pyplot as pltkeep_prob = 0.8epochs = 20batch_size = 128n_classes = 10 # 总共10类 定义placeholderinputs = tf.placeholder(tf.float32, [None, 32, 32, 3], name=&apos;inputs&apos;)targets = tf.placeholder(tf.float32, [None, 10], name=&apos;logits&apos;)learning_rate = 0.001 显示图片def show_images(images): fig, axes = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(9, 9)) img = images[: 60] for image, row in zip([img[: 20], img[20: 40], img[40: 60]], axes): for img, ax in zip(image, row): ax.imshow(img) ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) fig.tight_layout(pad=0.1) # plt.show() 存储网络参数(alexnet)weights = &#123; &apos;wc1&apos;: tf.Variable(tf.random_normal(shape=[11, 11, 3, 96])), &apos;wc2&apos;: tf.Variable(tf.random_normal(shape=[5, 5, 96, 256])), &apos;wc3&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 256, 384])), &apos;wc4&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 384, 384])), &apos;wc5&apos;: tf.Variable(tf.random_normal(shape=[3, 3, 384, 256])), &apos;wd1&apos;: tf.Variable(tf.random_normal(shape=[4*4*256, 4096])), &apos;wd2&apos;: tf.Variable(tf.random_normal(shape=[4096, 1024])), &apos;out&apos;: tf.Variable(tf.random_normal(shape=[1024, n_classes]))&#125;biases = &#123; &apos;bc1&apos;: tf.Variable(tf.random_normal([96])), &apos;bc2&apos;: tf.Variable(tf.random_normal([256])), &apos;bc3&apos;: tf.Variable(tf.random_normal([384])), &apos;bc4&apos;: tf.Variable(tf.random_normal([384])), &apos;bc5&apos;: tf.Variable(tf.random_normal([256])), &apos;bd1&apos;: tf.Variable(tf.random_normal([4096])), &apos;bd2&apos;: tf.Variable(tf.random_normal([1024])), &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))&#125;​```## 测试模型新建TestModel.py,复制以下代码### 模型评估​```import tensorflow as tfimport configimport Read_datadef evaluate(X_data, y_data, inputs, logits, targets): batch_size = config.batch_size correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1)) accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) num_examples = len(X_data) total_accuracy = 0 sess = tf.get_default_session() for offset in range(0, num_examples, batch_size): batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size] accuracy = sess.run(accuracy_operation, feed_dict=&#123;inputs: batch_x, targets: batch_y&#125;) total_accuracy += (accuracy * len(batch_x)) return total_accuracy / num_examples​```### 读取模型​```def run(inputs, logits, targets): print(&apos;TESTING....&apos;) x_train, y_train, x_test, y_test = Read_data.cifar10_data() saver = tf.train.Saver() with tf.Session() as sess: print(&quot;Evaluate The Model&quot;) # TODO: 读取模型 saver.restore(sess, &apos;./model/cifar.model&apos;) test_accuracy = evaluate(x_test, y_test, inputs, logits, targets) print(&quot;Test Accuracy = &#123;:.3f&#125;&quot;.format(test_accuracy))​```## 训练创建TrainModel.py,复制以下代码​```from sklearn.model_selection import train_test_splitimport tensorflow as tfimport Read_dataimport configimport TestModeldef run(logits): # 读取数据 global train_loss x_train, y_train, x_test, y_test = Read_data.cifar10_data() print(y_train.shape) # 构造验证集和训练集 train_rate = 0.8 x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, train_size=train_rate) # 初始化卷积神经网络参数 epochs = config.epochs batch_size = config.batch_size # 定义输入和标签的placeholder inputs = config.inputs targets = config.targets # TODO: 计算损失值并初始化optimizer learning_rate = config.learning_rate cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets) loss_operation = tf.reduce_mean(cross_entropy) optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) training_operation = optimizer.minimize(loss_operation) # TODO: 初始化变量 init = tf.global_variables_initializer() print(&quot;FUNCTION READY!!&quot;) # TODO: 保存模型 saver = tf.train.Saver() # TODO: 训练模型 with tf.Session() as sess: sess.run(init) num_examples = len(x_train) print(&quot;Training.....&quot;) for n in range(epochs): for offset in range(0, num_examples, batch_size): batch_x, batch_y = x_train[offset:offset+batch_size], y_train[offset:offset+batch_size] train_loss, _ = sess.run([loss_operation, training_operation], feed_dict=&#123;inputs: batch_x, targets: batch_y&#125;) print(&quot;EPOCH &#123;&#125; ...&quot;.format(n + 1)) print(&quot;Train Loss &#123;:.4f&#125;&quot; .format(train_loss)) print(&quot;Validation Accuracy = &#123;:.3f&#125;&quot;.format(TestModel.evaluate(x_validation, y_validation, inputs, logits, targets))) saver.save(sess, &apos;./model/cifar.model&apos;) print(&quot;Model saved&quot;)​```## 测试图片新建testPhoto.py​```import numpy as npimport tensorflow as tffrom PIL import Imageimport Networkimport configdef main(): with tf.Session() as sess: photo_classes = &#123;0: &apos;airplane&apos;, 1: &apos;automobile&apos;, 2: &apos;bird&apos;, 3: &apos;cat&apos;, 4: &apos;deer&apos;, 5: &apos;dog&apos;, 6: &apos;frog&apos;, 7: &apos;horse&apos;, 8: &apos;ship&apos;, 9: &apos;truck&apos;&#125; logits = Network.VGG16(config.inputs) x = config.inputs saver = tf.train.Saver() saver.restore(sess, &apos;./model/cifar.model&apos;) # input im = Image.open(&apos;image/dog-3.jpg&apos;) # im.show() im = im.resize((32, 32)) # print(im.size, im.mode) im = np.array(im).astype(np.float32) im = np.reshape(im, [-1, 32*32*3]) im = (im - (255 / 2.0)) / 255 batch_xs = np.reshape(im, [-1, 32, 32, 3]) output = sess.run(logits, feed_dict=&#123;x: batch_xs&#125;) print(output) print(&apos;the out put is :&apos;, photo_classes[np.argmax(output)])if __name__ == &apos;__main__&apos;: main()​```## 主程序新建main.py​```import TrainModelimport TestModelimport configimport Network# logits = Network.LeNet(Setting.inputs)# logits = Network.alex_net(Setting.inputs, Setting.weights, Setting.biases, Setting.keep_prob)logits = Network.CNN_1(config.inputs)# logits = Network.VGG16(config.inputs)# logits = Network.VGG19(Setting.inputs)TrainModel.run(logits)TestModel.run(config.inputs, logits, config.targets)​```]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keras实现CNN]]></title>
    <url>%2F2019%2F01%2F13%2Fkeras%E5%AE%9E%E7%8E%B0CNN%2F</url>
    <content type="text"><![CDATA[0.导入环境import osfrom tensorflow.examples.tutorials.mnist import input_dataimport tensorflow as tffrom keras.layers.core import Dense, Flattenfrom keras.layers.convolutional import Conv2Dfrom keras.layers.pooling import MaxPooling2Dfrom keras.objectives import categorical_crossentropyfrom keras import backend as KK.image_data_format()os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos; 1.数据准备# 使用tensorflow自带的工具加载MNIST手写数字集合mnist = input_data.read_data_sets(&apos;data&apos;, one_hot=True)# 查看数据的维度和target的维度print(mnist.train.images.shape)print(mnist.train.labels.shape) 2.准备好palceholderx = tf.placeholder(tf.float32, [None, 784])y = tf.placeholder(tf.float32, [None, 10])learnRate = tf.placeholder(tf.float32) 3.构建网络计算图结构# 把输入数据reshape--28x28=784, 单通道， -1表示Nonewith tf.name_scope(&apos;reshape&apos;): x_image = tf.reshape(x, [-1, 28, 28, 1])# 构建第一层卷积计算层--将一个灰度图像映射到32个feature maps, 卷积核为5x5net = Conv2D(32, kernel_size=[5, 5], strides=[1, 1], activation=&apos;relu&apos;, padding=&apos;same&apos;, input_shape=[28, 28, 1])(x_image)# 构建池化层--采用最大池化net = MaxPooling2D(pool_size=[2, 2])(net)# 构建第二层卷积计算层--maps 32 feature maps to 64.net = Conv2D(64, kernel_size=[5, 5], strides=[1, 1], activation=&apos;relu&apos;, padding=&apos;same&apos;)(net)# 构建第二层池化层--采用最大池化net = MaxPooling2D(pool_size=[2, 2])(net)# 构建全连接层--经过的两层的下采样（池化），28x28x1的图像--&gt;7x7x64，然后映射到1024个特征net = Flatten()(net)net = Dense(1024, activation=&apos;relu&apos;)(net)# 构建第二层全连接层--将1024个特性映射到10个类，每个类对应一个数字net = Dense(10, activation=&apos;softmax&apos;)(net) 4.计算损失值并初始化optimizercross_entropy = tf.reduce_mean(categorical_crossentropy(y, net))l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])total_loss = cross_entropy + 7e-5*l2_losstrain_step = tf.train.AdamOptimizer(learnRate).minimize(total_loss) 5.初始化变量init = tf.global_variables_initializer()print(&quot;FUNCTION READY!!&quot;) 6.在会话中执行网络定义的运算with tf.Session() as sess: sess.run(init) for step in range(3000): batch_xs, batch_ys = mnist.train.next_batch(100) lr = 0.01 _, loss, l2_loss_value, total_loss_value = sess.run( [train_step, cross_entropy, l2_loss, total_loss], feed_dict=&#123;x: batch_xs, y: batch_ys, learnRate: lr&#125;) if (step + 1) % 100 == 0: print(&quot;step %d, entropy loss: %f, l2_loss: %f, total loss: %f&quot; % (step + 1, loss, l2_loss_value, total_loss_value)) # 验证训练的模型 correct_prediction = tf.equal(tf.argmax(net, 1), tf.argmax(y, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) print(&quot;Train accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;)) if (step + 1) % 1000 == 0: print(&quot;Text accuracy:&quot;, sess.run(accuracy, feed_dict=&#123;x: batch_xs, y: batch_ys&#125;))]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度卷积对抗生成网络-DCGAN]]></title>
    <url>%2F2019%2F01%2F13%2F%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C-DCGAN%2F</url>
    <content type="text"><![CDATA[导入环境import numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltfrom tensorflow.examples.tutorials.mnist import input_data 数据准备运行程序下面代码，mnist数据集会自动下载mnist = input_data.read_data_sets(&apos;data&apos;) 获得输入数据def get_inputs(noise_dim, image_height, image_width, image_depth): # 真实数据 inputs_real = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth], name=&apos;inputs_real&apos;) # 噪声数据 inputs_noise = tf.placeholder(tf.float32, [None, noise_dim], name=&apos;inputs_noise&apos;) return inputs_real, inputs_noise 生成器def get_generator(noise_img, output_dim, is_train=True, alpha=0.01): with tf.variable_scope(&quot;generator&quot;, reuse=(not is_train)): # 100 x 1 to 4 x 4 x 512 # 全连接层 layer1 = tf.layers.dense(noise_img, 4 * 4 * 512) layer1 = tf.reshape(layer1, [-1, 4, 4, 512]) # batch normalization layer1 = tf.layers.batch_normalization(layer1, training=is_train) # Leaky ReLU layer1 = tf.maximum(alpha * layer1, layer1) # dropout layer1 = tf.nn.dropout(layer1, keep_prob=0.8) # 4 x 4 x 512 to 7 x 7 x 256 layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding=&apos;valid&apos;) layer2 = tf.layers.batch_normalization(layer2, training=is_train) layer2 = tf.maximum(alpha * layer2, layer2) layer2 = tf.nn.dropout(layer2, keep_prob=0.8) # 7 x 7 256 to 14 x 14 x 128 layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding=&apos;same&apos;) layer3 = tf.layers.batch_normalization(layer3, training=is_train) layer3 = tf.maximum(alpha * layer3, layer3) layer3 = tf.nn.dropout(layer3, keep_prob=0.8) # 14 x 14 x 128 to 28 x 28 x 1 logits = tf.layers.conv2d_transpose(layer3, output_dim, 3, strides=2, padding=&apos;same&apos;) # MNIST原始数据集的像素范围在0-1，这里的生成图片范围为(-1,1) # 因此在训练时，记住要把MNIST像素范围进行resize outputs = tf.tanh(logits) return outputs 判别器def get_discriminator(inputs_img, reuse=False, alpha=0.01): with tf.variable_scope(&quot;discriminator&quot;, reuse=reuse): # 28 x 28 x 1 to 14 x 14 x 128 # 第一层不加入BN layer1 = tf.layers.conv2d(inputs_img, 128, 3, strides=2, padding=&apos;same&apos;) layer1 = tf.maximum(alpha * layer1, layer1) layer1 = tf.nn.dropout(layer1, keep_prob=0.8) # 14 x 14 x 128 to 7 x 7 x 256 layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding=&apos;same&apos;) layer2 = tf.layers.batch_normalization(layer2, training=True) layer2 = tf.maximum(alpha * layer2, layer2) layer2 = tf.nn.dropout(layer2, keep_prob=0.8) # 7 x 7 x 256 to 4 x 4 x 512 layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding=&apos;same&apos;) layer3 = tf.layers.batch_normalization(layer3, training=True) layer3 = tf.maximum(alpha * layer3, layer3) layer3 = tf.nn.dropout(layer3, keep_prob=0.8) # 4 x 4 x 512 to 4*4*512 x 1 flatten = tf.reshape(layer3, (-1, 4 * 4 * 512)) logits = tf.layers.dense(flatten, 1) outputs = tf.sigmoid(logits) return logits, outputs 目标函数def get_loss(inputs_real, inputs_noise, image_depth, smooth=0.1): g_outputs = get_generator(inputs_noise, image_depth, is_train=True) d_logits_real, d_outputs_real = get_discriminator(inputs_real) d_logits_fake, d_outputs_fake = get_discriminator(g_outputs, reuse=True) # 计算Loss g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_outputs_fake) * (1 - smooth))) d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_outputs_real) * ( 1 - smooth))) d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_outputs_fake))) d_loss = tf.add(d_loss_real, d_loss_fake) return g_loss, d_loss 优化器def get_optimizer(g_loss, d_loss, learning_rate=0.001): train_vars = tf.trainable_variables() g_vars = [var for var in train_vars if var.name.startswith(&quot;generator&quot;)] d_vars = [var for var in train_vars if var.name.startswith(&quot;discriminator&quot;)] # Optimizer with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): g_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(g_loss, var_list=g_vars) d_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(d_loss, var_list=d_vars) return g_opt, d_opt 显示图片def plot_images(samples): fig, axes = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True, figsize=(7, 7)) for img, ax in zip(samples, axes.flatten()): ax.imshow(img.reshape((28, 28)), cmap=&apos;Greys_r&apos;) ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) fig.tight_layout(pad=0) plt.show()def show_generator_output(sess, n_images, inputs_noise, output_dim): noise_shape = inputs_noise.get_shape().as_list()[-1] # 生成噪声图片 examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape]) samples = sess.run(get_generator(inputs_noise, output_dim, False), feed_dict=&#123;inputs_noise: examples_noise&#125;) result = np.squeeze(samples, -1) return result 开始训练# 定义参数batch_size = 64noise_size = 100epochs = 5n_samples = 25learning_rate = 0.001def train(noise_size, data_shape, batch_size, n_samples): # 存储loss losses = [] steps = 0 inputs_real, inputs_noise = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3]) g_loss, d_loss = get_loss(inputs_real, inputs_noise, data_shape[-1]) print(&quot;FUNCTION READY!!&quot;) for _ in range(6): g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, learning_rate) print(&quot;TRAINING....&quot;) #exit() with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # 迭代epoch for e in range(epochs): for batch_i in range(mnist.train.num_examples // batch_size): steps += 1 batch = mnist.train.next_batch(batch_size) batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3])) # scale to -1, 1 batch_images = batch_images * 2 - 1 # noise batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size)) # run optimizer sess.run(g_train_opt, feed_dict=&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) sess.run(d_train_opt, feed_dict=&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) if steps % 101 == 0: train_loss_d = d_loss.eval(&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) train_loss_g = g_loss.eval(&#123;inputs_real: batch_images, inputs_noise: batch_noise&#125;) losses.append((train_loss_d, train_loss_g)) print(&quot;Epoch &#123;&#125;/&#123;&#125;....&quot;.format(e + 1, epochs), &quot;Discriminator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_d), &quot;Generator Loss: &#123;:.4f&#125;....&quot;.format(train_loss_g)) if e % 1 == 0: # 显示图片 samples = show_generator_output(sess, n_samples, inputs_noise, data_shape[-1]) plot_images(samples)with tf.Graph().as_default(): train(noise_size, [-1, 28, 28, 1], batch_size, n_samples) print(&quot;OPTIMIZER END!!&quot;)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>DCGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNN实践之写文章]]></title>
    <url>%2F2019%2F01%2F13%2FRNN%2F</url>
    <content type="text"><![CDATA[文章下载下载文章或重新找一篇文章：https://pan.baidu.com/s/1-dZd1oKZSawCN0R7LQWz1g 导入环境import numpy as npimport tensorflow as tffrom tensorflow.contrib import rnnimport randomimport timefrom collections import Counterstart_time = time.time()tf.reset_default_graph()train_file = &apos;words.txt&apos; 简单时间处理def str_time(sec): if sec &lt; 60: return str(sec) + &quot; sec&quot; elif sec &lt; (60 * 60): return str(sec / 60) + &quot; min&quot; else: return str(sec / (60 * 60)) + &quot; hour&quot; 处理汉字def get_char(txt_file): labels = str() with open(file=txt_file, mode=&apos;rb&apos;) as f: for label in f: labels = label.decode(&quot;utf-8&quot;) return labels 处理多个中文文件def readfile(files): labels = list() for txt_file in files: target = get_char(txt_file) labels.append(target) return labels 将文本数组转换为向量def char_vector(files, num_map, label=None): word_size = len(num_map) vector = lambda word: num_map.get(word, word_size) if files: label = get_char(files) labels_vector = list(map(vector, label)) return labels_vector 样本预处理train_data = get_char(train_file)print(&quot;Loading training data...&quot;)print(len(train_data))counter = Counter(train_data)words = sorted(counter)words_size = len(words)words_num_map = dict(zip(words, range(words_size)))print(&quot;字表大小：&quot;, words_size)word_label = char_vector(train_file, words_num_map) 超参数设置learning_rate = 0.001epochs = 100000display_step = 1000n_input = 4 # 每次输入4个汉字， 预测第5个汉字# 隐层神经元n_hidden1 = 256n_hidden2 = 512n_hidden3 = 512keep_prob=0.8layer_num=3batch_size=1# 定义X, Y的placeholderx = tf.placeholder(&quot;float&quot;, [None, n_input, 1])y = tf.placeholder(&quot;float&quot;, [None, words_size])# 对 weights biases 初始值的定义weights = &#123; &apos;in&apos;: tf.Variable(tf.random_normal([n_input,n_hidden1])), &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden2,words_size]))&#125;biases = &#123; # shape (128, ) &apos;in&apos;: tf.Variable(tf.constant(0.1, shape=[n_hidden1,])), # shape (10, ) &apos;out&apos;: tf.Variable(tf.constant(0.1, shape=[words_size, ]))&#125; 定义网络结构def lstm_call(): cell = tf.nn.rnn_cell.LSTMCell(num_units=n_hidden1, reuse=tf.get_variable_scope().reuse) return tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)def RNN(x, weights, biases): x = tf.reshape(x, [batch_size, n_input, 1]) # (1,4,1) 相当于batch =1 # rnn cell = tf.contrib.rnn.BasicLSTMCell(n_hidden2) init_state = cell.zero_state(batch_size, dtype=tf.float32) # final_state 的维度是 batch * n_hidden --&gt; 1 * 512 # outputs 的维度是 batch * n_input(time_step) * n_hidden --&gt; 1 * 4 * 512 outputs, final_state = tf.nn.dynamic_rnn(cell, x, initial_state=init_state, time_major=False) # print (&quot;before unstack , output shape : &quot;,outputs.shape) # output shape : (1,3,512) (batch,time_step,cell_n_hidden) # unstack 更改维度 outputs = tf.unstack(tf.transpose(outputs, [1, 0, 2])) # 这个时候 outputs 变成了list # print (&quot;output shape[-1] 2: &quot;,outputs[-1].shape) # output shape : (3,1,512), outputs[-1] shape (1,512) results = tf.matmul(outputs[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;] # (1,112) 这个的表示意义是一个(1,112)的onehot，112表示字典里面总共有112个词汇 return results 计算损失值并初始化optimizerpredicted = RNN(x,weights,biases)# Loss optimizerloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predicted, labels=y))optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)# Model evaluationcorrect_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))# 保存模型save_dir = &quot;model/&quot;saver = tf.train.Saver(max_to_keep=1)# 初始化所有变量init = tf.global_variables_initializer() 训练及测试模型with tf.Session() as sess: sess.run(init) # 每训练一次，取后面四个文字向量当做输入，第五个文字向量当做标签用作计算loss offset = random.randint(0, n_input + 1) end_offset = n_input + 1 step = 0 loss_total = 0. acc_total = 0. # 恢复模型并继续训练 model = tf.train.latest_checkpoint(save_dir) print(&quot;model-ckpt:&quot;, model) start_epoch = 0 if model: saver.restore(sess, model) ind = model.find(&quot;-&quot;) start_epoch = int(model[ind + 1:]) print(start_epoch) step = start_epoch while step &lt; epochs: # 随机选择一个位置 if offset &gt; (len(train_data) - end_offset): offset = random.randint(0, n_input + 1) # 按照指定的位置获取后四个文字向量，当做输入 in_words = [[word_label[word]] for word in range(offset, offset + n_input)] in_words = np.reshape(np.array(in_words), [-1, n_input, 1]) out_onehot = np.zeros([words_size], dtype=float) out_onehot[word_label[offset + n_input]] = 1.0 # 所有的字都变成onehot out_onehot = np.reshape(out_onehot, [1, -1]) _, acc, loss_val, onehot_pred = sess.run([optimizer, accuracy, loss, predicted], feed_dict=&#123;x: in_words, y: out_onehot&#125;) loss_total += loss_val acc_total += acc if (step + 1) % display_step == 0: print(&quot;Iter= &quot; + str(step + 1) + &quot;, Average Loss= &quot; + &quot;&#123;:.6f&#125;&quot;.format(loss_total / display_step) + &quot;, Average Accuracy= &quot; + &quot;&#123;:.2f&#125;%&quot;.format(100 * acc_total / display_step)) acc_total = 0. loss_total = 0. in2 = [words[word_label[i]] for i in range(offset, offset + n_input)] out2 = words[word_label[offset + n_input]] out_pred = words[int(tf.argmax(onehot_pred, 1).eval())] print(&quot;%s - [%s] vs [%s]&quot; % (in2, out2, out_pred)) saver.save(sess, save_dir + &quot;CharRNN.cpkt&quot;, global_step=step) # 中间隔了一个，作为预测 offset += (n_input + 1) step += 1 print(&quot;Finished!&quot;) saver.save(sess, save_dir + &quot;CharRnn.cpkt&quot;, global_step=step) print(&quot;Elapsed time: &quot;, str_time(time.time() - start_time)) # 测试模型 while True: prompt = &quot;请输入%s个字: &quot; % n_input sentence = input(prompt) input_word = sentence.strip() if len(input_word) != n_input: print(&quot;您输入的字符长度为：&quot;, len(input_word), &quot;请输入4个字&quot;) continue try: input_word = char_vector(None, words_num_map, input_word) for i in range(100): keys = np.reshape(np.array(input_word), [-1, n_input, 1]) onehot_pred = sess.run(predicted, feed_dict=&#123;x: keys&#125;) onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval()) sentence = &quot;%s%s&quot; % (sentence, words[onehot_pred_index]) input_word = input_word[1:] input_word.append(onehot_pred_index) print(sentence) except: print(&quot;该字我还没学会&quot;)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循环神经网络RNN-写诗]]></title>
    <url>%2F2019%2F01%2F13%2F%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN-%E5%86%99%E8%AF%97%2F</url>
    <content type="text"><![CDATA[数据下载下载地址：https://pan.baidu.com/s/19fAqY0_ajkTiKfOBbpY_Sg 训练数据预处理import collectionsimport numpy as npimport tensorflow as tfpoetry_file = &apos;data/poetry.txt&apos;# 数据清洗，生成诗集poetrys = []with open(poetry_file, &quot;r&quot;, encoding=&apos;utf-8&apos;) as f: for line in f: try: line = line.strip(u&apos;\n&apos;) #strip() 方法用于移除字符串头尾指定的字符 title, content = line.strip(u&apos; &apos;).split(u&apos;:&apos;) content = content.replace(u&apos; &apos;, u&apos;&apos;) if u&apos;_&apos; in content or u&apos;(&apos; in content or u&apos;（&apos; in content or u&apos;《&apos; in content or u&apos;[&apos; in content: continue if len(content) &lt; 5 or len(content) &gt; 79: continue content = u&apos;[&apos; + content + u&apos;]&apos; poetrys.append(content) except Exception as e: pass# print(poetrys[0])# 按诗的字数排序poetrys = sorted(poetrys, key=lambda lines: len(lines))print(&apos;唐诗总数: &apos;, len(poetrys))# 统计每个字出现次数all_words = []for poetry in poetrys: all_words += [word for word in poetry]counter = collections.Counter(all_words) #Counter是一个无序的容器类型，以字典的键值对形式存储，其中元素作为key，其计数作为value。count_pairs = sorted(counter.items(), key=lambda x: -x[1])words, _ = zip(*count_pairs)# 取前多少个常用字words = words[:len(words)] + (&apos; &apos;,)# 每个字映射为一个数字IDword_num_map = dict(zip(words, range(len(words))))# 把诗转换为向量形式.trans_to_num = lambda word: word_num_map.get(word, len(words))poetrys_vector = [list(map(trans_to_num, poetry)) for poetry in poetrys]class DataSet(object): def __init__(self, data_size): self._data_size = data_size self._epochs_completed = 0 self._index_in_epoch = 0 self._data_index = np.arange(data_size) def next_batch(self, batch_size): start = self._index_in_epoch if start + batch_size &gt; self._data_size: np.random.shuffle(self._data_index) self._epochs_completed = self._epochs_completed + 1 self._index_in_epoch = batch_size full_batch_features, full_batch_labels = self.data_batch(0, batch_size) return full_batch_features, full_batch_labels else: self._index_in_epoch += batch_size end = self._index_in_epoch full_batch_features, full_batch_labels = self.data_batch(start, end) if self._index_in_epoch == self._data_size: self._index_in_epoch = 0 self._epochs_completed = self._epochs_completed + 1 np.random.shuffle(self._data_index) return full_batch_features, full_batch_labels def data_batch(self, start, end): batches = [] for i in range(start, end): batches.append(poetrys_vector[self._data_index[i]]) length = max(map(len, batches)) xdata = np.full((end - start, length), word_num_map[&apos; &apos;], np.int32) for row in range(end - start): xdata[row, :len(batches[row])] = batches[row] ydata = np.copy(xdata) ydata[:, :-1] = xdata[:, 1:] return xdata, ydata 构建RNN网络计算图# 每次取64首诗进行训练batch_size = 64n_chunk = len(poetrys_vector) // batch_sizeinput_data = tf.placeholder(tf.int32, [batch_size, None])output_targets = tf.placeholder(tf.int32, [batch_size, None])# 定义RNNdef neural_network(model=&apos;lstm&apos;, rnn_size=128, num_layers=2): global cell_fun if model == &apos;rnn&apos;: cell_fun = tf.nn.rnn_cell.BasicRNNCell elif model == &apos;gru&apos;: cell_fun = tf.nn.rnn_cell.GRUCell elif model == &apos;lstm&apos;: cell_fun = tf.nn.rnn_cell.BasicLSTMCell cell = cell_fun(rnn_size, state_is_tuple=True) cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True) initial_state = cell.zero_state(batch_size, tf.float32) with tf.variable_scope(&apos;rnnlm&apos;): softmax_w = tf.get_variable(&quot;softmax_w&quot;, [rnn_size, len(words)]) softmax_b = tf.get_variable(&quot;softmax_b&quot;, [len(words)]) with tf.device(&quot;/cpu:0&quot;): embedding = tf.get_variable(&quot;embedding&quot;, [len(words), rnn_size]) inputs = tf.nn.embedding_lookup(embedding, input_data) outputs, last_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, scope=&apos;rnnlm&apos;) output = tf.reshape(outputs, [-1, rnn_size]) logits = tf.matmul(output, softmax_w) + softmax_b probs = tf.nn.softmax(logits) return logits, last_state, probs, cell, initial_state 训练模型def load_model(sess, saver, ckpt_path): latest_ckpt = tf.train.latest_checkpoint(ckpt_path) if latest_ckpt: print(&apos;resume from&apos;, latest_ckpt) saver.restore(sess, latest_ckpt) return int(latest_ckpt[latest_ckpt.rindex(&apos;-&apos;) + 1:]) else: print(&apos;building model from Training....&apos;) sess.run(tf.global_variables_initializer()) return -1# 训练def train_neural_network(): logits, last_state, _, _, _ = neural_network() targets = tf.reshape(output_targets, [-1]) loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [targets], [tf.ones_like(targets, dtype=tf.float32)], len(words))##这个函数用于计算所有examples（假设一句话有n个单词，一个单词及单词所对应的label就是一个example,所有example就是一句话中所有单词）的加权交叉熵损失 cost = tf.reduce_mean(loss) tf.summary.scalar(&apos;loss&apos;, tf.reshape(cost, []))##画损失图 learning_rate = tf.Variable(0.0, trainable=False) tvars = tf.trainable_variables()##返回的是需要训练的变量列表 grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), 5)##tf.gradients：计算梯度；tf.clip_by_global_norm（t_list 是梯度张量， clip_norm 是截取的比率）让权重的更新限制在一个合适的范围 optimizer = tf.train.AdamOptimizer(learning_rate) train_op = optimizer.apply_gradients(zip(grads, tvars)) Session_config = tf.ConfigProto(allow_soft_placement=True) Session_config.gpu_options.allow_growth = True trainds = DataSet(len(poetrys_vector)) with tf.Session(config=Session_config) as sess: merged = tf.summary.merge_all()##tensorflow的可视化是使用summary和tensorboard合作完成的.###########tf.summary.merge_all: 将之前定义的所有summary op整合到一起 log_writer = tf.summary.FileWriter(&quot;logs&quot;, sess.graph) sess.run(tf.initialize_all_variables()) saver = tf.train.Saver(tf.all_variables()) last_epoch = load_model(sess, saver, &apos;model/&apos;) for epoch in range(last_epoch + 1, 1000): sess.run(tf.assign(learning_rate, 0.002 * (0.97 ** epoch))) #tf.assign(A, new_number): 这个函数的功能主要是把A的值变为new_number all_loss = 0.0 for batche in range(n_chunk): x, y = trainds.next_batch(batch_size) train_loss, _, _, merged_summary = sess.run([cost, last_state, train_op, merged], feed_dict=&#123;input_data: x, output_targets: y&#125;) all_loss = all_loss + train_loss if batche % 50 == 1: log_writer.add_summary(merged_summary, batche) print(&quot;epoch:&#123;&#125; \n&quot;.format(epoch), &quot;batch:&#123;&#125; \n&quot;.format(batche), &quot;Learning_rate:&#123;&#125; \n&quot;.format(0.002 * (0.97 ** epoch)), &quot;train_loss:&#123;&#125; \n&quot;.format(train_loss)) print(epoch, &apos; Loss: &apos;, all_loss * 1.0 / n_chunk) saver.save(sess, &apos;model/poetry.module-%d&apos; % epoch) log_writer.close()train_neural_network() 生成古诗数据预处理import collectionsimport numpy as npimport tensorflow as tfpoetry_file = &apos;data/poetry.txt&apos;# 诗集poetrys = []with open(poetry_file, &quot;r&quot;, encoding=&apos;utf-8&apos;) as f: for line in f: try: line = line.strip(u&apos;\n&apos;) title, content = line.strip(u&apos; &apos;).split(u&apos;:&apos;) content = content.replace(u&apos; &apos;, u&apos;&apos;) if u&apos;_&apos; in content or u&apos;(&apos; in content or u&apos;（&apos; in content or u&apos;《&apos; in content or u&apos;[&apos; in content: continue if len(content) &lt; 5 or len(content) &gt; 79: continue content = u&apos;[&apos; + content + u&apos;]&apos; poetrys.append(content) except Exception as e: pass # 按诗的字数排序poetrys = sorted(poetrys, key=lambda line: len(line))print(&apos;唐诗总数: &apos;, len(poetrys))# 统计每个字出现次数all_words = []for poetry in poetrys: all_words += [word for word in poetry]counter = collections.Counter(all_words)count_pairs = sorted(counter.items(), key=lambda x: -x[1])words, _ = zip(*count_pairs)# 取前多少个常用字words = words[:len(words)] + (&apos; &apos;,)# 每个字映射为一个数字IDword_num_map = dict(zip(words, range(len(words))))# 把诗转换为向量形式to_num = lambda word: word_num_map.get(word, len(words))poetrys_vector = [list(map(to_num, poetry)) for poetry in poetrys]# 每次取64首诗进行训练batch_size = 1n_chunk = len(poetrys_vector) // batch_size# ---------------------------------------RNN--------------------------------------#input_data = tf.placeholder(tf.int32, [batch_size, None])output_targets = tf.placeholder(tf.int32, [batch_size, None])# 定义RNNdef neural_network(model=&apos;lstm&apos;, rnn_size=128, num_layers=2): global cell_fun if model == &apos;rnn&apos;: cell_fun = tf.nn.rnn_cell.BasicRNNCell elif model == &apos;gru&apos;: cell_fun = tf.nn.rnn_cell.GRUCell elif model == &apos;lstm&apos;: cell_fun = tf.nn.rnn_cell.BasicLSTMCell cell = cell_fun(rnn_size, state_is_tuple=True) cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True) initial_state = cell.zero_state(batch_size, tf.float32) with tf.variable_scope(&apos;rnnlm&apos;): softmax_w = tf.get_variable(&quot;softmax_w&quot;, [rnn_size, len(words)]) softmax_b = tf.get_variable(&quot;softmax_b&quot;, [len(words)]) with tf.device(&quot;/cpu:0&quot;): embedding = tf.get_variable(&quot;embedding&quot;, [len(words), rnn_size]) inputs = tf.nn.embedding_lookup(embedding, input_data) outputs, last_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state, scope=&apos;rnnlm&apos;) output = tf.reshape(outputs, [-1, rnn_size]) logits = tf.matmul(output, softmax_w) + softmax_b probs = tf.nn.softmax(logits) return logits, last_state, probs, cell, initial_state 用训练完成的模型生成古诗def gen_head_poetry(heads, type): if type != 5 and type != 7: print(&apos;The second para has to be 5 or 7!&apos;) return def to_word(weights): t = np.cumsum(weights)#a = np.array([[1,2,3], [4,5,6]])### np.cumsum(a)###array([ 1, 3, 6, 10, 15, 21])####array([1，1+2=3，1+2+3=6，1+2+3+4=10，1+2+3+4+5=15，1+2+3+4+5+6=21]） s = np.sum(weights) sample = int(np.searchsorted(t, np.random.rand(1) * s))##np.random.rand(3,2)##括号中为shape##np.searchsorted:寻找某个数应该插在数组的什么位置上，这个数组必须是按序排列的 return words[sample] _, last_state, probs, cell, initial_state = neural_network() Session_config = tf.ConfigProto(allow_soft_placement=True) Session_config.gpu_options.allow_growth = True with tf.Session(config=Session_config) as sess: with tf.device(&apos;/gpu:1&apos;): sess.run(tf.initialize_all_variables()) saver = tf.train.Saver(tf.all_variables()) saver.restore(sess, &apos;model/poetry.module-99&apos;) poem = &apos;&apos; for head in heads: flag = True while flag: state_ = sess.run(cell.zero_state(1, tf.float32)) x = np.array([list(map(word_num_map.get, u&apos;[&apos;))]) [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) sentence = head x = np.zeros((1, 1)) x[0, 0] = word_num_map[sentence] [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) sentence += word while word != u&apos;。&apos;: x = np.zeros((1, 1)) x[0, 0] = word_num_map[word] [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) sentence += word if len(sentence) == 2 + 2 * type: sentence += u&apos;\n&apos; poem += sentence flag = False return poemdef gen_poetry(): def to_word(weights): t = np.cumsum(weights) s = np.sum(weights) sample = int(np.searchsorted(t, np.random.rand(1) * s)) return words[sample] _, last_state, probs, cell, initial_state = neural_network() with tf.Session() as sess: sess.run(tf.initialize_all_variables()) saver = tf.train.Saver(tf.all_variables()) saver.restore(sess, &apos;model/poetry.module-99&apos;) state_ = sess.run(cell.zero_state(1, tf.float32)) x = np.array([list(map(word_num_map.get, &apos;[&apos;))]) [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) poem = &apos;&apos; while word != &apos;[&apos;: poem += word x = np.zeros((1, 1)) x[0, 0] = word_num_map[word] [probs_, state_] = sess.run([probs, last_state], feed_dict=&#123;input_data: x, initial_state: state_&#125;) word = to_word(probs_) return poem#print(gen_poetry())print(gen_head_poetry(u&apos;言叶之庭&apos;, 5))]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow-基础语法]]></title>
    <url>%2F2019%2F01%2F12%2Ftensorflow-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[数学公式API：https://github.com/tensorflow/docs/blob/master/site/en/api_guides/python constanta = tf.constant(0, name=&apos;B&apos;)b = tf.constant(1) 常量x = tf.zeros([2, 3], tf.int32)y = tf.zeros_like(x, optimize=True) 变量with tf.variable_scope(&apos;meh&apos;) as scope: a = tf.get_variable(&apos;a&apos;, [10]) b = tf.get_variable(&apos;b&apos;, [100])writer = tf.summary.FileWriter(&apos;./graphs/test&apos;, tf.get_default_graph())writer.close() placeholdder占位符input1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)output = tf.multiply(input1, input2)with tf.Session() as sess: print(sess.run([output], feed_dict=&#123;input1:[7.], input2:[2.]&#125;)) 类型转换tf.cast(tf.constant(2.0), tf.int32) 把numpy转换成Tensorimport numpy as npa = np.zeros((3,3))print(a)print(&apos;----------------&apos;)ta = tf.convert_to_tensor(a)with tf.Session() as sess: print(sess.run(ta))]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow-可视化]]></title>
    <url>%2F2019%2F01%2F12%2Ftensorflow-%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[导入包import numpy as npimport osimport tensorflow as tfimport matplotlib.pyplot as plt 设置生成的图像尺寸和去除警告os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos;plt.rcParams[&quot;figure.figsize&quot;] = (14, 8) # 生成的图像尺寸 随机生成一个线性的数据n_observations = 100xs = np.linspace(-3, 3, n_observations) #生成-3到3的n为100等差数列ys = 0.8*xs + 0.1 + np.random.uniform(-0.5, 0.5, n_observations)plt.scatter(xs, ys) #画图plt.show() #画图 准备placeholderX = tf.placeholder(tf.float32, name=&apos;X&apos;)Y = tf.placeholder(tf.float32, name=&apos;Y&apos;) 初始化参数/权重W = tf.Variable(tf.random_normal([1]), name=&apos;weight&apos;)tf.summary.histogram(&apos;weight&apos;, W) #画图b = tf.Variable(tf.random_normal([1]), name=&apos;bias&apos;)tf.summary.histogram(&apos;bias&apos;, b)#画图 计算预测结果Y_pred = tf.add(tf.multiply(X, W), b) 计算损失值loss = tf.square(Y - Y_pred, name=&apos;loss&apos;) #tf.square:平方tf.summary.scalar(&apos;loss&apos;, tf.reshape(loss, []))#画图 初始化optimizerlearning_rate = 0.01optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss) 指定迭代次数，并在session里执行graphn_samples = xs.shape[0]init = tf.global_variables_initializer()with tf.Session() as sess: # 记得初始化所有变量 sess.run(init) merged = tf.summary.merge_all()#画图 log_writer = tf.summary.FileWriter(&quot;./logs/linear_regression&quot;, sess.graph) # 训练模型 for i in range(50): total_loss = 0 for x, y in zip(xs, ys): # 通过feed_dic把数据灌进去 _, loss_value, merged_summary = sess.run([optimizer, loss, merged], feed_dict=&#123;X: x, Y: y&#125;) total_loss += loss_value if i % 5 == 0: print(&apos;Epoch &#123;0&#125;: &#123;1&#125;&apos;.format(i, total_loss / n_samples)) log_writer.add_summary(merged_summary, i)#画图 # 关闭writer log_writer.close()#画图 # 取出w和b的值 W, b = sess.run([W, b])print(W, b)print(&quot;W:&quot;+str(W[0]))print(&quot;b:&quot;+str(b[0])) 画出线性回归线plt.plot(xs, ys, &apos;bo&apos;, label=&apos;Real data&apos;)plt.plot(xs, xs * W + b, &apos;r&apos;, label=&apos;Predicted data&apos;)plt.legend()plt.show() Tensorboard查看图形数据tensorboard --logdir path/to/logs(你保存文件所在位置) 如：（log_writer = tf.summary.FileWriter(“./logs/linear_regression”, sess.graph)保存的地址）： tensorboard —logdir ./logs/linear_regression 输出：TensorBoard x.x.x at http://(你的用户名):6006 (Press CTRL+C to quit) 然后打开网页：http://localhost:6006]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20单元语法]]></title>
    <url>%2F2019%2F01%2F11%2F20%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[N + なら（ば）＜凸显、条件＞用法一接在体言后面，凸显、强调所指事物，作提示助词，提出主题，并用自信、有把握的语气进行叙述，如果以此为主题的话。接续：N+ ✿汉语：就~方面来说、~的话 1、お金なら心配は要りません。2、花なら桜です。 用法2以假设的形式提出话题，前项为前提，后项为说话人判断、决定或建议；接续： N ・ A ・ V ・ Na 直接裸接 なら ✿汉语：要是~的话~1、私ならそんなことを言いませんよ。2、海が静かならいいですが。3、彼が出席するなら、私は行きません。 ～場合は＜假设＞表示假设的情况。当假设出现了前项情况时，后项一般为针对此情况所采取的方法或对策。接续：N ・ A ・ V ・ Na 连体形+場合は ✿汉语：当~时、在~的情况下 1、王さんの都合が悪い場合は、ほかの日にしましょう。2、電話が通じない場合はどうしたらいいですか。3、雨が降った場合は、運動会を中止します。 Vたらどうですか＜建议＞表示建议或劝诱的惯用表达， ✿汉语：~怎么样、~如何★：礼貌表达方式为：~たらどうですか。 ~たらいかがですか。 ~たらいかがでしょうか1、ABC病院に行ってみたらどうでしょう。(2011年真题)2、朝からずっと勉強していますね。少し休んだらどうですか。3、ネクタイでも買ってあげたらどう？(2010年真题) くらい＜程度＞接在分句后面表示程度。举出具体的事例来说明其程度。也可写做ぐらい。基本可与「ほど」互换。接续：裸接分句后 1、怖くて怖くて、大声で叫びたいくらいだった。(2009年真题)2、涙が出るくらい痛いです。 「ほど」VS「くらい」在表示某种程度时: 如果说话人心目中对其程度没有进行高低取向时，くらい和ほど有时可以互换使用，表示相同的意思。 1、日曜は足が痛くなる**ぐらい**（〇ほど）歩いた。 如果有高低取向，则くらい表示低，而ほど表示高， 1、彼**くらい**（Ｘほど）のレベルでは通訳はできない。2、党の御恩は山**ほど**（Ｘくらい）高く、海**ほど**（Ｘくらい）深い。3、死ぬ**ほど**（×くらい）疲れた。 Vてくださいませんか＜客气的请求＞表示请求别人做某事。比｢Vてくれませんか｣更加委婉、客气，是一种尊他，客气的表达。 ✿ 汉语：能不能请您（为我做)～ １、先生のお写真を見せてくださいませんか。２、もう少し説明してくださいませんか。 VてしまったVてしまった＜感慨＞表示说话人对意外发生的事（无法挽回的事情、消极的结果等）感到很遗憾、后悔的语气。常与副词「もう」搭配１、バスで財布を落としてしまった。２、急いで来たから、財布を忘れてしまった。(2005年真题) Vてしまった＜完了＞表示动作过程的完了。用于表示持续动作的动词时，与｢V第一连用－おわる｣意思相近。１、この宿題をしてしまったら、遊びに行ける。２、この本はもう読んでしまったから、図書館に返します。 N+の＋うち＜范围＞表示限定范围。 ✿ 汉语：~当中、~之中★在表示从某范围中挑选某事物时，可与｢Ｎのなか｣替换。１、三人のうち、林さんが一番若いです。２、クラスメートのうち、6人が男性です。３、相撲とサッカーと野球のうちで、一番人気があるのはやはり野球だそうだ。 N1 または N2＜选择＞表示两者择一，多用于书面语，表示要求、指示等场合。 ✿ 汉语：~或是~1、3番の部屋、または4番の部屋に行ってください。(2008年真题)2、漢字または仮名で書いてください。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19单元语法]]></title>
    <url>%2F2019%2F01%2F11%2F19%E5%8D%95%E5%85%83%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Nとは～という意味だ汉语：~是~的意思★口语：Ｎというのは、～✿帰省とは故郷に帰るという意味です。✿下水とは台所などで使った汚れた水のことである。✿進入禁止とは入ってはいけないという意味です。 ~うちに＜时段＞前接表示状态的词，表示在该 状态持续期间 内，发生了某件事或做某件事（有尽快进行该动作的语感）。接续： ✿ N + の + うちに ✿ Na + な + うちに ✿ A - い + うちに ✿ V - る / V-ている V-ない + うちに 汉语 ：趁着~、~时候、在~之内✿どうぞ、温かいうちに食べてください。（2008年真题）✿父が元気なうちに、一度一緒に温泉に行きたいと思います。 V-（よ）うか＜犹豫＞用于简体的会话。 自言自语 或是 与对方商量 的语气。表示说话人对是否要做某动作而 犹豫不决、踌躇不定 的心情。接续：动词意志形+か✿もう時間だから、行こうか。✿結果はどうなるかわからないけど、やってみようか。✿いくら考えてもわからないから、しばらく休んで、後にしようか。 ても・でも＜让步＞表示让步的条件。就算前项从句成立，后项主句的结果也不会改变。（同19课2单元）接续： ✿N・Na + でも ✿A-く + ても ✿V-て + ても汉语：即使~也~、就算~都~ ✿あの美術館はいつ行っても人がたくさんいる。(2007年真题)✿学校を卒業しても、日本語の勉強を続けていくつもりだ。 (2005年真题)✿今必要だから、高くても買う。✿先生でもわからないかもしれません V-ると～た＜契机＞表示说话人在 前面的事情成立 的情况下，重新认识后项事物，是一些 新的发现、认识 等，具有意外性。或以此为契机 发生了后项的事物 。 ✿五月に入ると、急に暑くなった。✿外に出ると、雨が降っていた。✿友達が怪我で入院したと聞き、慌てて病院に行ってみると思っていたより元気で安心した。 「～たら～た」 VS 「～と～た」相同点：表示“以~为契机发现了~”这一用法时，两者一般可以替换使用。 不同点：1、“と”常用于小说或故事等，而“たら”则多用于说话人表述自己直接的经历。 2、当前后两个句子表示为 同一人物的意志可控制 的连续动词时，只可以用“と”。✿男は部屋に入ると、友達に電話した。 3、当表示 说话人身体的感觉 时，只可以用“たら”，不能用“と”。✿昨夜、この薬を飲んだら、よく効いた。 でも＜极端的情况＞助词でも除了表示“示例”以外，更多的是接在名词（或者部分副词、助词）后，用于举出极端的事例。 中文：“就连~都~”“即使~也~”“尽管~也~”✿この店は日本料理が本格的ですが。日本人でもこの味に満足している。 ✿先生でもわからないかもしれない。✿この仕事は病気でも休めません✿今度の日曜日、雨でもサッカーの試合を行います。 ～し～(し)＜并列＞连接两个或两个以上的分句，列举。多用罗列于原因理由接续：分句+し翻译：“既~又~”“又~又~”✿お金もないし、時間もないから、遊びに行けない。(2008年真题)✿アパートは綺麗だし、広いし、駅からも近い。(2005年真题) ～Ｖばいい・よい&lt;建议＞常用在表示提议时。汉语：只要~就可、~就好 ✿ A:どうすればいいですか。 B:ちゃんと謝ればいいですよ。✿ お金がなければ、お父さんに借りればいいでしょう。 のに＜转折＞ ✿ V-る・V-た +のに ✿ A-い・A-かった +のに ✿ N・Na な+のに 位于句中起逆接作用，是接续助词。连接起来的句子往往都有意外、不满、埋怨等语感汉语：可是~、却~✿雨が降っているのに、傘を持たないで出かけた。✿知っているのに知らないと言った。 置于句末是终助词，表示事与愿违时的遗憾、惋惜、后悔等心情，一般多用口语。可以跟在｢ばいい｣后面。✿この部屋がもう少し広げればいいのに。✿注意していたのに。 たら＜条件＞表示 假设，属于动词的另一种条件形。接续上和动词的过去式｢た｣是一样的。表 一次性的，特定 的依存关系。表示主句的实现，建立在从句动作或变化完成的基础上。汉语： ~之后就~ ~以后~✿仕事が終わったら、お茶でも飲みにいきましょう。✿そんなにたくさん食べたら、おなかを壊しますよ。✿大学を卒業したらどんな仕事をしますか。 V-て/V-ないで&lt;伴随状态&gt;表示（没有）在前项的伴随状态下进行后项主体动作。 ✿マスクをして出かけました。✿ネクタイを締めないで会社に行きます。 V-て（は）いられない&lt;状态难以持续&gt;表示因为在紧迫的情况下，不能继续那种状态而要急于想付诸另一种行动之意。汉语：不能~，哪能~ ✿もう時間がないから、遅れてくる人を待っていられない。すぐ始めよう。✿こんなに忙しいときに、寝ていられないよ。 Nによって&lt;原因&gt;表示“那就是原因”之意，后续表示结果的词句。讲述已经发生的事情，谓语一般为过去式，多用于书面语。 ✿私の不注意な発言によって、彼を傷つけた。✿交通事故によって、電車は三時間も遅れた。 N として（は・も・の）&lt;资格性质&gt;表示动作主体进行某动作时的身份、资格、立场、性质等。汉语：作为~、以~身份、以~立场、以~资格 ✿通訳として、一緒に行く。(2011年真题)✿私としては賛成ですが、ほかの人の意見も聞いてみないと決められない。✿彼女は母としても妻としても完璧な素晴らしい女性です。✿私には私としての考えがあります。 と总结 必然结果，自然现象 ✿春になると、花が咲く✿雨だと明日の試合は中止になります。✿右に曲がると、大きな建物が見える。 契机，发现（ｖたら～た也有该用法） ✿デパートに行くと、休みだった。✿うちへ帰ると、友達が待っていた。 习惯动作 ✿起きると、すぐ顔を洗う✿彼は家に帰ると、パソコンに向かっています。 ば总结 必然结果，自然现象（と～也有该用法） ✿春になれば、花が咲く。 假定条件 ✿このごろ日本へ行けば、桜が見える。 ★注意：1、当假定式为动作或者变化时，后项不能使用ください、たい、ましょう雨が降れば、窓を閉めてください。× 2、当假定式为状态或存在时，后项可以使用ください、たい暑ければ、エアコンをつけてください。〇 3、主句一般不能使用过去式窓を開けば、富士山が見えた。× たら总结 假定（ば也有该用法） ✿安かったら、買う✿困ったら、電話してね。 契机，发现（と也有该用法） ✿窓を開けたら、海が見えた。 在～之后 ✿本を読んだら貸してください。✿大阪に着いたら電話してください。 ★注意：1、たら含有明显的完成之意，特别是前后都是动词时，一定是前项先发生，后项再发生。2、たら后项可使用命令、劝诱、依赖等表达。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wine安装qq]]></title>
    <url>%2F2019%2F01%2F11%2Fwine%E5%AE%89%E8%A3%85qq%2F</url>
    <content type="text"><![CDATA[安装wine下载地址： https://github.com/wszqkzqk/deepin-wine-ubuntu解压后安装：sudo sh ./install.sh 安装QQ、微信wine应用下载地址： http://mirrors.aliyun.com/deepin/pool/non-free/d/常用下载应用：QQ： http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.qq.im/微信： http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.wechat/Foxmail: http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin.com.foxmail/ 异常说明微信无法发送图片：sudo apt install libjpeg62:i386 卸载：sudo apt remove 软件包名 比如deepin.com.qq.office_2.0.0deepin4_i386.deb的卸载命令：sudo apt remove deepin.com.qq.office 托盘图标安装icons-plus扩展sudo apt-get install gnome-shell-extension-top-icons-plus gnome-tweaks 然后在gnome-tweaks里设置]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>qq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-图片处理及绘图]]></title>
    <url>%2F2019%2F01%2F11%2Fopencv-%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E5%8F%8A%E7%BB%98%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[原始图片： 彩色图片灰度化方式1：import cv2 # 导入cv库img = cv2.imread(&apos;image2.jpg&apos;,0)cv2.imwrite(&apos;gray_image.jpg&apos;,img) 方式2：import cv2img = cv2.imread(&apos;image2.jpg&apos;,1)dst = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)# 颜色空间转换 1 data 2 BGR graycv2.imshow(&apos;dst&apos;,dst) 方式3#方法4 gray = r*0.299+g*0.587+b*0.114import cv2import numpy as npimg = cv2.imread(&apos;image0.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]dst = np.zeros((height,width,3),np.uint8)for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = int(b) g = int(g) r = int(r) gray = r*0.299+g*0.587+b*0.114 dst[i,j] = np.uint8(gray)cv2.imshow(&apos;dst&apos;,dst) 马赛克import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]for m in range(200,400): for n in range(400,500): # pixel -&gt;10*10 if m%10 == 0 and n%10==0: for i in range(0,10): for j in range(0,10): (b,g,r) = img[m,n] img[i+m,j+n] = (b,g,r)cv2.imwrite(&apos;msk.jpg&apos;,img) 边缘检测方式1：import cv2import numpy as npimport randomimg = cv2.imread(&apos;image2.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]#cv2.imshow(&apos;src&apos;,img)#canny 1 gray 2 高斯 3 cannygray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)imgG = cv2.GaussianBlur(gray,(3,3),0)dst = cv2.Canny(img,50,50) #图片卷积——》th#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;canny.jpg&apos;,dst) 方式2：import cv2import numpy as npimport randomimport mathimg = cv2.imread(&apos;image2.jpg&apos;, 1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]#cv2.imshow(&apos;src&apos;, img)# sobel 1 算子模版 2 图片卷积 3 阈值判决# [1 2 1 [ 1 0 -1# 0 0 0 2 0 -2# -1 -2 -1 ] 1 0 -1 ]# [1 2 3 4] [a b c d] a*1+b*2+c*3+d*4 = dst# sqrt(a*a+b*b) = f&gt;thgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)dst = np.zeros((height, width, 1), np.uint8)for i in range(0, height - 2): for j in range(0, width - 2): gy = gray[i, j] * 1 + gray[i, j + 1] * 2 + gray[i, j + 2] * 1 - gray[i + 2, j] * 1 - gray[i + 2, j + 1] * 2 - \ gray[i + 2, j + 2] * 1 gx = gray[i, j] + gray[i + 1, j] * 2 + gray[i + 2, j] - gray[i, j + 2] - gray[i + 1, j + 2] * 2 - gray[ i + 2, j + 2] grad = math.sqrt(gx * gx + gy * gy) if grad &gt; 50: dst[i, j] = 255 else: dst[i, j] = 0cv2.imwrite(&apos;sobel.jpg&apos;,dst) 颜色风格变化import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]#rgb -》RGB new “蓝色”# b=b*1.5# g = g*1.3dst = np.zeros((height,width,3),np.uint8)for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] b = b*1.5 g = g*1.3 if b&gt;255: b = 255 if g&gt;255: g = 255 dst[i,j]=(b,g,r)#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;dst2.jpg&apos;,dst) 油画特效import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)dst = np.zeros((height,width,3),np.uint8)for i in range(4,height-4): for j in range(4,width-4): array1 = np.zeros(8,np.uint8) for m in range(-4,4): for n in range(-4,4): p1 = int(gray[i+m,j+n]/32) array1[p1] = array1[p1]+1 currentMax = array1[0] l = 0 for k in range(0,8): if currentMax&lt;array1[k]: currentMax = array1[k] l = k # 简化 均值 for m in range(-4,4): for n in range(-4,4): if gray[i+m,j+n]&gt;=(l*32) and gray[i+m,j+n]&lt;=((l+1)*32): (b,g,r) = img[i+m,j+n] dst[i,j] = (b,g,r)cv2.imwrite(&apos;dst3.jpg&apos;,dst) 线段绘制import cv2import numpy as npnewImageInfo = (500,500,3)dst = np.zeros(newImageInfo,np.uint8)# line# 绘制线段 1 dst 2 begin 3 end 4 colorcv2.line(dst,(100,100),(400,400),(0,0,255))# 5 line wcv2.line(dst,(100,200),(400,200),(0,255,255),20)# 6 line typecv2.line(dst,(100,300),(400,300),(0,255,0),20,cv2.LINE_AA)cv2.imwrite(&apos;line.jpg&apos;,dst) 绘制矩形、圆形import cv2import numpy as npnewImageInfo = (500,500,3)dst = np.zeros(newImageInfo,np.uint8)# 1 2 左上角 3 右下角 4 5 fill -1 &gt;0 line wcv2.rectangle(dst,(50,100),(200,300),(255,0,0),5)# 2 center 3 rcv2.circle(dst,(300,100),(50),(0,255,0),2)# 2 center 3 轴(a,b) 4 angle 5 begin 6 end 7cv2.ellipse(dst,(256,350),(150,100),30,0,360,(255,255,0),-1)points = np.array([[350,50],[140,140],[200,170],[250,250],[350,50]],np.int32)print(points.shape)points = points.reshape((-1,1,2))print(points.shape)cv2.polylines(dst,[points],True,(0,0,255))cv2.imwrite(&apos;dst4.jpg&apos;,dst) 添加文字import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)font = cv2.FONT_HERSHEY_SIMPLEXcv2.rectangle(img,(400,300),(950,900),(0,255,0),3)# 1 dst 2 文字内容 3 坐标 4 5 字体大小 6 color 7 粗细 8 line typecv2.putText(img,&apos;this is flower&apos;,(500,500),font,2,(200,100,255),3,cv2.LINE_AA)cv2.imwrite(&apos;word.jpg&apos;,img)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-图片几何变换]]></title>
    <url>%2F2019%2F01%2F11%2Fopencv-%E5%9B%BE%E7%89%87%E5%87%A0%E4%BD%95%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[原始图片： 图片缩放一import cv2 # 导入cv库img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色imgInfo = img.shape # 获取图片的维度print(imgInfo)height = imgInfo[0] width = imgInfo[1]mode = imgInfo[2]# 1 放大 缩小 2 等比例 非 2:3 dstHeight = int(height*0.5)dstWidth = int(width*0.5)#最近临域插值 双线性插值 像素关系重采样 立方插值dst = cv2.resize(img,(dstWidth,dstHeight))#cv2.imshow(&apos;image&apos;,dst)cv2.imwrite(&apos;resize_image.jpg&apos;,dst) 图片缩放二import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色#cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]matScale = np.float32([[0.5,0,0],[0,0.5,0]]) # 定义缩放矩阵dst = cv2.warpAffine(img,matScale,(int(width/2),int(height/2))) # 原始数据，缩放矩阵，目标的宽高信息cv2.imwrite(&apos;warp_image.jpg&apos;,dst) 图片剪切import cv2 # 导入cv库img = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色#imgInfo = img.shapeprint(img.shape)dst = img[100:600,250:800] # 获取宽度100-600， 高度250-800的图像cv2.imwrite(&apos;cut_image.jpg&apos;,dst) 图片镜像import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]deep = imgInfo[2]newImgInfo = (height*2,width,deep) # 新图片的维度dst = np.zeros(newImgInfo,np.uint8)#uint8 # 目标图片的数据维度# 刷新图片的数据for i in range(0,height): for j in range(0,width): dst[i,j] = img[i,j] #x y = 2*h - y -1 dst[height*2-i-1,j] = img[i,j]for i in range(0,width): # 添加分割线 dst[height,i] = (0,0,255)#BGRcv2.imshow(&apos;dst&apos;,dst) 图片旋转import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]# 2*3 定义旋转矩阵--旋转的中心点，旋转的角度， 缩放系数matRotate = cv2.getRotationMatrix2D((height*0.5,width*0.5),45,1)# mat rotate 1 center 2 angle 3 scale#100*100 25dst = cv2.warpAffine(img,matRotate,(height,width)) # 仿射方法#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;rotate_image.jpg&apos;,dst) 图片仿射变换import cv2 # 导入cv库import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;src&apos;,img)imgInfo = img.shape # 获取图片的维度height = imgInfo[0]width = imgInfo[1]#src 3-&gt;dst 3 (左上角 左下角 右上角)matSrc = np.float32([[0,0],[0,height-1],[width-1,0]]) # 获取原图片三个点坐标matDst = np.float32([[50,50],[300,height-200],[width-300,100]]) # 三个点的新坐标#把两个矩阵组合matAffine = cv2.getAffineTransform(matSrc,matDst) # 获取矩阵的组合，dst = cv2.warpAffine(img,matAffine,(width,height)) # 仿射变换方法#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;aft_image.jpg&apos;,dst)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown]]></title>
    <url>%2F2019%2F01%2F09%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[粗体、斜体*这是斜体***这是粗体*****这是粗体+斜体*** 删除线~~就像这样~~ 引用通过在行首加上大于号&gt;来添加引用格式。&gt; This is the first level of quoting.&gt;&gt; &gt; This is nested blockquote.&gt;&gt; Back to the first level. 列表无序列表使用星号、加号或是减号作为列表标记：* Red+ Green- Blue 分隔线* * *********- - ---------------------------------------- 链接[an example](http://example.com/)[an example](http://example.com/ &quot;Optional Title&quot;) 图像普通方式![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg &quot;Optional Title&quot;) 通过管理文件夹&#123;% asset_path slug %&#125;&#123;% asset_img slug [title] %&#125;&#123;% asset_link slug [title] %&#125; 通过图床引用&lt;figure class=&quot;half&quot;&gt; &lt;img src=&quot;http://address.com/images/image.png&quot; title=&quot;title1&quot;/&gt; &lt;img src=&quot;http://path/image.png&quot; title=&quot;title2&quot;/&gt;&lt;/figure&gt; 表格| Item | Value | Qty || :------- | ----: | :---: || Computer | $1600 | 5 || Phone | $12 | 12 || Pipe | $1 | 234 | TeX公式更换渲染器： $ npm uninstall hexo-renderer-marked --save$ npm install hexo-renderer-kramed --save 插入公式形式： $$\Gamma(z) = \int_0^\infty t^&#123;z-1&#125;e^&#123;-t&#125;dt\,.$$ 公式说明文档： https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference typora编辑器#for Linux# or run:# sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAEwget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add -# add Typora&apos;s repositorysudo add-apt-repository &apos;deb https://typora.io/linux ./&apos;sudo apt-get update# install typorasudo apt-get install typora]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv图像美化]]></title>
    <url>%2F2019%2F01%2F09%2Fopencv%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%8C%96%2F</url>
    <content type="text"><![CDATA[直方图均衡化-灰度import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # 图片灰度化cv2.imshow(&apos;gray&apos;,gray)cv2.imwrite(&apos;gray2.jpg&apos;,gray)hist = cv2.equalizeHist(gray) # api 完成直方图均衡化cv2.imshow(&apos;hist&apos;,hist)cv2.imwrite(&apos;hist2.jpg&apos;,hist)cv2.waitKey(0) 直方图均衡化-彩色import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)cv2.imshow(&apos;src&apos;,img)(b,g,r) = cv2.split(img) # 通道分解# 图片单通道处理bH = cv2.equalizeHist(b)gH = cv2.equalizeHist(g)rH = cv2.equalizeHist(r)result = cv2.merge((bH,gH,rH))# 通道合成cv2.imshow(&apos;dst&apos;,result)cv2.imwrite(&apos;dst2.jpg&apos;,result)cv2.waitKey(0) 直方图均衡化-YUVimport cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)imgYUV = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb) #cv2.imshow(&apos;src&apos;,img)channelYUV = cv2.split(imgYUV) # 图片分解channelYUV[0] = cv2.equalizeHist(channelYUV[0]) # 直方图均衡化channels = cv2.merge(channelYUV) # 合成result = cv2.cvtColor(channels,cv2.COLOR_YCrCb2BGR)cv2.imshow(&apos;result2&apos;,result)cv2.imwrite(&apos;result2.jpg&apos;,result)cv2.waitKey(0) 图片修补import cv2import numpy as np#制作一张损坏的图片img = cv2.imread(&apos;image2.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色for i in range(1,100): # 总共一百个像素点 img[500+i,500] = (255,255,255) # 写入标准的白色cv2.imwrite(&apos;damaged.jpg&apos;,img)#修补损坏的图片img = cv2.imread(&apos;damaged.jpg&apos;,1)cv2.imshow(&apos;src&apos;,img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]paint = np.zeros((height,width,1),np.uint8)# 描绘图片坏的数组；进行修补for i in range(500,600): paint[i,500] = 255cv2.imshow(&apos;paint&apos;,paint)#1 src 2 maskimgDst = cv2.inpaint(img,paint,3,cv2.INPAINT_TELEA)cv2.imshow(&apos;image&apos;,imgDst)cv2.imwrite(&apos;imgDst.jpg&apos;,imgDst)cv2.waitKey(0) 亮度增强import cv2import numpy as npimg = cv2.imread(&apos;image2.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]cv2.imshow(&apos;src&apos;,img)dst = np.zeros((height,width,3),np.uint8)for i in range(0,height): for j in range(0,width): (b,g,r) = img[i,j] bb = int(b)+40 gg = int(g)+40 rr = int(r)+40 if bb&gt;255: bb = 255 if gg&gt;255: gg = 255 if rr&gt;255: rr = 255 dst[i,j] = (bb,gg,rr)cv2.imshow(&apos;dst3&apos;,dst)cv2.imwrite(&apos;dst3.jpg&apos;,dst) 高斯滤波import cv2import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1)cv2.imshow(&apos;src&apos;,img)dst = cv2.GaussianBlur(img,(5,5),1.5)cv2.imwrite(&apos;dst4.jpg&apos;,dst)cv2.imshow(&apos;dst4&apos;,dst)cv2.waitKey(0) 均值滤波# 均值 6*6 1 。 * 【6*6】/36 = mean -》Pimport cv2import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;, 1)#cv2.imshow(&apos;src&apos;, img)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]dst = np.zeros((height, width, 3), np.uint8)for i in range(3, height - 3): for j in range(3, width - 3): sum_b = int(0) sum_g = int(0) sum_r = int(0) for m in range(-3, 3): # -3 -2 -1 0 1 2 for n in range(-3, 3): (b, g, r) = img[i + m, j + n] sum_b = sum_b + int(b) sum_g = sum_g + int(g) sum_r = sum_r + int(r) b = np.uint8(sum_b / 36) g = np.uint8(sum_g / 36) r = np.uint8(sum_r / 36) dst[i, j] = (b, g, r)cv2.imshow(&apos;dst5&apos;, dst)cv2.imwrite(&apos;dst5.jpg&apos;, dst) 中值滤波import cv2import numpy as npimg = cv2.imread(&apos;image1.jpg&apos;,1)imgInfo = img.shapeheight = imgInfo[0]width = imgInfo[1]img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)#cv2.imshow(&apos;src&apos;,img)cv2.imwrite(&apos;src6.jpg&apos;,img)dst = np.zeros((height,width,3),np.uint8)collect = np.zeros(9,np.uint8)for i in range(1,height-1): for j in range(1,width-1): k = 0 for m in range(-1,2): for n in range(-1,2): gray = img[i+m,j+n] collect[k] = gray k = k+1 # 0 1 2 3 4 5 6 7 8 # 1 for k in range(0,9): p1 = collect[k] for t in range(k+1,9): if p1&lt;collect[t]: mid = collect[t] collect[t] = p1 p1 = mid dst[i,j] = collect[4]#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;dst6.jpg&apos;,dst) 皮肤磨皮美白-双边滤波import cv2img = cv2.imread(&apos;image3.png&apos;,1)#cv2.imshow(&apos;src&apos;,img)dst = cv2.bilateralFilter(img,15,35,35) # 滤波函数#cv2.imshow(&apos;dst&apos;,dst)cv2.imwrite(&apos;dst7.png&apos;,dst)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图像美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[amd配置]]></title>
    <url>%2F2019%2F01%2F07%2FAMD%20GPU%20Pytorch%20%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[AMD GPU Pytorch 配置安装AMD显卡驱动sudo apt updatesudo apt install wget gnupg2# 安装驱动wget https://repo.radeon.com/amdgpu-install/5.4.2/ubuntu/focal/amdgpu-install_5.4.50402-1_all.debsudo apt-get install ./amdgpu-install_5.4.50402-1_all.deb# 然后安装单个用例sudo amdgpu-install --usecase=rocm,hip,mllib --no-dkms# 添加用户至render组sudo usermod -a -G video,render $LOGNAME#下载miopen内核,用于减少启动时间sudo apt-cache search miopenkernels-gfx908sudo apt-get install miopenkernels-gfx908-120kdb 配置环境 # 需要额外加一行参数export HSA_OVERRIDE_GFX_VERSION=9.0.8 重启然后验证 reboot# 显示gpu信息rocm-smi# 两项都显示gpu信息/opt/rocm/bin/rocminfo/opt/rocm/opencl/bin/clinfo 配置torchconda create -n py39 python=3.9pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/rocm5.2 测试 import torchtorch.cuda.is_available()# output = True 即可以调用gpu 测试速度 import torchimport torch.nn as nnimport numpy as npimport timex = torch.randn([1024,1024],device=torch.device(&apos;cuda:0&apos;))start = time.time()r = x @ xend = time.time()print(end - start)x2 = x.cpu()start = time.time()for i in range(10): r2 = x2 @ x2end = time.time()print(end - start)x3 = x2.to(torch.device(&apos;cuda:0&apos;))start = time.time()for i in range(10): r3 = x3 @ x3end = time.time()print(end - start)# 似乎第一次需要初始化，耗时较长，3.0左右 第二次耗时在0.0002左右 docker 配置由于 pip 安装的backward慢，且docker中 apex、deepspeed库更容易安装，所以使用docker安装 docker pull rocm/pytorch:latestdocker run -it --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --device=/dev/kfd --device=/dev/dri --group-add video --ipc=host --shm-size 8G --name amd_torch_jiangwei -p 6606:22 --mount type=bind,source=/ganzhi/ssd/data,target=/data6 rocm/pytorch:latest 配置ssh 登录（可选）配置参考docker/docker ssh远程连接篇 重新启动 docker run -d --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --device=/dev/kfd --device=/dev/dri --group-add video --ipc=host --shm-size 32G --name torch20_ssh -p 6606:22 --mount type=bind,source=/ganzhi/ssd/data,target=/data6 pytorch2-0:ssh /usr/sbin/sshd -D torch2.0 依赖安装（可选）先在/etc/apt/source.list加入以下内容 deb http://apt.llvm.org/focal/ llvm-toolchain-focal-13 maindeb-src http://apt.llvm.org/focal/ llvm-toolchain-focal-13 main 然后执行以下shell命令 sudo apt updatesudo apt install clang-13 解决torch.compile报错 SystemError: &lt;built-in function load_binary&gt; returned NULL without setting an exception export ROCM_PATH=/opt/rocm-5.4.2rm -rf /tmp/* 解决找不到cmath.h sudo apt install libstdc++-12-dev torch等rocm相关包手动安装安装依赖 , 安装apex必备sudo apt install rocm-dkms rocm-dev rocm-libs miopen-hip miopengemm hipsparse rccl rocthrust hipcub roctracer-dev 安装rocm-dkms可以安装上rocm-clang 安装torchaudiogit clone https://github.com/pytorch/audio.gitcd audiopython setup.py install 版本依赖解决指定版本如：sudo apt install rocm-dev5.2.4sudo amdgpu-install --usecase=rocm,hip,mllib --no-dkms --rocmrelease=5.2.4 最好不要手动指定，amdgpu-install已经包含了版本信息依赖问题dpkg faild to overwrite …. sudo dpkg -P xxx]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>amd配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cuda配置]]></title>
    <url>%2F2019%2F01%2F07%2Fcuda%20%E6%89%8B%E5%8A%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[下载地址cuda:https://developer.nvidia.com/cuda-toolkit-archive cudnn:https://developer.nvidia.com/rdp/cudnn-archive 安装cudawget https://developer.download.nvidia.com/compute/cuda/11.7.1/local_installers/cuda_11.7.1_515.65.01_linux.runsudo sh cuda_11.7.1_515.65.01_linux.run cudnnwget https://developer.nvidia.com/compute/cudnn/secure/8.5.0/local_installers/11.7/cudnn-linux-x86_64-8.5.0.96_cuda11-archive.tar.xztar -xvf cudnn-linux-x86_64-8.5.0.96_cuda11-archive.tar.xzcd cudnn-linux-x86_64-8.5.0.96_cuda11-archivesudo cp include/cudnn.h /usr/local/cuda/include/ sudo cp lib/libcudnn* /usr/local/cuda/lib64/ sudo chmod a+r /usr/local/cuda/include/cudnn.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* 配置环境export PATH=/usr/local/cuda-11.7/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-11.7/lib64:$LD_LIBRARY_PATH]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>cuda配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装]]></title>
    <url>%2F2019%2F01%2F07%2Fdocker%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[换源aliyun1.卸载老版本sudo apt-get remove docker docker-engine docker-ce docker.io 2.添加秘钥curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 3.设置存储库sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; 安装1.安装sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin 2.查看版本docker version 3.查看状态systemctl status docker 4.启动dockersudo systemctl start docker 5.设置开机启动sudo systemctl enable docker 6.demo验证sudo docker run hello-world 7.进入容器docker run -it ubuntu bash 8.清空docker system prune 9.换源#使用阿里云镜像加速器mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [ &quot;https://hub-mirror.c.163.com&quot;, &quot;https://ghcr.io&quot;, &quot;https://mirror.baidubce.com&quot;]&#125;EOFsystemctl daemon-reloadsystemctl restart docker doker-compose1.安装sudo apt install docker-compose 2.解决连接问题ERROR: Couldn’t connect to Docker daemon at http+docker://localunixsocket - is it running? If it’s at a non-standard location, specify the URL with the DOCKER_HOST environment variable. sudo gpasswd -a $&#123;USER&#125; dockersudo susu sylviadocker-compose up -d]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker容器挂载硬盘]]></title>
    <url>%2F2019%2F01%2F07%2Fdocker%E5%AE%B9%E5%99%A8%E6%8C%82%E8%BD%BD%E7%A1%AC%E7%9B%98%2F</url>
    <content type="text"><![CDATA[容器挂载硬盘1.停止 docker 引擎systemctl stop docker.service 2.编辑config.v2.jsonvim /var/lib/docker/containers/&lt;container-ID&gt;/config.v2.json ‘其中就是你想让哪个docker容器挂载硬盘空间，如果想要多个容器共享一个挂载硬盘，那就得挨个打开每个容器的config.v2.json文件’ 3.更换config.v2.json中MountPoints在config.v2.json查找MountPoints部分，通常来说，要是在创建容器的时候没有选择挂载硬盘，那么在这种情况下是空的：“MountPoints”:{}。接下来用这样的东西替换内容。 &quot;MountPoints&quot;: &#123; &quot;/mnt&quot;: &#123; &quot;Source&quot;: &quot;/home/&lt;user-name&gt;&quot;, #这个路径就是你要挂载的路径，比如说我的挂载路径为:/media/zz/newdir &quot;Destination&quot;: &quot;/mnt&quot;, #这个路径就是挂载路径映射到你在容器里面的路径，这里我就简单设置为/mnt &quot;RW&quot;: true, &quot;Name&quot;: &quot;&quot;, &quot;Driver&quot;: &quot;&quot;, &quot;Type&quot;: &quot;bind&quot;, &quot;Propagation&quot;: &quot;rprivate&quot;, &quot;Spec&quot;: &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/home/&lt;user-name&gt;&quot;, #同上Source &quot;Target&quot;: &quot;/mnt&quot; #同上Destination &#125;, &quot;SkipMountpointCreation&quot;: false &#125; &#125; 上述内容只需要修改”Source”、“Destination”、”Target”这些路径就可以了，其他的直接复制下来就可以了。然后，保存退出vim。 4.重启docker服务systemctl start docker.service 5.重启docker容器docker start &lt;container-name/ID&gt;]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-ldap-mysql]]></title>
    <url>%2F2019%2F01%2F07%2Fdocker-ldap-mysql%2F</url>
    <content type="text"><![CDATA[yml创建ldap-mysql1.编写ymlversion: &apos;2&apos;services: db: image: mysql:latest volumes: - &quot;./.data/db:/var/lib/mysql&quot; - &quot;./conf/mysql:/etc/mysql/conf.d&quot; restart: always ports: - 3306:3306 environment: MYSQL_ROOT_PASSWORD: ldap MYSQL_DATABASE: ldap MYSQL_USER: vives MYSQL_PASSWORD: ldap ldap-client: image: osixia/phpldapadmin:latest hostname: vivesdata domainname: ldap.vives.be depends_on: - db - ldap links: - db - ldap:ldap.vives.be ports: - 6443:443 restart: always environment: LDAP_DB_HOST: db:3306 LDAP_DB_PASSWORD: ldap LDAP_DB_USER: vives LDAP_DB_NAME: ldap PHPLDAPADMIN_LDAP_HOSTS: ldap.vives.be PHPLDAPADMIN_LDAP_CLIENT_TLS: &quot;false&quot; ldap: depends_on: - db image: osixia/openldap:latest hostname: vivesdata domainname: ldap.vives.be ports: - &quot;389:389&quot; volumes: - &quot;./.data/var/lib/ldap:/var/lib/ldap&quot; - &quot;./.data/etc/ldap/slapd.d:/etc/ldap/slapd.d&quot; links: - db restart: always environment: LDAP_DB_HOST: db:3306 LDAP_DB_PASSWORD: ldap LDAP_DB_USER: vives LDAP_DB_NAME: ldap LDAP_ORGANISATION: Vives LDAP_DOMAIN: ldap.vives.be LDAP_ADMIN_PASSWORD: ldap LDAP_TLS: &quot;false&quot; ldapbackup: depends_on: - db - ldap image: osixia/openldap-backup:latest hostname: vivesdata domainname: ldap.vives.be #volumes: # - &quot;./.data/openldap/backup:/data/backup&quot; # - &quot;./.data/etc/ldap/slapd.d:/etc/ldap/slapd.d&quot; links: - db - ldap:ldap.vives.be restart: always environment: LDAP_DB_HOST: db:3306 LDAP_DB_PASSWORD: ldap LDAP_DB_USER: vives LDAP_DB_NAME: ldap LDAP_ORGANISATION: Vives LDAP_DOMAIN: ldap.vives.be LDAP_ADMIN_PASSWORD: ldap LDAP_BACKUP_CONFIG_CRON_EXP: &quot;0 5 * * *&quot; LDAP_BACKUP_DATA_CRON_EXP: &quot;0 5 * * *&quot; 2.运行Containers runnen:docker-compose up Terminal krijgen op ldap container:docker-compose exec ldap /bin/bash Users zoeken in ldap directory:ldapsearch -x -h localhost -b dc=ldap,dc=vives,dc=be -D &quot;cn=admin,dc=ldap,dc=vives,dc=be&quot; -w ldap # extended LDIF## LDAPv3# base with scope subtree# filter: (objectclass=*)# requesting: ALL#[...]# numResponses: 3# numEntries: 2 PhpLdapAdmin in webbrowser openen op host:https://localhost:6443login: cn=admin,dc=ldap,dc=vives,dc=be psw: ldap 允许远程mysql连接2.进入mysql容器docker exec -it my_db /bin/bash 2.进入mysqlmysql -uroot -puse ladp; 2.修改权限ALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;123456&apos;; ### 123456 mysql的登录密码flush privileges; dokerfile 创建ldap-mysql1.拉取镜像sudo docker pull ubuntu:18.04 2.下载ODBC驱动https://dev.mysql.com/downloads/connector/odbc/ 需要下载ubuntu18.04对应的版本，比如8.0.19.tar.gz x86_64 3.写ODBC配置文件vim odbcinst.ini 内容为[MySQL]Description = MySQL driverDriver = /usr/local/lib/libmyodbc8a.soSetup = /usr/local/lib/libmyodbc8S.so vim odbc.ini 内容为[my_db]Driver = MySQLDescription = MySQLServer = my_dbPort = 3306User = rootPassword = secretDatabase = testdb 4.写openldap配置文件vim slapd_my.conf 内容为# $OpenLDAP$## See slapd.conf(5) for details on configuration options.# This file should NOT be world readable.#include /usr/local/etc/openldap/schema/core.schemainclude /usr/local/etc/openldap/schema/cosine.schemainclude /usr/local/etc/openldap/schema/inetorgperson.schema# Define global ACLs to disable default read access.# Do not enable referrals until AFTER you have a working directory# service AND an understanding of referrals.#referral ldap://root.openldap.orgpidfile /usr/local/var/slapd.pidargsfile /usr/local/var/slapd.args######################################################################## sql database definitions#######################################################################database sqlsuffix &quot;dc=example,dc=com&quot;rootdn &quot;cn=root,dc=example,dc=com&quot;rootpw secretdbname my_dbdbuser admindbpasswd secret#insentry_stmt &quot;insert into ldap_entries (id,dn,oc_map_id,parent,keyval) values ((select max(id)+1 from ldap_entries),?,?,?,?)&quot;insentry_stmt &quot;INSERT INTO ldap_entries (dn,oc_map_id,parent,keyval) VALUES (?,?,?,?)&quot;subtree_cond &quot;ldap_entries.dn LIKE CONCAT(&apos;%&apos;,?)&quot;has_ldapinfo_dn_ru no 5.编写dockerfilevim Dockerfile 内容为FROM ubuntu:18.04EXPOSE 389ADD [&quot;mysql-connector-odbc-8.0.19-linux-ubuntu18.04-x86-64bit.tar.gz&quot;, &quot;/&quot;]RUN apt-get update &amp;&amp; \ apt-get install -y unixodbc &amp;&amp; \ cp -r /mysql-connector-odbc-8.0.19-linux-ubuntu18.04-x86-64bit/lib/* /usr/local/lib/ &amp;&amp; \ apt-get install -y unixodbc-dev curl make groff-base unzip &amp;&amp; \ curl -L ftp://ftp.openldap.org/pub/OpenLDAP/openldap-release/openldap-2.4.44.tgz | \ tar xzf - &amp;&amp; \ cd openldap-2.4.44 &amp;&amp; \ export CFLAGS=&apos;-O2 -mtune=sandybridge -pipe -s&apos; &amp;&amp; \ ./configure --enable-modules --enable-sql --enable-bdb=no --enable-hdb=no --enable-memberof --enable-dyngroup --enable-ppolicy &amp;&amp; \ make depend &amp;&amp; \ make -j &amp;&amp; \ make install &amp;&amp; \ cd contrib/slapd-modules/passwd &amp;&amp; \ curl -LO https://github.com/wclarie/openldap-bcrypt/archive/master.zip &amp;&amp; \ unzip master.zip &amp;&amp; \ cd openldap-bcrypt-master &amp;&amp; \ make &amp;&amp; \ make install &amp;&amp; \ cd / &amp;&amp; \ rm -r /openldap-2.4.44 &amp;&amp; \ apt-get remove -y --purge unixodbc-dev curl make groff-base unzip &amp;&amp; \ apt-get autoremove -y --purge &amp;&amp; \ apt-get clean &amp;&amp; \ rm -rf /var/lib/apt/lists/*ADD [&quot;odbc.ini&quot;, &quot;/etc/&quot;]ADD [&quot;odbcinst.ini&quot;, &quot;/etc/&quot;]ADD [&quot;slapd_my.conf&quot;, &quot;/usr/local/etc/openldap/&quot;]CMD [&quot;/usr/local/libexec/slapd&quot;, &quot;-f&quot;, &quot;/usr/local/etc/openldap/slapd_my.conf&quot;, &quot;-d&quot;, &quot;257&quot;] 6.测试ODBC驱动是否正常(可选)isql -v my_db //my_db 为database 5.自动化脚本#!/bin/shset -eecho &quot;Creating MySQL and PostgreSQL database ...&quot;docker run -d --name my_db -p 3306:3306 -e MYSQL_DATABASE=testdb -e MYSQL_USER=admin -e MYSQL_PASSWORD=secret -e MYSQL_ROOT_PASSWORD=secret mysql#echo &quot;Building OpenLDAP image ...&quot;docker build -t ldap-sql .sleep 15 # DB needs time until upecho &quot;Loading data into databases ...&quot;docker exec -i my_db mysql -h127.0.0.1 -uadmin -psecret testdb &lt; my_dump.sqlecho &quot;Trying with MySQL, works ...&quot;docker run -d -p 389:389 --link my_db --name ldap-sql ldap-sql /usr/local/libexec/slapd -f /usr/local/etc/openldap/slapd_my.conf -d 257sleep 10docker exec ldap-sql ldapsearch -x -h localhost -b &quot;dc=example,dc=com&quot; &quot;(objectClass=*)&quot;#echo &quot;Deleting all Docker images ...&quot;#docker rm -vf ldap-sql my_db]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github上传代码]]></title>
    <url>%2F2019%2F01%2F07%2Fgithub%E4%B8%8A%E4%BC%A0%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[初次上传 clash换个窗口echo &quot;# demo&quot; &gt;&gt; README.mdgit initgit add README.mdgit commit -m &quot;first commit&quot;git branch -M maingit remote add origin https://github.com/ddxxz/demo.gitproxychains4 git push -u origin main 第二次上传 git add .git commit -m &quot;second commit&quot;git branch -M main#git remote add origin https://github.com/ddxxz/demo.gitproxychains4 git push -u origin main#图片路径直接复制上传图片的网页地址]]></content>
      <categories>
        <category>dxz</category>
      </categories>
      <tags>
        <tag>github上传代码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaldi安装]]></title>
    <url>%2F2019%2F01%2F07%2Fkaldi%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[kaldi 安装下载git clone https://github.com/kaldi-asr/kaldi.git 安装toolscd toolsextras/check_dependencies.sh 保证OK之后进行make make -j4 如果check inter mkl失败,需要安装 extras/install_mkl.sh 如果安装失败，可以手动安装 cd /tmpwget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS-2019.PUBapt-key add GPG-PUB-KEY-INTEL-SW-PRODUCTS-2019.PUBsudo apt-get install intel-mkl-64bit-2020.2#source 可选source /opt/intel/compilers_and_libraries_2020/linux/mkl/bin/mklvars.sh intel64 ilp64 make 中出现gzip failed,多半是因为文件下载中出错，找到大小为0的压缩文件删除后重新make All done OK. 表示安装成功 安装src./configure --sharedmake depend -j 8make -j 8]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>kaldi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用工具]]></title>
    <url>%2F2019%2F01%2F07%2Flinux%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[换源ubantu换源阿里源sudo python3 -c &quot;d=&apos;mirrors.aliyun.com&apos;;import re;from pathlib import Path;p=Path(&apos;/etc/apt/sources.list&apos;);s=p.read_text();bak=p.with_name(p.name+&apos;.bak&apos;);bak.exists() or bak.write_text(s);p.write_text(re.sub(r&apos;(cn.archive|security|archive)\.ubuntu\.com&apos;, d, s))&quot; pip换源修改或创建 ~/.pip/pip.conf ：[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple conda 换源channels: - defaultsshow_channel_urls: truedefault_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/rcustom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pip导出环境pip freeze &gt; requirements.txt 解压.tar格式# 打包 tar -cvf 文件名.tar # 要打包的文件# 解包 tar -xvf 文件名.tar#查看包里的内容tar -tvf 包的文件名.tar .gz格式tar -zcvf xxx.tar.gz 文件 # 压缩tar -zxvf xxx.tar.gz 文件 # 解压# 解压到指定目录 tar -zxvf xxx.tar.gz -C dirname .bz2格式tar -jcvf xxx.tar.bz2 文件 # 压缩tar -jxvf xxx.tar.bz2 # 解压 .zip格式安装sudo apt-get install zip 使用压缩文件 zip 压缩文件 源文件解压 unzip 压缩文件-d 解压到指定目录 如果目录不存在 会自动创建新目录 并压缩进去unzip test.zip -d filename 压缩文件拆分与合并拆分 split train-clean-100.tar.gz -b 1G -d train.tar.gz 合并 cat train.tar.gz* &gt;&gt;train.tar.gz vim编辑器工作模式：命令模式、输入模式、末行模式 模式切换当打开一个文件时处于命令模式在命令模式下，按 i 进入输入模式在输入模式，按ESC回到命令模式。在命令模式下，按shift+; ，末行出现:冒号，则进入末行模式 进入与退出进入 vim filename退出 :wq 末行模式，wq 保存退出 :q 末行模式，q 直接退出 :q! 末行模式，q! 强制退出，不保存 复制与粘贴复制和粘贴 yy 复制整行内容 3yy 复制3行内容 yw 复制当前光标到单词尾内容 p 粘贴 删除删除 dd 删除光标所在行 dw 删除一个单词 x 删除光标所在字符 u 撤销上一次操作 s 替换 ctrl + r 撤销 查找查找 / 命令模式下输入：/ 向前搜索 不能空格 ? 命令模式下输入：? 向后搜索# / 方式 n 向下查找 N 向上查找# ? 方式 n 向上查找 N 向下查找]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh 远程连接docker]]></title>
    <url>%2F2019%2F01%2F07%2Fssh%20%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5docker%2F</url>
    <content type="text"><![CDATA[ssh 远程连接docker 先拉一个ubuntu镜像 docker pull nvidia/cuda:10.0-base-ubuntu18.04 启动一个容器，并将50003端口映射到容器的22端口上 docker run --name jhag --gpus all -it -p 50003:22 nvidia/cuda:10.0-base-ubuntu18.04 进入容器 docker exec -it jhang /bin/bash 设置容器密码 root@576e4ca3aa7b:~$ sudo passwd rootChanging password for user root.New password:Retype new password:passwd: all authentication tokens updated successfully. 安装 ssh 服务 sudo apt-get update &amp;&amp; apt-get install openssl openssh-server 修改配置，获取远程ROOT权限 sudo vim /etc/ssh/sshd_config，PubkeyAuthentication yes #启用公钥私钥配对认证方式PermitRootLogin yes #root能使用ssh登录port=22 #开启22端口 开启 ssh 服务 service ssh restart 登录测试 ssh root@10.1.1.2 -p 50003 保存容器 sudo docker commit 容器id pytorch2-0:ssh 重新运行 docker run -d -p 50003:22 pytorch2-0:ssh /usr/sbin/sshd -D 关掉该容器 在宿主机通过 docker stop 容器id 即可关闭 启动容器 docker start 容器id]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>ssh 远程连接docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[conda常用命令]]></title>
    <url>%2F2019%2F01%2F07%2F%E5%AF%BC%E5%87%BA%2F</url>
    <content type="text"><![CDATA[导出conda env export &gt; plome.yaml 导入conda env create -f environment.yaml 示例结果name: demucschannels: - pytorch - conda-forgedependencies: - python&gt;=3.7,&lt;3.10 - ffmpeg&gt;=4.2 - pytorch&gt;=1.8.1 - torchaudio&gt;=0.8 - tqdm&gt;=4.36 - pip - pip: - diffq&gt;=0.2 - dora-search - hydra-colorlog&gt;=1.1 - hydra-core&gt;=1.1 - julius&gt;=0.2.3 - lameenc&gt;=1.2 - openunmix - musdb&gt;=0.4.0 - museval&gt;=0.4.0 - soundfile - submitit - treetable&gt;=0.2.3]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>conda常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[换源]]></title>
    <url>%2F2019%2F01%2F07%2F%E6%8D%A2%E6%BA%90%2F</url>
    <content type="text"><![CDATA[换源apt 换源sudo mv /etc/apt/sources.list /etc/apt/sources.list.bak sudo bash -c &quot;cat &lt;&lt; EOF &gt; /etc/apt/sources.list &amp;&amp; apt update deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverseEOF&quot; pip换源修改或创建 ~/.pip/pip.conf ： [global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple conda换源修改~/.condarc channels: - defaultsshow_channel_urls: truedefault_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/rcustom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud docker换源#使用阿里云镜像加速器mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [ &quot;https://hub-mirror.c.163.com&quot;, &quot;https://ghcr.io&quot;, &quot;https://mirror.baidubce.com&quot;]&#125;EOFsystemctl daemon-reloadsystemctl restart docker]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>换源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv基础]]></title>
    <url>%2F2019%2F01%2F07%2Fopencv%2F</url>
    <content type="text"><![CDATA[安装# pippip3 install opencv-python# condaconda install --channel https://conda.anaconda.org/menpo opencv3# conda虚拟环境source activate 环境名pip install opencv-python 读取与展示import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imshow(&apos;image&apos;,img) # 显示图片cv2.waitKey(0) # 没有会一闪而过 写入import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imwrite(&apos;image1.jpg&apos;,img) # 写入文件名字 ， 图片数据 有损压缩import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imwrite(&apos;imageTest.jpg&apos;,img,[cv2.IMWRITE_JPEG_QUALITY,50]) # 写入文件名字 ， 图片数据 ， 当前jpg图片保存的质量（范围0-100）#1M 100k 10k 0-100 有损压缩 无损压缩# 1 无损 2 透明度属性import cv2 # 导入cv库img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色cv2.imwrite(&apos;imageTest.png&apos;,img,[cv2.IMWRITE_PNG_COMPRESSION,0]) # 写入文件名字 ， 图片数据 ， 当前jpg图片保存的质量（范围0-100）# jpg 0 压缩比高0-100 png 0 压缩比低0-9 像素操作import cv2 # 导入cv库 img = cv2.imread(&apos;image0.jpg&apos;,1) # 读取图片文件， 1：彩色， 0：灰色(b,g,r) = img[100,100] # 获取图片的（100,100）坐标的像素值，按照bgr的形式读取print(b,g,r)# bgr#10 100 --- 110 100for i in range(1,100): # 总共一百个像素点 img[10+i,100] = (255,0,0) # 写入标准的蓝色cv2.imshow(&apos;image&apos;,img)]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[敬语]]></title>
    <url>%2F2019%2F01%2F06%2F%E6%95%AC%E8%AF%AD%2F</url>
    <content type="text"><![CDATA[敬语用于对会话中涉及的人物或者听话人表示敬意。现在日语的敬语大致分为四类： ①尊他语（尊敬語 そんけいご）：对他人的行为、状态及有关事物等表示敬意的语言。②自谦语（謙譲語 けんじょうご）：以谦逊的态度叙述自己或自己一方的行为、状态及有关事物的语言。③郑重语（丁寧語 ていねいご）：表示客气、有礼貌、文雅、郑重的态度的语言。如：です、ます、ましょう等。④美化语（美化語 びかご）：名词的接头接尾词，指令人听上去很优美很文雅的一些表达方式，给人优雅而又有教养的印象。 尊他语名词的尊他语①加前缀或后缀：前缀：お：お手紙、お話、お宅、お電話 （和语词，日常常用词）ご：ご案内、ご希望、ご協力 （汉语词）后缀：～さん ： 山田さん、学生さん～様（さま）： 田中さま、二人さま～殿（どの）： 吉田殿、会長殿前后缀：お父さん（さま）：お母さん（さま）お嬢さん（さま）：お客さん（さま） ②Ｎ本身变化会社：貴社 宅：お住まい 形容词的尊他语お＋形容詞✿ 歩くのがお速いですね。✿ 最近お忙しいですか。✿ お元気ですね。✿ お上手ですよ。 动词的尊他语一般动词お＋マス形＋になるご＋サ変动词词干＋になる✿ 何時ごろお帰りになりますか。✿ 先生がご案内になってくださったのです。 特殊动词 请求的尊他表示用于请求对方做某事。汉语：请您~接续：お＋マス形＋ください ご＋サ変动词词干＋ください✿ あしたの会議、ぜひご参加ください。✿ もう大丈夫ですので、どうぞご安心ください。✿ どうぞ、おかけください。 ★ 特殊词的接续：特殊词て型＋ください 其他尊他语形式１、お（ご） + ＶＲ（サ変語幹）+ なさるお帰りなさるご心配なさるあなたが行けば、おばあさんはきっとお喜びなさるでしょう。 ２、お（ご） + ＶＲ（サ変語幹）+ ですお客さんがこちらでお待ちです。 客人们请在这里等候。お父さんはご在宅ですか。 您父亲在家吗。 谦让语名词的自谦Ｎ本身变化わたくし茶：粗茶（そちゃ①０）贈り物：つまらない物当社：弊社（へいしゃ①）妻：愚妻（ぐさい０） 动词的自谦一般动词接续：お＋マス形＋ する/いたすご＋サ変动词词干＋する/いたす ★「いたす」自谦程度更高✿ 授業の後で お電話します。✿ それでは お願いいたします。 ★自谦句形不能用在单纯的说话人自己本身的行为动作及不涉及对方的行为动作上。★必须用在与对方有关的自己的动作上。 特殊动词 其他自谦语形式１、お（ご） + ＶＲ（サ変語幹）+ 申し上げるお客様を空港までお見送り申し上げます。把客人送到机场ご援助申し上げるつもりでございます。 我愿意为您效劳 郑重语郑重语不是对话题人物的尊敬，也不是对自己的自谦，而是用郑重地说话来表示对听话人的尊重。也是表示自己有高雅教养的表现。 郑重语的最基本的表现是です和ます。 其他还有ござる、まいる、いたす、おる等。✿ これが弟の写真です。✿ 私の父でございます。✿ 雪が降ってまいりました。✿ 何か変な匂いがいたしますよ。✿ 用意が出来ておりました。 美化语①加前缀：（同名词的尊他变形）お：お手紙、お話、お宅、お電話 （和语词，日常常用词）ご：ご案内、ご希望、ご協力 （汉语词） ②Ｎ本身变化めし：ご飯腹（はら）：お腹（おなか）便所（べんじょ）：お手洗い]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>敬语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础命令]]></title>
    <url>%2F2019%2F01%2F05%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[电源管理shutdown now # 关机shutdown -h 30 # 30分钟后关机 shutdown -r now # 重启shutdown -r 05:30 # 于05:30重启shutdown -c # 取消关机 目录结构/bin： bin是Binary的缩写, 这个目录存放着最经常使用的命令。 /boot： 这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ： dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。 /etc： 这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home： 用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib： 这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found： 这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media： linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。 /mnt： 系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /opt： 这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc： 这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。 这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器：echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all /root： 该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin： s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /selinux： 这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv： 该目录存放一些服务启动之后需要提取的数据。 /sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。 sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统 针对设备的devfs文件系统 针对伪终端的devpts文件系统。/tmp： 这个目录是用来存放一些临时文件的。/usr： 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。/usr/bin： 系统用户使用的应用程序。/usr/sbin： 超级用户使用的比较高级的管理程序和系统守护程序。/usr/src：内核源代码默认的放置目录。/var： 这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 显示文件目录ls-a 列出隐藏文件，文件中以“.”开头的均为隐藏文件，如：~/.bashrc-l 列出文件的详细信息-R 连同子目录中的内容一起列出 文件权限-rwx-rwx-rwx # 第一个代表文件类型# 代表所有者的权限 # 代表所属组的权限# 代表其他人的权限 改变权限r 读取权限 如果没有r 就不能 ls 查看里面的内容 对应数字 4w 写权限 如果没有w 就不能在目录下创建新的文件 对应数字 2x 执行权限 如果没有x 就不能cd进入这个目录 对应数字 1- 没权限 对应数字 0chmod 777 filenamerwx-rwx-rwx 切换文件夹cd filename # 进入文件-filename：文件名cd - # 返回上一次进入的目录cd ~ # 进入根目录cd .. # 返回上级目录 查看当前路径pwd 创建目录mkdir filename # 创建一个filename的文件 删除空目录rmdir filename # 删除一个空的filename的文件 复制复制文件或目录cp file1 file2cp file1 dir/cp file1 ../ 拷贝目录cp dir1 dir2 -rcp dir1 ~/ -r 删除文件或目录rm -r # 递归删除文件rm -rf # 强制删除文件***** 查看文件从第一行开始；“-b”显示行号cat file # 一次查看所有的文件cat file1 file2 # 一次查看两个命令 从最后一行开始tac filename 显示的时候，顺道输出行号！nl filename 一页一页的显示文件内容more filename 按Space键：显示文本的下一屏内容。 按Enier键：只显示文本的下一行内容。 按斜线符/：接着输入一个模式，可以在文本中寻找下一个相匹配的模式。 按H键：显示帮助屏，该屏上有相关的帮助信息。 按B键：显示上一屏内容。 按Q键：退出more命令。 查找命令which command # 查看 -二进制文件whereis 可执行文件 # 二进制文件 、man手册帮助文档： 1.man手册 ，帮助文档 man ls 2.--help , ls --help 查找文件find 路径 参数# 常用参数 -name # 按照名字-size # 按照大小find ./ -size +100k -size -10M # 在当前目录下找大于100k 小于 10的文件 文本搜索grep &apos;content&apos; filename# 常用参数-v 显示不包含匹配文本的所有‘行’ (求反)-n 显示匹配行及行号-i 忽略大小写# 内容参数^wu 行首 搜索以wu开头的行wh$ 行尾 索以wh结束的行 创建链接文件ln file hardlink # 硬链接ln -s file softlink # 软链接 软链接: 相当于 window上的快捷方式 源文件删除则软链接失效 硬链接: 硬链接只能连接普通的文件 不能连接目录 注意 如果软链接文件和源文件不在同一个目录 源文件要使用绝对路径 不能使用相对路径 创建别名alias # 查看所有别名 alias c4=&apos;cat 4.txt&apos;unalias # 删除别名 注意 这种定义别名的方式 只在当前登录有效 如果要永久定义生效 可以通过修改~/.bashrc文件 这个修改要下次登录才能生效 想要立即生效 可以输入source ~/.bashrc]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些忘记书名的心理学笔记]]></title>
    <url>%2F2019%2F01%2F04%2F%E4%B8%80%E4%BA%9B%E5%BF%98%E8%AE%B0%E4%B9%A6%E5%90%8D%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[酒与污水定律 把一勺酒倒入一桶污水，得到的是一桶污水；把一勺污水倒入一桶酒，得到的还是一桶污水。只要酒里有污水，再多的酒都是污水。 羊群效应 在组织散乱的羊群中，头羊起着关键作用，它的任何一个行动都会引起整个羊群中其他羊的关注，这些羊会效仿头羊。这是一种典型的从众心理，这种现象普遍存在于人类社会群体中。 安泰效应 指的是每种能力都要借助一定的条件和环境，一旦失去这种条件或环境，就可能失去某种能力。它告诉我们，人要学会借力，善于运用自己周围的环境。 踢猫效应 指人的不满情绪和糟糕心情，通常会沿着等级由高到低依次传递，由金字塔尖传到金字塔底，最终将危机转嫁到弱者身上。 矛盾选择定律 只有一只手表，可以告诉人们准确的时间，而拥有两只手表非但不能告诉一个人准确的时间，反而会让看表的人失去对准确时间的判断，这就是“手表定律”，也称“矛盾选择定律”。 贯性原理 你们对某样东西投入了巨大的精力，对它倾注了心血和金钱。你们投入的越多，贯性原理就越会促使你们想：“现在它必须成功。如果我再投入一点，它就会成功。” 如何对付错误和那些改变赢面的新情况，也是你们必须掌握的知识之一。生活有时候就像扑克游戏，有时候你们即使拿到一把非常喜欢的牌，但也必须学会放弃。 这时候，“剥夺性超级反映综合征”也会出现：如果不再投入一点，你们就要前功尽弃啦。人们就是这样破产的——因为他们不懂停下来反思，然后说：“我可以放弃这个，从头再来。我不会执迷不悟下去——那样的话我会破产的。” 社会科学理论 社会科学理论的命运取决于其传染性，而不是其正确性。 预期 假设一项计划预期在79天内完成。在第79天，假如计划还未完成，那么人们预测它还需要25天；但在第90天，假如计划还未完成，它会还需要58天；在第100天还需要89天；在第119天还需要149天；在第600天，如果计划还未完成，你会预测它还需要1590天。如你所见，你等待的时间越长，你预期还要继续等待的时间就越长。 喜欢 我们喜欢可触摸的东西、被证实的东西、显而易见的东西、真实的东西、可见的东西、具体的东西、已知的东西、已观察到的东西、生动的东西、视觉性的东西、有社会特点的东西、被灌输的东西、富有情感的东西、突出的东西、典型的东西、打动人心的东西、富有戏剧性的东西、传奇的东西、美化的东西、官方的东西、学术性的空话、虚有其表的高斯派经济学家、数学废话、华而不实的东西、法兰西学院、哈佛商学院、诺贝尔奖、黑西服白衬衣加领带、令人激动的演讲和耀眼的东西。而我们最喜欢的，是故事。 可惜，现存的人类天性不愿理解抽象事物，我们需要具体背景。随机性和不确定性是抽象事物。我们尊重发生的事，忽视本来可能发生的事。也就是说，我们天生肤浅，却浑然不知。这不是心理学问题，它来自信息的主要特性。人们很难看到月亮的阴面，照亮它是花费能量的。同样，照亮没有被看到的事物既费力又劳神。 假想实验 把一群各式各样的老鼠放进A实验室里，对它们进行越来越高的辐射。把幸存下来的老鼠放入城市B，幸存下来的老鼠在城市B老鼠中显得很强壮。看到的人于是分析为什么这些老鼠更强壮，因为他们来自A实验室，实验室把它们训练得很强壮。 沉默的证据 千多年前西塞罗讲了这样一个故事，有人把一幅画给一个无神论者看，画上画着一群正在祈祷的拜神者，他们在随后的沉船事故中幸存了下来。其寓意在于说明祈祷能保护人们不被淹死。无神论者问，‘那些祈祷后被淹死的人的画像在哪儿？’ 淹死的拜神者已经死了，所以很难从海底出来宣扬他们的事迹。 沉默的证据遍及所有与历史概念有关的一切，历史是具有事后影响的全部事件。 抓猴子的故事 树上挂一个空椰子，上面开个洞，放上米，猴子把手伸进去，抓了米，手就出不来。 长痛与短痛 短时间的巨大痛苦大于将痛苦在长时间中分散的痛苦; 短时间的巨大幸福小于长时间中分散的幸福。 改变他人 世界上唯一能影响对方的方法，就是讨论他所要的，而且还告诉他，如何才能得到。 也许在潜意识里，我们很希望能够通过我们的看法去左右别人的行为，因而会憎恨那些不受我们影响的人。 自重感 人们渴望成为重要的人，即自重感。献出你真实，诚恳的赞赏。 如果你想得到仇人，你就胜过你的朋友，如果你想获得更多的朋友，就让你的朋友胜过你。 当朋友胜过我们，他们会获得自重感。当我们胜过朋友，他会自卑，并引起猜疑和妒忌。 当我们猜疑，妒忌的人，发生一桩不幸的事，会使我们有一种恶意的快感。 有些朋友，看你遭遇困难，比看你成功或许更为满意。 批评与被批评 批评是没有用的，因它使人增加一层防御，而且竭力地替自己辩护。批评也是危险的，它会伤害一个人的自尊，和自重的感觉，并引起他的反抗。 被批评： 1.做你认为正确的事，反正你会受到批评，会因为做了某些事被骂，也会因为什么都不做而被骂。结果都是一样的。 2.如果你身居领导地位，那就注定要被批评，想办法习惯它吧！ 3.只要我不对任何的攻讦作出反应，那这件事就只有到此为止。 了解 你永远也不可能真正了解一个人，除非你穿上他的鞋子走来走去，站在他的角度考虑问题。 从众原则 大多数人好像都认为他们是对的，你是错的…… 他们当然有权利那样想，他们的看法也有权得到充分的尊重，但是，我在接受他人之前，首先要接受自己。有一种东西不能遵循从众原则，那就是人的良心。 为小事烦恼 错过列车，只有在你追赶它时才是痛苦的！同样，不能达到别人对你期望的成功，只有在它也是你所追求的东西时才是痛苦的。 只要是你的决定，放弃一份高薪职位带来的回报会超过金钱带给你的效用。这是向命运说“随你怎么样”的第一步。如果你确定了自己的标准，你对自己的生活会有大得多的控制。 我们很容易忘记我们活着本身就是极大的运气，一个可能性微小的事件，一个极大的偶然。 想象一个10亿倍于地球的行星边上的一粒尘埃。这粒尘埃就代表你出生的概率，庞大的行星则代表相反的概率。所以不要再为小事烦恼了。 是与不 使对方很快地回答“是，是“ 一个不字的反应，是最不容易克服的障碍。当一个人说出不字后，为了他人格的尊严，他不得不坚持到底。事后，他或许觉得他说出这个不字是错误的，可是，他必须考虑到自己的尊严。他所说的每句话，必须坚持到底，所以使人一开始，就往正面走，是非常重要的。 指责 尊重别人的意见，永远别指责对方是错误的。 我们不只反对有人指责我们的表错误，或者我们的汽车太旧，而是不愿意有人想要纠正我们的任何错误。 争辩 永远避免正面冲突、争辩 为什么一定要找出证据来证明别人的错误呢？ 这么做会让人喜欢你？ 他并没有征求你的意见，也不要你的意见，你又何必去跟他争辩呢？ 让人喜欢你的方法1.真诚地对别人发生兴趣2.微笑3.记住你所接触中，每一个人的姓名4.做一个静听的人，鼓励别人多谈谈他们自己。5.就别人的兴趣谈论6.使别人感觉到他的重要，必须真诚的这样做深入人们心底的最佳途径，就是对那人讲他知道得最多的事物。 保持愉快1.现在你何不问问自己：“我到底在烦恼些什么呢？”你多半会发现，你所担心的事既不重要，也没有意义。2.世上最好的医生，就是饮食有度、保持平和以及愉悦的心情。3.罗根·史密斯有一句智慧之言：“人生有两项主要目标，第一，拥有你所向往的；第二，享受它们。只有最具智慧的人才能做到第二点。” 工作1.如果你“假装”对工作有兴趣，一点点假装就会使你的兴趣成真，也可以减少你的疲劳。2.如果你是一个脑力劳动者，使你感觉疲劳的原因很少是因为你的工作超量，相反是由于你的工作量不足。3.要不停地提醒你自己，对自己的工作感兴趣，就能使你不再忧虑；而且最后还可能会给你带来升迁和加薪的机会。即使没有这么好的结果，那至少也可以使你的疲劳降到最低程度。 养成4种良好的工作习惯：第一，将你桌上所有的纸张收拾好，只留下你正要处理的问题。第二，根据事情的重要程度来安排做事的先后顺序。第三，当你遇到必须当场作决定的问题时，就当场解决，不要犹豫不决。第四，学会如何组织、分级负责和监督。 你可以把自己的生活想象成一个沙漏。在沙漏的上一半有成千上万粒的沙子，它们缓慢而均匀地流过中间那条细缝。除非把沙漏弄坏，否则，你和我都不能让两粒以上的沙子同时穿过那条窄缝。我们就如同沙漏。每天清晨醒来的时候，就有许许多多的工作摆在面前，要在这一天之内完成。但我们一定要均匀地安排自己的工作和生活，如果我们每次要几件事情同时做，就像要两粒以上的沙子同时通过窄缝一样，一定会损害自己的身体和精神。 表象 我们的头脑总是被所谓的真相，错误的“常识一样明白的”虚构的故事，以及服务于特别利益集团的带有偏见的结论所填满。一个有判别力的思考者要超越已有的信息，发掘隐藏在信息表面下的真正含义，以理解信息的本质为目标而不被表面的映像和风格所迷惑。技巧：1.避免把相关关系推论为因果关系。2.要求关键术语和概念有操作定义，并对其含义达成一致意见。3.你很容易在寻求辩解时发现确定的证据，但在寻找确定的证据前，首先要考虑如何反驳某一理论、假设或信仰。4.总是对已提出的明显解释寻求其他的可能解释，特别是那些有利于提案人的解释。5.认识到个人偏见能歪曲对现实的理解。6.怀疑对复杂问题给出的简单答案，怀疑对复杂现象和难题给出的单一理由和对策。7.质疑任何关于治疗、参与、或产品效果的声明，办法是找到比较结果的基础：比较什么？8.成为思想开朗而又好怀疑的人：认识到大多数结论都具有尝试性和不确定性；寻找新的证据来减少你的不确定性，同时使自己能不断变革和修正自己的观点。9.向权威挑战，那些权威通常用个人的观点代替证据，而且又不接受建设性的批评。 预期 通常，人们看见的,听到的只是他们所预期的，而不是事实的本来面目。 强迫 没有人喜欢强迫自己去买某样东西，或是被人派遣去做一件事。我们都喜欢随自己心愿去买东西，照自己的意思去做事情。同时希望有人跟我们谈谈我们的愿望，需要和想法。 失眠 下面是五条规则，可以让你不为失眠症而忧虑：第一，如果睡不着的话，就起来工作或看书，直到打瞌睡为止。第二，从来没有人会因为缺乏睡眠而死。因担心失眠而忧虑，通常对你的损害比失眠更厉害。第三，试着祈祷，或者像珍妮·麦克唐纳一样诵读诗篇的第二十三篇。第四，放松全身，看看《消除神经紧张》这本书。第五，多运动，或做一些体力活，直至你累得酣然入睡。 会议1.出了什么问题2.问题的原因是什么？3.有哪些可能解决的办法4.你觉得哪种方法最合适 职业 以下是我想向您请教的问题：①如果您的生命从头开始，您是否愿意再做一名建筑师？②在您仔细打量我之后，我想请问您，您是否认为我具备成为一名成功的建筑师的条件？③建筑师这一行业是否已经人满为患？④假如我学习了4年的建筑学课程，想要找到工作是否困难？我应该首先接受哪一类的工作？⑤如果我的能力属于中等，在头5年中，我可以希望赚多少钱？⑥当一名建筑师，有什么样的好处和坏处？⑦假如我是您的儿子，您愿意鼓励我当一名建筑师吗？ 古希腊哲学家艾皮科蒂塔说，哲学的精华就是：“一个人生活上的快乐，应该来自于尽可能减少对外来事物的依赖。”罗马的政治家及哲学家塞尼加也说：“如果你一直都觉得不满足，那即使是给你整个世界，你也会觉得伤心。” 忧虑1.混乱是产生忧虑的主要原因。在没有以客观的态度搜集到所有的事实之前，不要想如何解决问题。2.一切和我们欲望相符合的，看来都是真理，其他的都会使我们感到愤怒。 解决办法：（亚里士多德法则）第一，清楚地写下我们所担心的是什么。第二，写下我们可以怎么办以及可能发生的结果。第三，决定该怎么办。第四，马上按照决定去做。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>心理学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经济学笔记]]></title>
    <url>%2F2019%2F01%2F04%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[复利 如果有1万，按每年投资回报率10%计算，10年收益为1.59万，20年为5.7万，30年为16.45万，40年为44.26万。所以在20岁投入10万，60岁养老金就有450万，在孩子1岁时，投入10万，孩子30岁时，就有160万。 然而国际公认平均收益率为12%，而投资自己，进行人力资源投资的投资收益最大。 二八定律 20%的客户会带来80%的收益 有个乞丐非常善于乞讨，每天都比同行赚得多，于是有同行就问他：“你有什么乞讨秘诀吗？” 这位乞丐说：“秘诀谈不上，不过我还是有点个人经验的。我从来不粘着顾客满街跑。如果乞讨不成，我会趁早放弃。因为他若肯给我钱，早就会给，就算他最后磨不过我，给了我钱，我也因此浪费了很多时间和精力，不如转而寻找下一个大目标。” 黑洞效应 黑洞效应：在宇宙中，一些大质量的物体在发生坍塌之后，会形成一个致密的点，由于它的质量非常大，所以产生的引力也非常大，大到光线进去之后也无法逃出来，于是就形成了一个黑洞。而且不断被吞噬进去的物质和能量又反过来成为黑洞的一部分，使得黑洞产生更大的吸引力。黑洞效应就是一种自我强化效应。当一个企业达到一定的规模之后，也会像一个黑洞一样产生非常强的吞噬和自我复制能力，把它势力所及的大量资源吸引过去，而这些资源使得企业更加强大，形成一个正向加速循环的旋涡。 黑洞效应使得资源和资本聚集，是产生社会贫富差距的原因之一。 沉没成本 沉没成本是指由于过去的决策已经发生了的，而不能由现在或将来的任何决策改变的成本。人们在决定是否去做一件事情的时候，不仅是看这件事对自己有没有好处，而且也看过去是不是已经在这件事情上有过投入。我们把这些已经发生不可收回的支出，如时间、金钱、精力等称为“沉没成本”。举例来说，如果你预订了一张电影票，已经付了票款且假设不能退票。此时你付的价钱已经不能收回，就算你不看电影钱也收不回来，电影票的价钱算做你的沉没成本。所以，如果你是理性的，那就不该在做决策时考虑沉没成本。 参照点 我们在头脑中形成参照点，比如销售预测，然后开始基于它构造信念，因为把一个观点与一个参照点进行比较比在绝对的环境下对它进行评价所需的思维努力更小。（系统1在起作用！）我们无法在没有参照点的情况下思考。 所以在预测者头脑中设置一个参照点能够带来奇妙的结果。在讨价还价过程中设置起点是一样的道理：你先提出一个较高的数字，如“这所房子要卖100万美元”，买方会说“只能85万”——议价过程将取决于初始报价。 讨价还价的故事 有一天，王先生到一个做服装生意的朋友那里去聊天。一个顾客看好了一套服装，服装的标价是800元。顾客说：“你便宜点吧，500元我就买！”朋友说：“你太狠了吧，再加80元！而且也图个吉利！”顾客说：“不行，就500元！”随后，他们又进行了一番讨价还价，最终朋友说：“好吧，就520元！”顾客去交款了，但是不一会儿又回来了。她有些不好意思地说：“算了，我不能买了，我带的钱不够了！”朋友又说：“有多少？”顾客说：“把零钱全算上也就只有430元了。”朋友为难地说：“那太少了，哪怕给我凑一个整数呢？”顾客说：“不是我不想买，的确是钱不够了！”最后，朋友似乎下了狠心，说：“就430元钱给你吧，算是给我开张了，说实在的，一分钱没有挣你的！”顾客满脸堆笑，兴高采烈地走了。 看着顾客远去的背影，朋友告诉王先生：“这件衣服是180元从广州进的货。”王先生听了哈哈大笑：“真是无商不奸啊，可是你有些太狠了吧？” 朋友说：“这你就是外行了，现在都时兴讲价，顾客讨价，我还价，这很正常。你要给顾客留出来讨价还价的空间，要让顾客心理上获得一种满足！其实这件衣服我300元的价格就卖，到换季的时候我本钱都往外抛。” 巧借名人效应的故事 美国一出版商有一批滞销书久久不能脱手，他忽然想出了一个主意：给总统送去一本书，并三番五次去征求意见。忙于政务的总统不愿与他多纠缠，便回了一句：“这本书不错。”出版商便借总统之名大做广告：“现有总统喜爱的书出售。”于是，这些书被一抢而空。不久，这个出版商又有书卖不出去，又送一本给总统。总统上过一回当，想奚落他，就说：“这书糟透了。”出版商闻之，脑子一转，又做广告：“现有总统讨厌的书出售。”不少人出于好奇争相抢购，书又售尽。 第三次，出版商将书送给总统。总统接受了前两次的教训，便不作任何答复。出版商却大做广告：“现有令总统难以下结论的书，欲购从速。”居然又被一抢而空，总统哭笑不得，商人却善借总统之名大发其财。 ~巧借名人效应，抱大腿。 博弈论智猪博弈 假设猪圈里有一头大猪、一头小猪。猪圈的一头有猪食槽，另一头安装着控制猪食供应的按钮，按一下按钮会有一定单位的猪食进槽，两头隔得很远。假设两头猪都是理性的猪，也就是说它们都是有着认识和懂得实现自身利益的猪。 再假设猪每次按动按钮都会有10个单位的饲料进入猪槽，但是并不是白白得到饲料的，猪在按按钮以及跑到食槽的过程中要付出的劳动会消耗相当于2个单位饲料的能量。此外，当一头猪按了按钮之后再跑回食槽的时候，它吃到的东西比另一头猪要少。也就是说，按按钮的猪不但要消耗2单位饲料的能量，还比等待的那个猪吃得少。再来看具体的情况，如果大猪去按按钮，小猪等待，大猪能吃到6份饲料，小猪4份，那么大猪消耗掉2份，最后大猪和小猪的收益为4∶4；如果小猪去按按钮，大猪等待，大猪能吃到9份饲料，小猪1份，那么小猪消耗掉2份，最后大猪和小猪的收益为9∶-1；若两头猪同时跑向按钮，那么大猪可以吃到7份饲料，而小猪可以吃到3份饲料，最后大猪和小猪收益为5∶1；最后一种情况就是两头猪都不动，那它们当然都吃不到东西，两头猪的收益就为0。 那么小猪努力的结果是-1，比不努力的结果4还差，所以小猪只能不动。大猪为了生存，只能来回跑。 启发：小企业可以搭大企业的便车，坐收渔翁之利。 囚徒困境 警方逮捕甲、乙两名嫌疑犯，但没有足够证据指控二人有罪。于是警方分开囚禁嫌疑犯，分别和二人见面，并向双方提供以下相同的选择： 若一人认罪并作证检控对方（相关术语称“背叛”对方），而对方保持沉默，此人将即时获释，沉默者将判监10年。若二人都保持沉默（相关术语称互相“合作”），则二人同样判监半年。若二人都互相检举（互相“背叛”），则二人同样判监5年。 囚徒困境假定每个参与者（即“囚徒”）都是利己的，即都寻求最大自身利益，而不关心另一参与者的利益。参与者某一策略所得利益，如果在任何情况下都比其他策略要低的话，此策略称为“严格劣势”，理性的参与者绝不会选择。另外，没有任何其他力量干预个人决策，参与者可完全按照自己意愿选择策略。 囚徒到底应该选择哪一项策略，才能将自己个人的刑期缩至最短？两名囚徒由于隔绝监禁，并不知道对方选择；而即使他们能交谈，还是未必能够尽信对方不会反口。就个人的理性选择而言，检举背叛对方所得刑期，总比沉默要来得低。试设想困境中两名理性囚徒会如何作出选择： 1、若对方沉默、我背叛会让我获释，所以会选择背叛。2、若对方背叛指控我，我也要指控对方才能得到较低的刑期，所以也是会选择背叛。 二人面对的情况一样，所以二人的理性思考都会得出相同的结论——选择背叛。背叛是两种策略之中的支配性策略。因此，这场博弈中唯一可能达到的纳什均衡，就是双方参与者都背叛对方，结果二人同样服刑5年。 这场博弈的纳什均衡，显然不是顾及团体利益的帕累托最优解决方案。以全体利益而言，如果两个参与者都合作保持沉默，两人都只会被判刑半年，总体利益更高，结果也比两人背叛对方、判刑5年的情况较佳。但根据以上假设，二人均为理性的个人，且只追求自己个人利益。均衡状况会是两个囚徒都选择背叛，结果二人判监均比合作为高，总体利益较合作为低。这就是“困境”所在。例子有效地证明了：非零和博弈中，帕累托最优和纳什均衡是互相冲突的。 斗鸡博弈 两只公鸡狭路相逢，即将展开一场撕杀。结果有四种可能：两只公鸡对峙，谁也不让谁。或者两者相斗。这两种可能性的结局一样——两败俱伤，这是谁也不愿意的。另两种可能是一退一进。但退者有损失、丢面子或消耗体力，谁退谁进呢？双方都不愿退，也知道对方不愿退。在这样的博弈中，要想取胜，就要在气势上压倒对方，至少要显示出破釜沉舟、背水一战的决心来，以迫使对方退却。但到最后的关键时刻，必有一方要退下来，除非真正抱定鱼死网破的决心。但把自己放在对方的位置上考虑，如果进的一方给予退的一方以补偿？只要这种补偿与损失相当，就会有愿意退者。 这类博弈也不胜枚举。如两人反向过同一独木桥，一般来说，必有一人选择后退。在该种博弈中，非理性、非理智的形象塑造往往是一种可选择的策略运用。如那种看上去不把自己的生命当回事的人，或者看上去有点醉醺醺、傻乎乎的人，往往能逼退独木桥上的另一人。还有夫妻争吵也常常是一个“斗鸡博弈”，吵到最后，一般地，总有一方对于对方的唠叨、责骂装聋作哑，或者干脆妻子回娘家去冷却怒火。冷战期间，美苏两大军事集团的争斗也是一种“斗鸡博弈”。在企业经营方面，在市场容量有限的条件下，一家企业投资了某一项目，另一家企业便会放弃对该项目的觊觎。 斗鸡博弈强调的是，如何在博弈中采用妥协的方式取得利益。如果双方都换位思考，它们可以就补偿进行谈判，最后造成以补偿换退让的协议，问题就解决了。博弈中经常有妥协，双方能换位思考就可以较容易地达成协议。考虑自己得到多少补偿才愿意退，并用自己的想法来理解对方。只从自己立场出发考虑问题，不愿退，又不想给对方一定的补偿，僵局就难以打破。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>经济学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《禅与摩托车维修艺术》摘录]]></title>
    <url>%2F2019%2F01%2F04%2F%E3%80%8A%E7%A6%85%E4%B8%8E%E6%91%A9%E6%89%98%E8%BD%A6%E7%BB%B4%E4%BF%AE%E8%89%BA%E6%9C%AF%E3%80%8B%E6%91%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[自我爬山者，他谈论的话题永远是别的事和别的地方。他的人虽然在这里，但是他的心却不在这里。因为他拒绝活在此时此刻，他想要赶快爬到山顶，但是一旦爬上去之后仍然不快乐，因为山顶立刻就变成了‘此地’。他追寻的，他想要的都已经围绕在他的四周，但是他并不要这一切，因为这些就在他旁边。于是在体力和精神上，他所跨出的每一步都很吃力，因为他总认为自己的目标在远方。 一个没有目标的人才能爬到最高。（by克伦威尔）例子：取消考试成绩加入良质的概念 归纳法：由个别的经验归纳出普遍的原则 演绎法:从一般的原则推论出特定的结果科学式的思考：问题是什么；假设问题的原因；证实每个问题的假设；预测实验的结果。观察实验的结果；由实验得出结论。 古典的认知认为这个世界是由一些基本形式组成的，而浪漫的认知则是从它的表象来观察。 人在思考和感觉的时候往往会偏向于某一种形式，而且会误解和看轻另一种形式。 熟悉往往会使一个人视而不见。 我们观察周遭成千上万的事物，你知道他们存在，但是你并没有全部注意到它们，除非出现某些奇特的或是我们容易观察到的事物。我们几乎不可能全部意识到这些东西，而且把它们记住。那样，我们心里会充满太多无用的细枝末节，从而无法思考。从这些观察当中，我们必须加以选择，而我们所选择的和所观察到的，永远不一样，因为经由选择而产生了变化。我们从所观察到的事物当中选出一把沙子，然后称这把沙子为世界。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>哲学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《当我遇见一个人》摘录]]></title>
    <url>%2F2019%2F01%2F04%2F%E3%80%8A%E5%BD%93%E6%88%91%E9%81%87%E8%A7%81%E4%B8%80%E4%B8%AA%E4%BA%BA%E3%80%8B%E6%91%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[当一个生命带着极大的爱和信任降临到家庭中，他最渴望的是被看见， 被父母看见真实的自己，而不是通过一堆‘正确’的数据来评价和矫正自己。 当我放下预期和目的，以我的全部本真与一个人或事物建立关系时，我就会与这个存在的全部本真相遇。 父母看不到孩子本身，他们看到的是孩子的功能价值。父母能否看到孩子本身的存在，而不是用外在价值去定义物质性的‘它’，这一点决定了孩子内心能否直接感受到爱。若孩子本然的存在不被看见，即使父母为孩子倾注一切，孩子也只是父母表达爱的道具。 爱，是如他所是，非吾所愿 我拒绝了这件事情，不等于拒绝你这个人，不等于你提的要求不合理，不等于我不在乎你。我的拒绝仅仅是因为现在我不想这样做。拒绝的同时，我不会把自己关闭，我依然感受到你的爱，理解你的需要，理解自己的需要，让我们的需要共同创造出爱的方式。如果我答应你，一定是因为我也喜欢用这种方式爱你，而不是迫于维持关系的委曲求全，所以即使我付出再多，你也不必内疚。 不带评判地拒绝，没有委屈地付出，爱的流动如此之美。 规则要建立在尊重感受的基础上，一个人内心极度缺爱，同时对得到爱已经绝望，会通过牺牲自己来满足所爱的人，间接地满足自己内在的小孩，而实际上，所爱的人抢走了那个内在小孩的爱，她付出越多，也就越怨恨所爱的人。 最好的教育就是不教育。在爱的陪伴下，不打扰就是对专注力最好的培养。孩子的精神世界我们无须全部了解，但需要时常放下成人已被高度训练过的头脑的假想，带着敬畏之心去体验。 我们面对痛苦时最容易做的就是直接解决掉引起痛苦的外在的人或事。真正的勇士，是直面痛苦，向内看的人。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>心理学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语法总结（5-15）]]></title>
    <url>%2F2019%2F01%2F04%2F%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93%EF%BC%885-15%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇记录综合日语5-15的语法，以便查询 Ｎ１はＮ２です名词谓语句:什么是什么否定形式：Ｎ１はＮ２では/じゃありません。✿问 ：Ｎ１はＮ２ですか。✿回答：はい、そうです。 いいえ、違います。 Ｎ１で、Ｎ２です✿高橋さんは高校の後輩で、今、京華大学の語学研究生です。✿京華大学はそちらで、北京大学はあちらです ～へようこそ迎接客人时使用的寒暄语，相当于汉语中的 {欢迎来到~}正式的说法是：ようこそいらっしゃいました✿中国へようこそ。 ～と申します用于介绍说话人自己的名字，一般用于正式场合，或对上级的人，语气比较郑重。✿高橋と申します。どうぞよろしく。 Ｎ１からＮ２まで相当于汉语的“从什么到什么之意”a:表时间范围b:表处所、顺序等的范围。✿授業は木曜日から金曜日までです。✿授業は何時からですか。 Ｎじゃありませんか不是~吗？✿今は呉先生の中国史の授業じゃありませんか。 どんなＮですか相当于汉语:什么样的，怎么样的✿呉先生はどんな先生ですか。 Ｎ１やＮ２など用于列举两个或两个以上的事物。(など可以省略)✿専門は中国語や中国経済、中国史などです。 注：如果用 “Ｎ１とＮ２とＮ３と” ，必须列举出全部事物 そんなにA１くないです/A２ではありません相当于汉语中的“并没有那么”（主观想法）✿そんなに簡単ではありません。 あまりA１くないです/A２ではありません单纯地表示程度不高，相当于汉语中的“不太，不怎么”（客观上）✿あまり簡単ではありません。 Ｎはどうですか用于询问事物性质，相当于汉语中的“怎么样。如何” ✿问：英語はどうですか。 ✿答：英語はやさしいです。 用于表示建议，相当于汉语中的“怎么样。如何”✿６時はどうですか。 Ｎはどうでしたか用于询问过去发生的事情结果或者情形✿きのうの試験はどうでしたか。 Ｎ１もＮ２も表示并列，相当于“~和~都”✿中国語の聞き取りも発音もとても難しいです。 Ｎのとき用于表示时间，“~时候、时”的意思。✿大学創立の時は、まだ学部は少なかったです。✿一年生のときの相互学習はとてもよかったですね。 時間＋ごろ表示大概时间点，在几点“左右、前后” Ｎと同じ与~相同。✿美穂さんですか。私と同じ名前ですね。 Ｎ１はＮ２がAです大小主语句，即大小主语之间一般为整体与部分✿日本語はアクセントが難しいです。✿私は英語が上手です。 ほとんどVません相当于汉语的“几乎没~，基本上不~”等✿手紙はほとんど書きません。 ＮしかＶません用于限定范围，相当于汉语中的“只，仅仅”之意✿明日しか休みません。 ～とか～とか口语句，“~啦~啦”✿料理はお寿司とかケーキとかです。 Ｎのあとで~之后✿あしたの授業の後、ここで宿題をします。 疑问词＋か表示虚指，不确定之意。回答要用はい、いいえ先说明，相当于“有没有”✿休みにどこかへ遊びに行きましたか。 疑问词+{格助词+}も+动词否定表示全面否定。 格助词是{が}或{を}时，一般省略。✿その後は何もしませんでした。 Ｎ１かN２表示选择性的并列，“N1或者N2” ✿明日、李さんか王さんが行きます。✿散歩か買い物に行きます。 Ｖましょう。表示建议语气的敬体形式，用于建议对方和自己一起做某事。相当于汉语中的“~吧、~怎么样” Ｎ１に｛は｝Ｎ２があります/います某地有某物 ✿机の上に本があります。 Ｎ１はＮ２にあります/います某物在某地✿王さんは教室にいます。 ～んです用于口语，书面语写为｛のです｝。接在动词、形容词的连体形后面，用于说明情况或者询问情况。✿東京の冬はあまり寒くないですね。北京の冬は寒いんですよ。✿人民大会堂もここにあるんですか。 Ｎが見えます看得见~看得到~✿晴れの日に、星がたくさん見える。 までに期限，表示该时间之前完成某一动作。 “在~之前” ✿本は１０日までに返します。 でも接在名词或者に、と等格助词后面；提建议时举出一个例子供对方考虑，语气比较委婉。✿お茶でも飲みましょうか。✿公園にでも行きましょうか。 Ｖませんか建议，“不一起~吗？”✿一緒に公園に行きませんか。 ～でしょう推测，“~吧” ✿１時ごろからは混むでしょう。 Ｎになる/A1くなる/A2になる客观事实的结果或状态✿そろそろ１２時になりますね。✿肌がきれいになりますよ。 Ｎにする、くする、にする人为造成的变化结果或状态✿音をもう少し大きくしてもいいですか。✿教室をきれいにしてください。 Ｎにする表示所选择或决定的事物，相当于 “要~，定~”✿どちらもきれいですね、じゃ、やっぱり赤にしましょう。 Ｖています1、表示某一动作正在进行✿今、授業をしています。 2、表示变化结果的持续✿もう外暗くなっています。 3、表示习惯性的动作，反复进行的动作及长期进行的动作✿学生の大多数は学校の寮に住んでいます。 Ｖていました表示在过去的某一时段或时点上的持续动作 ✿午前中図書館で勉強していました。✿８時から１０時まではテレビを見ていました。 って用于提出话题，在口语中使用。✿鈴木さんってどんな人ですか。 もうＶました表示动作已经完成，“已经~了” ✿もうタイトルは決めましたか。✿王さんはもう帰りました。 まだＶていません。还没，尚未做某事。✿朝からまだ何も食べていません。✿まだ来ていません。 Ｖて、Ｖて、Ｖます。表示连续进行几个动作在时间上的先后顺序。✿朝起きて、運動をして、食事をして、会社に行きます。 Ｖたい接在动词的第一连用形后面构成愿望的派生形容词，“想做~~”。使用Ｖたいですか询问第二、三人称的愿望被视为不礼貌的行为。✿おいしいものが食べたいです。✿有名な大学に入りたいです。 注：当表达第三人称具有进行某一动作的愿望时，一般用Ｖたがる这种形式。这时を格不能够改为が✿父は新しいパソコンを買いたがっています。✿先生は山本に会いたがっていました。 Ｎがほしい表示希望，想要得到某东西，其非过去式只能用于表示第一人称的愿望，直接问对方Ｎがほしいですか是不礼貌的。 ✿家族と友達へのお土産がほしいですが…。✿時間がほしいです。 Ｎができます表示具备某种能力，能做某事，会做某事✿日本語で買い物ができますか。✿王さんはテニスができます。 Ｎがわかります表示对人或事物的了解,助词一般用が，否定句中多用は。相当于”明白，了解”的意思。 ✿店員は大体日本語がわかります。✿この漢字の意味がわかりますか。 Ｖてもいい表允许，同意别人做某事。或者是询问别人的同意。✿試着してもいいですか。✿ここに座ってもいいですか。 Ｎはいかがですか用于提出建议并征求对方意见，或询问情况。表示“~怎么样 ~如何”等。是Ｎはどうですか的郑重表达方式✿もう一杯いかがですか。✿今晩、日本料理はいかがですか。 数量词+も带有说话人的主观评价色彩， “竟，足足，达”。✿駅で１時間も友達を待ちました。 だけ只有，仅仅。用在格助词が、を前面时，が、を有时省略。 ✿これは日英だけの辞書ですか。✿今朝は果物だけ｛を｝食べました。 Ｖてください请求对方做某事，一般不对上级或长者使用。✿それを見せてください。✿日本語を教えてください。 动词词典形+ことができる表示：①具有做某事的能力，②表示某种条件下行动行为的可能性。✿図書館のパソコンは何時まで使うことができますか。✿金さんはフランス語を話すことができます。 ずつ接在表示数量词或表示数量，程度的副词后面，表示数量的均等分配或者动作、变化的等量反复。 ✿毎日、少しずつ練習しています。✿りんごは一人に２つずつある。 Ｖてはいけない表示禁止，相当于不许、不准，多用于规则纪律，由于语气强烈，最好不要用于当面禁止别人做某事。✿教室ではタバコを吸ってはいけない。 Ｖないでください表示禁止，请不要做~、请勿~✿気にしないでください。✿大きい声を出さないでください。 Ｖている/Ｖないとき~的时候✿人が下を歩いているときに、窓からごみを捨ててはいけない。✿私は家に誰もいないとき、自分で料理を作ります。 Ｖなくてもいい表示不做什么也可以 ✿靴を脱がなくてもいいですよ。✿もう薬を飲まなくてもいいですよ。 ＶるＶた/とき{に}✿日本へ行くとき、パソコンを買いました。去日本之前买了电脑。✿日本へ行ったとき、パソコンを買いました。去日本之后买了电脑。 Ｖなくては｛なければ｝いけない同：Ｖなくては｛なければ｝ならない表示：必须做某事，应该做某事在口语中なくては经常说成なくちゃ；なければ经常说成なきゃ✿もう、病院へ戻らなくちゃいけません。✿日本で家に入るとき、靴を脱がなくてはいけないんでしょう。 どうして…（ん）ですか为什么~呢？✿山本さんはどうして来ないんですか。✿どうして先生に話さなかったんですか。 ～でしょう表示确认，要读升调✿もう宿題は終わったでしょう。✿まだいいでしょう。 Ｎについて/Ｎについての接在名词后面表示“关于，有关”✿日本文化についての資料を集めています。 ～と言う表示直接引语✿食事のとき、日本は皆で「いただきます」と言う。✿日本人は夜寝るときに、「お休みなさい」と言う。 N１というＮ2叫做~的~✿渡辺さんという人を知っていますか。✿これは何という花ですか。 Ｎが好き/嫌い喜欢，讨厌某物，表示感情的形容词助词用が✿高橋さん、京劇が好きですよね。✿鈴木さんは高橋さんが好きです。 Ｎ &lt;周期&gt; に Ｎ &lt;数量&gt;表示某一周期内动作的频率✿３ヶ月に１回ぐらい何かを見ていました。✿この薬を一日に３回飲んでください。 Ｖ简体の动词名词化✿明日、三保さんが来るのを知っていますか。 Ｎ1だけで｛じゃ｝なく、Ｎ2も不仅N1~N2也~ ✿あの人は英語だけでなく、日本語も話せます。✿肉だけでなく、野菜も食べなければならないんです。 ＮでもＮでも｛いい｝~和~都可以 ✿土曜日でも日曜日でも大丈夫です。✿男の子でも女の子でもいいんですよ。 なかなかＶ{能动态}ない与动词能动态否定形式搭配，表示该动作很难做到。 ✿みんな忙しい、なかなか会えません。✿この町では刺身はなかなか食べられません。 Ｎ1はＮ2より{比较}N1比~N2要~~~ ✿母は父より朝早く起きます。✿月曜日は火曜日より忙しい。 Ｎ1よりＮ2のほうが～比起N1 ，N2更~✿父より母のほうが朝早く起きます。✿火曜日より月曜日のほうが忙しい。 Ｎのなかで｝Ｎが一番～在~中~是最~✿クラスの中で、王さんが一番日本語が上手です。✿中華料理の中では、北京ダックが一番おいしいです。 ｛Ｎ1もＮ2も｝どちらも｛同じくらい｝～N1还是N2都一样~✿どちらも同じくらい好きです。✿山本さんは英語も日本語も、どちらも上手です。 Ｎ1はＮ2とともにN1和N2一样✿英語は日本語とともに必修科目である。 ～と思う～Ｖ意志形と思う 表达第一人称当时的意愿，想法。✿きょうは早く帰ろうと思います。 ～Ｖ意志形と思っている表达第一人称一直以来的想法，表达其他人称的意愿，想法。✿私は将来教師になろうと思っています。✿王さんは日本に行こうと思っている。 ～Ｖたいと思っている 单纯地表达一个愿望，没有落实行动，只停留在想法上。✿私は日本に行きたいと思っている。 简体句と思う。表示“我认为～，我觉得～” ✿プレゼント交換がいいと思う 简体句と思っている认为~~（无人称区别） ✿英語より日本語のほうが難しいと思っている人が多いです。 动词词典形+予定です表示某人的计划，客观性比较强。✿夏休みは国に帰る予定です。✿私たち日本語学科もコンパを開く予定です。 动词词典形+つもりです表示打算做某事，主观性比较强。✿夏休みには、小説をたくさん読むつもりです。✿あしたからはタバコを吸わないつもりです。 ～かどうか接续：动词、形1简体，名词、形2词干 ~还是不~✿東京の冬は寒いかどうか、日本人の友達に聞きます。✿このことは、あの人が知っているかどうか、わかりません。 だろうだろう接在动词、形容词的简体形式以及形容动词的词干，名词后面表示推测，是的でしょう简体。✿その辞書は高いだろうと思う。✿あそこへは電車よりバスのほうが便利だろう。 Ｖたことがある表示曾经有做过某事的经历✿私は富士山に登ったことがあります。✿私は一度も飛行機に乗ったことがありません。 动词词典形+ことがある有时、偶尔做某事✿私はははと喧嘩するこがある ばかり接在名词或格助词后面，用于限定，带有消极的感情色彩。表示： “光做某事，净做某事”✿あの人は毎日テレビばかり見て、何もしません。 授受动词给给我✿句型：Aは｛私に｝～をくれる。✿意思：A给我某物。✿注：私に可以省略。 给其他人✿句型：A（我或我方的人）はBに～をあげる。✿意思：A给B某物。 收✿句型：AはBに/から～をもらう。✿意思：A从B那里得到某物。✿注：这个句子中的B一般不用わたし。 具体用法 动词 ✿Ｖます：动词敬体（礼貌体），第一连用形。#V变形后去掉的形态为动词的第一连用形，它用于句子的中顿，#大多表示两个或两个以上的动词并列，也可以表示动作先后顺序，#通常用于书面语。 ✿Ｖない动词未然形（动词的简体否定） ✿Ｖた动词简体过去时 ✿Ｖて形表示动作的中顿，语法活用 ✿动词能动态#表示“可能”的意义。#既可以表示人具有某种能力，也可以表示在某种状态下行为动作的可能性。 ✿Ｖ（よ）う 意志形#动词后接表示意志、建议后缀的事构成动词的意志，建议形。 详见 动词总结]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[on_my_zsh]]></title>
    <url>%2F2019%2F01%2F03%2Fon-my-zsh%2F</url>
    <content type="text"><![CDATA[1. 安装 Oh My Zsh安装 Zsh安装:sudo apt install zsh 将 Zsh 设置为默认 Shellchsh -s /bin/zsh 安装 Oh My Zshwget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 2. 配置 Oh My Zsh下载字体git clone https://github.com/powerline/fonts.git --depth=1cd fonts.\install.ps1 配置字体git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9kgit clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git $&#123;ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom&#125;/themes/powerlevel10k autojump更快地切换目录，不受当前所在目录的限制。sudo apt install autojump# 跳转到目录j dir# 可以通过GUI文件管理器打开指定目录，执行命令:jo dir fasd快速访问文件或目录，功能比前一个插件强大。 安装：sudo apt install fasd 使用：alias f=&apos;fasd -f&apos; # 文件alias d=&apos;fasd -d&apos; # 目录alias a=&apos;fasd -a&apos; # 任意alias s=&apos;fasd -si&apos; # 显示并选择alias sd=&apos;fasd -sid&apos; # 选择目录alias sf=&apos;fasd -sif&apos; # 选择文件alias z=&apos;fasd_cd -d&apos; # 跳转至目录alias zz=&apos;fasd_cd -d -i&apos; # 选择并跳转至目录 zsh-autosuggestions命令行命令键入时的历史命令建议插件git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions zsh-syntax-highlighting语法高亮插件git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting 修改「.zshrc」文件Oh My Zsh 配置文件的完整修改结果，只有对配置文件进行如下修改，才能使上述配置生效。# 设置字体模式以及配置命令行的主题，语句顺序不能颠倒# POWERLEVEL9K_MODE=&apos;nerdfont-complete&apos;#ZSH_THEME=&quot;powerlevel9k/powerlevel9k&quot;ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;# 以下内容去掉注释即可生效：# 启动错误命令自动更正ENABLE_CORRECTION=&quot;true&quot;# 在命令执行的过程中，使用小红点进行提示COMPLETION_WAITING_DOTS=&quot;true&quot;# 启用已安装的插件plugins=( git extract fasd zsh-autosuggestions zsh-syntax-highlighting) 添加环境变量打开配置文件vim ~/.zshrc 添加环境变量export PATH=/usr/local/python/bin:$PATH 注：环境变量中，各个值是以“冒号”分隔开的。上面的语句表示给PATH这个变量重新赋值，让它等于/usr/local/python/bin ；再加上原来的$PATH 使配置生效source ~/.zshrc]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Anconda常用命令总结]]></title>
    <url>%2F2019%2F01%2F02%2FAnconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[anaconda是python发行的包的管理工具，其中自带python的版本，还带很多python的包.安装它比起安装python可以省掉再安装python包的时间。并且利用 Python 进行科学计算，就需要一一安装所需的模块， 而这些模块可能又依赖于其它的软件包或库，安装和使用起来相对麻烦但是用Anaconda只需直接输入conda install &lt;包名&gt;，所有依赖的包和库会自动安装好。 下载地址官网：https://www.anaconda.com/最新版本下载地址：https://www.anaconda.com/download/历史版本：https://repo.anaconda.com/archive/ Anaconda的安装进入文件所在路径bash Anaconda3-4.4.0-Linux-x86_64.sh (下载的对应的文件名) conda的环境管理比如创建名为tensorflow的tensorflow-gpu版的python环境conda create --name tensorflow python=3.6 tensorflow-gpu 激活tensorflow环境source activate tensorflow 测试环境python --version 退出虚拟环境source deactivate tensorflow 删除虚拟环境conda remove --name tensorflow --all Conda的包管理安装包conda install -n tensorflow sklearn注：如果不用-n指定环境名称，则被安装在当前活跃环境 删除包conda remove -n tensorflow numpy 在当前环境下安装anaconda包集合conda install anaconda 添加Anaconda的TUNA镜像conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ pip换源： cdmkdir .pipcd .pip/nano pip.conf#粘贴以下内容[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple jupter notebook添加conda环境首先安装：conda install ipykernel 激活对应的conda环境source activate 环境名称 将环境写入notebook的kernel中python -m ipykernel install --user --name 环境名称 --display-name &quot;Python (环境名称)&quot; 安装pytorch 添加Pytorch镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/# for legacy win-64conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/ 安装 conda install pytorch torchvision cudatoolkit=9.0]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>anconda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11-18句型总结]]></title>
    <url>%2F2019%2F01%2F02%2F%E5%8F%A5%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[名词化 の vs こと1、一般而言「こと」指事。表示向别人传达的内容或决定的内容、概念、以及 抽象的事情时使用。2、「の」可以指人、物、事。表示自己实际感觉到的做的事情等具体的行动或体 验时使用。有时二者可通用。 ✿ 友達に電話する こと/の を忘れた。 ✿ 明日鈴木さんが来る こと/の を知っていました。 「こと」しか使えない場合1、后续动词为传达、表达等语言行为的动词，如「話す、伝える、教える」等。 ✿ みんなに会議があることを伝えてください。2、名词化的动词直接加「です」结句。 ✿ 私の趣味は映画を見ることです。3、后续为表示意志的动词 ，「命じる、许す、决める、願う、约束する」等。 ✿ 結婚することに決めました。 「の」しか使えない場合1、后续动词是表示感觉、知觉等感官动词，如「聞こえる、見える、感じる、 聞く、見る、気がつく」等。 ✿ 誰か叫んでいるのを聞こえました。 ✿先生が車から降りるのを見ました。2、在句型「Ｖのは、～だ」中，一般不能换。 ✿ 彼女が買ったのは、この赤いかばんです。 たい VS ほしいＶたい“想做某事”１、接续：动词第一连用形+たい（只能用于第一人称） ✿ 美味しいものが食べたいです。2、「Ｖたかった」过去时可以用于第一、二，三人称，陈述已发生的事实。 ✿ 彼女はあのケーキが食べたかったです。３、第三人称一般使用「Vたがる」的形式，构成一类的派生动词。做他动词使用。 ✿ 高橋さんはアイスを食べたがります。 Nがほしい”想要某物”１、表示希望，想要得到某东西。一般只能用于第一人称。 ✿ お金が欲しいです。2、「Nがほしかった」过去时可以用于第一、二，三人称，陈述已发生的事实。 ✿ 李さんはゲーム機が欲しかったです。３、第三人称一般使用「ほしがる」的形式，构成一类的派生动词。做他动词使用。 ✿ 山田さんは休みを欲しがっています。 Vてほしい“希望别人做某事”１、动词て形+ほしい。表示说话人希望听话人采取某一行动，或者造成某种状态。 ✿ 明日の朝も来て欲しい。 ✿ 君にこの仕事を担当して欲しい。 あいだ VS あいだにあいだに&lt;时点&gt;1、表示在某状态持续的阶段或时期内的某一时点上的某一动作或变化。 ✿ 留守のあいだに、泥棒が入った。 あいだ&lt;时段&gt;1、表示在某状态持续的整个阶段，时期内持续地进行了谓语动词的动作。 常与ずっと搭配。后句一般会用到表示持续状态的ている。 ✿ 彼は会議のあいだ、ずっと居眠りをしていた。 Vたら～た&lt;契机~发现&gt;1、表示以前项为契机，紧接着发生了后项的事件或发现了后项的状态。 ✿ 本屋に行ったら、偶然学生時代の友人に会った。★ 后项事物一般为说话人意志所不能及的事物，或是一些新发现、新认识等， 具有意外性。 と～と&lt;条件&gt; “一～就～、（如果）~就~1、达成某种条件就会得到必然结果、现象。 主要用在表述：恒常性状态，真理， 指路，反复性状态，习惯等方面。 ✿ 前の交差点を右に曲がると、学校が見える。 ～と&lt;反复、习惯&gt;“一~就~ ”1、表示特定的人或物的习惯和动作的反复，常伴有“いつも、よく”等副词。 ✿ 毎年、冬になるとスキーに行く。 ～ないと～ない＜否定性条件＞1、否定性条件从句，后项常表否定性意义。口语中后项常省略。表示前项不成立 的话，后项一定会出现某消极或否定结果。 ✿ 早く行かないと、間に合わないよ。 (否定结果) ✿ 急がないと遅刻するよ。(消极结果) よにVる / Ｖないようにする1、表示设法做（或不做）某事。为实现某种状态做（或不做）某事。可以与｢でき るだけ、必ず、ちゃんと｣等构成呼应。 ✿ 夜は甘いものを食べないようにしている。 Vる / Ｖないようにしてください1、对听话人表示要求、忠告或劝告。”请尽量~、请注意~” ✿ ちゃんとメモを取るようにしてください。 句型1、Ｖましょうか/ましょう&lt;意志、征求同意&gt;2、って&lt;话题&gt;3、N/A２にする/A１くする4、どうして&lt;原因（疑问）&gt;5、でしょう&lt;确认&gt;6、Nについて/Nについての7、N１は N２より～ （比较句）8、N２よりN１のほう（方）が～ （比较句）9、N1はＮ２ほど～ない （比较句）10、N１だけで（じゃ）なくN２も～ 不光/不仅……还/而且……11、(N1の中で) Ｎ２が一番～12、Ｎ１でもＮ２でも（いい）13、Ｎ１とＮ２と（では）どちら（のほう）が～14、Ｎ１はＮ２とともに相同15、それで：因果关系16、~かどうか&lt;选择&gt;17、Ｖたことがある&lt;经历&gt;18、Vることがある&lt;频率低&gt;19、~だろう&lt;推测&gt;20、Nがする&lt;感觉&gt;21、Nによって（違う）&lt;基准&gt;22、どうやって～んですか&lt;方式&gt;23、Nにとって&lt;评价的立场和角度&gt;24、はず&lt;判断，估计&gt;25、かもしれない&lt;推测&gt;26、～途中で＜动作进行中＞27、～のは～（ ～からではなくて）からだ28、疑问词 ＋でも＋肯定句＜全面肯定＞29、～まえに＜动作的顺序＞30、～あとで＜先后顺序＞ 31、それに&lt;并列&gt;：~，而且~32、それとも&lt;选择&gt;：是~还是~33、~とおり&lt;基准 标准&gt;34、もう&lt;加强语义&gt;]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>句型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日语助词总结]]></title>
    <url>%2F2019%2F01%2F02%2F%E6%97%A5%E8%AF%AD%E5%8A%A9%E8%AF%8D%2F</url>
    <content type="text"><![CDATA[本篇主要记载日语助词用法，以便个人查询 か1、＜疑问＞ （5.1 P41） ✿ その人は王さんですか。 お元気ですか。2、疑问词 か＜虚指＞ （9.1 P152） ✿ どこかへ行きますか。3、NかN＜选择＞ （9.2 P161） ✿ 朝はミルクかジュースを飲みます4、含疑问词的简体句 か （17.2 P44） ✿ 図書館はどこか教えてください。 で1、＜处所＞（动作发生的场所） （8.1 P129） ✿ 喫茶店でコーヒーを飲みます。 2、＜工具，方式，手段＞ (8.2 P138) ✿ バスで行きます。 3、＜限定範囲，数量，主体＞ ✿ 富士山は日本で一番高い山です。 ✿ 300元ぐらいでシルクのチャイナドレスが買えます。 ✿ 二人で行きましょう。 4、＜原材料＞ （12-1 p232） ✿ 紙で飛行機を作った。（变化小：で 变化大：から） 5、＜原因＞ ✿ 事故で遅刻しました。 6、＜事件发生的场所＞ ✿ 運動場で試合がある。 と1、＜并列＞ （5.2 P55） ✿ 家族は三人です。父と母とわたしです。 2、＜比较的基准＞ （7.2 P100） ✿ 私は鈴木さんと同じ大学です。3、＜相互动作的对象、同一动作的参与者＞ （9.1 P152） ✿ 兄は私の友達と結婚しました。 （双向性） ✿ 私は友達と一緒にお酒を飲みます。４、と＜引用＞ （11.1 ｐ204） ✿ 李さんは来週帰国すると聞きました。５、と言う＜引用＞ （13-3 p274） ✿ 食事のとき、「いただきます」と言います。６、と言うＮ （14-1 p282） ✿ 浜崎あゆみという歌手7、条件 （17-1 p33） ✿ 春になると、花が咲きます。8、习惯，反复 （17-1 p33） ✿ 子供のころ、冬になると毎年スキーに行った。 は1、は＜部分否定＞ (13.3 p275) ✿ 毎日はしません。 も1、も＜主观多量＞ （12.2 p242） ✿ 3万円もするんです。 の1、＜准体＞ （12-1 p231） ✿ 美味しいのが好きです。2、＜连体修饰语从句主语＞ （14-2 p293） ✿ 母の作った料理は美味しい。3、＜名词化＞ (14-2 p293) ✿ 先生が行ったのを見ました。 に1、に＜周期＞ （14-2 p291） ✿ 一週間に2回家族に電話します。2、に＜状态、性质的对象＞ （14-2 p291） ✿ 京劇に詳しい。 ✿ 学生に優しい。 ので VS から1、接续不同：名词/2类形容词词干+なので 名词/2类形容词词干+だから2、意义不同：「ので」一般用于陈述客观的原因。 后项既定事实、客观事实、绝大多数人的看法，语气更缓和； 「から」一般用于陈述主观的理由。 后项可以是既定事实也可以是意志、推测、主张。3、语气不同：から较生硬，因此妇女和儿童一般来说为避免过分强调自己的主张 Ｎ（＋格助词）のＮA、「が/を/に/へ/で/と/から/まで」等格助词一般接名词后与动词搭配使用。B、除此之外，还可以与「の」结合后构成复合形式，用于修饰名词。 ✿ 高橋さんが留学する 高橋さんの留学 ✿ 日本語を学習する 日本語の学習 ✿ 日本に留学する 日本への留学 ✿ 学校まで案内する 学校までの案内 ✿ 海外へ出張する 海外への出張 ✿ 北京で生活する 北京での生活 ✿ 日本人と会話する 日本人との会話 ✿ 母に手紙を送る 母への手紙注意：没有がの、をの，另外にの要变成への。]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>助词</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[词型总结]]></title>
    <url>%2F2018%2F12%2F31%2F%E6%97%A5%E8%AF%AD%E5%8F%98%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[本篇主要记载日语常用变形，以便个人查询 词型 词序： 词类：1、独立词:能在句子中单独使用、但需要附属词连接构成句子。2、附属词: 在句子中只能附在独立词后面起一定的语法作用。 体言/二类形容词非过去时：肯定: 私は 学生です/だ否定: 私は 学生では(じゃ)ありません/ では ないです。 过去时：表达过去曾是/不是~肯定:学生でした /だった否定:学生ではなかったです。 ではありませんでした。 形容词一类形容词おもしろい 面白い 敬体非过去时肯定：面白いです否定：おもしろくないです 敬体过去时肯定：おもしろかったです否定：おもしろくなかったです 简体直接去掉です。 二类形容词簡単 敬体非过去时肯定：簡単です否定：簡単ではありません 敬体过去时肯定：簡単でした否定：簡単ではありませんでした 简体非过去时肯定：簡単だ否定：簡単ではない 简体过去时肯定：簡単だった否定：簡単ではなかった 形容词的副词化一类形容词的副词化1: 面白くなりました2: 面白くて 二类形容词的副词化1：簡単にする2：簡単で 动词的分类I类动词 （五段动词）a、词尾是る、倒数第二个假名不在い段或え段（始まる）b、词尾在う段（行く） II类动词 （一段动词）倒数第二个假名在い段（起きる） 或え段（食べる） III类动词カ变动词：来る（只有这一个）サ变动词：a、する（实义动词） b、词干+する：勉强する 词尾是る 动词的敬体I类动词う段变成い段，再接ます：かく ＝＞ かきます II类动词去掉る接ます：みる ＝＞ みます III类动词くる ＝＞ きますする ＝＞ します 动词的て型I类动词① く、ぐ → いて、いで「特例：行く → 行って」 （聞く→ 聞いて） （防ぐ→防いで） ② う、つ、る → って （会う→ 会って） （打つ→打って）（降る→ 降って）③ む、ぶ、ぬ → んで （読む→読んで） （呼ぶ→呼んで）（死ぬ→死んで）④ す →して （探す→探して） II类动词去掉词尾「る」＋て （食べる → 食べて） III类动词来る → 来てする → して 勉強する→勉強して て型用法1、连接两个动词，表示先后/并列/因果关系（句子的时态由后面的动词决定） ✿ 手を洗ってご飯を食べます。 ✿ 町へ行って、服を買いました。2、动词+てから+动词表示先做...再做...（表示先后的动作，强调动作的顺序） ✿ 手を洗ってから、ご飯を食べます。 ✿ 宿題を終わってから、テレビを見ます。3、动词+てもいいです即使...也可以（表示假定条件/让步） ✿ バスで行ってもいいです。 ✿ このケーキを食べてもいい。4、动词+てはいけません 不许做...（轻微命令/禁止） ✿ ここは、写真を撮ってはいけません。 ✿ この本を売ってはいけません。5、动词+ている 表示正在进行的事情/状态 a、表示正在做...（强调正在进行） ✿ 今、雨が降っています。 ✿ 今、ご飯を食べています b、表示动作结果的持续 （强调句子中提到的这个动作正在持续中的一个状态） （一般接一些表示状态变化的动词：開く、行く、来る、帰る、住む、着る「穿戴动词」） ✿ 田中さんは結婚しています。 （表示田中先生现在是一个已婚，结了婚的状态） ✿ あの時、雨が降っていました。 （这里的ている表示的是一种下着雨的状态，而“那个时候”是过去，所以要用过去时态）5、动词+て行く / て来る &lt;主体的移动&gt; a、表示移动性动词动作的方向性。 ✿ 由近及远为ていく(~去)：風船が飛んでいった。 ✿ 由远及近为てくる(~来)：日本から戻ってきた。 b、表示完成V动作后再进行方向性移动，或表示保持某状态进行移动。 ✿ 携帯電話を持って行く。 ✿ 飲み物を買ってくる。 动词的简体否定型I类动词う段变成あ段，再接ない：読む ＝＞ よまない II类动词去掉る接ない：着る ＝＞ きない III类动词くる ＝＞ こないする ＝＞ しない ない型的接续和用法1、动词ない形+ないでください请不要（做某个动作） ✿ 見ないでください。 ✿ 泣かないでください。2、动词ない形+なくてもいい即使不...也不可以 ✿ この薬は飲まなくてもいいです。 ✿ 会社に行かなくてもいいです。3、动词ない形+なければなりません（或なくてはいけない） 一定，必须（比较正式，书面化） ✿ ご飯を食べなければなりません。 ✿ 薬を飲まなければなりません。4、动词ない形+ないといけません 一定，必须（比较口语化） ✿ ご飯を食べないといけません。 ✿ 薬を飲まないといけません。 动词的简体过去式I类动词く、ぐ发生“イ音变”：Vく ＝＞ Vいた； Vぐ ＝＞ Vぃだう、つ、る发生“促音变”：Vう/つ/る ＝＞ Vったぬ、ぶ、む发生“拨音变”：Vぬ/ぶ/む ＝＞ Vんだす不发生音变：Vす ＝＞ Vした特殊动词：行く ＝＞ 行った II类动词直接去掉“る”,然后接“た” III类动词くる ＝＞ きたする ＝＞ した 动词的连体形（体：体言，即名词）连体形的形式1、动词原形+名词：表示现在/即将发生的动作/状态&amp;经常性的动作/状态 電話する人。 話す人。２、动词「た」形（动词过去式）+名词：表示已经发生的动作/状态 服を買った人。 電話をした人。 连体形的接续和用法1、动词连体形+形式体言「こと」（こと一般不翻译） 魚を食べること。 吃鱼（这件事情） 魚を食べることが嫌いです。2、动词连体形+ことができる 会、能（做...） 日本語を喋ることができます。「动词连体形+ことができません 不会、不能（做...）」 日本語を喋ることができません。3、动词连体形+ことがあります表示曾经（做过...） 日本人と話したことがあります。 アメリカに行ったことがあります。4、动词连体形+ほうがいい最好（做...） 水を飲むほうがいいです。 はやく寝たほうがいいです。５、动词连体形（动词原形）+前に＋动词/句子 在做...之前，先做 テレビを見る前に、勉強します。 会社に行く前に、朝ご飯を食べました。６、动词连体形（动词过去式）+後で＋动词/句子 在做了...之后，再做... 勉強した後で、遊びに行きました。 手を洗った後で、お菓子を食べました。 动词的能动态相当于汉语的“能～，会～，可以～”等意 I类动词う段变成え段，再接る：送る ＝＞ 送れる II类动词去掉る接られる：出る ＝＞ 出られる III类动词くる ＝＞ こられるする ＝＞ できる 表示能力的几种方式1、本身具有表示能力的自动词（見える、聞こえる） ✿ 海が見える。2、Ｎができます（できる表示具备某种能力的意思）“能~，会~” ✿ 私はピアノができる。3、Ｎがわかります（わかる表示对人或事物的了解）“明白~，了解~，懂~” ✿ 私は英語はわかりません。 注意：一般用が提示，否定多用「は」4、Vる＋ことができる表示“可能”，表示本身具有某能力做某事。 ✿ 一気に十階まで登ることができます。 动词的意志型表示意志、建议 I类动词う段变成お段，再接う：かく ＝＞ かこう II类动词去掉る接ます：あつめる ＝＞ あつめよう III类动词くる ＝＞ こようする ＝＞ しよう 意志型的使用1、用于第一人称句时，表明说话人的意志； 用于第一、二人称时，表示建议对方做某事。（「Ｖましょう」的简体）2、动词的意志形后接「と思う」构成「Ｖようと思う」句型。 用于表达说话人做某事的决心、打算。“要~，决心~”。 ✿ 僕もそうしよう。 ✿ みんなと一緒に遊ぼうよ。 动词的命令型I类动词う段变成え段，再接う：行く ＝＞ 行け II类动词去掉る接ろ：食べる ＝＞ 食べろ III类动词来る ＝＞ こいする ＝＞ しろ 动词的被动型I类动词う段变成あ段，再接れる：買う → 買われる II类动词去掉る接られる：食べる → 食べられる III类动词来る→ こられる する→ される 动词的使役型I类动词う段变成あ段，再接せる：知る → 知らせる II类动词去掉る接させる：食べる → 食べさせる III类动词来る→ こさせる する→ させる 动词、形容词的条件型相当于汉语的“如果～就～、假如～、要是～”等 I类动词う段变成え段，再接ば：いそぐ ＝＞いそげば II类动词去掉る接れば：おきる ＝＞ おきれば III类动词くる ＝＞ くればする ＝＞ しれば 形容词I类：去掉i加けれ：たかい ＝＞ たかければII类：接なら，再接ば(现代日语中ば大多省略)：げんき ＝＞ げんきなら(ば) 动词的ない型Vない ＝＞ Vなければ 被动态定义：以中心动词的行为者以外的非积极参与者为主语进行描写的句式叫做被动态。多伴有受到危害、损害、伤害之意，但在现代日语中，主体受益、中立（既非受害也非受益）、间接受到影响时也常用被动句式来表示。 I类动词将词尾う段假名 =&gt; あ段假名 + れる 書く =&gt; 書かれる II类动词去掉词尾 る + られる 食べる =&gt; 食べられる III类动词来（く）る =&gt; 来（こ）られる する =&gt; される 使役态I类动词将词尾う段假名 =&gt; あ段假名 + せる 書く 書かせる 読む 読ませる II类动词去掉词尾る =&gt; + させる 見る 見させる 食べる 食べさせる III类动词来る =&gt; 来（こ）させるする させる支援する 支援させる 使动被动态I类动词把结尾う段假名，变あ段 ＋せられる ＋される 書く→書かせられる / 書かされる II类动词去掉结尾的る ＋させられる 見る→見させられる 起きる→起きさせられる III类动词来る こさせられる する させられる 勉強させられる 命令形I类动词う段 → え段書く 書け行く 行け II类动词去る ＋ ①ろ ②よ＜书面语＞食べる 食べろ 食べよ見る 見ろ 見よ III类动词来る → 来いする → ①しろ ②せよ＜书面语＞勉強する → 勉強しろ 勉強せよ 特殊： 信じる 愛しろ（ｘ）]]></content>
      <categories>
        <category>日语</category>
      </categories>
      <tags>
        <tag>词型变换</tag>
      </tags>
  </entry>
</search>
